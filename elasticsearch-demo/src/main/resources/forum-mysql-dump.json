{"_id":"6211","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545268463","category_id":"14","comments":"10","has_attach":"1","id":"6211","message":"让Elasticsearch飞起来!——性能优化实践干货\r\n\r\n# 0、题记\r\nElasticsearch性能优化的最终目的：用户体验```爽```。\r\n关于爽的定义——著名产品人梁宁曾经说过“人在满足时候的状态叫做愉悦，人不被满足就会难受，就会开始寻求。如果这个人在寻求中，能立刻得到即时满足，这种感觉就是爽！”。\r\nElasticsearch的爽点就是：```快、准、全```!\r\n关于Elasticsearch性能优化，阿里、腾讯、京东、携程、滴滴、58等都有过很多深入的实践总结，都是非常好的参考。本文换一个思路，基于Elasticsearch的```爽点```，进行性能优化相关探讨。\r\n\r\n# 1、集群规划优化实践\r\n## 1.1 基于目标数据量规划集群\r\n在业务初期，经常被问到的问题，要几个节点的集群，内存、CPU要多大，要不要SSD？\r\n最主要的考虑点是：你的```目标存储数据量```是多大？可以针对目标数据量反推节点多少。\r\n\r\n## 1.2 要留出容量Buffer\r\n注意：Elasticsearch有三个警戒水位线，磁盘使用率达到85%、90%、95%。\r\n不同警戒水位线会有不同的应急处理策略。\r\n这点，磁盘容量选型中要规划在内。控制在```85%之下```是合理的。\r\n当然，也可以通过配置做调整。\r\n\r\n## 1.3 ES集群各节点尽量不要和其他业务功能复用一台机器。\r\n除非内存非常大。\r\n举例：普通服务器，安装了ES+Mysql+redis，业务数据量大了之后，势必会出现内存不足等问题。\r\n\r\n## 1.4 磁盘尽量选择SSD\r\nElasticsearch官方文档肯定```推荐SSD```，考虑到成本的原因。需要结合业务场景，\r\n如果业务对写入、检索速率有较高的速率要求，建议使用SSD磁盘。\r\n阿里的业务场景，SSD磁盘比机械硬盘的速率提升了5倍。\r\n但要因业务场景而异。\r\n\r\n## 1.5 内存配置要合理\r\n官方建议：堆内存的大小是官方建议是：Min（32GB，机器内存大小/2）。\r\nMedcl和wood大叔都有明确说过，不必要设置32/31GB那么大，建议：```热数据设置：26GB，冷数据：31GB```。\r\n总体内存大小没有具体要求，但肯定是内容越大，检索性能越好。\r\n经验值供参考：每天200GB+增量数据的业务场景，服务器至少要64GB内存。\r\n除了JVM之外的预留内存要充足，否则也会经常OOM。\r\n\r\n## 1.6 CPU核数不要太小\r\nCPU核数是和ESThread pool关联的。和写入、检索性能都有关联。\r\n建议：```16核+```。\r\n\r\n## 1.7 超大量级的业务场景，可以考虑跨集群检索\r\n除非业务量级非常大，例如：滴滴、携程的PB+的业务场景，否则基本不太需要跨集群检索。\r\n\r\n## 1.8 集群节点个数无需奇数\r\nES内部维护集群通信，不是基于zookeeper的分发部署机制，所以，```无需奇数```。\r\n但是discovery.zen.minimum_master_nodes的值要设置为：候选主节点的个数/2+1，才能有效避免脑裂。\r\n\r\n## 1.9 节点类型优化分配\r\n集群节点数：\u0026lt;=3，建议：所有节点的master：true， data：true。既是主节点也是路由节点。\r\n集群节点数：\u0026gt;3, 根据业务场景需要，建议：逐步独立出Master节点和协调/路由节点。\r\n\r\n## 1.10 建议冷热数据分离\r\n```热数据存储SSD```和普通历史数据存储机械磁盘，物理上提高检索效率。\r\n\r\n# 2、索引优化实践\r\nMysql等关系型数据库要分库、分表。Elasticserach的话也要做好充分的考虑。\r\n## 2.1 设置多少个索引？\r\n建议根据业务场景进行存储。\r\n不同通道类型的数据要```分索引存储```。举例：知乎采集信息存储到知乎索引；APP采集信息存储到APP索引。\r\n\r\n## 2.2 设置多少分片？\r\n建议根据数据量衡量。\r\n经验值：建议每个分片大小```不要超过30GB```。\r\n\r\n## 2.3 分片数设置？\r\n建议根据集群节点的个数规模，分片个数建议\u0026gt;=集群节点的个数。\r\n5节点的集群，5个分片就比较合理。\r\n注意：除非reindex操作，```分片数是不可以修改```的。\r\n\r\n## 2.4副本数设置？\r\n除非你对系统的健壮性有异常高的要求，比如：银行系统。可以考虑2个副本以上。\r\n否则，1个副本足够。\r\n注意：```副本数是可以通过配置随时修改```的。\r\n\r\n## 2.5不要再在一个索引下创建多个type\r\n即便你是5.X版本，考虑到未来版本升级等后续的可扩展性。\r\n建议：一个索引对应一个type。6.x默认对应_doc，5.x你就直接对应type统一为doc。\r\n\r\n## 2.6 按照日期规划索引\r\n随着业务量的增加，单一索引和数据量激增给的矛盾凸显。\r\n按照日期规划索引是必然选择。\r\n好处1：可以实现历史数据秒删。很对历史索引delete即可。注意：一个索引的话需要借助delete_by_query+force_merge操作，慢且删除不彻底。\r\n好处2：便于冷热数据分开管理，检索最近几天的数据，直接物理上指定对应日期的索引，速度快的一逼！\r\n操作参考：```模板使用+rollover API使用```。\r\n\r\n## 2.7 务必使用别名\r\nES不像mysql方面的更改索引名称。使用别名就是一个相对灵活的选择。\r\n\r\n# 3、数据模型优化实践\r\n## 3.1 不要使用默认的Mapping\r\n默认Mapping的字段类型是系统```自动识别```的。其中：string类型默认分成：text和keyword两种类型。如果你的业务中不需要分词、检索，仅需要精确匹配，仅设置为keyword即可。\r\n根据业务需要选择合适的类型，有利于节省空间和提升精度，如：浮点型的选择。\r\n\r\n## 3.2 Mapping各字段的选型流程\r\n[attach]3334[/attach]\r\n\r\n\r\n\r\n## 3.3 选择合理的分词器\r\n常见的开源中文分词器包括：ik分词器、ansj分词器、hanlp分词器、结巴分词器、海量分词器、“ElasticSearch最全分词器比较及使用方法” 搜索可查看对比效果。\r\n如果选择ik，建议使用ik_max_word。因为：粗粒度的分词结果基本包含细粒度ik_smart的结果。\r\n\r\n## 3.4 date、long、还是keyword\r\n根据业务需要，如果需要基于时间轴做分析，必须date类型；\r\n如果仅需要秒级返回，建议使用```keyword```。\r\n\r\n# 4、数据写入优化实践\r\n## 4.1 要不要秒级响应？\r\nElasticsearch近实时的本质是：最快1s写入的数据可以被查询到。\r\n如果```refresh_interval```设置为1s，势必会产生大量的segment，检索性能会受到影响。\r\n所以，非实时的场景可以调大，设置为30s，甚至-1。\r\n\r\n## 4.2 减少副本，提升写入性能。\r\n写入前，副本数设置为0，\r\n写入后，副本数设置为原来值。\r\n\r\n## 4.3 能批量就不单条写入\r\n批量接口为bulk，批量的大小要结合队列的大小，而队列大小和线程池大小、机器的cpu核数。\r\n\r\n## 4.4 禁用swap\r\n在Linux系统上，通过运行以下命令临时禁用交换：\r\n\r\n    sudo swapoff -a\r\n\r\n# 5、检索聚合优化实战\r\n## 5.1 禁用 wildcard模糊匹配\r\n数据量级达到TB+甚至更高之后，wildcard在多字段组合的情况下很容易出现卡死，甚至导致集群节点```崩溃宕机```的情况。\r\n后果不堪设想。\r\n替代方案：\r\n方案一：针对精确度要求高的方案:两套分词器结合，standard和ik结合，使用match_phrase检索。\r\n方案二：针对精确度要求不高的替代方案：建议ik分词，通过match_phrase和slop结合查询。\r\n\r\n## 5.2极小的概率使用match匹配\r\n```中文match匹配显然结果是不准确```的。很大的业务场景会使用短语匹配“match_phrase\u0026quot;。\r\nmatch_phrase结合合理的分词词典、词库，会使得搜索结果精确度更高，避免噪音数据。\r\n\r\n## 5.3 结合业务场景，大量使用filter过滤器\r\n对于不需要使用计算相关度评分的场景，无疑```filter缓存机制```会使得检索更快。\r\n举例：过滤某邮编号码。\r\n\r\n## 5.3控制返回字段和结果\r\n和mysql查询一样，业务开发中，select * 操作几乎是不必须的。\r\n同理，ES中，_source 返回全部字段也是非必须的。\r\n要通过```_source 控制字段```的返回，只返回业务相关的字段。\r\n网页正文content，网页快照html_content类似字段的批量返回，可能就是业务上的设计缺陷。\r\n显然，摘要字段应该提前写入，而不是查询content后再截取处理。\r\n\r\n## 5.4 分页深度查询和遍历\r\n分页查询使用：from+size;\r\n遍历使用：scroll；\r\n并行遍历使用：```scroll+slice```。\r\n斟酌集合业务选型使用。\r\n\r\n## 5.5 聚合Size的合理设置\r\n聚合结果是不精确的。除非你设置size为2的32次幂-1，否则聚合的结果是取每个分片的Top size元素后综合排序后的值。\r\n实际业务场景要求精确反馈结果的要注意。\r\n```尽量不要获取全量聚合结果```——从业务层面取TopN聚合结果值是非常合理的。因为的确排序靠后的结果值意义不大。\r\n\r\n## 5.6 聚合分页合理实现\r\n聚合结果展示的时，势必面临聚合后分页的问题，而ES官方基于性能原因不支持聚合后分页。\r\n如果需要```聚合后分页```，需要自开发实现。包含但不限于：\r\n方案一：每次取聚合结果，拿到内存中分页返回。\r\n方案二：scroll结合scroll after集合redis实现。\r\n\r\n# 6、业务优化\r\n让Elasticsearch做它擅长的事情，很显然，它更擅长基于倒排索引进行搜索。\r\n业务层面，用户想最快速度看到自己想要的结果，中间的“字段处理、格式化、标准化”等一堆操作，用户是不关注的。\r\n为了让Elasticsearch更高效的检索，建议：\r\n1）要做足“前戏”\r\n字段抽取、倾向性分析、分类/聚类、相关性判定放在写入ES之前的ETL阶段进行；\r\n2）“睡服”产品经理\r\n产品经理基于各种奇葩业务场景可能会提各种无理需求。\r\n作为技术人员，要“通知以情晓之以理”，给产品经理讲解明白搜索引擎的原理、Elasticsearch的原理，哪些能做，哪些真的“```臣妾做不到```”。\r\n\r\n# 7、小结\r\n实际业务开发中，公司一般要求又想```马儿不吃草，又想马儿飞快跑```。\r\n对于Elasticsearch开发也是，硬件资源不足（cpu、内存、磁盘都爆满）几乎没有办法提升性能的。\r\n除了检索聚合，让Elasticsearch做N多相关、不相干的工作，然后得出结论“Elastic也就那样慢，没有想像的快”。\r\n你脑海中是否也有类似的场景浮现呢？\r\n提供相对NB的硬件资源、做好前期的各种准备工作、让Elasticsearch```轻装上阵```，相信你的Elasticsearch也会飞起来！\r\n\r\n来日我们再相会......\r\n\r\n推荐阅读：\r\n1、阿里：https://elasticsearch.cn/article/6171\r\n2、滴滴：http://t.cn/EUNLkNU\r\n3、腾讯：http://t.cn/E4y9ylL\r\n4、携程：https://elasticsearch.cn/article/6205\r\n5、社区：https://elasticsearch.cn/article/6202\r\n6、社区：https://elasticsearch.cn/article/708\r\n7、社区：https://elasticsearch.cn/article/6202\r\n\r\n\r\n[attach]3335[/attach]\r\n\r\nElasticsearch基础、进阶、实战第一公众号","title":"Day 20 - Elastic性能实战指南 ","uid":"1341","views":"569","votes":"7"},"_type":"doc"}
{"_id":"6199","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544841333","category_id":"2","comments":"0","has_attach":"0","id":"6199","message":"## 介绍\n\n本次想和大家分享一款Elasticsearch分词插件，该插件是基于天津海量信息股份有限公司的中文分词核心开发的。海量分词针对大数据检索场景专门做了定制和优化，更贴近搜索需求，整体分词的性能也是非常高效。\n\n本文章有广告成分。但希望将公司研究成果分享出来，给大家实际工作中多一种选择...\n\n## 海量分词检索优化点\n\n- 地名方面海量分词5.0可以识别并**检索出关于地名后缀**的结果\n\n  可以通过搜索“河南”得到“河南省”的结果，搜索“天津”得到“天津市”的搜索结果，而不是简单河南、天津的识别。\n\n- 著名人物的**人名识别更精准**，如刘翔、傅莹等\n\n  部分分词器处理中文分词只有两种方式：一种是单字（unigrams）形式，即简单粗暴的将中文的每一个汉字作为一个词（token）分开；另一种是两字（bigrams）的，也就是任意相邻的两个汉字作为一个词分开。这种简单粗暴的切分方式无法实现时效性较新的人名识别，如刘翔、傅莹等会被识别为单字切开。\n\n- **外国人名识别**方面海量可以将人名识别智能识别\n\n  “玛利亚 凯利”、“乔治·史密斯”、“玛丽·戴维斯”将完整的外国人名识别出姓氏和名，如“乔治·史密斯”可以被识别为“乔治”和 “史密斯”。\n\n- 常见词的**品牌名称**识别方面，海量分词5.0识别的结果中包含实际意义的品牌名称\n\n  如“乐高”，“吉米作为简单的词，可以被识别，但是词放在文档语境中有其品牌的属性，海量分词识别的结果中可以准确搜索出品牌的结果。\n\n- **机构名识别**方面\n\n  海量分词5.0可以识别完整的机构名称，如“天津海量信息技术股份有限公司”，可以完整的识别出全称。\n\n## 海量分词性能评测\n\n### 评测用例\n\n本次评测选取的语料一共三个。一个是2MB的海量测试语料，一个是4MB的北大语料（新版旧版各2MB），一个是9.4GB海量的线上实际数据\n\n### 评测指标\n\n本次评测是在开源评测程序上修改而来，评测指标有分词速度、行数完美率、字数完美率（该指标仅供参考）、内存消耗\n\n### 评测结果\n\n#### 2MB海量测试语料\n\n| 分词器      | 分词模式     | 分词速度（字符/毫秒） | 行数完美率  | 字数完美率  | 占用内存（MB） |\n| -------- | -------- | ----------- | ------ | ------ | -------- |\n| 海量       | /        | 1049.0212   | 74.11% | 65.97% | 85       |\n| ltp      | /        | 33.748833   | 55.68% | 45.23% | 201      |\n| IctClass | 普通分词     | 208.69612   | 48.77% | 37.10% | 51       |\n| IctClass | 细粒度分词    | 691.5951    | 38.33% | 27.95% | 51       |\n| Jieba    | SEARCH分词 | 592.697     | 47.64% | 36.25% | 236      |\n| FudanNLP | /        | 121.7537    | 42.99% | 31.59% | 99       |\n| HanLP    | 标准分词     | 212.74121   | 45.30% | 34.00% | 63       |\n| HanLP    | NLP分词    | 378.23676   | 44.09% | 32.55% | 71       |\n| HanLP    | N-最短路径分词 | 189.29959   | 44.19% | 32.22% | 60       |\n| HanLP    | 最短路径分词   | 415.63605   | 43.19% | 31.28% | 59       |\n| HanLP    | 极速词典分词   | 6735.1934   | 36.78% | 25.10% | 18       |\n| THULAC   | /        | 0.20857348  | 54.49% | 43.79% | 110      |\n| Stanford | CTB      | 0.13520464  | 44.43% | 33.25% | 1101     |\n| Stanford | PKU      | 0.12508623  | 45.15% | 34.01% | 1065     |\n\n可以看到海量分词的行数完美率是最高的，而且速度十分优异；仅有的一个比海量分词速度快的算法是一个追求极限性能舍弃准确率的算法\n\n#### 4MB北大语料\n\n| 词器       | 分词模式     | 分词速度（字符/毫秒） | 行数完美率  | 字数完美率  | 占用内存（MB） |\n| -------- | -------- | ----------- | ------ | ------ | -------- |\n| 海量       | /        | 1121.7269   | 85.94% | 48.28% | 85       |\n| ltp      | /        | 35.81329    | 87.37% | 49.37% | 201      |\n| IctClass | 普通分词     | 226.11554   | 78.55% | 42.04% | 51       |\n| IctClass | 细粒度分词    | 756.5135    | 59.06% | 30.61% | 51       |\n| Jieba    | SEARCH分词 | 957.52826   | 47.07% | 20.01% | 236      |\n| FudanNLP | /        | 126.09879   | 58.54% | 27.78% | 99       |\n| HanLP    | 标准分词     | 369.66      | 65.46% | 35.04% | 63       |\n| HanLP    | NLP分词    | 439.75632   | 61.93% | 31.37% | 71       |\n| HanLP    | N-最短路径分词 | 223.30482   | 69.20% | 35.07% | 60       |\n| HanLP    | 最短路径分词   | 440.72244   | 67.74% | 33.83% | 59       |\n| HanLP    | 极速词典分词   | 7522.581    | 58.09% | 27.82% | 18       |\n\n（注：THULAC和stanford由于速度问题，不纳入评测）\n\n可以看到海量的速度和行数完美率都很优异而且达到了兼顾，行数完美率只落后更高的ltp算法1.4个百分点，速度却是它的三十多倍\n\n#### 9.4GB线上数据\n\n| 分词器      | 分词模式     | 分词速度（字符/毫秒） |\n| -------- | -------- | ----------- |\n| ltp      | /        | 33.592      |\n| 海量       | /        | 960.611     |\n| IctClass | 普通分词     | 198.094     |\n| HanLP    | N-最短路径分词 | 201.735     |\n| HanLP    | 最短路径分词   | 425.482     |\n| HanLP    | 标准分词     | 473.400     |\n| HanLP    | NLP分词    | 361.842     |\n| IctClass | 细粒度分词    | 689.183     |\n| FudanNLP | /        | 120.860     |\n| HanLP    | 极速词典分词   | 6238.916    |\n| Jieba    | SEARCH分词 | 568.262     |\n\n（注：THULAC和stanford由于速度问题，不纳入评测）\n\n本表格中分词顺序按（4MB北大语料的）行数完美率进行排序，越靠前的（4MB北大语料的）行数完美率越高\n\n可以看出海量的分词速度十分优秀，分词速度拉开了大多数分词数倍，相比于行数完美率小幅领先的ltp要快几十倍\n\n## 海量分词插件使用方法\n\n### 安装使用\n\n* 下载安装 - 地址: https://github.com/HylandaOpen/elasticsearch-analysis-hlseg/releases \n\n  ```\n  unzip plugin to folder `your-es-root/plugins/`\n  ```\n\n* 使用 elasticsearch-plugin 安装\n\n  ```\n  ./bin/elasticsearch-plugin install https://github.com/HylandaOpen/elasticsearch-analysis-hlseg/releases/download/v6.4.2/elasticsearch-analysis-hlseg-6.4.2.zip\n  ```\n\n* 重启es集群\n\n#### 实例（借用github-ik分词插件的实例）\n\n1.创建index\n\n```bash\ncurl -XPUT http://localhost:9200/hylanda_seg\n```\n\n2.配置mapping\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/_mapping -H 'Content-Type:application/json' -d'\n{\n  \u0026quot;properties\u0026quot;: {\n    \u0026quot;msg\u0026quot;: {\n      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n      \u0026quot;analyzer\u0026quot;: \u0026quot;hlseg_search\u0026quot;\n    }\n  }\n}'\n```\n\n3.插入测试数据\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/1 -H 'Content-Type:application/json' -d'\n{\u0026quot;content\u0026quot;:\u0026quot;美国留给伊拉克的是个烂摊子吗\u0026quot;}\n'\n```\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/2 -H 'Content-Type:application/json' -d'\n{\u0026quot;content\u0026quot;:\u0026quot;公安部：各地校车将享最高路权\u0026quot;}\n'\n```\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/3 -H 'Content-Type:application/json' -d'\n{\u0026quot;content\u0026quot;:\u0026quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船\u0026quot;}\n'\n```\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/4 -H 'Content-Type:application/json' -d'\n{\u0026quot;content\u0026quot;:\u0026quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首\u0026quot;}\n'\n```\n\n4.查询\n\n```bash\ncurl -XPOST http://localhost:9200/hylanda_seg/data/_search  -H 'Content-Type:application/json' -d'\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;content\u0026quot;: \u0026quot;中国\u0026quot;\n    }\n  },\n  \u0026quot;highlight\u0026quot;: {\n    \u0026quot;fields\u0026quot;: {\n      \u0026quot;content\u0026quot;: {}\n    }\n  }\n}\n'\n```\n\n返回结果\n\n```json\n{\n  \u0026quot;took\u0026quot; : 11,\n  \u0026quot;timed_out\u0026quot; : false,\n  \u0026quot;_shards\u0026quot; : {\n    \u0026quot;total\u0026quot; : 5,\n    \u0026quot;successful\u0026quot; : 5,\n    \u0026quot;skipped\u0026quot; : 0,\n    \u0026quot;failed\u0026quot; : 0\n  },\n  \u0026quot;hits\u0026quot; : {\n    \u0026quot;total\u0026quot; : 2,\n    \u0026quot;max_score\u0026quot; : 0.5754429,\n    \u0026quot;hits\u0026quot; : [\n      {\n        \u0026quot;_index\u0026quot; : \u0026quot;hylanda_seg\u0026quot;,\n        \u0026quot;_type\u0026quot; : \u0026quot;data\u0026quot;,\n        \u0026quot;_id\u0026quot; : \u0026quot;4\u0026quot;,\n        \u0026quot;_score\u0026quot; : 0.5754429,\n        \u0026quot;_source\u0026quot; : {\n          \u0026quot;content\u0026quot; : \u0026quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船\u0026quot;\n        },\n        \u0026quot;highlight\u0026quot; : {\n          \u0026quot;content\u0026quot; : [\n            \u0026quot;中韩渔警冲突调查：韩警平均每天扣1艘\u0026lt;em\u0026gt;中国\u0026lt;/em\u0026gt;渔船\u0026quot;\n          ]\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot; : \u0026quot;hylanda_seg\u0026quot;,\n        \u0026quot;_type\u0026quot; : \u0026quot;data\u0026quot;,\n        \u0026quot;_id\u0026quot; : \u0026quot;5\u0026quot;,\n        \u0026quot;_score\u0026quot; : 0.2876821,\n        \u0026quot;_source\u0026quot; : {\n          \u0026quot;content\u0026quot; : \u0026quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首\u0026quot;\n        },\n        \u0026quot;highlight\u0026quot; : {\n          \u0026quot;content\u0026quot; : [\n            \u0026quot;\u0026lt;em\u0026gt;中国\u0026lt;/em\u0026gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首\u0026quot;\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n#### 字典配置\n\n```\n海量分词分为基础词词典CoreDict.dat和自定义词典userDict_utf8.txt。基础词词典在dictionary目录下，需要将CoreDict.zip解压后放在config目录下，可以通过修改config下的userDict_utf8.txt来更新自定义词典\n```\n\n自定义词典格式如下\n\n---\n\n```\n1.用户自定义词典采用文本格式，utf-8编码，每行一个词\n\n2.每个词包含三列属性，分别是词串、词的属性以及idf值的加权等级，并以Tab作为分隔，其中除了词串必填外，其他列可以不填，不填写则系统采用默认值\n\n3.“#”表示注释，会在加载时被忽略\n\n4.词的属性以西文逗号分隔，可以是词性、停止词标志或者自定义属性\n\n5.词性标记参考北大标准，用于词性标注时参考，该项不填则默认为名词\n\n6.停止词标志为：stopword，由SegOption.outputStopWord来控制是否输出停止词\n\n7.自定义属性不参与分词过程，分词结果中若Token.userTag不为空，则可以获取到该词的自定义属性。\n\n8.idf值的加权分5级，从低到高的定义是idf-lv1 — idf-lv5，等级越高则该词在关键词计算时的权重会越大，若不填写该值则系统默认是idf-lv3(中等权重）\n```\n","title":"Day 15 - 基于海量公司分词ES中文分词插件","uid":"1609","views":"550","votes":"3"},"_type":"doc"}
{"_id":"6194","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544664851","category_id":"14","comments":"3","has_attach":"1","id":"6194","message":"# ES-Hadoop打通Elasticsearch和Hadoop\n\n## 介绍\n\nElasticsearch作为强大的搜索引擎，Hadoop HDFS是分布式文件系统。\n\nES-Hadoop是一个深度集成Hadoop和ElasticSearch的项目，也是ES官方来维护的一个子项目。Elasticsearch可以将自身的Document导入到HDFS中用作备份；同时也可以将存储在HDFS上的结构化文件导入为ES中的Document，通过实现Hadoop和ES之间的输入输出，可以在Hadoop里面对ES集群的数据进行读取和写入，充分发挥Map-Reduce并行处理的优势，为Hadoop数据带来实时搜索的可能。 \n\nES-Hadoop插件支持Map-Reduce、Cascading、Hive、Pig、Spark、Storm、yarn等组件。\n\nES-Hadoop整个数据流转图如下：\n\n\n[attach]3275[/attach]\n\n\n## 环境配置\n\n* Elasticsearch 5.0.2\n* Centos 7\n* elasticsearch-hadoop 5.0.2\n* repository-hdfs-5.0.2\n\n## Elasticsearch备份数据到HDFS\n\n### 介绍\n\nElasticsearch副本提供了数据高可靠性，在部分节点丢失的情况下不中断服务；但是副本并不提供对灾难性故障的保护，同时在运维人员误操作情况下也不能保障数据的可恢复性。对于这种情况，我们需要对Elasticsearch集群数据的真正备份。\n\n通过快照的方式，将Elasticsearch集群中的数据备份到HDFS上，这样数据既存在于Elasticsearch集群中，有存在于HDFS上。当ES集群出现不可恢复的故障时，可以将数据从HDFS上快速恢复。\n\n### 操作步骤\n\n* 下载插件 \u0026lt;https://artifacts.elastic.co/downloads/elasticsearch-plugins/repository-hdfs/repository-hdfs-5.0.2.zip\u0026gt;   保存在/usr/local下\n\n* 安装插件 \n\n  ```\n  cd /usr/local/es/elasticsearch-5.0.2/bin\n  ./elasticsearch-plugin install file:///usr/local/repository-hdfs-5.0.2.zip\n  ```\n\n* 安装成功后需要重启Elasticsearch\n\n### 备份与恢复\n\n* 构建一个仓库\n\n  ```\n  PUT http://192.168.10.74:9200/_snapshot/backup\n  {  \n    \u0026quot;type\u0026quot;: \u0026quot;hdfs\u0026quot;,  \n      \u0026quot;settings\u0026quot;: {  \n              \u0026quot;uri\u0026quot;: \u0026quot;hdfs://192.168.10.170:9000\u0026quot;,  \n              \u0026quot;path\u0026quot;: \u0026quot;/es\u0026quot;,  \n              \u0026quot;conf_location\u0026quot;: \u0026quot;/usr/local/hadoop/etc/hadoop/hdfs-site.xml\u0026quot;  \n      }\n  }\n  ```\n\n* 备份快照\n\n  ```\n  PUT http://192.168.10.74:9200/_snapshot/backup/snapshot_users?wait_for_completion=true\n  {\n    \u0026quot;indices\u0026quot;: \u0026quot;users\u0026quot;,  //备份users的index，注意不设置这个属性，默认是备份所有index\n    \u0026quot;ignore_unavailable\u0026quot;: true,\n    \u0026quot;include_global_state\u0026quot;: false\n  }\n  ```\n\n* 恢复快照\n\n  ```\n  POST http://192.168.10.74:9200/_snapshot/backup/snapshot_users/_restore\n  {\n    \u0026quot;indices\u0026quot;: \u0026quot;users\u0026quot;,    //指定索引恢复，不指定就是所有\n    \u0026quot;ignore_unavailable\u0026quot;: true,     //忽略恢复时异常索引\n    \u0026quot;include_global_state\u0026quot;: false    //是否存储全局转态信息,fasle代表有一个或几个失败，不会导致整个任务失败\n  }\n  ```\n\n\n## 整合Spark与Elasticsearch\n\n### 整体思路\n\n* 数据首先存储在HDFS上，可以通过Spark SQL直接导入到ES中\n* Spark SQL可以直接通过建立Dataframe或者临时表连接ES，达到搜索优化、减少数据量和数据筛选的目的，此时数据只在ES内存中而不再Spark SQL中\n* 筛选后的数据重新导入到Spark SQL中进行查询\n\n### 引入依赖\n\n```java\n\u0026lt;dependency\u0026gt;\n    \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt;\n    \u0026lt;artifactId\u0026gt;elasticsearch-hadoop\u0026lt;/artifactId\u0026gt;\n    \u0026lt;version\u0026gt;5.0.2\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n```\n\n\n\n### 具体流程\n\n* 数据在HDFS上，数据存储在HDFS的每个DataNode的block上\n\n\n[attach]3276[/attach]\n\n\n* 数据加载到Spark SQL\n\n  * 数据从HDFS加载到Spark SQL中，以RDD形式存储\n\n    ```java\n    JavaRDD\u0026lt;String\u0026gt; textFile = spark.read().textFile(\u0026quot;hdfs://192.168.10.170:9000/csv/user.csv\u0026quot;)\n    ```\n\n  * 添加数据结构信息转换为新的RDD\n\n    ```java\n    JavaRDD\u0026lt;UserItem\u0026gt; dataSplits = textFile.map(line -\u0026gt; {\n        String records = line.toString().trim();\n        String record = records.substring(0,records.length() - 1).trim();\n        String[] parts = record.split(\u0026quot;\\\\|\u0026quot;);\n        UserItem u = new UserItem();\n        u.setName(parts[0]);\n        u.setAge(parts[1]);\n        u.setHeight(parts[2]);\n        return u;\n    });\n    ```\n\n  * 根据新的RDD创建DataFrame\n\n    ```java\n    DataSet\u0026lt;Row\u0026gt; ds = spark.createDataFrame(dataSplits, UserItem.class);\n    ```\n\n  \n[attach]3277[/attach]\n\n\n  * 由Dataset\u0026lt;Row\u0026gt;创建索引，并写入ES\n\n    ```\n    JavaEsSparkSQL.saveToEs(ds, \u0026quot;es_spark/users\u0026quot;);\n    ```\n\n* 数据在ES中建立索引\n\n\n[attach]3278[/attach]\n\n\n* Spark SQL通过索引对ES中的数据进行查询\n\n  ```java\n  SparkSession spark = SparkSession.builder().appName(\u0026quot;es-spark\u0026quot;).master(\u0026quot;local\u0026quot;).config(\u0026quot;es.index.auto.create\u0026quot;, true).getOrCreate();\n  Map\u0026lt;String, String\u0026gt; options = new HashMap\u0026lt;\u0026gt;();\n  options.put(\u0026quot;pushdown\u0026quot;, \u0026quot;true\u0026quot;);\n  options.put(\u0026quot;es.nodes\u0026quot;,\u0026quot;192.168.10.74:9200\u0026quot;);\n  \n  Dataset\u0026lt;Row\u0026gt; df = spark.read().options(options).format(\u0026quot;org.elasticsearch.spark.sql\u0026quot;).load(\u0026quot;es_spark/users\u0026quot;);\n  df.createOrReplaceTempView(\u0026quot;users\u0026quot;);\n  \n  Dataset\u0026lt;Row\u0026gt; userSet = spark.sql(\u0026quot;SELECT name FORM users WHERE age \u0026gt;=10 AND age \u0026lt;= 20\u0026quot;);\n  userSet.show();\n  ```\n\n## 结束\n\nES-Hadoop无缝打通了ES和Hadoop两个非常优秀的框架，从而让ES的强大检索性能帮助我们快速分析海量数据。","title":"Day 13 - Elasticsearch-Hadoop打通Elasticsearch和Hadoop","uid":"1912","views":"408","votes":"2"},"_type":"doc"}
{"_id":"6192","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544609847","category_id":"3","comments":"2","has_attach":"1","id":"6192","message":"为什么我的数据中没有updateTime 和 createTime 字段的；  理论上是不会执行if 里面的代码才对的；  但是为什么看日志输出好像是执行了if代码块的代码呢 \n \n下面的是数据源， 并没有time字段的\n[code]{\n  \u0026quot;仓ku\u0026quot;: \u0026quot;华南\u0026quot;,\n   \u0026quot;originName\u0026quot;:  \u0026quot;\u0026quot;,\n   \u0026quot;Code\u0026quot;:  \u0026quot;23248\u0026quot;,\n   \u0026quot;BrandName\u0026quot;:  \u0026quot;\u0026quot;,\n   \u0026quot;originCode\u0026quot;:  null,\n   \u0026quot;CategoryName\u0026quot;:  \u0026quot;原厂\u0026quot;\n}[/code]","title":"logstash filter如何判断字段是够为空或者null","uid":"9895","views":"283","votes":"0"},"_type":"doc"}
{"_id":"6191","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544603705","category_id":"14","comments":"0","has_attach":"0","id":"6191","message":"## 1. 背景\n\nElasticsearch可广泛应用于日志分析、全文检索、结构化数据分析等多种场景，大幅度降低维护多套专用系统的成本，在开源社区非常受欢迎。然而Elasticsearch为满足多种不同的使用场景，底层组合使用了多种数据结构，部分数据结构对具体的用户使用场景可能是冗余的，从而导致默认情况下无法达到性能和成本最优化。\n幸运的是，Elasticsearch提供非常灵活的模板配置能力，用户可以按需进行优化。多数情况下，用户结合使用场景进行优化后，Elasticsearch的性能都会有数倍的提升，成本也对应有倍数级别的下降。本文主要介绍不同日志使用场景下的调优经验。\n\n## 2. 日志处理基本流程\n日志处理的基本流程包含：日志采集 -\u0026gt; 数据清洗 -\u0026gt; 存储 -\u0026gt; 可视化分析。Elastic Stack提供完整的日志解决方案，帮助用户完成对日志处理全链路的管理，推荐大家使用。每个流程的处理如下：\n\n- 日志采集：从业务所在的机器上，较实时的采集日志传递给下游。常用开源组件如Beats、Logstash、Fluentd等。\n- 数据清洗：利用正则解析等机制，完成日志从文本数据到结构化数据的转换。用户可使用Logstash 或 Elasticsearch Ingest模块等完成数据清洗。\n- 存储：使用Elasticsearch对数据进行持久存储，并提供全文搜索和分析能力。\n- 可视化分析：通过图形界面，完成对日志的搜索分析，常用的开源组件如Kibana、Grafana。\n![](http://km.oa.com/files/photos/pictures//20181210//1544431419_97.png)\n\n使用Elastic Stack处理日志的详细过程，用户可参考官方文章[Getting started with the Elastic Stack](https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-elastic-stack.html)，这里不展开介绍。\n\n\n## 3. 日志场景调优\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;对于Elasticsearch的通用调优，之前分享的文章[Elasticsearch调优实践](https://cloud.tencent.com/developer/article/1156231)，详细介绍了Elasticsearch在性能、稳定性方面的调优经验。而对于日志场景，不同的场景使用方式差别较大，这里主要介绍常见使用方式下，性能和成本的优化思路。\n\n### 3.1 基础场景\n对于多数简单日志使用场景，用户一般只要求存储原始日志，并提供按关键字搜索日志记录的能力。对于此类场景，用户可跳过数据清洗阶段，并参考如下方式进行优化：\n\n- 建议打开最优压缩，一般可降低40%存储。\n- 设置原始日志字段（message）为text，去除keyword类型子字段，提供全文搜索能力，降低存储。\n- 关闭_all索引，前面已通过message提供全文搜索能力。\n- 对于其他字符串字段，统一设置为keyword类型，避免默认情况下字符串字段同时存储text、keyword两种类型的数据。\n- 使用开源组件（如Beats）上报数据时会包含较多辅助信息，用户可通过修改组件配置文件进行裁剪。\n\n这样去除message的keyword子字段、_all等冗余信息后，再加上最优压缩，可以保证数据相对精简。下面给出这类场景的常用模板，供用户参考：\n``` \n{\n\t\u0026quot;order\u0026quot;: 5,\n\t\u0026quot;template\u0026quot;: \u0026quot;my_log_*\u0026quot;,\n\t\u0026quot;settings\u0026quot;: {\n\t\t\u0026quot;translog.durability\u0026quot;: \u0026quot;async\u0026quot;,\n\t\t\u0026quot;translog.sync_interval\u0026quot;: \u0026quot;5s\u0026quot;,\n\t\t\u0026quot;index.refresh_interval\u0026quot;: \u0026quot;30s\u0026quot;,\n\t\t\u0026quot;index.codec\u0026quot;: \u0026quot;best_compression\u0026quot;    # 最优压缩\n\t},\n\t\u0026quot;mappings\u0026quot;: {\n\t\t\u0026quot;_default_\u0026quot;: {\n\t\t\t\u0026quot;_all\u0026quot;: {                        # 关闭_all索引\n\t\t\t\t\u0026quot;enabled\u0026quot;: false\n\t\t\t},\n\t\t\t\u0026quot;dynamic_templates\u0026quot;: [\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;log\u0026quot;: {                 # 原始日志字段，分词建立索引\n\t\t\t\t\t\t\u0026quot;match\u0026quot;: \u0026quot;message\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;strings\u0026quot;: {             # 其他字符串字段，统一设置为keyword类型\n\t\t\t\t\t\t\u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n``` \n\n\n### 3.2 精准搜索场景\n对于部分用户，普通的全文检索并不能满足需求，希望精准搜索日志中的某部分，例如每条日志中包含程序运行时多个阶段的耗时数据，对具体一个阶段的耗时进行搜索就比较麻烦。对于此类场景，用户可基于基础场景，进行如下调整：\n\n- 清洗过程中，可仅解析出需要精准搜索的部分作为独立字段，用于精准搜索。\n- 对于精准搜索字段，如果无排序/聚合需求，可以关闭doc_values；对于字符串，一般使用keyword，可按需考虑使用text。\n\n下面给出这类场景的常用模板，供用户参考：\n``` \n{\n\t\u0026quot;order\u0026quot;: 5,\n\t\u0026quot;template\u0026quot;: \u0026quot;my_log_*\u0026quot;,\n\t\u0026quot;settings\u0026quot;: {\n\t\t\u0026quot;translog.durability\u0026quot;: \u0026quot;async\u0026quot;,\n\t\t\u0026quot;translog.sync_interval\u0026quot;: \u0026quot;5s\u0026quot;,\n\t\t\u0026quot;index.refresh_interval\u0026quot;: \u0026quot;30s\u0026quot;,\n\t\t\u0026quot;index.codec\u0026quot;: \u0026quot;best_compression\u0026quot;    # 最优压缩\n\t},\n\t\u0026quot;mappings\u0026quot;: {\n\t\t\u0026quot;_default_\u0026quot;: {\n\t\t\t\u0026quot;_all\u0026quot;: {                        # 关闭_all索引\n\t\t\t\t\u0026quot;enabled\u0026quot;: false\n\t\t\t},\n\t\t\t\u0026quot;dynamic_templates\u0026quot;: [\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;log\u0026quot;: {                 # 原始日志字段，分词建立索引\n\t\t\t\t\t\t\u0026quot;match\u0026quot;: \u0026quot;message\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;precise_fieldx\u0026quot;: {       # 精准搜索字段\n\t\t\t\t\t\t\u0026quot;match\u0026quot;: \u0026quot;fieldx\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n\t\t\t\t\t\t\t\u0026quot;doc_values\u0026quot;: false\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;strings\u0026quot;: {             # 其他字符串字段，统一设置为keyword类型\n\t\t\t\t\t\t\u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n``` \n\n### 3.3 统计分析场景\n对于某些场景，日志包含的主要是程序运行时输出的统计信息，用户通常会完全解析日志进行精确查询、统计分析，而是否保存原始日志关系不大。对于此类场景，用户可进行如下调整：\n\n- 清洗过程中，解析出所有需要的数据作为独立字段；原始日志非必要时，建议去除。\n- 如果有强需求保留原始日志，可以设置该字段enabled属性为false，只存储不索引。\n- 多数字段保持默认即可，会自动建立索引、打开doc_values，可用于查询、排序、聚合。\n- 对部分无排序/聚合需求、开销高的字段，可以关闭doc_values。\n\n\n下面给出这类场景的常用模板，供用户参考：\n\n\n``` \n{\n\t\u0026quot;order\u0026quot;: 5,\n\t\u0026quot;template\u0026quot;: \u0026quot;my_log_*\u0026quot;,\n\t\u0026quot;settings\u0026quot;: {\n\t\t\u0026quot;translog.durability\u0026quot;: \u0026quot;async\u0026quot;,\n\t\t\u0026quot;translog.sync_interval\u0026quot;: \u0026quot;5s\u0026quot;,\n\t\t\u0026quot;index.refresh_interval\u0026quot;: \u0026quot;30s\u0026quot;,\n\t\t\u0026quot;index.codec\u0026quot;: \u0026quot;best_compression\u0026quot;    # 最优压缩\n\t},\n\t\u0026quot;mappings\u0026quot;: {\n\t\t\u0026quot;_default_\u0026quot;: {\n\t\t\t\u0026quot;_all\u0026quot;: {                        # 关闭_all索引\n\t\t\t\t\u0026quot;enabled\u0026quot;: false\n\t\t\t},\n\t\t\t\u0026quot;dynamic_templates\u0026quot;: [\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;log\u0026quot;: {                 # 原始日志字段，关闭索引\n\t\t\t\t\t\t\u0026quot;match\u0026quot;: \u0026quot;message\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;enabled\u0026quot;: false\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;index_only_fieldx\u0026quot;: {   # 仅索引的字段，无排序/聚合需求\n\t\t\t\t\t\t\u0026quot;match\u0026quot;: \u0026quot;fieldx\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n\t\t\t\t\t\t\t\u0026quot;doc_values\u0026quot;: false\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\u0026quot;strings\u0026quot;: {             # 其他字符串字段，统一设置为keyword类型\n\t\t\t\t\t\t\u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot;,\n\t\t\t\t\t\t\u0026quot;mapping\u0026quot;: {\n\t\t\t\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t}\n}\n``` \n\u0026gt;ES 5.1及之后的版本，支持关键字查询时[自动选择目标字段](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-query-string-query.html#_default_field)，用户没有必要再使用原始日志字段提供不指定字段进行查询的能力。\n\n\n## 4. 小结\n日志的使用方式比较灵活，本文结合常见的客户使用方式，从整体上对性能、成本进行优化。用户也可结合自身业务场景，参考文章[Elasticsearch调优实践](https://cloud.tencent.com/developer/article/1156231)进行更细致的优化。\n\n\n\n\n\n\n","title":"Day 12 - Elasticsearch日志场景最佳实践","uid":"4610","views":"813","votes":"2"},"_type":"doc"}
{"_id":"6184","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544413418","category_id":"14","comments":"4","has_attach":"1","id":"6184","message":"\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;大家好，今天为大家分享一次 ES 的填坑经验。主要是关于集群恢复过程中，分片恢复并发数调整过大导致集群 hang 死的问题。\n\n### 场景描述\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;废话不多说，先来描述场景。某日，腾讯云线上某 ES 集群，15个节点，2700+ 索引，15000+ 分片，数十 TB 数据。由于机器故障，某个节点被重启，此时集群有大量的 unassigned 分片，集群处于 yellow 状态。为了加快集群恢复的速度，手动调整分片恢复并发数，原本想将默认值为2的 node_concurrent_recoveries 调整为10，结果手一抖多加了一个0，设定了如下参数：\n\n```\ncurl -X PUT \u0026quot;localhost:9200/_cluster/settings\u0026quot; -H 'Content-Type: application/json' -d'\n{\n    \u0026quot;persistent\u0026quot;: {\n        \u0026quot;cluster.routing.allocation.node_concurrent_recoveries\u0026quot;: 100,\n        \u0026quot;indices.recovery.max_bytes_per_sec\u0026quot;: \u0026quot;40mb\u0026quot;\n    }\n}\n'\n```\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;设定之后，观察集群 unassigned 分片，一开始下降的速度很快。大约几分钟后，数量维持在一个固定值不变了，然后，然后就没有然后了，集群所有节点 generic 线程池卡死，虽然已存在的索引读写没问题，但是新建索引以及所有涉及 generic 线程池的操作全部卡住。立马修改分片恢复并发数到10，通过管控平台一把重启了全部节点，约15分钟后集群恢复正常。接下来会先介绍一些基本的概念，然后再重现这个问题并做详细分析。\n\n### 基本概念\n#### ES 线程池（thread pool）\nES 中每个节点有多种线程池，各有用途。重要的有：\n\n-  __generic__ ：通用线程池，后台的 node discovery，上述的分片恢复（node recovery）等等一些通用后台的操作都会用到该线程池。该线程池线程数量默认为配置的处理器数量（processors）* 4，最小128，最大512。\n-  __index__ ：index/delete 等索引操作会用到该线程池，包括自动创建索引等。默认线程数量为配置的处理器数量，默认队列大小：200.\n-  __search__ ：查询请求处理线程池。默认线程数量：int((# of available_processors * 3) / 2) + 1，默认队列大小：1000.\n-  __get__ ：get 请求处理线程池。默认线程数量为配置的处理器数量，默认队列大小：1000.\n-  __write__ ：单个文档的 index/delete/update 以及 bulk 请求处理线程。默认线程数量为配置的处理器数量，默认队列大小：200，在写多的日志场景我们一般会将队列调大。\n还有其它线程池，例如备份回档（snapshot）、analyze、refresh 等，这里就不一一介绍了。详细可参考官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html\n\n#### 集群恢复之分片恢复\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;我们知道 ES 集群状态分为三种，green、yellow、red。green 状态表示所有分片包括主副本均正常被分配；yellow 状态表示所有主分片已分配，但是有部分副本分片未分配；red 表示有部分主分片未分配。\n一般当集群中某个节点因故障失联或者重启之后，如果集群索引有副本的场景，集群将进入分片恢复阶段（recovery）。此时一般是 master 节点发起更新集群元数据任务，分片的分配策略由 master 决定，具体分配策略可以参考腾讯云+社区的这篇文章了解细节：https://cloud.tencent.com/developer/article/1334743 。各节点收到集群元数据更新请求，检查分片状态并触发分片恢复流程，根据分片数据所在的位置，有多种恢复的方式，主要有以下几种：\n\n-  EXISTING_STORE ： 数据在节点本地存在，从本地节点恢复。\n-  PEER ：本地数据不可用或不存在，从远端节点（源分片，一般是主分片）恢复。\n-  SNAPSHOT ： 数据从备份仓库恢复。\n-  LOCAL_SHARDS ： 分片合并（shrink）场景，从本地别的分片恢复。\n\nPEER 场景分片恢复并发数主要由如下参数控制：\n\n- cluster.routing.allocation.node_concurrent_incoming_recoveries：节点上最大接受的分片恢复并发数。一般指分片从其它节点恢复至本节点。\n-  cluster.routing.allocation.node_concurrent_outgoing_recoveries ：节点上最大发送的分片恢复并发数。一般指分片从本节点恢复至其它节点。\n-  cluster.routing.allocation.node_concurrent_recoveries ：该参数同时设置上述接受发送分片恢复并发数为相同的值。\n详细参数可参考官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html\n\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;集群卡住的主要原因就是从远端节点恢复（PEER Recovery）的并发数过多，导致 generic 线程池被用完。涉及目标节点（target）和源节点（source）的恢复交互流程，后面分析问题时我们再来详细讨论。\n\n### 问题复现与剖析\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;为了便于描述，我用 ES 6.4.3版本重新搭建了一个三节点的集群。单节点 1 core，2GB memory。新建了300个 index， 单个 index 5个分片一个副本，共 3000 个 shard。每个 index 插入大约100条数据。\n先设定分片恢复并发数，为了夸张一点，我直接调整到200，如下所示：\n```\ncurl -X PUT \u0026quot;localhost:9200/_cluster/settings\u0026quot; -H 'Content-Type: application/json' -d'\n{\n    \u0026quot;persistent\u0026quot;: {\n        \u0026quot;cluster.routing.allocation.node_concurrent_recoveries\u0026quot;: 200 // 设定分片恢复并发数\n    }\n}\n'\n```\n\u0026amp;nbsp;\n接下来停掉某节点，模拟机器挂掉场景。几分钟后，观察集群分片恢复数量，卡在固定数值不再变化：\n\n[attach]3246[/attach]\n\n\u0026amp;nbsp;\n通过 allocation explain 查看分片分配状态，未分配的原因是受到最大恢复并发数的限制：\n\n[attach]3247[/attach]\n\u0026amp;nbsp;\n观察线程池的数量，generic 线程池打满128.\n\n[attach]3248[/attach]\n\n此时查询或写入已有索引不受影响，但是新建索引这种涉及到 generic 线程池的操作都会卡住。\n通过堆栈分析，128 个 generic 线程全部卡在 PEER recovery 阶段。\n\n[attach]3249[/attach]\n\u0026amp;nbsp;\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;现象有了，我们来分析一下这种场景，远程分片恢复（PEER Recovery）流程为什么会导致集群卡住。\n\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;当集群中有分片的状态发生变更时，master 节点会发起集群元数据更新（cluster state update）请求给所有节点。其它节点收到该请求后，感知到分片状态的变更，启动分片恢复流程。部分分片需要从其它节点恢复，代码层面，涉及分片分配的目标节点（target）和源节点（source）的交互流程如下：\n\n[attach]3250[/attach]\n\u0026amp;nbsp;\n\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;6.x 版本之后引入了 seqNo，恢复会涉及到 seqNo+translog，这也是6.x提升恢复速度的一大改进。我们重点关注流程中第 2、4、5、7、10、12 步骤中的远程调用，他们的作用分别是：\n\n- 第2步：分片分配的目标节点向源节点（一般是主分片）发起分片恢复请求，携带起始 seqNo 和 syncId。\n- 第4步：发送数据文件信息，告知目标节点待接收的文件清单。\n- 第5步：发送 diff 数据文件给目标节点。\n- 第7步：源节点发送 prepare translog 请求给目标节点，等目标节点打开 shard level 引擎，准备接受 translog。\n- 第10步：源节点发送指定范围的 translog 快照给目标节点。\n- 第12步：结束恢复流程。\n\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;我们可以看到除第5步发送数据文件外，多次远程交互 submitRequest  都会调用 txGet，这个调用底层用的是基于 AQS 改造过的 sync 对象，是一个同步调用。 __如果一端 generic 线程池被这些请求打满，发出的请求等待对端返回，而发出的这些请求由于对端 generic 线程池同样的原因被打满，只能 pending 在队列中，这样两边的线程池都满了而且相互等待对端队列中的线程返回，就出现了分布式死锁现象。__ \n\n###问题处理\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;为了避免改动太大带来不确定的 side effect，针对腾讯云 ES 集群我们目前先在 rest 层拒掉了并发数超过一定值的参数设定请求并提醒用户。与此同时，我们向官方提交了 issue：https://github.com/elastic/elasticsearch/issues/36195 进行跟踪。\n\n###总结\n\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;本文旨在描述集群恢复过程出现的集群卡死场景，避免更多的 ES 用户踩坑，没有对整体分片恢复做详细的分析，大家想了解详细的分片恢复流程可以参考腾讯云+社区 Elasticsearch 专栏相关的文章：https://cloud.tencent.com/developer/column/2428\n\n完结，谢谢！\n\n","title":"Day 10 - Elasticsearch 分片恢复并发数过大引发的bug分析 ","uid":"2095","views":"775","votes":"4"},"_type":"doc"}
{"_id":"6181","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544321514","category_id":"18","comments":"0","has_attach":"0","id":"6181","message":"1.ElasticSearch连接：Has_Child，Has_parent查询。\nhttp://t.cn/EyEJZGO\n2.(自备梯子)将full-scale ELK栈部署到Kubernetes。\nhttp://t.cn/EyEiOtk\n3.(自备梯子)Facebook建立在不平等的基础之上。\nhttp://t.cn/EyE6quM\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6181\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第473期 (2018-12-09)","uid":"4460","views":"205","votes":"0"},"_type":"doc"}
{"_id":"6177","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544143270","category_id":"18","comments":"0","has_attach":"0","id":"6177","message":"1、使用Elasticsearch作为主数据存储实践\nhttp://t.cn/EyS6wcL\n2、Elasticsearch 6.x启动过程\nhttp://t.cn/EyJgQ7U\n3、Elasticsearch你知道多少？\nhttp://t.cn/EyS6I4P\n\n编辑：铭毅天下\n归档: https://elasticsearch.cn/article/6177\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第471期 (2018-12-07)","uid":"1341","views":"269","votes":"0"},"_type":"doc"}
{"_id":"6178","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544162113","category_id":"14","comments":"2","has_attach":"1","id":"6178","message":"# 前言\n很多使用Elasticsearch的同学会关心数据存储在ES中的存储容量，会有这样的疑问：xxTB的数据入到ES会使用多少存储空间。这个问题其实很难直接回答的，只有数据写入ES后，才能观察到实际的存储空间。比如同样是1TB的数据，写入ES的存储空间可能差距会非常大，可能小到只有300~400GB，也可能多到6-7TB，为什么会造成这么大的差距呢？究其原因，我们来探究下Elasticsearch中的数据是如何存储。文章中我以Elasticsearch 2.3版本为示例，对应的lucene版本是5.5，Elasticsearch现在已经来到了6.5版本，数字类型、列存等存储结构有些变化，但基本的概念变化不多，文章中的内容依然适用。\n\n# Elasticsearch索引结构\nElasticsearch对外提供的是index的概念，可以类比为DB，用户查询是在index上完成的，每个index由若干个shard组成，以此来达到分布式可扩展的能力。比如下图是一个由10个shard组成的index。\n\n\n[attach]3233[/attach]\n\nshard是Elasticsearch数据存储的最小单位，index的存储容量为所有shard的存储容量之和。Elasticsearch集群的存储容量则为所有index存储容量之和。\n\n一个shard就对应了一个lucene的library。对于一个shard，Elasticsearch增加了translog的功能，类似于HBase WAL，是数据写入过程中的中间数据，其余的数据都在lucene库中管理的。\n\n所以Elasticsearch索引使用的存储内容主要取决于lucene中的数据存储。\n\n# lucene数据存储\n下面我们主要看下lucene的文件内容，在了解lucene文件内容前，大家先了解些lucene的基本概念。\n## lucene基本概念\n* segment : lucene内部的数据是由一个个segment组成的，写入lucene的数据并不直接落盘，而是先写在内存中，经过了refresh间隔，lucene才将该时间段写入的全部数据refresh成一个segment，segment多了之后会进行merge成更大的segment。lucene查询时会遍历每个segment完成。由于lucene* 写入的数据是在内存中完成，所以写入效率非常高。但是也存在丢失数据的风险，所以Elasticsearch基于此现象实现了translog，只有在segment数据落盘后，Elasticsearch才会删除对应的translog。\n* doc : doc表示lucene中的一条记录\n* field ：field表示记录中的字段概念，一个doc由若干个field组成。\n* term ：term是lucene中索引的最小单位，某个field对应的内容如果是全文检索类型，会将内容进行分词，分词的结果就是由term组成的。如果是不分词的字段，那么该字段的内容就是一个term。\n* 倒排索引（inverted index）: lucene索引的通用叫法，即实现了term到doc list的映射。\n* 正排数据：搜索引擎的通用叫法，即原始数据，可以理解为一个doc list。\n* docvalues :Elasticsearch中的列式存储的名称，Elasticsearch除了存储原始存储、倒排索引，还存储了一份docvalues，用作分析和排序。\n\n## lucene文件内容\nlucene包的文件是由很多segment文件组成的，segments_xxx文件记录了lucene包下面的segment文件数量。每个segment会包含如下的文件。\n\n| Name | Extension | Brief Description |\n| ------ | ------ | ------ |\n|Segment Info|.si|segment的元数据文件|\n|Compound File|.cfs, .cfe|一个segment包含了如下表的各个文件，为减少打开文件的数量，在segment小的时候，segment的所有文件内容都保存在cfs文件中，cfe文件保存了lucene各文件在cfs文件的位置信息|\n|Fields|.fnm|保存了fields的相关信息|\n|Field Index|.fdx|正排存储文件的元数据信息|\n|Field Data|.fdt|存储了正排存储数据，写入的原文存储在这|\n|Term Dictionary|.tim|倒排索引的元数据信息|\n|Term Index|.tip|倒排索引文件，存储了所有的倒排索引数据|\n|Frequencies|.doc|保存了每个term的doc id列表和term在doc中的词频|\n|Positions|.pos|Stores position information about where a term occurs in the index\u0026lt;br\u0026gt;全文索引的字段，会有该文件，保存了term在doc中的位置|\n|Payloads|.pay|Stores additional per-position metadata information such as character offsets and user payloads\u0026lt;br\u0026gt;全文索引的字段，使用了一些像payloads的高级特性会有该文件，保存了term在doc中的一些高级特性|\n|Norms|.nvd, .nvm|文件保存索引字段加权数据|\n|Per-Document Values|.dvd, .dvm|lucene的docvalues文件，即数据的列式存储，用作聚合和排序|\n|Term Vector Data|.tvx, .tvd, .tvf|Stores offset into the document data file\u0026lt;br\u0026gt;保存索引字段的矢量信息，用在对term进行高亮，计算文本相关性中使用|\n|Live Documents|.liv|记录了segment中删除的doc|\n\n# 测试数据示例\n下面我们以真实的数据作为示例，看看lucene中各类型数据的容量占比。\n\n写100w数据，有一个uuid字段，写入的是长度为36位的uuid，字符串总为3600w字节，约为35M。\n\n数据使用一个shard，不带副本，使用默认的压缩算法，写入完成后merge成一个segment方便观察。\n\n使用线上默认的配置，uuid存为不分词的字符串类型。创建如下索引：\n\n```\nPUT test_field\n{\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;index\u0026quot;: {\n      \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot;,\n      \u0026quot;number_of_replicas\u0026quot;: \u0026quot;0\u0026quot;,\n      \u0026quot;refresh_interval\u0026quot;: \u0026quot;30s\u0026quot;\n    }\n  },\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;type\u0026quot;: {\n      \u0026quot;_all\u0026quot;: {\n        \u0026quot;enabled\u0026quot;: false\n      }, \n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;uuid\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n          \u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;\n        }\n      }\n    }\n  }\n}\n```\n\n首先写入100w不同的uuid，使用磁盘容量细节如下：\n\n```\n\nhealth status index      pri rep docs.count docs.deleted store.size pri.store.size \ngreen  open   test_field   1   0    1000000            0    122.7mb        122.7mb \n\n-rw-r--r--  1 weizijun  staff    41M Aug 19 21:23 _8.fdt\n-rw-r--r--  1 weizijun  staff    17K Aug 19 21:23 _8.fdx\n-rw-r--r--  1 weizijun  staff   688B Aug 19 21:23 _8.fnm\n-rw-r--r--  1 weizijun  staff   494B Aug 19 21:23 _8.si\n-rw-r--r--  1 weizijun  staff   265K Aug 19 21:23 _8_Lucene50_0.doc\n-rw-r--r--  1 weizijun  staff    44M Aug 19 21:23 _8_Lucene50_0.tim\n-rw-r--r--  1 weizijun  staff   340K Aug 19 21:23 _8_Lucene50_0.tip\n-rw-r--r--  1 weizijun  staff    37M Aug 19 21:23 _8_Lucene54_0.dvd\n-rw-r--r--  1 weizijun  staff   254B Aug 19 21:23 _8_Lucene54_0.dvm\n-rw-r--r--  1 weizijun  staff   195B Aug 19 21:23 segments_2\n-rw-r--r--  1 weizijun  staff     0B Aug 19 21:20 write.lock\n```\n可以看到正排数据、倒排索引数据，列存数据容量占比几乎相同，正排数据和倒排数据还会存储Elasticsearch的唯一id字段，所以容量会比列存多一些。\n\n35M的uuid存入Elasticsearch后，数据膨胀了3倍，达到了122.7mb。Elasticsearch竟然这么消耗资源，不要着急下结论，接下来看另一个测试结果。\n\n我们写入100w一样的uuid，然后看看Elasticsearch使用的容量。\n\n```\nhealth status index      pri rep docs.count docs.deleted store.size pri.store.size \ngreen  open   test_field   1   0    1000000            0     13.2mb         13.2mb \n\n-rw-r--r--  1 weizijun  staff   5.5M Aug 19 21:29 _6.fdt\n-rw-r--r--  1 weizijun  staff    15K Aug 19 21:29 _6.fdx\n-rw-r--r--  1 weizijun  staff   688B Aug 19 21:29 _6.fnm\n-rw-r--r--  1 weizijun  staff   494B Aug 19 21:29 _6.si\n-rw-r--r--  1 weizijun  staff   309K Aug 19 21:29 _6_Lucene50_0.doc\n-rw-r--r--  1 weizijun  staff   7.0M Aug 19 21:29 _6_Lucene50_0.tim\n-rw-r--r--  1 weizijun  staff   195K Aug 19 21:29 _6_Lucene50_0.tip\n-rw-r--r--  1 weizijun  staff   244K Aug 19 21:29 _6_Lucene54_0.dvd\n-rw-r--r--  1 weizijun  staff   252B Aug 19 21:29 _6_Lucene54_0.dvm\n-rw-r--r--  1 weizijun  staff   195B Aug 19 21:29 segments_2\n-rw-r--r--  1 weizijun  staff     0B Aug 19 21:26 write.lock\n```\n\n这回35M的数据Elasticsearch容量只有13.2mb，其中还有主要的占比还是Elasticsearch的唯一id，100w的uuid几乎不占存储容积。\n\n所以在Elasticsearch中建立索引的字段如果基数越大(count distinct)，越占用磁盘空间。\n\n我们再看看存100w个不一样的整型会是如何。\n\n```\nhealth status index      pri rep docs.count docs.deleted store.size pri.store.size \ngreen  open   test_field   1   0    1000000            0     13.6mb         13.6mb \n\n-rw-r--r--  1 weizijun  staff   6.1M Aug 28 10:19 _42.fdt\n-rw-r--r--  1 weizijun  staff    22K Aug 28 10:19 _42.fdx\n-rw-r--r--  1 weizijun  staff   688B Aug 28 10:19 _42.fnm\n-rw-r--r--  1 weizijun  staff   503B Aug 28 10:19 _42.si\n-rw-r--r--  1 weizijun  staff   2.8M Aug 28 10:19 _42_Lucene50_0.doc\n-rw-r--r--  1 weizijun  staff   2.2M Aug 28 10:19 _42_Lucene50_0.tim\n-rw-r--r--  1 weizijun  staff    83K Aug 28 10:19 _42_Lucene50_0.tip\n-rw-r--r--  1 weizijun  staff   2.5M Aug 28 10:19 _42_Lucene54_0.dvd\n-rw-r--r--  1 weizijun  staff   228B Aug 28 10:19 _42_Lucene54_0.dvm\n-rw-r--r--  1 weizijun  staff   196B Aug 28 10:19 segments_2\n-rw-r--r--  1 weizijun  staff     0B Aug 28 10:16 write.lock\n```\n\n从结果可以看到，100w整型数据，Elasticsearch的存储开销为13.6mb。如果以int型计算100w数据的长度的话，为400w字节，大概是3.8mb数据。忽略Elasticsearch唯一id字段的影响，Elasticsearch实际存储容量跟整型数据长度差不多。\n\n我们再看一下开启最佳压缩参数对存储空间的影响：\n\n```\nhealth status index      pri rep docs.count docs.deleted store.size pri.store.size \ngreen  open   test_field   1   0    1000000            0    107.2mb        107.2mb \n\n-rw-r--r--  1 weizijun  staff    25M Aug 20 12:30 _5.fdt\n-rw-r--r--  1 weizijun  staff   6.0K Aug 20 12:30 _5.fdx\n-rw-r--r--  1 weizijun  staff   688B Aug 20 12:31 _5.fnm\n-rw-r--r--  1 weizijun  staff   500B Aug 20 12:31 _5.si\n-rw-r--r--  1 weizijun  staff   265K Aug 20 12:31 _5_Lucene50_0.doc\n-rw-r--r--  1 weizijun  staff    44M Aug 20 12:31 _5_Lucene50_0.tim\n-rw-r--r--  1 weizijun  staff   322K Aug 20 12:31 _5_Lucene50_0.tip\n-rw-r--r--  1 weizijun  staff    37M Aug 20 12:31 _5_Lucene54_0.dvd\n-rw-r--r--  1 weizijun  staff   254B Aug 20 12:31 _5_Lucene54_0.dvm\n-rw-r--r--  1 weizijun  staff   224B Aug 20 12:31 segments_4\n-rw-r--r--  1 weizijun  staff     0B Aug 20 12:00 write.lock\n```\n\n结果中可以发现，只有正排数据会启动压缩，压缩能力确实强劲，不考虑唯一id字段，存储容量大概压缩到接近50%。\n\n我们还做了一些实验，Elasticsearch默认是开启_all参数的，_all可以让用户传入的整体json数据作为全文检索的字段，可以更方便的检索，但在现实场景中已经使用的不多，相反会增加很多存储容量的开销，可以看下开启_all的磁盘空间使用情况：\n\n```\n\nhealth status index      pri rep docs.count docs.deleted store.size pri.store.size \ngreen  open   test_field   1   0    1000000            0    162.4mb        162.4mb \n\n-rw-r--r--  1 weizijun  staff    41M Aug 18 22:59 _20.fdt\n-rw-r--r--  1 weizijun  staff    18K Aug 18 22:59 _20.fdx\n-rw-r--r--  1 weizijun  staff   777B Aug 18 22:59 _20.fnm\n-rw-r--r--  1 weizijun  staff    59B Aug 18 22:59 _20.nvd\n-rw-r--r--  1 weizijun  staff    78B Aug 18 22:59 _20.nvm\n-rw-r--r--  1 weizijun  staff   539B Aug 18 22:59 _20.si\n-rw-r--r--  1 weizijun  staff   7.2M Aug 18 22:59 _20_Lucene50_0.doc\n-rw-r--r--  1 weizijun  staff   4.2M Aug 18 22:59 _20_Lucene50_0.pos\n-rw-r--r--  1 weizijun  staff    73M Aug 18 22:59 _20_Lucene50_0.tim\n-rw-r--r--  1 weizijun  staff   832K Aug 18 22:59 _20_Lucene50_0.tip\n-rw-r--r--  1 weizijun  staff    37M Aug 18 22:59 _20_Lucene54_0.dvd\n-rw-r--r--  1 weizijun  staff   254B Aug 18 22:59 _20_Lucene54_0.dvm\n-rw-r--r--  1 weizijun  staff   196B Aug 18 22:59 segments_2\n-rw-r--r--  1 weizijun  staff     0B Aug 18 22:53 write.lock\n\n```\n\n开启_all比不开启多了40mb的存储空间，多的数据都在倒排索引上，大约会增加30%多的存储开销。所以线上都直接禁用。\n\n然后我还做了其他几个尝试，为了验证存储容量是否和数据量成正比，写入1000w数据的uuid，发现存储容量基本为100w数据的10倍。我还验证了数据长度是否和数据量成正比，发现把uuid增长2倍、4倍，存储容量也响应的增加了2倍和4倍。在此就不一一列出数据了。\n\n\n# lucene各文件具体内容和实现\n## lucene数据元信息文件\n文件名为：segments_xxx\n\n该文件为lucene数据文件的元信息文件，记录所有segment的元数据信息。\n\n该文件主要记录了目前有多少segment，每个segment有一些基本信息，更新这些信息定位到每个segment的元信息文件。\n\nlucene元信息文件还支持记录userData，Elasticsearch可以在此记录translog的一些相关信息。\n### 文件示例\n\n[attach]3237[/attach]\n\n\n### 具体实现类\n\n```\npublic final class SegmentInfos implements Cloneable, Iterable\u0026lt;SegmentCommitInfo\u0026gt; {\n  // generation是segment的版本的概念，从文件名中提取出来，实例中为：2t/101\n  private long generation;     // generation of the \u0026quot;segments_N\u0026quot; for the next commit\n \n  private long lastGeneration; // generation of the \u0026quot;segments_N\u0026quot; file we last successfully read\n                               // or wrote; this is normally the same as generation except if\n                               // there was an IOException that had interrupted a commit\n \n  /** Id for this commit; only written starting with Lucene 5.0 */\n  private byte[] id;\n \n \n  /** Which Lucene version wrote this commit, or null if this commit is pre-5.3. */\n  private Version luceneVersion;\n \n  /** Counts how often the index has been changed.  */\n  public long version;\n\n  /** Used to name new segments. */\n  // TODO: should this be a long ...?\n  public int counter;\n \n  /** Version of the oldest segment in the index, or null if there are no segments. */\n  private Version minSegmentLuceneVersion;\n\n  private List\u0026lt;SegmentCommitInfo\u0026gt; segments = new ArrayList\u0026lt;\u0026gt;();\n\n  /** Opaque Map\u0026amp;lt;String, String\u0026amp;gt; that user can specify during IndexWriter.commit */\n  public Map\u0026lt;String,String\u0026gt; userData = Collections.emptyMap();\n}\n \n/** Embeds a [read-only] SegmentInfo and adds per-commit\n *  fields.\n *\n *  @lucene.experimental */\npublic class SegmentCommitInfo {\n  \n  /** The {@link SegmentInfo} that we wrap. */\n  public final SegmentInfo info;\n\n  // How many deleted docs in the segment:\n  private int delCount;\n\n  // Generation number of the live docs file (-1 if there\n  // are no deletes yet):\n  private long delGen;\n\n  // Normally 1+delGen, unless an exception was hit on last\n  // attempt to write:\n  private long nextWriteDelGen;\n\n  // Generation number of the FieldInfos (-1 if there are no updates)\n  private long fieldInfosGen;\n  \n  // Normally 1+fieldInfosGen, unless an exception was hit on last attempt to\n  // write\n  private long nextWriteFieldInfosGen; //fieldInfosGen == -1 ? 1 : fieldInfosGen + 1;\n  \n  // Generation number of the DocValues (-1 if there are no updates)\n  private long docValuesGen;\n  \n  // Normally 1+dvGen, unless an exception was hit on last attempt to\n  // write\n  private long nextWriteDocValuesGen; //docValuesGen == -1 ? 1 : docValuesGen + 1;\n\n  // TODO should we add .files() to FieldInfosFormat, like we have on\n  // LiveDocsFormat?\n  // track the fieldInfos update files\n  private final Set\u0026lt;String\u0026gt; fieldInfosFiles = new HashSet\u0026lt;\u0026gt;();\n \n  // Track the per-field DocValues update files\n  private final Map\u0026lt;Integer,Set\u0026lt;String\u0026gt;\u0026gt; dvUpdatesFiles = new HashMap\u0026lt;\u0026gt;();\n  \n  // Track the per-generation updates files\n  @Deprecated\n  private final Map\u0026lt;Long,Set\u0026lt;String\u0026gt;\u0026gt; genUpdatesFiles = new HashMap\u0026lt;\u0026gt;();\n  \n  private volatile long sizeInBytes = -1;\n}\n \n```\n\n## segment的元信息文件\n文件后缀：.si\n\n每个segment都有一个.si文件，记录了该segment的元信息。\n\nsegment元信息文件中记录了segment的文档数量，segment对应的文件列表等信息。\n\n### 文件示例\n\n[attach]3240[/attach]\n\n\n### 具体实现类\n\n```\n/**\n * Information about a segment such as its name, directory, and files related\n * to the segment.\n *\n * @lucene.experimental\n */\npublic final class SegmentInfo {\n \n  // _bl\n  public final String name;\n \n  /** Where this segment resides. */\n  public final Directory dir;\n \n  /** Id that uniquely identifies this segment. */\n  private final byte[] id;\n\n  private Codec codec;\n \n  // Tracks the Lucene version this segment was created with, since 3.1. Null\n  // indicates an older than 3.0 index, and it's used to detect a too old index.\n  // The format expected is \u0026quot;x.y\u0026quot; - \u0026quot;2.x\u0026quot; for pre-3.0 indexes (or null), and\n  // specific versions afterwards (\u0026quot;3.0.0\u0026quot;, \u0026quot;3.1.0\u0026quot; etc.).\n  // see o.a.l.util.Version.\n  private Version version;\n \n  private int maxDoc;         // number of docs in seg\n \n  private boolean isCompoundFile;\n\n\n  private Map\u0026lt;String,String\u0026gt; diagnostics;\n\n  private Set\u0026lt;String\u0026gt; setFiles;\n\n  private final Map\u0026lt;String,String\u0026gt; attributes;\n}\n```\n\n## fields信息文件\n文件后缀：.fnm\n\n该文件存储了fields的基本信息。\n\nfields信息中包括field的数量，field的类型，以及IndexOpetions，包括是否存储、是否索引，是否分词，是否需要列存等等。\n\n### 文件示例\n\n[attach]3238[/attach]\n\n\n### 具体实现类\n\n```\n/**\n *  Access to the Field Info file that describes document fields and whether or\n *  not they are indexed. Each segment has a separate Field Info file. Objects\n *  of this class are thread-safe for multiple readers, but only one thread can\n *  be adding documents at a time, with no other reader or writer threads\n *  accessing this object.\n **/\npublic final class FieldInfo {\n  /** Field's name */\n  public final String name;\n \n  /** Internal field number */\n  //field在内部的编号\n  public final int number;\n \n  //field docvalues的类型\n  private DocValuesType docValuesType = DocValuesType.NONE;\n \n  // True if any document indexed term vectors\n  private boolean storeTermVector;\n\n  private boolean omitNorms; // omit norms associated with indexed fields \n \n  //index的配置项\n  private IndexOptions indexOptions = IndexOptions.NONE;\n \n  private boolean storePayloads; // whether this field stores payloads together with term positions \n\n  private final Map\u0026lt;String,String\u0026gt; attributes;\n \n  // docvalues的generation\n  private long dvGen;\n}\n```\n\n## 数据存储文件\n文件后缀：.fdx, .fdt\n\n索引文件为.fdx，数据文件为.fdt，数据存储文件功能为根据自动的文档id，得到文档的内容，搜索引擎的术语习惯称之为正排数据，即doc_id -\u0026gt; content，es的_source数据就存在这\n\n索引文件记录了快速定位文档数据的索引信息，数据文件记录了所有文档id的具体内容。\n\n### 文件示例\n\n[attach]3239[/attach]\n\n\n### 具体实现类\n```\n/**\n * Random-access reader for {@link CompressingStoredFieldsIndexWriter}.\n * @lucene.internal\n */\npublic final class CompressingStoredFieldsIndexReader implements Cloneable, Accountable {\n  private static final long BASE_RAM_BYTES_USED = RamUsageEstimator.shallowSizeOfInstance(CompressingStoredFieldsIndexReader.class);\n\n  final int maxDoc;\n\n  //docid索引，快速定位某个docid的数组坐标\n  final int[] docBases;\n\n  //快速定位某个docid所在的文件offset的startPointer\n  final long[] startPointers;\n\n  //平均一个chunk的文档数\n  final int[] avgChunkDocs;\n\n  //平均一个chunk的size\n  final long[] avgChunkSizes;\n\n  final PackedInts.Reader[] docBasesDeltas; // delta from the avg\n\n  final PackedInts.Reader[] startPointersDeltas; // delta from the avg\n}\n \n/**\n * {@link StoredFieldsReader} impl for {@link CompressingStoredFieldsFormat}.\n * @lucene.experimental\n */\npublic final class CompressingStoredFieldsReader extends StoredFieldsReader {\n\n  //从fdt正排索引文件中获得\n  private final int version;\n \n  // field的基本信息\n  private final FieldInfos fieldInfos;\n \n  //fdt正排索引文件reader\n  private final CompressingStoredFieldsIndexReader indexReader;\n \n  //从fdt正排索引文件中获得，用于指向fdx数据文件的末端，指向numChunks地址4\n  private final long maxPointer;\n \n  //fdx正排数据文件句柄\n  private final IndexInput fieldsStream;\n \n  //块大小\n  private final int chunkSize;\n \n  private final int packedIntsVersion;\n \n  //压缩类型\n  private final CompressionMode compressionMode;\n \n  //解压缩处理对象\n  private final Decompressor decompressor;\n \n  //文档数量，从segment元数据中获得\n  private final int numDocs;\n \n  //是否正在merge，默认为false\n  private final boolean merging;\n \n  //初始化时new了一个BlockState，BlockState记录下当前正排文件读取的状态信息\n  private final BlockState state;\n  //chunk的数量\n  private final long numChunks; // number of compressed blocks written\n \n  //dirty chunk的数量\n  private final long numDirtyChunks; // number of incomplete compressed blocks written\n \n  //是否close，默认为false\n  private boolean closed;\n}\n```\n## 倒排索引文件\n索引后缀：.tip,.tim\n\n倒排索引也包含索引文件和数据文件，.tip为索引文件，.tim为数据文件，索引文件包含了每个字段的索引元信息，数据文件有具体的索引内容。\n\n5.5.0版本的倒排索引实现为FST tree，FST tree的最大优势就是内存空间占用非常低 ，具体可以参看下这篇文章：[http://www.cnblogs.com/bonelee/p/6226185.html ](http://www.cnblogs.com/bonelee/p/6226185.html )\n\n[http://examples.mikemccandless.com/fst.py?terms=\u0026amp;cmd=Build+it](http://examples.mikemccandless.com/fst.py?terms=\u0026amp;cmd=Build+it) 为FST图实例，可以根据输入的数据构造出FST图\n\n```\n输入到 FST 中的数据为:\nString inputValues[] = {\u0026quot;mop\u0026quot;,\u0026quot;moth\u0026quot;,\u0026quot;pop\u0026quot;,\u0026quot;star\u0026quot;,\u0026quot;stop\u0026quot;,\u0026quot;top\u0026quot;};\nlong outputValues[] = {0,1,2,3,4,5};\n```\n生成的 FST 图为:\n\n[attach]3234[/attach]\n\n[attach]3235[/attach]\n\n### 文件示例\n\n[attach]3242[/attach]\n\n\n### 具体实现类\n```\npublic final class BlockTreeTermsReader extends FieldsProducer {\n  // Open input to the main terms dict file (_X.tib)\n  final IndexInput termsIn;\n  // Reads the terms dict entries, to gather state to\n  // produce DocsEnum on demand\n  final PostingsReaderBase postingsReader;\n  private final TreeMap\u0026lt;String,FieldReader\u0026gt; fields = new TreeMap\u0026lt;\u0026gt;();\n \n  /** File offset where the directory starts in the terms file. */\n  /索引数据文件tim的数据的尾部的元数据的地址\n  private long dirOffset;\n  /** File offset where the directory starts in the index file. */\n \n  //索引文件tip的数据的尾部的元数据的地址\n  private long indexDirOffset;\n \n  //semgent的名称\n  final String segment;\n  \n  //版本号\n  final int version;\n \n  //5.3.x index, we record up front if we may have written any auto-prefix terms，示例中记录的是false\n  final boolean anyAutoPrefixTerms;\n}\n \n/**\n * BlockTree's implementation of {@link Terms}.\n * @lucene.internal\n */\npublic final class FieldReader extends Terms implements Accountable {\n\n  //term的数量\n  final long numTerms;\n \n  //field信息\n  final FieldInfo fieldInfo;\n \n  final long sumTotalTermFreq;\n \n  //总的文档频率\n  final long sumDocFreq;\n \n  //文档数量\n  final int docCount;\n \n  //字段在索引文件tip中的起始位置\n  final long indexStartFP;\n \n  final long rootBlockFP;\n \n  final BytesRef rootCode;\n \n  final BytesRef minTerm;\n \n  final BytesRef maxTerm;\n \n  //longs：metadata buffer, holding monotonic values\n  final int longsSize;\n\n  final BlockTreeTermsReader parent;\n \n  final FST\u0026lt;BytesRef\u0026gt; index;\n}\n```\n\n## 倒排链文件\n文件后缀：.doc, .pos, .pay\n\n.doc保存了每个term的doc id列表和term在doc中的词频\n\n全文索引的字段，会有.pos文件，保存了term在doc中的位置\n\n全文索引的字段，使用了一些像payloads的高级特性才会有.pay文件，保存了term在doc中的一些高级特性\n\n### 文件示例\n\n[attach]3236[/attach]\n\n\n### 具体实现类\n```\n/**\n * Concrete class that reads docId(maybe frq,pos,offset,payloads) list\n * with postings format.\n *\n * @lucene.experimental\n */\npublic final class Lucene50PostingsReader extends PostingsReaderBase {\n  private static final long BASE_RAM_BYTES_USED = RamUsageEstimator.shallowSizeOfInstance(Lucene50PostingsReader.class);\n  private final IndexInput docIn;\n  private final IndexInput posIn;\n  private final IndexInput payIn;\n  final ForUtil forUtil;\n  private int version;\n \n  //不分词的字段使用的是该对象，基于skiplist实现了倒排链\n  final class BlockDocsEnum extends PostingsEnum {\n  }\n \n  //全文检索字段使用的是该对象\n  final class BlockPostingsEnum extends PostingsEnum {\n  }\n \n  //包含高级特性的字段使用的是该对象\n  final class EverythingEnum extends PostingsEnum {\n  }\n}\n```\n\n## 列存文件（docvalues）\n文件后缀：.dvm, .dvd\n\n 索引文件为.dvm，数据文件为.dvd。\n\nlucene实现的docvalues有如下类型：\n\n* 1、NONE 不开启docvalue时的状态\n* 2、NUMERIC 单个数值类型的docvalue主要包括（int，long，float，double）\n* 3、BINARY 二进制类型值对应不同的codes最大值可能超过32766字节，\n* 4、SORTED 有序增量字节存储，仅仅存储不同部分的值和偏移量指针，值必须小于等于32766字节\n* 5、SORTED_NUMERIC 存储数值类型的有序数组列表\n* 6、SORTED_SET 可以存储多值域的docvalue值，但返回时，仅仅只能返回多值域的第一个docvalue\n* 7、对应not_anaylized的string字段，使用的是SORTED_SET类型，number的类型是SORTED_NUMERIC类型\n\n其中SORTED_SET 的 SORTED_SINGLE_VALUED类型包括了两类数据 ： binary + numeric， binary是按ord排序的term的列表，numeric是doc到ord的映射。\n\n### 文件示例\n\n[attach]3241[/attach]\n\n\n### 具体实现类\n```\n/** reader for {@link Lucene54DocValuesFormat} */\nfinal class Lucene54DocValuesProducer extends DocValuesProducer implements Closeable {\n  //number类型的field的列存列表\n  private final Map\u0026lt;String,NumericEntry\u0026gt; numerics = new HashMap\u0026lt;\u0026gt;();\n \n  //字符串类型的field的列存列表\n  private final Map\u0026lt;String,BinaryEntry\u0026gt; binaries = new HashMap\u0026lt;\u0026gt;();\n \n  //有序字符串类型的field的列存列表\n  private final Map\u0026lt;String,SortedSetEntry\u0026gt; sortedSets = new HashMap\u0026lt;\u0026gt;();\n \n  //有序number类型的field的列存列表\n  private final Map\u0026lt;String,SortedSetEntry\u0026gt; sortedNumerics = new HashMap\u0026lt;\u0026gt;();\n \n  //字符串类型的field的ords列表\n  private final Map\u0026lt;String,NumericEntry\u0026gt; ords = new HashMap\u0026lt;\u0026gt;();\n \n  //docId -\u0026gt; address -\u0026gt; ord 中field的ords列表\n  private final Map\u0026lt;String,NumericEntry\u0026gt; ordIndexes = new HashMap\u0026lt;\u0026gt;();\n \n  //field的数量\n  private final int numFields;\n \n  //内存使用量\n  private final AtomicLong ramBytesUsed;\n \n  //数据源的文件句柄\n  private final IndexInput data;\n \n  //文档数\n  private final int maxDoc;\n  // memory-resident structures\n  private final Map\u0026lt;String,MonotonicBlockPackedReader\u0026gt; addressInstances = new HashMap\u0026lt;\u0026gt;();\n  private final Map\u0026lt;String,ReverseTermsIndex\u0026gt; reverseIndexInstances = new HashMap\u0026lt;\u0026gt;();\n  private final Map\u0026lt;String,DirectMonotonicReader.Meta\u0026gt; directAddressesMeta = new HashMap\u0026lt;\u0026gt;();\n \n  //是否正在merge\n  private final boolean merging;\n}\n \n/** metadata entry for a numeric docvalues field */\n  static class NumericEntry {\n    private NumericEntry() {}\n    /** offset to the bitset representing docsWithField, or -1 if no documents have missing values */\n    long missingOffset;\n \n    /** offset to the actual numeric values */\n\t//field的在数据文件中的起始地址\n    public long offset;\n \n    /** end offset to the actual numeric values */\n\t//field的在数据文件中的结尾地址\n    public long endOffset;\n \n    /** bits per value used to pack the numeric values */\n    public int bitsPerValue;\n \n    //format类型\n    int format;\n    /** count of values written */\n    public long count;\n    /** monotonic meta */\n    public DirectMonotonicReader.Meta monotonicMeta;\n \n    //最小的value\n    long minValue;\n \n    //Compressed by computing the GCD\n    long gcd;\n \n    //Compressed by giving IDs to unique values.\n    long table[];\n    /** for sparse compression */\n    long numDocsWithValue;\n    NumericEntry nonMissingValues;\n    NumberType numberType;\n  }\n \n  /** metadata entry for a binary docvalues field */\n  static class BinaryEntry {\n    private BinaryEntry() {}\n    /** offset to the bitset representing docsWithField, or -1 if no documents have missing values */\n    long missingOffset;\n    /** offset to the actual binary values */\n\t//field的在数据文件中的起始地址\n    long offset;\n    int format;\n    /** count of values written */\n    public long count;\n \n\t//最短字符串的长度\n    int minLength;\n \n    //最长字符串的长度\n    int maxLength;\n    /** offset to the addressing data that maps a value to its slice of the byte[] */\n    public long addressesOffset, addressesEndOffset;\n    /** meta data for addresses */\n    public DirectMonotonicReader.Meta addressesMeta;\n    /** offset to the reverse index */\n    public long reverseIndexOffset;\n    /** packed ints version used to encode addressing information */\n    public int packedIntsVersion;\n    /** packed ints blocksize */\n    public int blockSize;\n  }\n```\n# 参考资料\n\n[lucene source code](https://github.com/apache/lucene-solr/tree/releases/lucene-solr/5.5.0)\n\n[lucene document](https://lucene.apache.org/core/5_5_0/)\n\n[lucene字典实现原理——FST](http://www.cnblogs.com/bonelee/p/6226185.html )","title":"Day 7 - Elasticsearch中数据是如何存储的","uid":"1703","views":"1289","votes":"8"},"_type":"doc"}
{"_id":"6159","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543392487","category_id":"2","comments":"0","has_attach":"0","id":"6159","message":"    因为刚才的一个问题，去看了一下es的文档中关于mapping参数的部分，发现了几个比较有意思的参数，index，store和enabled。下面简要说一下这几个参数的作用，有理解错和不足的地方希望大家指正。\n[u][size=16]enabled参数：[/size][/u]\n    默认是true。只用于mapping中的object字段类型。当设置为false时，其作用是使es不去解析该字段，并且该字段[size=16][b]不能被查询和store[/b][/size]，只有在_source中才能看到（即查询结果中会显示的_source数据）。设置enabled为false，可以不设置字段类型，默认为object\n[u][size=16]index参数：[/size][/u]\n    默认是true。当设置为false，表明该字段[size=16][b]不能被查询[/b][/size]，如果查询会报错。但是可以被store。当该文档被查出来时，在_source中也会显示出该字段。\n[u][size=16]store参数：[/size][/u]\n    默认false。store参数的功能和_source有一些相似。我们的数据默认都会在_source中存在。但我们也可以将数据store起来，不过大部分时候这个功能都很鸡肋。不过有一个例外，当我们使用copy_to参数时，copy_to的目标字段并不会在_source中存储，此时store就派上用场了。\n[u][size=16]三者能否同时存在：[/size][/u]\n[size=8]   [/size][size=14] 首先设置了enabled为false就不能设置store为true了，这两者冲突。而index和store是不冲突的。最后index和enabled之间的问题：enabled需要字段类型为object，而当字段类型为object时，好像不能设置index参数，试了几次都会报错。[/size][code]PUT mindex/\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;type\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;name\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n          \u0026quot;copy_to\u0026quot;: \u0026quot;name_title\u0026quot;,\n          \u0026quot;store\u0026quot;: true,\n          \u0026quot;index\u0026quot;: false\n        },\n        \u0026quot;title\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n          \u0026quot;copy_to\u0026quot;: \u0026quot;name_title\u0026quot;\n        },\n        \u0026quot;name_title\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n          \u0026quot;store\u0026quot;: true\n        },\n        \u0026quot;notenabled\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n          \u0026quot;enabled\u0026quot;: false\n        }\n      }\n    }\n  }\n}[/code][code]PUT mindex/type/1\n{\n  \u0026quot;name\u0026quot;:\u0026quot;zz\u0026quot;,\n  \u0026quot;title\u0026quot;:\u0026quot;zxx\u0026quot;,\n  \u0026quot;notenabled\u0026quot;:\u0026quot;baby\u0026quot;\n}[/code]在搜索中使用了stored_fields之后，_source不会自己出现了，要手动指定字段。stored_fields里面不能出现notenabled。[code]GET /mindex/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;title\u0026quot;: \u0026quot;zxx\u0026quot;\n    }\n  },\n  \u0026quot;stored_fields\u0026quot;: [\u0026quot;name_title\u0026quot;,\u0026quot;title\u0026quot;,\u0026quot;name\u0026quot;],\n  \u0026quot;_source\u0026quot;: [\u0026quot;name_title\u0026quot;,\u0026quot;title\u0026quot;,\u0026quot;name\u0026quot;,\u0026quot;notenabled\u0026quot;]\n}[/code]结果[code]\u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;zz\u0026quot;,\n          \u0026quot;title\u0026quot;: \u0026quot;zxx\u0026quot;,\n          \u0026quot;notenabled\u0026quot;: \u0026quot;baby\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;name\u0026quot;: [\n            \u0026quot;zz\u0026quot;\n          ],\n          \u0026quot;name_title\u0026quot;: [\n            \u0026quot;zz\u0026quot;,\n            \u0026quot;zxx\u0026quot;\n          ]\n        }[/code]看到结果，与上面的分析吻合。","title":"关于es映射mapping中的enabled，store，index参数的理解","uid":"10181","views":"347","votes":"0"},"_type":"doc"}
{"_id":"6160","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543395496","category_id":"18","comments":"0","has_attach":"0","id":"6160","message":"Elastic日报 第462期 (2018-11-28)\n\n1. 让天下没有难用的搜索 阿里搜索如何成长为贴心“暖男”\nhttp://t.cn/E2UjZ6d\n2.Elasticsearcharch索引生命周期管理探索\nhttp://t.cn/RDUxF3t\n3. 实例展示Elasticsearch集群生态,分片以及水平扩展\nhttp://t.cn/RzIQzrR\n\n编辑：江水\n归档：http://elasticsearch.cn/article/6160\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第462期 (2018-11-28)","uid":"8625","views":"229","votes":"0"},"_type":"doc"}
{"_id":"6148","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542685035","category_id":"18","comments":"0","has_attach":"0","id":"6148","message":"1、快速体验Elasticsearch 6.5带来的新特性。\n​http://t.cn/E20PA5a\n2、GitLab 11.5 将支持 Elasticsearch 6，放弃支持5.5。\n​http://t.cn/E20Pq9j\n3、ElasticSearch搜索之布尔和聚合。\n​http://t.cn/E20PxFB\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6148\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第454期 (2018-11-20)","uid":"3788","views":"187","votes":"0"},"_type":"doc"}
{"_id":"6144","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542590335","category_id":"2","comments":"1","has_attach":"0","id":"6144","message":"就在 11月14日，ElasticStack 6.5.0 发布了，此次发布带来了许多激动人心的特性，我们一起来体验一下：\n\n![WX20181118-120551@2x](https://ws1.sinaimg.cn/large/006tNbRwgy1fxcdzlhrwhj31hb0u016u.jpg)\n\n如果没有任何数据，kibana会提示我们导入sample数据，这边我选择**Try our sample data**, 然后导入全部3个样例数据，这可以让我们在没有数据的情况下快速体验新特性。\n\n### Infrastructure \u0026amp; Logs UI\n\n很多用户使用 ElasticStack 收集基础架构的日志和指标，比如系统日志、安全日志、CPU指标，内存指标等等。在6.5中，kibana 侧边栏中增加了 Infrastructure 和 Logs 两个新的 tab，让用户更简单地查看自己的基础架构，和每台主机或者容器里的日志。\n\n\n\n### logs\n\n进入logs标签页，如果当前没有数据，kibana会引导我们添加数据\n\n![WX20181118-121032@2x](https://ws2.sinaimg.cn/large/006tNbRwgy1fxck2kr3u5j31hb0u0k01.jpg)\n\n我们选择 system logs\n\n![WX20181118-121047@2x](https://ws4.sinaimg.cn/large/006tNbRwgy1fxck2qs2uyj31h50u0ti3.jpg)\n\n根据指示，我们安装部署好filebeat并启动，再次进入 logs 标签页便可以看到收集到的系统日志了\n\n![image-20181118185158451](https://ws1.sinaimg.cn/large/006tNbRwgy1fxck2sujfxj31h40u0dxw.jpg)\n\n1. **搜索过滤框**：在这里可以像在 *discover* 里一样写*query string*，并且会有输入提示\n2. **时间选择框**：可以选择需要查看的时间点，如果点了 *Stream live*，会持续监听尾部新输出的日志内容，类似 linux 命令中的*tail -f*\n3. **日志时间轴**：高亮的部位是当前查看日志所在的时间范围，对应的区域图标识了日志量\n\n假如我想实现 `tail -f /var/log/system.log | grep google.com` 一样的效果，可以打开 Stream live，并在搜索过滤框中这样输入：\n\n![WX20181118-173432@2x](https://ws3.sinaimg.cn/large/006tNbRwgy1fxck2v8k3ej31hd0u014h.jpg)\n\n很简单，很方便有木有？\n\n\n\n### Infrastructure\n\n同样在kibana的引导下安装 Metric beat，并开启system模块，启动后进入 infrastructure 标签页：\n\n![image-20181118190614385](https://ws3.sinaimg.cn/large/006tNbRwgy1fxck2y16y3j31h80u079i.jpg)\n\n这里可以直观地看到所有基础架构的指标状况，深色的内层代表主机，颜色代表了健康状况。浅灰色的外层代表了group，因为我只在自己的笔记本上做了部署，所以只能看到一个host。\n\n![image-20181118191527060](https://ws4.sinaimg.cn/large/006tNbRwgy1fxck31ygtij31h50u0tep.jpg)\n\n点击主机会弹出菜单\n\n- **View logs** : 跳转到 logs 标签页，并通过搜索过滤框指定host，只查看这台主机的日志。\n- **View metrics** : 跳转到这台主机的指标详情，可以查看历史数据\n  ![shoot](https://ws2.sinaimg.cn/large/006tNbRwgy1fxcfrhkdb5j30uv0u0gw1.jpg)\n\n\n\n## APM\n\n### Java 和 Go\n\n不负众望，继 Nodejs、Python、Ruby、Javascript 之后，Elastic APM 5.6.0 新增了对 Java 和 Golang 的支持！\n\n### Distributed Tracing\n\n在 SOA 和 MSA 大行其道的年代，如何追踪请求在各个系统之间的流动成为了apm的关键问题。\n\nElastic APM 支持 [OpenTracing](https://opentracing.io/) 标准，并在各个agent里内置了 OpenTracing 兼容的bridge\n\n以下是官网上该特性的截图：\n\n![distributed_tracing](https://ws4.sinaimg.cn/large/006tNbRwgy1fxcggc7jsqj30u00voqb6.jpg)\n\n\n\n### APM Server 监控\n\n如 ElasticStack的其他产品一般，APM也支持了监控，并可以在 Kinbana Montoring下查看监控信息：\n\n![apm_monitoring](https://ws2.sinaimg.cn/large/006tNbRwgy1fxcgjmm2lzj30tt0tvwld.jpg)\n\n### APM Server 内存占用优化\n\n通过新的基于NDJSON的协议，agent可以在采集信息后通过事件流立即发往APM server，这样 APM Server可以一个接一个地处理接收到的事件，而不是一次性地收到一大块(chunk)，这样在很大程度上减少了APM Server的内存占用。\n\n\n\n## Elasticsearch\n\n### Cross-cluster replication\n\n这里的副本并非我们平时常见的分片副本，而是通过在集群B配置一个副本indexB来追随集群A中的indexA，indexA中发生的任何变化都会同步到indexB中来。另外也可以配置一个pattern，当集群A出现符合pattern的索引，自动在集群B创建他的副本，这听起来很酷。值得一提的是，这将是[白金版](https://www.elastic.co/subscriptions)里新增的一个特性。\n\n\n\n### Minimal Snapshots\n\nsnapshot 是 es 中用来创建索引副本的特性，在之前的版本中，snapshot会把完整的 index 都保存下来，包括原始数据和索引数据等等。新的 *Minimal Snapshots* 提供了一种只备份 `_source` 内容和 `index metadata`，当需要恢复时，需要通过 reindex 操作来完成。最小快照最多可能帮你节省50%的磁盘占用，但是会花费更多的时间来恢复。这个特性可能并不适合所有人，但给恢复窗口比较长，且磁盘容量有限的用户多了一种选择。\n\n\n\n### SQL / ODBC\n\n现在可以使用 支持 ODBC 的第三方工具来连接 elasticsearch 了！我想可以找时间试试用 tableau 直连 elasticsearch会是啥效果。\n\n\n\n### Java 11\n\nJava11 是一个 LTS 版本，相信会有越来越多的用户升级到 java11\n\n\n\n### G1GC支持\n\n经过无数的测试，Elasticsearch官方宣布了在 JDK 10+ 上支持 G1GC。G1GC 相比 CMS有诸多优势，如今可以放心地使用G1GC了。(期待对ZGC的支持！)\n\n\n\n### Authorization  realm\n\nX-Pack Security中的新特性，可以对用户认证和用户授权分别配置 realm，比如使用内置的用户体系来认证，再去ldap中获取用户的角色、权限等信息。这也是白金版新增的特性。\n\n\n\n### 机器学习的新特性\n\n- 支持在同一个机器学习任务中分析多个时间系列\n- 为机器学习任务添加了新的*多分桶*(multi-bucket) 分析\n\n\n\n## Kibana\n\n### Canvas\n\nCanvas ! 我在做数据分析师的同学看到之后说太酷了，像 PPT。\n\n点击侧边栏的 canvas 标签，可以看到我们先前导入的样本数据也包含了 canvas 样例：\n\n![WX20181118-210126@2x](https://ws3.sinaimg.cn/large/006tNbRwgy1fxcilltkg9j31hd0u0h15.jpg)\n\n在 11月的 深圳开发者大会上，上海普翔 也用 canvas 对填写调查问卷的参会人员做了分析：\n\n![UNADJUSTEDNONRAW_thumb_1adc](https://ws2.sinaimg.cn/large/006tNbRwgy1fxck27lvccj30ww0ig0vw.jpg)\n\nhttps://github.com/alexfrancoeur/kibana_canvas_examples 这里有很多非常不错的 canvas 样例供大家学习，把json文件直接拖到 canvas 页面就可以导入学习了！\n\n\n\n### Spaces\n\n把 kibana 对象（比如 visualizations、dashboards）组织到独立的 space 里，并且通过 RBAC 来控制哪些用户可以访问哪些 space。这实在是太棒了，想象在一个企业里，多个部门通过kibana查询、分析数据，大家关注的dashboard肯定是不一样的，在6.5之前，我们只能通过社区插件来实现这样的需求，而大版本的升级可能直接导致插件不可用，有了 Space，我们不必再担心！\n\n![image-20181118212404768](https://ws1.sinaimg.cn/large/006tNbRwgy1fxcj8qgq4pj31hd0u0afd.jpg)\n\n\n\n### Rollups UI\n\nRollup 是 es6.4 中新增的一个特性，用来把一些历史数据压缩归档，用作以后的分析。6.5.0 中 kibana 增加了一个界面用来查看和管理 Rollup 任务。\n\n![image9](https://ws3.sinaimg.cn/large/006tNbRwgy1fxcjcyv7c1j311x0ilgog.jpg)\n\n\n\n### Data visualizer for files\n\n通过可视化的方式查看文件的结构，查看其中出现最频繁的内容：\n\n![highlights_6_5_viz-logs](https://ws4.sinaimg.cn/large/006tNbRwgy1fxcjh8470oj313e0u0qez.jpg)\n\n\n\n## Beats\n\n### Beats Central Management\n\nBeats 终于也支持中心化配置管理了！我们只需按照往常一样安装filebeat、metricbeat，然后使用 `filebeat enroll \u0026lt;kibana-url\u0026gt; \u0026lt;token\u0026gt;`，便可以通过kibana来管理beats的配置、甚至给他们打上tag：\n\n![Image from iOS](https://ws1.sinaimg.cn/large/006tNbRwgy1fxcjplgp6sj30sf0ibn0t.jpg)\n\n想一想，假如我们在上千台机器上部署filebeat，如果哪天需要批量变更配置文件，只需要通过脚本调用配置管理的API就可以了\n\n\n\n### Functionbeat\n\nFunctionbeat是一种新的beat类型，可以被部署为一个方法，而不需要跑在服务器环境上，比如  AWS Lambda function。\n\n\n\n以上就是 6.5.0 版本的主要特性，更详细的内容可以查看 https://www.elastic.co/blog/elastic-stack-6-5-0-released ，希望通过我的介绍，可以让大家了解到新版本所带来的激动人心的特性。\n\n![Image from iOS](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)","title":"ET007 ElasticStack 6.5 介绍","uid":"9765","views":"807","votes":"5"},"_type":"doc"}
{"_id":"6172","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543975052","category_id":"14","comments":"0","has_attach":"0","id":"6172","message":"day5 - es存储设备全解析\n\nElastic Search 作为一个分布式系统，它的最小单元(shard)实现基于 lucene , lucene是一个io密集cpu密集的系统。cpu密集可以通过使用更多核，更快的cpu以及优化算法来解决。而io密集部分需要搭配高性能的存储设备以及存储策略来解决。\n\n传统的服务器硬盘分为SATA,SAS硬盘以及现在最高性能的SSD硬盘，其中SSD硬盘又分为 SATA SSD,PCI-E SSD ,M.2 SSD（性能依次提升）。\n\n两者的区别在于 SATA 最高可以提供 7200转的。著名的HADOOP集群中，一半都会选择企业级SATA盘来降低存储成本。而SATA盘容易损坏以及恢复速度的问题，则交给10g高速网卡以及三副本策略来解决。\n\n如果是了解数据库领域的同学就会知道，MySQL 之类的数据库严重推荐使用SSD来做存储。TiDB这种新时代的分布式数据库甚至在安装过程中会见存储是否是高性能设备，当时低速设备时，安装将失败。\n\n### 如何查看io压力\n\n`iostat -x 1 100`\n\n可以根据 iowait , ioutil 等值来综合判断. 当iowait长期接近100%基本代表io系统出现瓶颈了。这时候可以用`iotop`命令来诊断出具体是什么进程在消耗io资源。\n\n\n### 如何测试硬盘性能\n\n通过 fio 测试 顺序读/写，随机读/写性能。\n\n顺序读\nfio -name iops -rw=read -bs=4k -runtime=60 -iodepth 32 -filename /dev/sda -ioengine libaio -direct=1\n随机读\nfio -name iops -rw=randread -bs=4k -runtime=60 -iodepth 32 -filename /dev/sda -ioengine libaio -direct=1\n顺序写\nfio -name iops -rw=write -bs=4k -runtime=60 -iodepth 32 -filename /dev/sda -ioengine libaio -direct=1\n随机写\nfio -name iops -rw=randwrite -bs=4k -runtime=60 -iodepth 32 -filename /dev/sda -ioengine libaio -direct=1\n\n更具体的测试可以参考[磁盘性能指标--IOPS、吞吐量及测试](http://blog.51cto.com/wushank/1708168)\n\n### RAID \n\n#### RAID 0 \n\n将数据分布在N块盘中，速度最快，可以享受磁盘的并行读取和写入；安全性最低，一块盘损坏，将导致所有数据丢失。\n\n![raid0.png](https://i.loli.net/2018/12/04/5c0673f515db4.png)\n\n#### RAID 1\n\n将数据同时保存在N块盘中，写入速度最慢（需要同时写多块盘）。安全性最高。\n\n![raid1.png](https://i.loli.net/2018/12/04/5c0673f411bdd.png)\n\n\n#### RAID 10 ?\n\n将RAID 1 和 RAID 0 结合起来，获得高安全性和高性能。最常用的RAID策略。同时也是TiDB，MySQL等数据库推荐的RAID策略。\n\n![raid10.png](https://i.loli.net/2018/12/04/5c0673f475d50.png)\n\n#### RAID 5 \n\nRAID 5 最低三块盘，存储数据的异或编码，在一块盘损坏时，可以提供编码恢复出数据。\n\n![raid5.png](https://i.loli.net/2018/12/04/5c0673f454d91.png)\n\n### ElasticSearch 使用低速设备的 Tips\n\n修改`index.merge.scheduler.max_thread_count`参数为1；该参数影响lucene后台的合并线程数量，默认设置只适合SDD。多个合并线程可能导致io压力过大，触发 (linux 120s timeout)[https://cyberdak.github.io/es/2018/07/01/es-force-merge-cause-es-down].\n\n\n### 存储策略\n\n1. 避免单机存储过多数据，如果单机故障，将导致集群需要大量数据，影响集群的吞吐量，特别是发生在高峰时候更会影响业务。千兆网卡每小时可以同步的数据为463gb，可以参考这个速度结合资深集群网卡以及存储来调节每个节点存储的数据量。\n2. 存储有条件使用RAID10，增加单节点性能以及避免单节点存储故障\n\n### RAID卡策略\n\n根据服务器RAID卡的等级不同，高级的RAID卡可以使用 write-back 写策略，数据写入会直接写入到缓存中，随后刷新到硬盘上。当主机掉电时，由RAID卡带的电池来保证数据成功写入到硬盘中。write back的设置需要电池有电才能支持，而某些场景可以设置为`force write-back`(即使电池没电了，也要写缓存),从而提高写入性能。","title":"Day 5 - Elasticsearch 存储设备全解析","uid":"4063","views":"511","votes":"2"},"_type":"doc"}
{"_id":"6131","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542093499","category_id":"18","comments":"0","has_attach":"0","id":"6131","message":"1、Elasticsearch中国开发者大会精彩回看。\nhttp://t.cn/EAE6hvv\n​2、从平台到中台 | Elasticsearch 在蚂蚁金服的实践经验。\nhttp://t.cn/EATs2iu\n3、一文介绍Spring Data Elasticsearch。\nhttp://t.cn/EAE698A\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6131\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第447期 (2018-11-13)","uid":"3788","views":"269","votes":"0"},"_type":"doc"}
{"_id":"6129","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541903876","category_id":"18","comments":"0","has_attach":"0","id":"6129","message":"1.利用Elastic Machine Learning改善GoDaddy用户体验。\nhttp://t.cn/EAKdvJf\n2.使用ELASTICSEARCH，LOGSTASH和KIBANA可视化数据。\nhttp://t.cn/EA9zCvV\n3.使用Golang的Elasticsearch查询示例。\nhttp://t.cn/RRmNcop\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6129\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第445期 (2018-11-11)","uid":"4460","views":"271","votes":"0"},"_type":"doc"}
{"_id":"6128","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541812570","category_id":"2","comments":"0","has_attach":"0","id":"6128","message":"1、jcseg：一个集成更多NLP相关功能的分词插件\n\n     http://t.cn/R5iirZ2\n\n2、PB级Elasticsearch集群的分片分配策略\n\n     http://t.cn/EAfPVjT\n\n3、使用Elasticsearch在地图上查找特定元素的方法\n\n     http://t.cn/EAfP8Bi\n\n\n\n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/6128\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第444期 (2018-11-10）","uid":"1874","views":"313","votes":"0"},"_type":"doc"}
{"_id":"6126","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541734460","category_id":"2","comments":"0","has_attach":"1","id":"6126","message":"## Elasticsearch在数据湖中的地位\n\n[attach]3101[/attach]\n\n* **解读Elasticsearch：**\n  * **定位：** ElasticSearch作为高扩展分布式搜索引擎，主要满足于海量数据实时存储与检索、全文检索与复查查询、统计分析。在如今大数据时代已经成为较popular的存储选择。\n  * **特点：** 由于Elasticsearch使用java作为开发语言、使用lucene作为核心处理索引与检索，尤其是使用简单的RestApi隐藏lucene的复杂，使得上手非常容易、海量数据索引与检索极快。es集群由于分片和副本的机制实现了自动容错、高可用、易扩展。\n  * **开源且流行：** Elasticsearch支持插件机制，社区活跃度高、官网更新频繁：提供了分析插件、同步插件、hadoop插件、es-sql插件、可视化插件、性能监控插件等，可以让我们站在巨人的肩膀上专心研究搜索需求\n  * **不支持：** 不支持频繁更新、关联查询、事务\n\n## 最优部署架构\n\n### 角色划分\n\n* **es分为三种角色：** master、client、data，三种角色根据elasticsearch.yml配置中node.master、node.data区分，分别为true false、false false、true true\n\n* **master：** 该节点不和应用创建连接，主要用于元数据(metadata)的处理，比如索引的新增、删除、分片分配等，master节点不占用io和cpu，内存使用量一般\n\n* **client：** 该节点和检索应用创建连接、接受检索请求，但其本身不负责存储数据，可当成负载均衡节点，client节点不占用io、cpu、内存\n\n* **data：** 该节点和索引应用创建连接、接受索引请求，该节点真正存储数据，es集群的性能取决于该节点个数（每个节点最优配置情况下），data节点会占用大量的cpu、io、内存\n\n* **各节点间关系：** master节点具备主节点的选举权，主节点控制整个集群元数据。client节点接受检索请求后将请求转发到与查询条件相关的的data节点的分片上，data节点的分片执行查询语句获得查询结果后将结果反馈至client，在client对数据进行聚合、排序等操作将最终结果返回给上层请求\n\n### 资源规划      \n\n* **master节点：** 只需部署三个节点，每个节点jvm分配2-10G，根据集群大小决定\n* **client节点：** 增加client节点可增加检索并发,但检索的速度还是取决于查询所命中的分片个数以及分片中的数据量。如果不清楚检索并发，初始节点数可设置和data节点数一致，每个节点jvm分配2-10\n* **data节点：** ①单个索引在一个data节点上分片数保持在3个以内；②每1GB堆内存对应集群的分片保持在20个以内；③每个分片不要超过30G。\n* **data节点经验：**\n  * 如果单索引每个节点可支撑90G数据，依此可计算出所需data节点数 。\n  * 如果是多索引按照单个data节点jvm内存最大30G来计算，一个节点的分片保持在600个以内，存储保持在18T以内。\n  * 主机的cpu、io固定，建议一台主机只部署一个data节点，不同角色节点独立部署，方便扩容\n  * 每条数据保持在2k以下索引性能大约3000-5000条/s/data节点，增加data节点数可大幅度增加索引速率，节点数与索引效率的增长关系呈抛物线形状​\n\n#### 优秀的插件与工具\n\n* **ik分词器：** es默认分词器只支持英文分词，ik分词器支持中文分词\n\n* **head数据查询工具：** 类似于mysql的Navicat\n\n* **logstash：** 数据处理管。采样各种样式、大小的数据来源，实时解析和转换数据，选择众多输出目标导出数据\n\n* **x-pack性能监控：** 获取进程运行时资源与状态信息并存储至es中。可通过kibana查看es、logstash性能指标，试用版包括集群状态、延迟、索引速率、检索速率、内存、cpu、io、磁盘、文件量等还可以看到集群数据负载均衡时的情况。商用版还支持安全、告警等功能\n\n* **kibana可视化工具：** es的可视化工具可制作各种图表，可在该工具上执行dsl语句灵活操作es\n\n* **es-sql：** 用sql查询elasticsearch的工具，将封装复杂的dsl语句封装成sql\n\n* **beats：** 轻量级的数据采集工具，可监控网络流量、日志数据、进程信息（负载、内存、磁盘等），支持docker镜像的file采集\n\n* **repository-hdfs：** 该插件支持将es中离线数据转存至hdfs中长期存储\n\n  ​\n\n## Elasticsearch优化经验\n\n-   参数调优\n\n    - 开启内存锁，禁止swapping\n\n      执行linux命令(临时生效)\n\n      ```shell\n      ulimit -l unlimited\n      ```\n\n      修改主机配置：/etc/security/limits.conf\n\n      ```shell\n      * soft memlock unlimited\n      * hard memlock unlimited\n      ```\n\n      修改es配置：config/elasticsearch.yml\n\n      ```shell\n      bootstrap.memory_lock : true\n      ```\n\n    - 调大文件描述符数量\n\n       执行linux命令(临时生效)\n\n      ```shell\n      ulimit -n 65535\n      ```\n\n      修改linux配置文件：/etc/security/limits.conf\n\n      ```shell\n      * soft nofile 65536\n      * hard nofile 65536\n      ```\n\n    - 调大最大映射数\n\n      执行linux命令(临时生效)\n      ```shell\n      sysctl -w vm.max_map_count=262144\n      ```\n      修改linux配置文件：/etc/sysctl.conf \n      ```shell\n      vm.max_map_count=262144\n      ```\n\n-   索引配置\n\n    - settings:{efresh_interval}：数据写入刷新间隔，默认1s，调整增加该值可以减少写入压力、增加写入速度，如设为60\n\n      ```json\n      {\n        \u0026quot;settings\u0026quot;: {\n          \u0026quot;refresh_interval\u0026quot;: \u0026quot;60s\u0026quot;\n        }\n      }\n      ```\n\n    - mappings:{dynamic}： 禁止es自动创建字段，仅允许预先设定好的字段存入es，防止索引结构混乱\n      ```json\n      {\n         \u0026quot;mappings\u0026quot;: {\n           \u0026quot;mytype\u0026quot;: {\n             \u0026quot;dynamic\u0026quot;: false\n           }\n         }\n      }\n      ```\n\n    - _all：建议禁用\n\n      ```json\n      {\n        \u0026quot;_all\u0026quot;: {\n           \u0026quot;enable\u0026quot;: false\n          }\n      }\n      ```\n\n    - keyword字段属性: ingore_above超过多少字符不写入，keyword一般用于精确查询，不能写入太长。 \n\n      ```json\n      {\n        \u0026quot;name\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n            \u0026quot;ingore_above\u0026quot;: 1000\n         } \n      }\n      ```\n\n    - index属性：将 不作为查询字段的index值设为false\n\n      ```json\n      {\n          {\n            \u0026quot;content\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n              \u0026quot;index\u0026quot;: \u0026quot;false\u0026quot;\n            }\n          }\n      }\n      ```\n\n-   JVM内存溢出处理\n\n          ​\t防止es节点内存溢出后处于僵死状态且无法恢复，影响整个集群，在进程出现OOM时让进程宕掉，退出ES集群并引发告警，然后重启。\n    \n          ​\t在config/jvm.options中增加JVM启动参数：\n\n    ```json\n            -XX:+ExitOnOutOfMemoryError\n    ```\n\u0026gt; 该参数在jdk 1.8.0_92版本上线\n\n* 数据生命周期\n\n  ​\tes中的开启状态的索引都会占用堆内存来存储倒排索引，过多的索引会导致集群整体内存使用率多大，甚至引起内存溢出。所以需要根据自身业务管理历史数据的生命周期，如近3个月的数据开启用于快速查询；过去3-6月的数据索引关闭以释放内存，需要时再开启；超过6个月的可以生成快照保存至hdfs并删除索引，需要的时候从hdfs选择需要的索引恢复至集群中进行查询\n\n  ​\t生产上常常使用logstash+索引模板的方式按照一定时间创建新的索引，例如按天创建索引，索引的命名可能是index-yyyy-mm-dd，每天生产不同的索引，清除历史数据时可直接关闭或删除\n\n  ​\t需要注意的是：如何按照logstash默认的时间分割索引会有8个小时的误差，所以需要在logstash中将真实数据中的时间字段作为分割条件，保障按照业务时间分割索引\n\n* 路由查询\n\n  ​\t在将数据写入es时，指定一个字段作为路由字段，es会将该字段进行hash计算写入到对应的分片上；查询时根据查询条件中的路由值，直接查找所在的分片，**大幅度提高查询速度**。\n\n  ​\t需要注意的是：路由字段必须是随机分布，否则会导致分片数据不平均引发的主机存储使用不平均，可以作为路由字段的：如业务流水、省份、系统编码等。\n\n* 过滤器\n\n  ​\tES中的查询操作分为2种：查询（query）和过滤（filter），查询默认会计算每个返回文档的得分，然后根据得分排序；而过滤（filter）只会筛选出符合的文档，并不计算得分，且它可以缓存文档。单从性能考虑，过滤比查询更快而且更节省io资源。过滤适合在大范围筛选数据，而查询则适合精确匹配数据。开发时应先使用过滤操作过滤数据，然后使用查询匹配数据\n\n* 查询限制\n\n  ​\t限制是为了保证es集群的稳定性。限制的内容包括：查询范围、单次查询数量等，过大的查询范围不仅会导致查询效率低，而且会是es集群资源耗费急剧增加，甚至引起es集群崩溃；单次查询数量限制是为了保证内存不会被查询内存大量占用，就是分页原理，es默认可以查询10000条数据\n\n* 批量导入\n\n\n  ​\t如果你在做大批量导入，考虑通过设置 `index.number_of_replicas: 0`关闭副本。把每个索引的 `index.refresh_interval` 改到 -1关闭刷新。导入完毕后再开启副本和刷新\n\n  ​","title":"elasticsearch优秀实践","uid":"3625","views":"921","votes":"5"},"_type":"doc"}
{"_id":"3697","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541183047","category_id":"44","comments":"0","has_attach":"1","id":"3697","message":"欢迎来到 Elastic 社区电台的第七期节目，我们本期节目的嘉宾是来自于今日头条广告系统的工程师徐磊和张海雷，今日头条作为业界非常流行的新闻资讯类软件，坐拥上亿互联网用户，其内部目前正大量使用了 Elasticsearch 来解决各式各样的业务问题，最早从15年开始的接触，到如今多达几十个集群的规模，以及成为公司平台化的基础服务，承载着PB级规模的数据，快来收听本期节目来一探究竟吧。\n\n## 嘉宾\n\n- 张海雷，今日头条广告系统研发工程师，现负责ES平台的运维以及平台化建设。\n- 徐磊，今日头条广告系统研发工程师，有3年大规模ELK集群运维及平台化经验。\n\n[attach]3090[/attach]\n\n\n## 主持人\n\nElastic 技术布道师，曾勇（Medcl）。\n\n## 收听\n\n可以点击下面的任意链接来收听（时长约 34 分钟）：\n\n- Apple iTunes: [https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/](https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/)\n- 喜马拉雅：[https://www.ximalaya.com/keji/14965410/133699689](https://www.ximalaya.com/keji/14965410/133699689)\n- 蜻蜓 FM：[https://www.qingting.fm/channels/244978/programs/10050814](https://www.qingting.fm/channels/244978/programs/10050814)\n\n## 关于今日头条\n\n北京字节跳动科技有限公司成立于2012年3月，公司的主要产品“今日头条”客户端，是一款基于数据挖掘技术的个性化推荐引擎产品。“今日头条”致力于帮助用户在移动互联网上方便快捷地获取最有价值的信息，它会根据用户的兴趣为其推荐内容，这是对传统信息分发方式的一次巨大颠覆\n\n“今日头条”面市后，迅速获得市场认可，长期占据苹果应用商店新闻类榜首。目前已有超过160万个个人、组织开设头条号。\n\n## 关于 Elastic 社区电台\n\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\n\n","title":"访谈：Elastic 在今日头条广告系统中的大规模应用","uid":"1","views":"369","votes":"0"},"_type":"doc"}
{"_id":"3681","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541072226","category_id":"18","comments":"2","has_attach":"0","id":"3681","message":"1.Elasticsearch的Query Cache梳理\nhttp://t.cn/EwtwDxL\n从Elastic APM发送数据到Logstash或Kafka\nhttp://t.cn/EwtAzg3\n使用Elasticsearch增强Wordpress搜索功能\nhttp://t.cn/EwtAyhK\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/3681\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第435期 (2018-11-01)","uid":"668","views":"169","votes":"0"},"_type":"doc"}
{"_id":"119","_index":"forum-mysql","_score":1,"_source":{"addtime":"1481644510","category_id":"2","comments":"7","has_attach":"0","id":"119","message":"[i][b]A customizable importer from mysql to elasticsearch.[/b][/i]\n可定制的 elasticsearch 数据导入工具 ——基于 elasticsearch 的 JS API\n \n \n【github 项目地址】\n[url]https://github.com/parksben/mysql_2_elasticsearch[/url] \n\n\n【主要功能】\n1. 完全使用 JS 实现数据从 MySQL 到 elasticsearch 的迁移；\n2. 可批量导入多张 MySQL 表；\n3. 可自定义的数据迁移规则（数据表/字段关系、字段过滤、使用正则进行数据处理）；\n4. 可自定义的异步分片导入方式，数据导入效率更高。\n\n\n【一键安装】[code]npm install mysql_2_elasticsearch[/code]\n\n【快速开始（简单用例）】[code]var esMysqlRiver = require('mysql_2_elasticsearch');\n\nvar river_config = {\n  mysql: {\n    host: '127.0.0.1',\n    user: 'root',\n    password: 'root',\n    database: 'users',\n    port: 3306\n  },\n  elasticsearch: {\n    host_config: {               // es客户端的配置参数\n      host: 'localhost:9200',\n      // log: 'trace'\n    },\n    index: 'myIndex'\n  },\n  riverMap: {\n    'users =\u0026gt; users': {}         // 将数据表 users 导入到 es 类型: /myIndex/users\n  }\n};\n\n\n/*\n** 以下代码内容：\n** 通过 esMysqlRiver 方法进行数据传输，方法的回调参数(一个JSON对象) obj 包含此次数据传输的结果\n** 其中：\n** 1. obj.total    =\u0026gt; 需要传输的数据表数量\n** 2. obj.success  =\u0026gt; 传输成功的数据表数量\n** 3. obj.failed   =\u0026gt; 传输失败的数据表数量\n** 4. obj.result   =\u0026gt; 本次数据传输的结论\n*/\n\nesMysqlRiver(river_config, function(obj) {\n  /* 将传输结果打印到终端 */\n  console.log('\\n---------------------------------');\n  console.log('总传送：' + obj.total + '项');\n  console.log('成功：' + obj.success + '项');\n  console.log('失败：' + obj.failed + '项');\n  if (obj.result == 'success') {\n    console.log('\\n结论：全部数据传送完成！');\n  } else {\n    console.log('\\n结论：传送未成功...');\n  }\n  console.log('---------------------------------');\n  console.log('\\n(使用 Ctrl + C 退出进程)');\n  /* 将传输结果打印到终端 */\n});[/code]\n\n【最佳实现（完整用例）】[code]var esMysqlRiver = require('mysql_2_elasticsearch');\n\n/*\n** mysql_2_elasticsearch 的相关参数配置(详情见注释)\n*/\n\nvar river_config = {\n\n  /* [必需] MySQL数据库的相关参数(根据实际情况进行修改) */\n  mysql: {\n    host: '127.0.0.1',\n    user: 'root',\n    password: 'root',\n    database: 'users',\n    port: 3306\n  },\n\n  /* [必需] es 相关参数(根据实际情况进行修改) */\n  elasticsearch: {\n    host_config: {               // [必需] host_config 即 es客户端的配置参数，详细配置参考 es官方文档\n      host: 'localhost:9200',\n      log: 'trace',\n      // Other options...\n    },\n    index: 'myIndex',            // [必需] es 索引名\n    chunkSize: 8000,             // [非必需] 单分片最大数据量，默认为 5000 (条数据)\n    timeout: '2m'                // [非必需] 单次分片请求的超时时间，默认为 1m\n    //(注意：此 timeout 并非es客户端请求的timeout，后者请在 host_config 中设置)\n  },\n\n  /* [必需] 数据传送的规则 */\n  riverMap: {\n    'users =\u0026gt; users': {            // [必需] 'a =\u0026gt; b' 表示将 mysql数据库中名为 'a' 的 table 的所有数据 输送到 es中名为 'b' 的 type 中去\n      filter_out: [                // [非必需] 需要过滤的字段名，即 filter_out 中的设置的所有字段将不会被导入 elasticsearch 的数据中\n        'password',\n        'age'\n      ],\n      exception_handler: {           // [非必需] 异常处理器，使用JS正则表达式处理异常数据，避免 es 入库时由于类型不合法造成数据缺失\n        'birthday': [                // [示例] 对 users 表的 birthday 字段的异常数据进行处理\n          {\n            match: /NaN/gi,          // [示例] 正则条件(此例匹配字段值为 \u0026quot;NaN\u0026quot; 的情况)\n            writeAs: null            // [示例] 将 \u0026quot;NaN\u0026quot; 重写为 null\n          },\n          {\n            match: /(\\d{4})年/gi,    // [示例] 正则表达式(此例匹配字段值为形如 \u0026quot;2016年\u0026quot; 的情况)\n            writeAs: '$1.1'          // [示例] 将 \u0026quot;2015年\u0026quot; 样式的数据重写为 \u0026quot;2016.1\u0026quot; 样式的数据\n          }\n        ]\n      }\n    },\n    // Other fields' options...\n  }\n\n};\n\n\n/*\n** 将传输结果打印到终端\n*/\n\nesMysqlRiver(river_config, function(obj) {\n  console.log('\\n---------------------------------');\n  console.log('总传送：' + obj.total + '项');\n  console.log('成功：' + obj.success + '项');\n  console.log('失败：' + obj.failed + '项');\n  if (obj.result == 'success') {\n    console.log('\\n结论：全部数据传送完成！');\n  } else {\n    console.log('\\n结论：传送未成功...');\n  }\n  console.log('---------------------------------');\n  console.log('\\n(使用 Ctrl + C 退出进程)');\n});[/code]\n\n【注意事项及参考】\n1. elasticsearch数据导入前请先配置好数据的 mapping；\n2. \u0026quot;host_config\u0026quot; 更多参数设置详见 [es官方API文档] https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/configuration.html\n3. mysql 表的自增 id 将自动替换为 \u0026quot;表名+_id\u0026quot; 的格式，如：\u0026quot;users_id\u0026quot;；\n4. 如出现数据缺失情况，请注意查看 elasticsearch 终端进程或日志，找出未成功导入的数据，通过设置 exception_handler 参数处理它。","title":"可定制的 elasticsearch 数据导入工具 ——mysql_2_elasticsearch","uid":"2096","views":"2383","votes":"0"},"_type":"doc"}
{"_id":"120","_index":"forum-mysql","_score":1,"_source":{"addtime":"1481778997","category_id":"14","comments":"33","has_attach":"1","id":"120","message":"[b]尝鲜[/b]\n\n10月26日，Elasticsearch5.0.0 GA终于放出，携程ES Ops团队也在第一时间在DEV和UAT环境分别进行了2.4.0 至5.0.0的升级和测试。升级完成后，除了部分Query不向前兼容（主要是Filtered Query)，需要在应用端做一些修改以外，未发现其他问题。通过监控系统看对比升级前后的主要系统指标，在同等索引量的情况下，CPU使用率有明显下降 ( 30% - 50%左右) ，相信性能方面5.0应该是有较大提升的。 \n\n在测试环境稳定运行了2周以后，我们决定选定一个生产集群进行升级，考验新版本在更为复杂的用户环境下的表现。 出于对业务影响最小化的考虑，用于日志分析的集群被圈定为升级目标。该集群也是携程十几个集群中规模最大的一个，共有120个数据结点运行于70台物理机上，总数据量接近1PB。\n\n升级前需要做一些准备工作，下载官方的Migration Helper插件，检查集群设置和索引的兼容性。对于不兼容的配置项，MH会详尽列出，其中标注为红色部分为为升级前必须修改项。1.x版本创建的索引，是无法直接升级到5的，需要先在2.x集群里做一次reindex 。 MH提供了不兼容索引扫描功能，对于找到的不兼容索引，可以直接在UI上发起reindex操作，等待结束即可。 如果是用于业务搜索集群，数据可能比较重要，建议升级前做一个Snapshot，万一升级过程出现意外，可以回退版本从备份里快速恢复数据。我们的日志集群数据量极大，也没有对数据100%不丢的要求，因此升级前没有做Snapshot。 做完所有的准备工作后，预先通知所有用户集群升级的时间以及可能产生的影响，选定了周五深夜用户低峰期，开始正式升级工作。 \n\n首先通过Ansible将新版本批量部署到所有结点并统一配置，紧接着对原有集群做了Full Stop，校验所有的ES已经停下后，开始Full Start。整个过程比较顺利，所有结点正常启动，数据恢复完成后，集群重新回到正常服务状态。\n\n周末两天运行，未发现有任何的异样，CPU利用率也降了不少，看起来很靠谱……直到周一\n\n\n[b]踏坑[/b]\n\n周一早上，随着用户访问量高峰来临，马上浮现出一个诡异的现象： 索引速率遇到了瓶颈，数据开始在前置的消息队列(Kafka)里堆积。 从监控数据看，尽管所有的数据结点CPU消耗都比上周同期低，磁盘IO也很低，但索引速率却低了很多。反复对比查看升级前后各类监控指标后，终于发现一个可疑点，所有结点的网络流量比升级前高了好几倍！  在集群架构上，我们是单独架设了几台client node做为数据写入和分发的入口，现在这几个node的网络流量已经饱和，成为数据写入的瓶颈。一开始，怀疑是否2.4启用了tcp压缩，而5.0取消了，但翻查官方文档后发现transport.tcp.compress在2.4和5.0里默认都是关闭的！ 这时候只有两个解决办法了，要么启用tcp压缩，要么扩容client node。 先考虑了一下tcp压缩的方案，快速扒了一下ES源码，在transport.TcpTransport这个类里，sendRequest和sendResponse两个方法会根据transport.tcp.compress设置来决定发送的消息是否要经过压缩，而在messageReceived方法则会读取消息头部的状态信息，探测消息是否经过压缩以及压缩的方法，而后决定是否需要解压，以及采用的解压方式。 这样看起来，ES是允许tcp压缩和不压缩的结点之间通讯的，那么只对client node启用压缩应该就可以了。测试环境测试过后，验证了想法的可行性。于是对生产的client node开启tcp压缩，同时在数据发送端(hangout的ES output)也启用tcp压缩，重启client node后入口网络流量降到和之前2.4差不多的程度，问题得到规避。 针对这个问题在Github上提交了issue https://github.com/elastic/elasticsearch/issues/21612， 但未得到官方合理的解释。\n\n解决好这个问题，另外一个问题来了，很多执行大量历史数据搜索的用户反映出不了结果。 从监控数据看，这类查询的搜索耗时非常久，直到网关300秒超时（查询api前置的nginx代理)。我们之前对集群设置过Global Search timeout为60s，用来保护集群资源过多被超高代价的查询消耗，在2.4版本是有效果的，现在看来不起作用了。手动测试了一下，这个参数果然失效！ 于是向官方报告了第2个问题：https://github.com/elastic/elasticsearch/issues/21595 。 这个问题很快被官方确认为Bug，修复也很快加入到了5.0.2。 为了规避这个问题，我们只好临时修改了一下Kibana以及第三方API访问要经过的nginx proxy，默认为所有的search request加入一个超时选项。此后，问题有一些缓解，但仍然发现用户查询大范围历史数据时，部分用于存储历史数据的结点响应很慢。\n\n我们的集群是做了冷热分离的结构的，热节点主要承担写入和存放过去24小时数据，冷结点没有写入，查询频率也低，所以为了最大化利用硬件资源，一台物理机上跑了3个实例，这样一台128GB内存的机器可以存放下近30TB的索引。查看冷结点的监控数据，看到用户查询期间磁盘的read IO非常高，直接将磁盘IO Util%撑到100%，并且可持续数小时，同时search thread pool有大量的active thread处于无法完成状态，search queue不断攀升直至饱和、开始reject。 表象上看search thread似乎一直在尝试从磁盘大量读取数据，一次search甚至可以持续几十分钟至一个小时，耗尽了所有的搜索线程，导致拒绝后续的搜索服务。 于是Github上报了第3个issue: https://github.com/elastic/elasticsearch/issues/21611  这个问题找到解决办法之前，我们只能通过反复重启有问题的冷结点来缓解。 和官方讨论过程中，得知5.0在Lucene文件访问方式上有一个比较大的改动，2.4使用mmapfs读取索引文件的部分，而5.0以后改为用mmapfs读取索引文件的全部。怀疑问题和这个变动有关，尝试将所有索引文件的设置改为NIOFS后，问题迎刃而解。 搜索性能一下回到了2.4时代，再也没出现搜索线程超长时间执行的问题。之后找时间复现了这个问题，并抓取了线程栈，看到长时间执行的搜索线程一直在做Global Ordinal的构造工作。 至于为何会这样，还不清楚。 从官方给出的信息看，底层索引文件的访问模式是没有变化的，仅仅是将文件读取方式全部改成了mmapfs，理论上应该性能更好，但是看起来在我们这种一台机器跑多个ES实例，所有分配的heap为系统缓存3倍的极端用例下，大范围的数据搜索可能造成过高的磁盘读IO，集群性能指数级下降。\n\n以上问题前后耗了4天才完全规避掉，支持团队连续熬夜后集群总算回复到平稳状态。然而好景不长，运行一段时间以后，数据结点出现疑似内存泄漏现象。结点总数据没怎么增加、甚至还有减少的情况下，heap使用率一只呈攀升趋势，Old GC无法回收内存。这个问题对用户影响较小，通过监控我们可以及时发现内存即将用尽的结点，做一次重启很快就恢复了。 为排查根源，我们对一个有问题的结点做了dump，通过MAT工具分析，看到meta data相关的一个alias对象被实例化了有6600万次之多！ 在Github上提交了第四个issue: https://github.com/elastic/elasticsearch/issues/22013，不多久被确认为已知问题https://github.com/elastic/elasticsearch/pull/21284 ,在5.0.1已经修复。\n\n最后还存在一个master node内存泄漏的问题，这个问题在2.4.0时代就存在了，升级到5.0.0以后依然没有修复。由于我们的master node和data node是分离的，所以这个问题比较容易通过监控发现，解决方式也很简单和迅速，重启master node即可，对用户完全无影响。之后不久，5.0.2版本正式发布，release notes里提到了对这个问题的修复 https://github.com/elastic/elasticsearch/pull/21578 。\n\n上周周末我们将集群rolling upgrade到了5.0.2，global search timeout失效和两个内存泄漏的问题从根源上解决掉了。 网络流量增大的问题依然存在，仍然需要通过启用client结点的transport.tcp.compress规避。 冷结点搜索性能的问题没看到有提及，估计没解决，安全起见，还是保持索引的文件系统为NIOFS。升级完成运行一段时间后，可以肯定，5.0.2已经比较稳定。\n\n\n[b]心得[/b]\n\n升到5.0.2后，对于其中一组数据结点这两天特意加了点索引负载，通过监控数据将v5.0.2与2.4.0做实际运行环境的索引吞吐量对比。\n\n[attach]371[/attach]\n\n[attach]370[/attach]\n \n在近似的CPU使用率和load情况下，5.0.2能够支撑更大的吞吐量。另外5.0带来的Instant aggregation功能，对于跨多个索引的时序类型数据的聚合也可以有效Cache了，在使用Kibana的时候提速感觉非常明显。\n\n升级过程虽然遇到很多波折，但由于集群架构上做了角色分离(client,master,data)和冷热分离，因而Bug引起的故障比较容易被限定在一个较小的范围而不至于影响所有的功能和所有的用户。 故障点定位更加容易，规避措施也更容易实施。 部分规避措施实施过程中甚至对用户是完全无影响的，比如: 重启内存泄漏的master node)。详尽的监控为问题的发现和诊断提供了有力的支持。\n\nElasticsearch是非常复杂的系统，官方的测试无法覆盖所有的用例场景和数据规模，一些极端的应用场景可能触发某个深藏的Bug或者缺陷而陷入困境。 因此对于稳定性要求极高的应用，最好还是采用经过长时间考验的版本，比如v2.4.2。","title":"Day 14: Elasticsearch 5 入坑指南","uid":"81","views":"19508","votes":"20"},"_type":"doc"}
{"_id":"123","_index":"forum-mysql","_score":1,"_source":{"addtime":"1483610708","category_id":"15","comments":"4","has_attach":"0","id":"123","message":"[list]\n[*]重新看lucene源码[/*]\n[*]看es源码[/*]\n[*]对比lucene和es[/*]\n[*]基于lucene实现自己的搜索框架[/*]\n[/list]\n","title":"2017年学习内容","uid":"2200","views":"2603","votes":"2"},"_type":"doc"}
{"_id":"129","_index":"forum-mysql","_score":1,"_source":{"addtime":"1484283797","category_id":"2","comments":"6","has_attach":"1","id":"129","message":"[attach]396[/attach]\n 最近 MongoDB 的安全事件闹得沸沸扬扬，应该不少人都听说了吧，事情大概是，因为 MongoDB 默认的安全设置造成了数据外泄并且被黑客勒索才能找回数据，想了解的，这里有几个链接：\n[url]http://www.jianshu.com/p/48d17a69e190[/url]\nhttp://mt.sohu.com/20170107/n478047698.shtml​ \nhttp://bbs.tianya.cn/post-itinfo-503786-1.shtml​ \n \n安全从来不是等到出事才要注意的事情，可以说安全是第一重要的事情，不管你是公司的CTO、技术总监、运维总监、架构师还是一线工程师，都应该有安全意识，好了，废话不多说了，Elasticsearch 的用户现在越来越多了，有些已经成为公司的基础服务，所以数据的安全非常重要，今天主要给大家介绍 Elasticsearch 围绕安全方面的的几点使用事项：\n \n[b]下载安装[/b]\n \n     请使用正规渠道下载 Elasticsearch，首选官方网站，下载完成，记得要验证下载文件的 sha1值和官网下载的提供的sha1值进行对比，避免下载过程中被人拦截破坏文件，甚至注入恶意代码。\n不要随便安装第三方的插件，插件有可能引入安全漏洞甚至本身自带后门，需谨慎使用。\n    链接君：[url]https://www.elastic.co/downloads[/url] \n \n \n[b]使用最新的 Elasticsearch[/b]\n \n    请关注 Elastic 网站，及时更新升级 Elasticsearch 的最新版本，Elasticsearch 每次版本发布都会优化和改进一部分功能，尤其是安全漏洞的补丁，仔细阅读 Elasticsearch 的更新记录，Elasticsearch 的版本遵照 [url=http://semver.org/lang/zh-CN/]语义化版本[/url] ，所以小版本间应该是能够无缝升级的，建议及时本地测试和线上更新，升级前，记得 snapshot 做好备份。\n    链接君：[url]https://www.elastic.co/downloads[/url]\n \n \n[b]修改默认的 Elasticsearch 集群名称[/b]\n \n     Elasticsearch 默认的集群名称是 elasticsearch，请在生成环境上一定要修改成其他的名称，并且不同的环境和不同的集群要保证不相同，监控集群节点情况，如果有未知节点加入，一定要及时预警。\n    文档君：[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html#cluster.name[/url]\n \n [b]不要暴露 Elasticsearch 在公网上[/b]\n \n      Elasticsearch 默认端口是9200，绑定的是本机127.0.0.1的这个 ip，这个默认参数其实很安全，但是有很多人想要绑定其他的 lan 口或者公网的 ip，可以修改相应参数，记住，修改有风险，如果确实需要将 Elasticsearch 暴露在公网环境，请修改特定的端口绑定IP，不要直接修改参数： network.host，而是要分别修改：http.port 来绑定 HTTP 协议9200 端口的 IP（RESTful 接口调用），修改：transport.tcp.port 对应的 TCP 9300 端口的 IP（集群内通信），如果你不需要 http 端口，你干脆禁用掉，另外还需要在 Elasticsearch 之上加上成熟的安全防护措施（注意是成熟的！），在这里提供几种方案：\n[list=1]\n[*]9200的 HTTP 接口之上加上 Nginx 来提供 Http Basic-Auth 的基本的身份认证，辅助 SSL 证书进行传输层的加密，Nginx 进一步限制可接受 Verb 请求类型及可被操作的索引前缀。[/*]\n[*]使用 Elastic 的 X-Pack 插件，同样提供了 Http Basic-Auth 和 SSL 传输层的加密，X-Pack 还能提供内外 Elasticsearch 集群节点间的流量加密，避免旁路攻击。[/*]\n[/list]\n \n     文档君：https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html#common-network-settings \n \n[b]禁用批量删除索引[/b]\n \nElasticsearch 支持通过_all（全部）和通配符（*）来批量删除索引，在生产环境，这个有点危险，你可以通过设置： action.destructive_requires_name: true 来禁用它。\n\n[b]安全使用动态脚本[/b]\n\n[b]     [/b]Elasticsearch 的脚本很方便的可以对数据进行操作，不过如果你暂时没有用上，还请禁用它（Elasticsearch 在1.2.x 以后已经默认禁用了），如果你已经在使用动态脚本，比如 Groovy，它不是沙盒机制的脚本引擎，启用 inline 或 store 类型的groovy 有安全风险，请限制脚本的接触方，比如通过模板的方式来限制脚本的调用，只需要执行特定预先定义好的脚本，对调用参数进行过滤和参数值的检测，做好验证，同时各种日志都必须要保留好，方便进行日志分析，异常的调用和请求一定要有发现和预警机制。\n      Elasticsearch 默认启用了  [url=https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-security.html#java-security-manager]Java Security Manager [/url]，但还请正确配置其白名单。\n      使用 Groovy 或者JavaScript 等脚本的用户，尽快迁移到 Painless 脚本，Painless 更快更安全。\n      文档君：[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-security.html[/url]\n \n[b]给 Elasticsearch 服务器加固[/b]\n \n     服务器加固是一个必备流程，不管上面运行的是什么服务；\n     首先，请开启防火墙，请设置防火墙规则，只开启必备的端口，完成之后，使用扫描工具扫描服务器，检查端口开发情况；\n     如果可能，不要用密码的方法来远程登录服务器，使用公私钥的方式来 ssh 登录服务器，如果只能使用密码，请妥善保管好你的用户名和密码，禁用 root 用户，不用使用弱密码。\n     关注 Java 最新的漏洞，使用安全的 JVM 运行时。\n     服务器及时更新最新的软件，使用安全的 repo 软件源，绑定软件源的 host和 ip，避免 dns 污染造成的攻击，关注服务器软件漏洞，及时打上补丁。\n     收集系统日志和安装相应的入侵检测软件，及时发现服务器是否有异常行为。\n \n[b]不要以 root 身份运行 Elasticsearch[/b]\n\n    如果你的运维人员打算以 root 身份来运行某个服务，这个运维人员一定是一个不合格的运维人员，记住一定不要以 root 身份来运行 Elasticsearch，另外，要不和其他的服务公用相同的用户，然后还要保证该用户的权限要最小化。\n     范例君：[code]sudo -u es-user ES_JAVA_OPTS=\u0026quot;-Xms1024m -Xmx1024m\u0026quot;  /opt/elasticsearch/bin/elasticsearc[/code]\n \n[b]正确设置 Elasticsearch 的数据目录[/b]\n \n     请确保 Elasticsearch 的目录分配了合理的读写权限，避免使用共享文件系统，确保只有 elasticsearch 的启动用户才能访问，同理，日志目录也一样需要正确配置，避免泄露敏感信息。\n     文档君：[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html#path-settings[/url]\n \n[b]定期对 Elasticsearch 进行备份[/b]\n \n     使用 Elasticsearch 提供的备份还原机制，定期对 Elasticsearch 的数据进行快照备份，以备不时之需。\n     文档君：[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html[/url]\n \n[b]加上监控和预警[/b]\n \n     Elasticsearch 提供了很好的默认参数，对参数方面还做了正确性检测，bootstrap 启动检查，不准确的参数，直接不允许 Elasticsearch 启动，以至于有很多人抱怨，怎么现在部署到线上默认就需要做这么多设置才能使用呢，是的，以前启动就默认绑定了所有的网卡，集群见自动发现和相连，现在需要手动绑定局域网网卡，默认只是绑定的本机127.0.0.1的 ip，对上线来说麻烦了一点，做了这些检查也就是为了保证数据安全，以前很多的公网都能直接访问的 Elasticsearch 实例，都是因为默认设置就绑定了公网 ip，但是这些还不够，作为用户，你还需要收集各种日志和系统监控信息，及时主动掌握服务健康和资源使用情况，发现异常情况要及时处理，这里提供一些方案:\n[list=1]\n[*]使用开源的 Elastic Stack 收集这些日志，可以使用 Filebeat 收集日志，Metricbeat收集系统监控信息，存进 Elasticsearch，一旦发现异常的波动，使用 Watcher 来进行预警，通过邮件或者 webhook 调用短信、微信或者电话。[/*]\n[*]使用其他厂商的安全监控产品。[/*]\n[*]使用托管的 Elasticsearch 云的产品，如 Elastic Cloud等等。[/*]\n[/list]\n\n是的，把安全这个事情考虑进去之后，很多事情都要比没考虑要变得更加复杂和麻烦，千里之堤毁于蚁穴，一个不起眼的忽视就有可能造成全部数据的丢失和泄露，出来混迟早是要还的，安全问题千万不能忽视。\n \n以上几点建议举例针对 linux 平台，其他平台思路基本上一样，仅供参考，安全是一个包含很多方方面面的学科，抛砖引玉，希望大家有用。 \n\n最后，Elastic 非常关心我们的产品安全，如果您发现有任何安全方面的问题，还请在这里上报：\n[url]https://www.elastic.co/community/security[/url]\n企业用户需要 X-Pack 及 Elastic 官方技术支持，请访问下面的链接：\n[url]https://www.elastic.co/cn/contact[/url]","title":"Elasticsearch 安全加固 101","uid":"1","views":"12416","votes":"10"},"_type":"doc"}
{"_id":"126","_index":"forum-mysql","_score":1,"_source":{"addtime":"1484053445","category_id":"2","comments":"2","has_attach":"0","id":"126","message":"[b]elasticsearch 2.x mapping tips[/b]\n\n[b]作者[/b]：杨振涛  [b]首发于[/b]：Elasticsearch 中文社区 [b] 日期[/b]：2017-1-10\n\n如果把elasticsearch中的mapping类比为关系型数据库中的schema的话，那么我们可能重点强调了两者之间的共性，而忽略了elasticsearch里mapping很不相同的部分 —— 这恰恰是实践中最容易被坑的地方。这里总结了几点实践中的小心得，希望对你所有帮助。\n\n[b]mapping 基础[/b]\n创建索引库index[code]curl -XPOST \u0026quot;http://192.168.9.19:9200/vivo_vimc\u0026quot;[/code]\n查看指定索引库的mapping:\n[quote]\n\ncurl -XGET \u0026quot;http://192.168.9.19:9200/vivo_vmic/_mapping?pretty\u0026quot;\n \n[/quote]\nPS: 这时你获得的结果为空，因为刚建的库，没有mapping信息。\n\n创建索引类型type并指定mapping :[code]curl -XPOST http://192.168.9.19:9200/vivo_vmic/apps/_mapping -d '{\n  \u0026quot;apps\u0026quot; : {\n    \u0026quot;properties\u0026quot; : {\n      \u0026quot;appName\u0026quot; : {\n        \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;,\n        \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;,\n        \u0026quot;fields\u0026quot; :{\n         \u0026quot;cn\u0026quot;: {\n           \u0026quot;type\u0026quot;  : \u0026quot;string\u0026quot;,\n           \u0026quot;index\u0026quot; : \u0026quot;analyzed\u0026quot;,\n           \u0026quot;analyzer\u0026quot;: \u0026quot;ik\u0026quot;\n          },\n          \u0026quot;en\u0026quot;: {\n           \u0026quot;type\u0026quot;  : \u0026quot;string\u0026quot;,\n          }\n        },\n        \u0026quot;store\u0026quot;:\u0026quot;yes\u0026quot;\n      },\n      \u0026quot;status\u0026quot; : {\n        \u0026quot;type\u0026quot; : \u0026quot;boolean\u0026quot;\n      },\n      \u0026quot;type\u0026quot; : {\n        \u0026quot;type\u0026quot; : \u0026quot;integer\u0026quot;\n      },\n      \u0026quot;onsaleDate\u0026quot; : {\n        \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot;\n      },\n    }\n  }\n}'[/code]\n更新mapping （只能增加字段，不能删除字段，也不能修改字段类型，或者说无法增加一个不同类型的同名字段）:\n\n增加属性 score：[code]curl -XPOST \u0026quot;http://192.168.9.19:9200/vivo_vmic/apps/_mapping?pretty\u0026quot; -d '{\n    \u0026quot;apps\u0026quot;: {\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;score\u0026quot;:{\n                \u0026quot;type\u0026quot;:\u0026quot;float\u0026quot;\n                }\n        }\n    }\n}'[/code]   \n更新成功会返回：[code]{\n  \u0026quot;acknowledged\u0026quot; : true\n}[/code]\n\n删除mapping :\n2.4版本开始ES已经不支持mapping的删除了。\n\n[b]tip1 dynamic 模式[/b]\n\n动态mapping是ES的一个重要特性，这个配置的可选值及含义如下：\n[list]\n[*]true  ：支持动态扩展，新增数据有新的属性时，自动添加，索引成功[/*]\n[*]false ：不支持动态扩展，新增数据有新的属性时，直接忽略，索引成功[/*]\n[*]strict: 不支持动态扩展，新增数据有新的属性时，会报错，索引失败[/*]\n[/list]\n\n\n[b]tip2 主要数据类型及注意事项[/b]\n[list]\n[*]string[/*]\n[/list]\n    分词和不分词的值都需要，中英文都需要 ，\n    长度截取，超长过滤 ，\n    大小写问题（不分词时索引数据不会转小写，搜索都会转小写）    \n    analyzer: analyzed, not_analyzed, no（表示该属性不能用来做搜索和聚合）\n    properties ： .raw, .en/.cn\n    \n[list]\n[*]date :           如果不明确指定，那么默认的date格式是：\u0026quot;strict_date_optional_time||epoch_millis\u0026quot;，这是官网的表述，意思是可以是一个字符串类型的输入，也可以是数值类型的输入，前者可以是日期或者日期加上时间，后者则是毫秒数。\n\n关于时区信息：不管业务上是否需要时区信息，我们建议依然保存，以防万一。\n\n另外，data类型在明确指定 format 参数时，也有很多坑，对于format: epoch_second, epools_millis ,如果你想用来排序，那么为了性能，我们强烈建议你使用 epoc_second，差距很大哟，你可以亲自做一个对比测试。[/*]\n[/list]\n \n[list]\n[*] long, integer, short, byte, double ,float \n希望此类字段参与搜索和聚合的话，就不能设置not_analyzed。[/*]\n[/list]\n \n[list]\n[*]boolean, binary\nboolean类型比较特殊，在ES里面只定义了false类的值（ false, \u0026quot;false\u0026quot;, \u0026quot;off\u0026quot;, \u0026quot;no\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;\u0026quot; , 0, 0.0 ），其他所有都认为是true。实践中，我们建议优先使用 0（编程和性能友好），其次使用 true（兼容json默认的类型）。[/*]\n[/list]\n \n[list]\n[*] ipv4 \ntype:ip 日志分析等最常用的数据类型，注意这里的是ipv4，ipv6目前暂不支持（ES 2.x）；赋值时其实传递的是字符串，但ES内部其实保存的是一个long类型。[/*]\n[/list]\n \n[list]\n[*]geo \ntype:geo_point ， type:geo_shape  LBS服务的必选数据类型，但不建议完全依赖此特性，业务层面要尽可能地缩小范围，或者在使用围栏类功能时，只要业务容忍，使用正方形代替圆形。[/*]\n[/list]\n \n[list]\n[*]数组，对象，内嵌\n将一个复杂对象放在一个属性中，其中数组最常用。[/*]\n[/list]\n \n[list]\n[*]completion\n主要是用来做自动完成和拼写纠错的。[/*]\n[/list]\n\n\n[b]tip3 id设置[/b]  \n\n在不设置id的情况下，默认的ES会给一个类似HASH串的随机ID；如果业务上需要且可以保证索引数据的唯一性，也可以使用业务ID作为索引ID，好处就是可以根据业务ID轻松地GET到索引数据，而无需维护索引ID和业务ID的关系。\n\n同时，设置mapping的时候也可以指定ID的生成策略，比如UUID：[code]curl -s -XPUT http://192.168.9.19:9200/vivo_vimc -d '\n{\n    \u0026quot;mappings\u0026quot;: {\n        \u0026quot;apps\u0026quot;: {\n            \u0026quot;_id\u0026quot;: {\n                \u0026quot;path\u0026quot;: \u0026quot;uuid\u0026quot;\n            },\n            \u0026quot;properties\u0026quot;: {\n                \u0026quot;cnName\u0026quot;: {\n                    \u0026quot;type\u0026quot;:   \u0026quot;string\u0026quot;,\n                    \u0026quot;index\u0026quot;:  \u0026quot;analyzed\u0026quot;\n                }\n            }\n        }\n    }\n}'[/code]\n\n[b]tip4 index和type规划[/b]\n\nindex的别名这个特性就不再强调了，不管是否用到，第一时间设置别名是最佳实践！ schema 比较相似的type，放在同一个index里；schema差异非常大的type，建议放在不同的index里；原因是跟搜索引擎的segment以及lucene有关，本质上同一个index里的type底层是同样的存储结构，差异越大意味着type a的属性在type b里大部分都是空值，那么最终会得到一个非常稀疏的矩阵，影响计算效率并浪费存储空间。\n\n关于滚动index的问题，对于日志类的搜索应用，按天或其他维度做滚动index是非常好必要的，这样可以更好地区分冷热数据。比如：\n[quote]\nindex                        alias\nvivo_appstore_log_20160108  \nvivo_appstore_log_20160109  vivo_appstore_log\nvivo_appstore_log_20160110  vivo_appstore_log\nvivo_appstore_log_20160111  vivo_appstore_log\n...\n[/quote]\n\n如果只需要查询最近3天的数据，那么只需要对3天前的index remove alias即可，然后每天循环滚动。一个细节是，对于这种场景下的索引，写入的时候必须使用原始的index name，而不能使用alias；查询的时候则使用alias。\n\n\n另一个问题，就是index容量的规划，副本数直接决定需要多少冗余空间；另外，索引数据本身也会有膨胀的现象，尤其是基于中文的全文搜索应用，term集可能会比较大。比如有10000个docs，占用100MB空间时，并不能简单认为100000个docs就占用约1GB。\n\n\n[b]tip5 测试分词器[/b]\n\n如果使用的是基于词典的分词器，比如IK这类，那么线上系统可能会需要按需添加自定义词，或者同义词等，技术上我们可以暴露该类功能给搜索引擎运营人员使用。所以，需要提供一个测试分词器的接口，方便对比和验证。ES默认就提供这样的REST接口的。\n\n按指定分词器分词指定文本：[code]GET /vivo_vimc/apps/_analyze?text=Hello, vivo 移动互联网\u0026amp;analyzer=ik[/code]\n按指定索引库的属性测试分词效果：[code]GET /vivo_vimc/apps/_analyze\n{\n  \u0026quot;field\u0026quot;: \u0026quot;appName\u0026quot;,\n  \u0026quot;text\u0026quot;: \u0026quot;Pokemon Go\u0026quot;\n}[/code]\n以上关于 mapping 的几点心得，并非金科玉律，需要根据不同的业务需求场景来区别分析和应对。如果你有更多心得，欢迎回复本文分享。\n\n\n[b]关于作者：[/b]\n杨振涛，vivo移动互联网 搜索架构师，关注实时搜索，搜索广告，以及大数据的存储、索引、搜索和可视化。","title":"Elasticsearch 2.x mapping tips","uid":"54","views":"2258","votes":"2"},"_type":"doc"}
{"_id":"130","_index":"forum-mysql","_score":1,"_source":{"addtime":"1484379797","category_id":"2","comments":"1","has_attach":"1","id":"130","message":"这几天一直在学习elasticsearch，很多地方不是太明白，于是去官方网站上查看说明文档，发现真的很不方便查看，一是由于文档布局排版不好，查看不同的API还得必须跳到不同页面上，最重要一点是需要翻墙才能看文档，很是烦恼，今天忽然在一个网站上发现了一个把elasticsearch官方2.3.3的java elasticsearch 文档翻译了，而且我看了一下，还是不错的，于是分享给大家，果断收藏啊：\r\n[url=https://www.blog-china.cn/template/documentHtml/1484101683485.html]Elasticsearch 2.3.3 JAVA api说明文档[/url]","title":"发现的一个不错的elasticsearch 官方文档的翻译文档","uid":"2244","views":"16273","votes":"3"},"_type":"doc"}
{"_id":"132","_index":"forum-mysql","_score":1,"_source":{"addtime":"1486118745","category_id":"2","comments":"24","has_attach":"1","id":"132","message":"[attach]410[/attach]\n 在 Elasticsearch 5.x 有一个字段折叠（Field Collapsing，[url=http://PR #22337]#22337[/url]）的功能非常有意思，在这里分享一下，\n \n字段折叠是一个很有历史的需求了，可以看这个 issue，编号[url=https://github.com/elastic/elasticsearch/issues/256]#256[/url]，最初是2010年7月提的issue，也是讨论最多的帖子之一（240+评论），熬了6年才支持的特性，你说牛不牛，哈哈。\n \n目测该特性将于5.3发布，尝鲜地址：[url=https://oss.sonatype.org/content/repositories/snapshots/org/elasticsearch/distribution/zip/elasticsearch/5.3.0-SNAPSHOT/]Elasticsearch-5.3.0-SNAPSHOT[/url]，文档地址：[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.x/search-request-collapse.html]search-request-collapse[/url]。\n \nSo，什么是字段折叠，可以理解就是按特定字段进行合并去重，比如我们有一个菜谱搜索，我希望按菜谱的“菜系”字段进行折叠，即返回结果每个菜系都返回一个结果，也就是按菜系去重，我搜索关键字“鱼”，要去返回的结果里面各种菜系都有，有湘菜，有粤菜，有中餐，有西餐，别全是湘菜，就是这个意思，通过按特定字段折叠之后，来丰富搜索结果的多样性。\n \n说到这里，有人肯定会想到，使用 term agg+ top hits agg 来实现啊，这种组合两种聚和的方式可以实现上面的功能，不过也有一些局限性，比如，不能分页，[url=https://github.com/elastic/elasticsearch/issues/4915]#4915[/url]；结果不够精确（top term+top hits，es 的聚合实现选择了牺牲精度来提高速度）；数据量大的情况下，聚合比较慢，影响搜索体验。\n \n而新的的字段折叠的方式是怎么实现的的呢，有这些要点：\n[list=1]\n[*]折叠+取 inner_hits 分两阶段执行（组合聚合的方式只有一个阶段），所以 top hits 永远是精确的。[/*]\n[*]字段折叠只在 top hits 层执行，不需要每次都在完整的结果集上对为每个折叠主键计算实际的 doc values 值，只对 top hits 这小部分数据操作就可以，和 term agg 相比要节省很多内存。[/*]\n[*]因为只在 top hits 上进行折叠，所以相比组合聚合的方式，速度要快很多。[/*]\n[*]折叠 top docs 不需要使用全局序列（global ordinals）来转换 string，相比 agg 这也节省了很多内存。[/*]\n[*]分页成为可能，和常规搜索一样，具有相同的局限，先获取 from+size 的内容，再合并。[/*]\n[*]search_after 和 scroll 暂未实现，不过具备可行性。[/*]\n[*] 折叠只影响搜索结果，不影响聚合，搜索结果的 total 是所有的命中纪录数，去重的结果数未知（无法计算）。[/*]\n[/list]\n \n下面来看看具体的例子，就知道怎么回事了，使用起来很简单。\n[list]\n[*]先准备索引和数据，这里以菜谱为例，name：菜谱名，type 为菜系，rating 为用户的累积平均评分[/*]\n[/list]\n[code]DELETE recipes\nPUT recipes\nPOST recipes/type/_mapping\n{\n  \u0026quot;properties\u0026quot;: {\n    \u0026quot;name\u0026quot;:{\n      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n    },\n    \u0026quot;rating\u0026quot;:{\n      \u0026quot;type\u0026quot;: \u0026quot;float\u0026quot;\n    },\u0026quot;type\u0026quot;:{\n      \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n    }\n  }\n}\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;清蒸鱼头\u0026quot;,\u0026quot;rating\u0026quot;:1,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;剁椒鱼头\u0026quot;,\u0026quot;rating\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;红烧鲫鱼\u0026quot;,\u0026quot;rating\u0026quot;:3,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;鲫鱼汤（辣）\u0026quot;,\u0026quot;rating\u0026quot;:3,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;鲫鱼汤（微辣）\u0026quot;,\u0026quot;rating\u0026quot;:4,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;鲫鱼汤（变态辣）\u0026quot;,\u0026quot;rating\u0026quot;:5,\u0026quot;type\u0026quot;:\u0026quot;湘菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;广式鲫鱼汤\u0026quot;,\u0026quot;rating\u0026quot;:5,\u0026quot;type\u0026quot;:\u0026quot;粤菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;鱼香肉丝\u0026quot;,\u0026quot;rating\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;川菜\u0026quot;\n}\n\nPOST recipes/type/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;奶油鲍鱼汤\u0026quot;,\u0026quot;rating\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;西菜\u0026quot;\n} [/code]\n[list]\n[*]现在我们看看普通的查询效果是怎么样的，搜索关键字带“鱼”的菜，返回3条数据[/*]\n[/list]\n[code]POST recipes/type/_search\n{\n  \u0026quot;query\u0026quot;: {\u0026quot;match\u0026quot;: {\n    \u0026quot;name\u0026quot;: \u0026quot;鱼\u0026quot;\n  }},\u0026quot;size\u0026quot;: 3\n} [/code]全是湘菜，我的天，最近上火不想吃辣，这个第一页的结果对我来说就是垃圾，如下：[code]{\n  \u0026quot;took\u0026quot;: 2,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: 0.26742277,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYF_OA-dG63Txsd\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.26742277,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（变态辣）\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHXO_OA-dG63Txsa\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.19100356,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;红烧鲫鱼\u0026quot;,\n          \u0026quot;rating\u0026quot;: 3,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHWy_OA-dG63TxsZ\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.19100356,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;剁椒鱼头\u0026quot;,\n          \u0026quot;rating\u0026quot;: 2,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        }\n      }\n    ]\n  }\n}[/code]我们再看看，这次我想加个评分排序，大家都喜欢的是那些，看看有没有喜欢吃的，执行查询：[code]POST recipes/type/_search\n{\n  \u0026quot;query\u0026quot;: {\u0026quot;match\u0026quot;: {\n    \u0026quot;name\u0026quot;: \u0026quot;鱼\u0026quot;\n  }},\u0026quot;sort\u0026quot;: [\n    {\n      \u0026quot;rating\u0026quot;: {\n        \u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\n      }\n    }\n  ],\u0026quot;size\u0026quot;: 3\n} [/code]结果稍微好点了，不过3个里面2个是湘菜，还是有点不合适，结果如下：[code]{\n  \u0026quot;took\u0026quot;: 1,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: null,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYF_OA-dG63Txsd\u0026quot;,\n        \u0026quot;_score\u0026quot;: null,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（变态辣）\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        },\n        \u0026quot;sort\u0026quot;: [\n          5\n        ]\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYW_OA-dG63Txse\u0026quot;,\n        \u0026quot;_score\u0026quot;: null,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;广式鲫鱼汤\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;粤菜\u0026quot;\n        },\n        \u0026quot;sort\u0026quot;: [\n          5\n        ]\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHX7_OA-dG63Txsc\u0026quot;,\n        \u0026quot;_score\u0026quot;: null,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（微辣）\u0026quot;,\n          \u0026quot;rating\u0026quot;: 4,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        },\n        \u0026quot;sort\u0026quot;: [\n          4\n        ]\n      }\n    ]\n  }\n}\n[/code]现在我知道了，我要看看其他菜系，这家不是还有西餐、广东菜等各种菜系的么，来来，帮我每个菜系来一个菜看看，换 terms agg 先得到唯一的 term 的 bucket，再组合 top_hits agg，返回按评分排序的第一个 top hits，有点复杂，没关系，看下面的查询就知道了：[code]GET recipes/type/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;name\u0026quot;: \u0026quot;鱼\u0026quot;\n    }\n  },\n  \u0026quot;sort\u0026quot;: [\n    {\n      \u0026quot;rating\u0026quot;: {\n        \u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\n      }\n    }\n  ],\u0026quot;aggs\u0026quot;: {\n    \u0026quot;type\u0026quot;: {\n      \u0026quot;terms\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;size\u0026quot;: 10\n      },\u0026quot;aggs\u0026quot;: {\n        \u0026quot;rated\u0026quot;: {\n          \u0026quot;top_hits\u0026quot;: {\n            \u0026quot;sort\u0026quot;: [{\n              \u0026quot;rating\u0026quot;: {\u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;}\n            }], \n            \u0026quot;size\u0026quot;: 1\n          }\n        }\n      }\n    }\n  }, \n  \u0026quot;size\u0026quot;: 0,\n  \u0026quot;from\u0026quot;: 0\n} [/code]看下面的结果，虽然 json 结构有点复杂，不过总算是我们想要的结果了，湘菜、粤菜、川菜、西菜都出来了，每样一个，不重样：[code]{\n  \u0026quot;took\u0026quot;: 4,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;: []\n  },\n  \u0026quot;aggregations\u0026quot;: {\n    \u0026quot;type\u0026quot;: {\n      \u0026quot;doc_count_error_upper_bound\u0026quot;: 0,\n      \u0026quot;sum_other_doc_count\u0026quot;: 0,\n      \u0026quot;buckets\u0026quot;: [\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;湘菜\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 6,\n          \u0026quot;rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 6,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYF_OA-dG63Txsd\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（变态辣）\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 5,\n                    \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    5\n                  ]\n                }\n              ]\n            }\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;川菜\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 1,\n          \u0026quot;rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 1,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYr_OA-dG63Txsf\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;鱼香肉丝\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 2,\n                    \u0026quot;type\u0026quot;: \u0026quot;川菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    2\n                  ]\n                }\n              ]\n            }\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;粤菜\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 1,\n          \u0026quot;rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 1,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYW_OA-dG63Txse\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;广式鲫鱼汤\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 5,\n                    \u0026quot;type\u0026quot;: \u0026quot;粤菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    5\n                  ]\n                }\n              ]\n            }\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;西菜\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 1,\n          \u0026quot;rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 1,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHY3_OA-dG63Txsg\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;奶油鲍鱼汤\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 2,\n                    \u0026quot;type\u0026quot;: \u0026quot;西菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    2\n                  ]\n                }\n              ]\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n[/code]上面的实现方法，前面已经说了，可以做，有局限性，那看看新的字段折叠法如何做到呢，查询如下，加一个 collapse 参数，指定对那个字段去重就行了，这里当然对菜系“type”字段进行去重了：[code]GET recipes/type/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;name\u0026quot;: \u0026quot;鱼\u0026quot;\n    }\n  },\n  \u0026quot;collapse\u0026quot;: {\n    \u0026quot;field\u0026quot;: \u0026quot;type\u0026quot;\n  },\n  \u0026quot;size\u0026quot;: 3,\n  \u0026quot;from\u0026quot;: 0\n}[/code]结果很理想嘛，命中结果还是熟悉的那个味道（和查询结果长的一样嘛），如下：[code]{\n  \u0026quot;took\u0026quot;: 1,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: null,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoDNlRJ_OA-dG63TxpW\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.018980097,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（微辣）\u0026quot;,\n          \u0026quot;rating\u0026quot;: 4,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;湘菜\u0026quot;\n          ]\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoDNlRk_OA-dG63TxpZ\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.013813315,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鱼香肉丝\u0026quot;,\n          \u0026quot;rating\u0026quot;: 2,\n          \u0026quot;type\u0026quot;: \u0026quot;川菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;川菜\u0026quot;\n          ]\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoDNlRb_OA-dG63TxpY\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.0125863515,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;广式鲫鱼汤\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;粤菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;粤菜\u0026quot;\n          ]\n        }\n      }\n    ]\n  }\n}[/code]我再试试翻页，把 from 改一下，现在返回了3条数据，from 改成3，新的查询如下：[code]{\n  \u0026quot;took\u0026quot;: 1,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: null,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoDNlRw_OA-dG63Txpa\u0026quot;,\n        \u0026quot;_score\u0026quot;: 0.012546891,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;奶油鲍鱼汤\u0026quot;,\n          \u0026quot;rating\u0026quot;: 2,\n          \u0026quot;type\u0026quot;: \u0026quot;西菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;西菜\u0026quot;\n          ]\n        }\n      }\n    ]\n  }\n}[/code]上面的结果只有一条了，去重之后本来就只有4条数据，上面的工作正常，每个菜系只有一个菜啊，那我不乐意了，帮我每个菜系里面多返回几条，我好选菜啊，加上参数 inner_hits 来控制返回的条数，这里返回2条，按 rating 也排个序，新的查询构造如下：[code]GET recipes/type/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;name\u0026quot;: \u0026quot;鱼\u0026quot;\n    }\n  },\n  \u0026quot;collapse\u0026quot;: {\n    \u0026quot;field\u0026quot;: \u0026quot;type\u0026quot;,\n    \u0026quot;inner_hits\u0026quot;: {\n      \u0026quot;name\u0026quot;: \u0026quot;top_rated\u0026quot;,\n      \u0026quot;size\u0026quot;: 2,\n      \u0026quot;sort\u0026quot;: [\n        {\n          \u0026quot;rating\u0026quot;: \u0026quot;desc\u0026quot;\n        }\n      ]\n    }\n  },\n  \u0026quot;sort\u0026quot;: [\n    {\n      \u0026quot;rating\u0026quot;: {\n        \u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\n      }\n    }\n  ],\n  \u0026quot;size\u0026quot;: 2,\n  \u0026quot;from\u0026quot;: 0\n}[/code]查询结果如下，完美：[code]{\n  \u0026quot;took\u0026quot;: 1,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 9,\n    \u0026quot;max_score\u0026quot;: null,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYF_OA-dG63Txsd\u0026quot;,\n        \u0026quot;_score\u0026quot;: null,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（变态辣）\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;湘菜\u0026quot;\n          ]\n        },\n        \u0026quot;sort\u0026quot;: [\n          5\n        ],\n        \u0026quot;inner_hits\u0026quot;: {\n          \u0026quot;top_rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 6,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYF_OA-dG63Txsd\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（变态辣）\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 5,\n                    \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    5\n                  ]\n                },\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHX7_OA-dG63Txsc\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;鲫鱼汤（微辣）\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 4,\n                    \u0026quot;type\u0026quot;: \u0026quot;湘菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    4\n                  ]\n                }\n              ]\n            }\n          }\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYW_OA-dG63Txse\u0026quot;,\n        \u0026quot;_score\u0026quot;: null,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;广式鲫鱼汤\u0026quot;,\n          \u0026quot;rating\u0026quot;: 5,\n          \u0026quot;type\u0026quot;: \u0026quot;粤菜\u0026quot;\n        },\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;type\u0026quot;: [\n            \u0026quot;粤菜\u0026quot;\n          ]\n        },\n        \u0026quot;sort\u0026quot;: [\n          5\n        ],\n        \u0026quot;inner_hits\u0026quot;: {\n          \u0026quot;top_rated\u0026quot;: {\n            \u0026quot;hits\u0026quot;: {\n              \u0026quot;total\u0026quot;: 1,\n              \u0026quot;max_score\u0026quot;: null,\n              \u0026quot;hits\u0026quot;: [\n                {\n                  \u0026quot;_index\u0026quot;: \u0026quot;recipes\u0026quot;,\n                  \u0026quot;_type\u0026quot;: \u0026quot;type\u0026quot;,\n                  \u0026quot;_id\u0026quot;: \u0026quot;AVoESHYW_OA-dG63Txse\u0026quot;,\n                  \u0026quot;_score\u0026quot;: null,\n                  \u0026quot;_source\u0026quot;: {\n                    \u0026quot;name\u0026quot;: \u0026quot;广式鲫鱼汤\u0026quot;,\n                    \u0026quot;rating\u0026quot;: 5,\n                    \u0026quot;type\u0026quot;: \u0026quot;粤菜\u0026quot;\n                  },\n                  \u0026quot;sort\u0026quot;: [\n                    5\n                  ]\n                }\n              ]\n            }\n          }\n        }\n      }\n    ]\n  }\n}[/code]好了，字段折叠介绍就到这里。","title":"Elasticsearch 5.x 字段折叠的使用","uid":"1","views":"23050","votes":"8"},"_type":"doc"}
{"_id":"143","_index":"forum-mysql","_score":1,"_source":{"addtime":"1489975500","category_id":"2","comments":"7","has_attach":"0","id":"143","message":"\n[url=https://github.com/13428282016/elasticsearch-CN/wiki/gettting-started]elasticsearch-官网同步更新，中文文档[/url]","title":"elasticsearch-官网中文文档","uid":"2495","views":"12089","votes":"2"},"_type":"doc"}
{"_id":"144","_index":"forum-mysql","_score":1,"_source":{"addtime":"1490342891","category_id":"2","comments":"1","has_attach":"0","id":"144","message":"我把自己建立一个简单的中文搜索引擎的过程写成了几篇博客。在这里和大家分享一下：\n \n轻轻松松做个强大的搜索引擎01 -- 数据库安装：\n[url]https://www.zhuxichi.com/2017/02/21/SearchEngineTutorial01/[/url]\n \n轻轻松松做个强大的搜索引擎02 -- 数据录入：\n[url]https://www.zhuxichi.com/2017/02/22/SearchEngineTutorial02/[/url]\n \n轻轻松松做个强大的搜索引擎03 -- 全文搜索：\n[url]https://www.zhuxichi.com/2017/02/23/SearchEngineTutorial03/[/url]\n \n轻轻松松做个强大的搜索引擎04 -- 分词：\n[url]https://www.zhuxichi.com/2017/03/03/SearchEngineTutorial04/[/url]\n \n轻轻松松做个强大的搜索引擎05 -- 关键词高亮：\n[url]https://www.zhuxichi.com/2017/03/07/SearchEngineTutorial05/[/url]\n \n轻轻松松做个强大的搜索引擎06 -- 搜索词建议：\n[url]https://www.zhuxichi.com/2017/03/08/SearchEngineTutorial06/[/url]\n \n轻轻松松做个强大的搜索引擎07 -- Boosting：\n[url]https://www.zhuxichi.com/2017/03/10/SearchEngineTutorial07/[/url]\n \n欢迎交流哈","title":"写了几篇ElasticSearch入门的文章分享一下","uid":"1579","views":"2475","votes":"3"},"_type":"doc"}
{"_id":"145","_index":"forum-mysql","_score":1,"_source":{"addtime":"1490368175","category_id":"2","comments":"1","has_attach":"0","id":"145","message":"`elasticsearch-query-tookit`是一款基于SQL查询elasticsearch编程工具包，支持SQL解析生成DSL，支持JDBC驱动，支持和Spring、MyBatis集成，提供Java编程接口可基于此工具包二次开发\n \n[b]只是重新造了个轮子，有兴趣的同学可以相互交流，QQ: 465360798[/b]\n \n项目地址：[url]https://github.com/gitchennan/elasticsearch-query-toolkit[/url]\n \n[b]一、SQL解析生成DSL使用示例[/b]\nSQL语法帮助手册戳这里: [url]https://github.com/gitchennan/elasticsearch-query-toolkit/wiki/elasticsearch-query-toolkit-help-doc[/url]\n \n[code]String sql = \u0026quot;select * from index.order where status='SUCCESS' and price \u0026gt; 100 order by nvl(pride, 0) asc routing by 'JD' limit 0, 20\u0026quot;;\n\nElasticSql2DslParser sql2DslParser = new ElasticSql2DslParser();\n//解析SQL\nElasticSqlParseResult parseResult = sql2DslParser.parse(sql);\n//生成DSL(可用于rest api调用)\nString dsl = parseResult.toDsl();\n\n//toRequest方法接收一个clinet对象参数\nSearchRequestBuilder searchReq = parseResult.toRequest(esClient);\n//执行查询\nSearchResponse response = searchReq.execute().actionGet();[/code]生成的DSL如下：\n[code]{\n  \u0026quot;from\u0026quot; : 0,\n  \u0026quot;size\u0026quot; : 20,\n  \u0026quot;query\u0026quot; : {\n    \u0026quot;bool\u0026quot; : {\n      \u0026quot;filter\u0026quot; : {\n        \u0026quot;bool\u0026quot; : {\n          \u0026quot;must\u0026quot; : [ {\n            \u0026quot;term\u0026quot; : {\n              \u0026quot;status\u0026quot; : \u0026quot;SUCCESS\u0026quot;\n            }\n          }, {\n            \u0026quot;range\u0026quot; : {\n              \u0026quot;price\u0026quot; : {\n                \u0026quot;from\u0026quot; : 100,\n                \u0026quot;to\u0026quot; : null,\n                \u0026quot;include_lower\u0026quot; : false,\n                \u0026quot;include_upper\u0026quot; : true\n              }\n            }\n          } ]\n        }\n      }\n    }\n  },\n  \u0026quot;sort\u0026quot; : [ {\n    \u0026quot;pride\u0026quot; : {\n      \u0026quot;order\u0026quot; : \u0026quot;asc\u0026quot;,\n      \u0026quot;missing\u0026quot; : 0\n    }\n  } ]\n}[/code][b]二、集成MyBatis、Spring[/b]\n \n首先在Spring配置文件中增加如下代码\n1. 指定driverClassName：org.elasticsearch.jdbc.api.ElasticDriver\n2. 指定连接ES的连接串：jdbc:elastic:192.168.0.109:9300/product_cluster\n3. 创建一个SqlMapClient对象，并指定sqlMapConfig.xml路径\n \n[code]\u0026lt;bean id=\u0026quot;elasticDataSource\u0026quot; class=\u0026quot;org.elasticsearch.jdbc.api.ElasticSingleConnectionDataSource\u0026quot; destroy-method=\u0026quot;destroy\u0026quot;\u0026gt;\n    \u0026lt;property name=\u0026quot;driverClassName\u0026quot; value=\u0026quot;org.elasticsearch.jdbc.api.ElasticDriver\u0026quot; /\u0026gt;\n    \u0026lt;property name=\u0026quot;url\u0026quot; value=\u0026quot;jdbc:elastic:192.168.0.109:9300/product_cluster\u0026quot; /\u0026gt;\n\u0026lt;/bean\u0026gt;\n\n\u0026lt;bean id=\u0026quot;sqlMapClient\u0026quot; class=\u0026quot;org.springframework.orm.ibatis.SqlMapClientFactoryBean\u0026quot;\u0026gt;\n    \u0026lt;property name=\u0026quot;dataSource\u0026quot; ref=\u0026quot;elasticDataSource\u0026quot; /\u0026gt;\n    \u0026lt;property name=\u0026quot;configLocation\u0026quot; value=\u0026quot;classpath:sqlMapConfig.xml\u0026quot;/\u0026gt;\n\u0026lt;/bean\u0026gt;[/code]sqlMapConfig.xml文件内容如下：\n[code]\u0026lt;sqlMapConfig\u0026gt;\n    \u0026lt;settings\n            cacheModelsEnabled=\u0026quot;true\u0026quot;\n            lazyLoadingEnabled=\u0026quot;true\u0026quot;\n            enhancementEnabled=\u0026quot;true\u0026quot;\n            maxSessions=\u0026quot;64\u0026quot;\n            maxTransactions=\u0026quot;20\u0026quot;\n            maxRequests=\u0026quot;128\u0026quot;\n            useStatementNamespaces=\u0026quot;true\u0026quot;/\u0026gt;\n\n    \u0026lt;sqlMap resource=\u0026quot;sqlmap/PRODUCT.xml\u0026quot;/\u0026gt;\n\n\u0026lt;/sqlMapConfig\u0026gt;[/code]PRODUCT.xml文件中声明select sql语句\n[code]\u0026lt;sqlMap namespace=\u0026quot;PRODUCT\u0026quot;\u0026gt;\n    \u0026lt;select id=\u0026quot;getProductByCodeAndMatchWord\u0026quot; parameterClass=\u0026quot;java.util.Map\u0026quot; resultClass=\u0026quot;java.lang.String\u0026quot;\u0026gt;\n        SELECT *\n        FROM index.product\n        QUERY match(productName, #matchWord#) or prefix(productName, #prefixWord#, 'boost:2.0f')\n        WHERE productCode = #productCode#\n        AND advicePrice \u0026gt; #advicePrice#\n        AND $$buyers.buyerName IN ('china', 'usa')\n        ROUTING BY #routingVal#\n    \u0026lt;/select\u0026gt;\n\u0026lt;/sqlMap\u0026gt;[/code]编写对应DAO代码：\n[code]@Repository\npublic class ProductDao {\n    @Autowired\n    @Qualifier(\u0026quot;sqlMapClient\u0026quot;)\n    private SqlMapClient sqlMapClient;\n\n\n    public List\u0026lt;Product\u0026gt; getProductByCodeAndMatchWord(String matchWord, String productCode) throws SQLException {\n        Map\u0026lt;String, Object\u0026gt; paramMap = Maps.newHashMap();\n        paramMap.put(\u0026quot;productCode\u0026quot;, productCode);\n        paramMap.put(\u0026quot;advicePrice\u0026quot;, 1000);\n        paramMap.put(\u0026quot;routingVal\u0026quot;, \u0026quot;A\u0026quot;);\n        paramMap.put(\u0026quot;matchWord\u0026quot;, matchWord);\n        paramMap.put(\u0026quot;prefixWord\u0026quot;, matchWord);\n        String responseGson = (String) sqlMapClient.queryForObject(\u0026quot;PRODUCT.getProductByCodeAndMatchWord\u0026quot;, paramMap);\n        \n        //反序列化查询结果\n        JdbcSearchResponseResolver responseResolver = new JdbcSearchResponseResolver(responseGson);\n        JdbcSearchResponse\u0026lt;Product\u0026gt; searchResponse = responseResolver.resolveSearchResponse(Product.class);\n\n        return searchResponse.getDocList();\n\n    }\n}[/code]编写测试方法[code]@Test\npublic void testProductQuery() throws Exception {\n    BeanFactory factory = new ClassPathXmlApplicationContext(\u0026quot;application-context.xml\u0026quot;);\n    ProductDao productDao = factory.getBean(ProductDao.class);\n    \n    List\u0026lt;Product\u0026gt; productList = productDao.getProductByCodeAndMatchWord(\u0026quot;iphone 6s\u0026quot;, \u0026quot;IP_6S\u0026quot;);\n    for (Product product : productList) {\n        System.out.println(product.getProductName());\n    }\n}[/code]\n \n ","title":"elasticsearch-query-tookit一款基于SQL查询elasticsearch编程工具包，支持SQL解析生成DSL，支持JDBC驱动，支持和Spring、MyBatis集成","uid":"1533","views":"4288","votes":"3"},"_type":"doc"}
{"_id":"149","_index":"forum-mysql","_score":1,"_source":{"addtime":"1491450925","category_id":"2","comments":"3","has_attach":"0","id":"149","message":"看一下Elastic官网对开启 bootstrap.memory_lock的介绍：\n \n[i]Swapping is very bad for performance and for node stability and should be avoided at all costs. It can cause garbage collections to last for minutes instead of milliseconds and can cause nodes to respond slowly or even to disconnect from the cluster.                                                                   ----截取自官网[/i]\n[quote]\n[i]意思是说发生系统swapping的时候ES节点的性能会非常差，也会影响节点的稳定性。所以要不惜一切代价来避免swapping。swapping会导致Java GC的周期延迟从毫秒级恶化到分钟，更严重的是会引起节点响应延迟甚至脱离集群。                                                                      ----[/i]如果不了解到底什么是swapping的，可以找点Linux IO章节文章看看\n[/quote]\n \n1. 先检查一下你的各个ES节点是否开启了Mem_lock\n[quote]\nGET 请求 /_nodes?filter_path=**.mlockall\n[/quote]\n[quote]\n{\n  \u0026quot;nodes\u0026quot;: {\n    \u0026quot;dCH5FCpATRO7D1azyPhsRQ\u0026quot;: {\n      \u0026quot;process\u0026quot;: {\n        \u0026quot;mlockall\u0026quot;: false\n      }\n    },\n    \u0026quot;GoNfwnNzSwmJy3y1QdfluA\u0026quot;: {\n      \u0026quot;process\u0026quot;: {\n        \u0026quot;mlockall\u0026quot;: false\n      }\n    },\n    \u0026quot;ijW61kA-SAqnnVHjpTSw2w\u0026quot;: {\n      \u0026quot;process\u0026quot;: {\n        \u0026quot;mlockall\u0026quot;: false\n      }\n    },\n    \u0026quot;yHl9GUGbS46o4hwKvHpwnQ\u0026quot;: {\n      \u0026quot;process\u0026quot;: {\n        \u0026quot;mlockall\u0026quot;: false\n      }\n    }\n  }\n}\n[/quote]\n上述返回内容，可见都没有开启mem_lock，集全随时都可能发生故障（尤其是集群正常运行了一段时间，莫名其妙的故障）\n \n2. root权限执行ulimit -l unlimited\n[quote]\n告诉操作系统可以无限制分配内存给一个进程\n[/quote]\n3.重新启动ES\n[quote]\n[2017-04-06T11:51:14,840][INFO ][o.e.b.BootstrapCheck     ] [Portal_ES_Node10_0_36_49] bound or publishing to a non-loopback or non-link-local address, enforcing bootstrap checks\nERROR: bootstrap checks failed\nmemory locking requested for elasticsearch process but memory is not locked\n[/quote]\n \n4. 如果你遇到上面的错误，说明你还需要配置/etc/security/limits.conf\n    增加下面3行到文件末尾，其中XXX表示当前用户\n[quote]\n# allow user 'XXX' mlockall\nXXX soft memlock unlimited\nXXX hard memlock unlimited\n[/quote]\n","title":"ES节点memory lock重要性与实现方式","uid":"2010","views":"11247","votes":"0"},"_type":"doc"}
{"_id":"172","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494560188","category_id":"8","comments":"0","has_attach":"0","id":"172","message":"看得出来是踩了不少坑总结出来的，推荐下： [url=http://mp.weixin.qq.com/s/eSCZc5P2ad8QL8VMJgM03Q]基于ElasticSearch的亿级实时日志系统实践[/url]\n ","title":"基于ElasticSearch的亿级实时日志系统实践","uid":"2844","views":"3482","votes":"2"},"_type":"doc"}
{"_id":"183","_index":"forum-mysql","_score":1,"_source":{"addtime":"1496367995","category_id":"5","comments":"0","has_attach":"0","id":"183","message":"昨日 Elastic 正式发布针对 5.4 Bug 的修复版本 Elasticsearch 5.4.1（基于 Lucene6.5.1 ），以及基于 Lucene6.4.2的 Elasticsearch 5.3.3。 Elasticsearch 5.4.1 是目前最新的稳定版本，在官方的 Elastic Cloud 上已可以直接部署和升级。此次发布包括两个安全补丁-- 所有 X-Pack Security 用户都应该升级。\n\n[b]5.4.x 相关链接：[/b]\n[url=https://www.elastic.co/downloads/elasticsearch]Elasticsearch 5.4.1 下载地址[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/release-notes-5.4.1.html]Elasticsearch 5.4.1 发行说明[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/breaking-changes-5.4.html]Elasticsearch 5.4 重要改变[/url]\n[url=https://www.elastic.co/guide/en/x-pack/current/xpack-release-notes.html#xpack-5.4.1]X-Pack 5.4.1 发行说明[/url]\n\n[b]5.3.x 相关链接:[/b]\n[url=https://www.elastic.co/downloads/past-releases/elasticsearch-5-3-3]Elasticsearch 5.3.3 下载地址[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.3/release-notes-5.3.3.html]Elasticsearch 5.3.3 发行说明[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.3/breaking-changes-5.3.html]Elasticsearch 5.3.3 重要改变[/url]\n[url=https://www.elastic.co/guide/en/x-pack/current/xpack-release-notes.html#xpack-5.3.3]X-Pack 5.3.3 发行说明[/url]\n\n你可以通过阅读上面的详细的发行说明来了解具体的发布内容，下面是一些重点摘要：\n\n[b]X-Pack Document Level Security and Aliases (ESA-2017-09) [/b]\n\nX-Pack 安全组件在版本 5.4.1 和 5.3.3 之前对于索引别名的文档层面的安全设置存在漏洞，这个 bug 允许单个用户在特定的操作下能通过别名查看未经允许的数据。\n\n[b]影响版本[/b]\nX-Pack Security 从 5.0.0 到 5.4.0 都受影响。\n\n[b]解决方案[/b]\n所有 X-Pack 安全组件的用户升级到 5.3.3 或者 5.4.1。如果不能升级，通过禁用索引层面的 request cache 可以临时解决这个问题。\n\n[b]CVE ID[/b]: CVE-2017-8441\n\n \n[b]X-Pack Privilege Escalation (ESA-2017-06)[/b]\n\n修复 run_as 功能存在的一个特权扩大的bug。正常情况下，当使用run_as执行某些操作会以特定的身份来执行，这个bug 让用户无法正常转换为 run_as 指定的用户身份，从而导致查询失败和结果异常。\n\n如果你不使用 run_as 功能或 _user 属性，则不受此bug影响。\n\n[b]影响版本[/b]\nX-Pack Security 从 5.0.0 到 5.4.0 都受影响。\n\n[b]解决方案[/b]\n建议升级 Elastic Stack 到 5.4.1，如果不能升级，请移除模板里面的 {{_user.username}} 占位符并确保 run_as 设置不会被不可信用户修改。\n\n[b]CVE ID[/b]: CVE-2017-8438\n\n\n[b]其它重要变化:[/b]\n[list=1]\n[*]修复 bug，单分片进行 scroll 操作可能引起 X-Pack Security 造成节点僵死及 OOM。[/*]\n[*]Elasticsearch 5.4.0 启用 TLS 不能对 5.3.x 和之前的节点进行认证。[/*]\n[*]LDAP 认证用户在撤销认证之后后可能任然驻留在缓存。[/*]\n[*]现在，Netty在处理线程池、缓冲池和其他资源时，尊重处理器的设置，而不是在其他容器上运行时，可能会对这些资源进行过度的调整。[/*]\n[*]对关闭的索引进行 Index setting 修改将进行验证，保护因为错误的配置造成索引无法打开的问题。[/*]\n[*]修复 TransportClient 关于嗅探可能造成客户端挂起的异常。[/*]\n[*]修复在KERBEROS安全模式，HDFS repository 插件与 Java Security Manager 发生的冲突。[/*]\n[*]修复 Snapshot/restore 在 Elasticsearch 5.2.x 及之前的版本在取回所有快照时异常缓慢的问题。[/*]\n[/list]\n\n \n最后，请下载和试用最新的 Elasticsearch 5.4.1，欢迎前往GitHub issue反馈任何遇到的问题。","title":"Elasticsearch 5.4.1 和 5.3.3 发布","uid":"1","views":"2413","votes":"2"},"_type":"doc"}
{"_id":"190","_index":"forum-mysql","_score":1,"_source":{"addtime":"1498548575","category_id":"8","comments":"8","has_attach":"0","id":"190","message":"本次分享主要包含两个方面的实战经验：索引性能和查询性能。\n一. 索引性能（Index Performance）\n首先要考虑的是，索引性能是否有必要做优化？\n索引速度提高与否？主要是看瓶颈在什么地方，若是 Read DB（产生DOC）的速度比较慢，那瓶颈不在 ElasticSearch 时，优化就没那么大的动力。实际上 Elasticsearch 的索引速度还是非常快的。\n我们有一次遇到 Elasticsearch 升级后索引速度很慢，查下来是新版 IK 分词的问题，修改分词插件后得到解决。\n如果需要优化，应该如何优化？\nSSD 是经济压力能承受情况下的不二选择。减少碎片也可以提高索引速度，每天进行优化还是很有必要的。在初次索引的时候，把 replica 设置为 0，也能提高索引速度。\nbulk 是不是一定需要呢？\n若是 Elasticsearch 普通索引已经导致高企的 LA，IO 压力已经见顶，这时候 bulk 也无法提供帮助，SSD 应该是很好的选择。\n在 create doc 速度能跟上的时候，bulk 是可以提高速度的。\n记得 threadpool.index.queue_size ++，不然会出现索引时队列不够用的情况。\nindices.memory.index_buffer_size:10% 这个参数可以进行适当调整。\n调整如下参数也可以提高索引速度：index.translog.flush_threshold_ops:50000 和 refresh_interval。\n二. 查询性能（Query Perofrmance）\n王道是什么？routing，routing，还是 routing。\n我们为了提高查询速度，减少慢查询，结合自己的业务实践，使用多个集群，每个集群使用不同的 routing。比如，用户是一个routing维度。\n在实践中，这个routing 非常重要。\n我们碰到一种情况，想把此维度的查询（即用户查询）引到非用户routing 的集群，结果集群完全顶不住！\n在大型的本地分类网站中，城市、类目也是一个不错的维度。我们使用这种维度进行各种搭配。然后在前端分析查询，把各个不同查询分别引入合适的集群。这样做以后，每个集群只需要很少的机器，而且保持很小的 CPU Usage 和 LA。从而查询速度够快，慢查询几乎消灭。\n分合？\n分别（索引和routing）查询和合并（索引和routing）查询，即此分合的意思。\n索引越来越大，单个 shard 也很巨大，查询速度也越来越慢。这时候，是选择分索引还是更多的shards？\n在实践过程中，更多的 shards 会带来额外的索引压力，即 IO 压力。\n我们选择了分索引。比如按照每个大分类一个索引，或者主要的大城市一个索引。然后将他们进行合并查询。如：http://cluster1:9200/shanghai,beijing/_search?routing=fang，自动将查询中城市属性且值为上海或北京的查询，且是房类目的，引入集群 cluster1，并且routing等于fang。\nhttp://cluster1:9200/other/_search?routing=jinan,linyi。小城市的索引，我们使用城市做 routing，如本例中同时查询济南和临沂城市。\nhttp://cluster1:9200/_all/_search，全部城市查询。\n再如： http://cluster2:9200/fang,che/_search?routing=shanghai_qiche,shanghai_zufang,beijing_qiche,beijing_zufang。查询上海和北京在小分类汽车、整租的信息，那我们进行如上合并查询。并将其引入集群 cluster2。\n使用更多的 shards？\n除了有 IO 压力，而且不能进行全部城市或全部类目查询，因为完全顶不住。\nElastic 官方文档建议：一个 Node 最好不要多于三个 shards。\n若是 \u0026quot;more shards”，除了增加更多的机器，是没办法做到这一点的。\n分索引，虽然一个 Node 总的shards 还是挺多的，但是一个索引可以保持3个以内的shards。\n我们使用分索引时，全量查询是可以顶住的，虽然压力有点儿高。\n索引越来越大，资源使用也越来越多。若是要进行更细的集群分配，大索引使用的资源成倍增加。\n有什么办法能减小索引？显然，创建 doc 时，把不需要的 field 去掉是一个办法；但是，这需要对业务非常熟悉。\n有啥立竿见影的办法？\n根据我们信息的特点，内容（field:description）占了索引的一大半，那我们就不把 description 索引进 ES，doc 小了一倍，集群也小了一倍，所用的资源（Memory, HD or SSD, Host, snapshot存储，还有时间）大大节省，查询速度自然也更快。\n那要查 description 怎么办？\n上面的实例中，我们可以把查询引入不同集群，自然我们也可以把 description 查询引入一个非实时（也可以实时）集群，这主要是我们业务特点决定的，因为description查询所占比例非常小，使得我们可以这样做。\n被哪些查询搞过？第一位是 Range 查询，这货的性能真不敢恭维。在最热的查询中，若是有这货，肯定是非常痛苦的，网页变慢，查询速度变慢，集群 LA 高企，严重的时候会导致集群 shard 自动下线。所以，建议在最热的查询中避免使用 Range 查询。\nFacet 查询，在后续版本这个被 aggregations 替代，我们大多数时候让它在后端进行运算。\n三. 其他\n1)线程池\n线程池我们默认使用 fixed，使用 cached 有可能控制不好。主要是比较大的分片 relocation时，会导致分片自动下线，集群可能处于危险状态。在集群高压时，若是 cached ，分片也可能自动下线。自 1.4 版本后，我们就一直 fixed，至于新版是否还存在这个问题，就没再试验了。\n两个原因：一是 routing王道带来的改善，使得集群一直低压运行；二是使用fixed 后，已经极少遇到自动下线shard了。\n我们前面说过，user 是一个非常好的维度。这个维度很重要，routing 效果非常明显。其他维度，需要根据业务特点，进行组合。\n所以我们的集群一直是低压运行，就很少再去关注新版本的 使用 cached 配置问题。\nhreadpool.search.queue_size 这个配置是很重要的，一般默认是够用了，可以尝试提高。\n2）优化\n每天优化是有好处的，可以大大改善查询性能。max_num_segments 建议配置为1。虽然优化时间会变长，但是在高峰期前能完成的话，会对查询性能有很大好处。\n3) JVM GC的选择：选择 G1还是 CMS？\n应该大多数人还是选择了 CMS，我们使用的经验是 G1 和 CMS 比较接近；但和 CMS 相比，还是有一点距离，至少在我们使用经验中是如此。\nJVM 32G 现象？\n128G内存的机器配置一个 JVM，然后是巨大的 heapsize （如64G）？\n还是配多个 JVM instance，较小的 heapsize（如32G）？\n我的建议是后者。实际使用中，后者也能帮助我们节省不少资源，并提供不错的性能。具体请参阅 “Don’t Cross 32 GB!\u0026quot; （https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops）\n跨 32G 时，有一个现象，使用更多的内存，比如 40G，效果还不如31G！\n这篇文档值得大家仔细阅读。\nJVM 还有一个配置 bootstrap.mlockall: true，比较重要。这是让 JVM 启动的时候就 锁定 heap 内存。\n有没有用过 较小的 heapsize，加上SSD？我听说有人使用过，效果还不错，当然，我们自己还没试过。\n4）插件工具\n推荐 kopf，是一个挺不错的工具，更新及时，功能完备，可以让你忘掉很多 API :)。\n\n\n\n上面是 kopf 的图片。管理Elasticsearch 集群真心方便。以前那些 API ，慢慢要忘光了:)\n索引，查询，和一些重要的配置，是今天分享的重点。\n\nQ\u0026amp;A\nQ1：您建议生产环境JVM采用什么样的参数设置？FULL GC频率和时间如何？\nCMS 标准配置。\nES_HEAP_NEWSIZE=?G\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:+UseCondCardMark\u0026quot;\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:CMSWaitDuration=250\u0026quot;\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:+UseParNewGC\u0026quot;\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:+UseConcMarkSweepGC\u0026quot;\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:CMSInitiatingOccupancyFraction=75\u0026quot;\nJAVA_OPTS=\u0026quot;$JAVA_OPTS -XX:+UseCMSInitiatingOccupancyOnly\u0026quot;\nFull GC 很少去care 它了。我们使用 Elasticsearch 在JVM上花的时间很少。\nQ2：生产环境服务器如何配置性价比较高？单机CPU核数、主频？内存容量？磁盘容量？\n内存大一些，CPU 多核是必要的，JVM 和 Elasticsearch 会充分使用内存和多核的。 关于内存容量的问题，很多是 JVM Tunning 的问题。 磁盘容量没啥要求。\nQ3： 分组统计(Facet 查询或 aggregations )大多数时候让它在后端进行运算，怎么实现？应用如果需要实时进行统计而且并发量较大，如何优化？\n因为我们是网站系统，所以对于 Facet 请求，引导到后端慢慢计算，前端初始的时候可能没数据，但是此后就会有了。\n如果是精确要求的话，那就只能从 提高 facet 查询性能去下手，比如 routing、filter、cache、更多的内存...\nQ4：存进Elasticsearch的数据，timestamp是UTC时间，Elasticsearch集群会在UTC 0点，也就是北京时间早上8点自动执行优化？如何改参数设置这个时间？\n我们没有使用Elasticsearch的自动优化设置。自己控制优化时间。\nQ5：我的Java程序，log4j2 Flume appender，然后机器上的Flume agent ，直接Elasticsearch 的sink avro到 es节点上，多少个agent 连在单个Elasticsearch节点比较合适 ？\nElasticSearch本身是一个分布式计算集群，所以，请求平均分配到每个 node 即可。\nQ6：我代码里直接用 Java API 生成Flume appender 格式，Flume agent 里interceptor去拆分几个字段，这样是不是太累了？比较推荐的做法是不是还是各业务点自己控制字段，调用Elasticsearch API 生成索引内容？\n业务点自己控制生成的文档吧？如果需要产生不同routing，并且分了索引，这些其实是业务相关的。routing和不同索引，都是根据业务情况哪些查询比较集中而进行处理的。\nQ7：您见过或管理过的生产环境的Elasticsearch数据量多大？\n我们使用 Elasticsearch 进行某些业务处理，数据量过亿。\nQ8：SSD性能提升多少？\nSSD 对索引帮助非常大，效果当当的，提高几十倍应该是没问题。不过，我们没有试过完全使用SSD顶查询，而是使用内存，内存性价比还是不错的。\nQ9：我们现在有256个shard，用uid做routing，所有查询都是走routing。每个shard有30多G，每次扩容很慢，有什么建议？\n可以考虑使用分合查询吗？ 或者使用更多的维度？ 256个 shard 确实比较难以控制。但是如果是分索引和查询，比more shards(256) 效果应该会好不少。\nQ10：Elasticsearch排序等聚合类的操作需要用到fielddata，查询时很慢。新版本中doc values聚合查询操作性能提升很大，你们有没有用过？\nFacet 查询需要更大的内存，更多的 CPU 资源。可以考虑routing、filter、cache等多种方式提高性能。\nAggs 将来是要替换 Facet，建议尽快替换原来的facet API。\nQ11：Elasticsearch配置bootstrap.mlockall，我们在使用中发现会导致启动很慢，因为Elasticsearch要获取到足够的内存才开始启动。\n启动慢是可以接受的，启动慢的原因也许是内存没有有效释放过，比如文件 cached了。 内存充足的情况下，启动速度还是蛮快的，可以接受。 JVM 和 Lucene 都需要内存，一般是JVM 50%, 剩下的50% 文件cached 为Lucene 使用。\nQ12：优化是一个开销比较大的操作，每天优化的时候是否会导致查询不可用？如何优化这块？\n优化是开销很大的。不会导致查询不可用。优化是值得的，大量的碎片会导致查询性能大大降低。 如果非常 care 查询，可以考虑多个集群。在优化时，查询 skip 这个集群就可以。\nQ13：Elasticsearch适合做到10亿级数据查询，每天千万级的数据实时写入或更新吗？\n10亿是可以做到的，如果文档轻量，10亿所占的资源还不是很多。\nELK 使用 Elasticsearch ，进行日志处理每天千万是小case吧？\n不过我们除了使用 ELK 进行日志处理，还进行业务处理，10亿级快速查询是可以做到，不过，需要做一些工作，比如索引和shards的分分合合：）\nQ14：Elasticsearch相比Solr有什么优势吗？\n我们当年使用 Solr 的时候，Elasticsearch 刚出来。他们都是基于 Lucene的。 Elasticsearch 相对于 solr ，省事是一个优点。而且现在 Elasticsearch 相关的应用软件也越来越多。Solr 和 Lucene 集成度很高，更新版本是和Lucene一起的，这是个优点。\n很多年没用 Solr了，毕竟那时候数据量还不大，所以折腾的就少了，主要还是折腾 JVM。所以，就不再过多的比较了。\nQ15：分词用的什么组件？Elasticsearch自带的吗？\n我们使用 IK 分词，不过其他分词也不错。IK分词更新还是很及时的。而且它可以远程更新词典。：）\nQ16： reindex有没有好的方法？\nreindex 这个和 Lucene 有关，它的 update 就是 delete+ add。\nQ17：以上面的两个例子为例 ： 是存储多份同样的数据么？\n是两个集群。第一个集群使用大城市分索引，不过，还有大部分小城市合并一个索引。大城市还是用类目进行routing，小城市合并的索引就使用城市进行routing 。\n第二个集群，大类分得索引，比如fang、che，房屋和车辆和其他类目在一个集群上，他们使用 city+二级类目做routing。\nQ18：集群部署有没有使用 Docker ？ 我们使用的时候 ，同一个服务器 节点之间的互相发现没有问题 ，但是跨机器的时候需要强制指定network.publish_host 和 discovery.zen.ping.unicast.hosts 才能解决集群互相发现问题。\n我们使用puppet进行部署。暂没使用 Docker。 强制指定network.publish_host 和 discovery.zen.ping.unicast.hosts 才能解决集群，跨IP段的时候是有这个需要。\nQ19：您建议采用什么样的数据总线架构来保证业务数据按routing写入多个Elasticsearch集群，怎么保证多集群Elasticsearch中的数据与数据库中数据的一致性？\n我们以前使用 php在web代码中进行索引和分析 query，然后引导到不同集群。 现在我们开发了一套go rest系统——4sea，使用 redis + elastic 以综合提高性能。\n索引时，更新db的同时，提交一个文档 ID 通知4sea 进行更新，然后根据配置更新到不同集群。\n数据提交到查询时，就是分析 query 并引导到不同集群。\n这套 4sea 系统，有机会的可以考虑开源，不算很复杂的。\nQ20： 能介绍一下Elasticsearch的集群rebanlance、段合并相关的原理和经验吗？\n“段”合并？，我们是根据业务特点，产生几个不一样的集群，主要还是 routing 不一样。\nshards 比较平均很重要的，所以选择routing 维度是难点，选择城市的话，大城市所在分片会非常大，此时可以考虑 分索引，几个大城市几个索引，然后小城市合并一个索引。\n如果 shards 大小分布平均的话，就不关心如何 allocation 了。\nQ21：关于集群rebalance，其实就是cluster.routing.allocation配置下的那些rebalance相关的设置，比如allow_rebalance／cluster_concurrent_rebalance／node_initial_primaries_recoveries，推荐怎么配置？\n分片多的情况下，这个才是需要的吧。\n分片比较少时，allow_rebalance disable，然后手动也可以接受的。\n分片多，一般情况会自动平衡。我们对主从不太关心。只是如果一台机器多个 JVM instance （多个 Elasticsearch node）的话，我们写了个脚本来避免同一shard 在一台机器上。\ncluster_concurrent_rebalance 在恢复的时候根据情况修改。正常情况下，再改成默认就好了。\nnode_initial_primaries_recoveries，在保证集群低压的情况下，不怎么care。\nkopf 上面有好多这种配置，你可以多试试。\nQ22：合并查询是异步请求还是同步请求？做缓存吗？\n合并查询是 Elasticsearch 自带 API。\nQ23：用http url connection请求的时候，会发现返回请求很耗时，一般怎么处理？\n尽可能减少慢查询吧？我们很多工作就是想办法如何减少慢查询，routing和分分合合，就是这个目的。\nQ24：生产环境单个节点存储多少G数据？\n有大的，有小的。小的也几十G了。不过根据我们自己的业务特点，某些集群就去掉了全文索引。唯一的全文索引，使用基本的routing（比较平衡的routing，比如user。城市的话，就做不到平衡了，因为大城市数据很多），然后做了 快照，反正是增量快照，1小时甚至更短时间都可以考虑！！！去掉全文索引的其他业务集群，就小多了。\n ","title":"关于Elasticsearch性能优化的几点问题","uid":"614","views":"6268","votes":"1"},"_type":"doc"}
{"_id":"227","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502845559","category_id":"18","comments":"5","has_attach":"0","id":"227","message":"1. 手摸手教你基于 5.2.2 搭建 ELK 日志处理系统，小白福音：\n[url]http://t.cn/RCPI7zF[/url] \n2. 基于 elasticsearch-learning-to-rank 插件的 Machine Learning：\n[url]http://t.cn/R9SHrJb[/url] \n3. 基于 Elasticsearch 的 Hive 查询，弹性伸缩的组合套餐：\n[url]http://t.cn/RCP6v1n[/url] \n\n编辑：江水\n\n归档：[url]https://elasticsearch.cn/article/227[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第18期 (2017-08-16)","uid":"3828","views":"863","votes":"1"},"_type":"doc"}
{"_id":"48","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451480569","category_id":"13","comments":"1","has_attach":"0","id":"48","message":"Packetbeat（https://www.elastic.co/products/beats/packetbeat）\n是一个开源的网络抓包与分析框架，内置了很多常见的协议解析，如HTPP、MySQL、Thrift等。但是网络协议有很多，如何扩展一个自己的协议呢，本文将为您介绍如何在Packetbeat基础上扩展实现您自己的协议。\n\n开发环境：\n1.Go语言\nPacketbeat是由Go语言编写，具有高性能和易部署的特点，有关Go语言的更多信息请访问：https://golang.org/。\n2.Git\n源码管理，相信大家都比较熟悉了。\n3.Tcpdump\n*nix下的抓包分析，可选，用于调试。\n4.Mac本一台\nWindows太伤，不建议。\n5.IDE\n推荐idea，其它只要你顺手都行。\n\n这个教程给大家介绍的是编写一个SMTP协议的扩展，SMTP就是我们发邮件使用的协议，加密的比较麻烦，为了方便，本教程使用不加密的名文传输的SMTP协议，默认对应端口是25。\n\nA.源码签出\n登陆Github打开https://github.com/elastic/beats \n[img]http://log.medcl.net/wp-content/uploads/2015/12/AA406C32-12F2-4633-BE49-0EA66559A722.jpg[/img]\nfork后得到你自己的仓库，比如我的：[url]https://github.com/medcl/packetbeat[/url] [code]#创建相应目录\nmkdir -p $GOPATH/src/github.com/elastic/ \ncd $GOPATH/src/github.com/elastic\n\n#签出源码\ngit clone https://github.com/elastic/beats.git\ncd beats\n\n#修改官方仓库为upstream源，设置自己的仓库为origin源\ngit remote rename origin upstream\ngit remote add origin git@github.com:medcl/packetbeat.git\n\n#获取上游最新的代码，如果是刚fork的话可不用管\ngit pull upstream master\n\n#签出一个名为smtpbeat的分支，用于开发这个功能\ngit checkout -b smtpbeat\n\n#切换到packetbeat模块\ncd packetbeat\n\n#获取依赖信息\n(mkdir -p $GOPATH/src/golang.org/x/\u0026amp;\u0026amp;cd $GOPATH/src/golang.org/x \u0026amp;\u0026amp;git clone https://github.com/golang/tools.git )\ngo get github.com/tools/godep\n\n#编译\nmake\n[/code]\n编译出来的文件：packetbeat就在根目录\n现在我们测试一下\n修改etc/packetbeat.yml,在output下面的elasticsearch下面添加enabled: true，默认是不启用的，另外如果你的Elasticsearch安装了Shield，比如我的Elasticsearch的用户名和密码都是tribe_user，哦，忘了说了，我们的Elasticsearch跑在本机。\npacketbeat.yml的详细配置可参见：[url]https://www.elastic.co/guide/en/beats/packetbeat/current/packetbeat-configuration.html[/url] [code]output:\n  elasticsearch:\n    enabled: true\n    hosts: [\u0026quot;localhost:9200\u0026quot;]\n    username: \u0026quot;tribe_user\u0026quot;\n    password: \u0026quot;tribe_user\u0026quot;[/code]\n现在可以运行命令启动packetbeat了，默认会监听所有内置的协议，如HTTP、DNS等。[code]./packetbeat -e -c etc/packetbeat.yml  -d \u0026quot;publish\u0026quot;[/code]\n介绍一下常用的参数：\n-N dry run模式，不实际output存储日志\n-e 控制台输出调试日志\n-d 仅显示对应logger的日志\n\n好的，我们打开几个网页，控制台会有相应的输出，如下：[code]2015/12/29 14:24:39.965037 preprocess.go:37: DBG  Start Preprocessing\n2015/12/29 14:24:39.965366 publish.go:98: DBG  Publish: {\n  \u0026quot;@timestamp\u0026quot;: \u0026quot;2015-12-29T14:24:39.709Z\u0026quot;,\n  \u0026quot;beat\u0026quot;: {\n    \u0026quot;hostname\u0026quot;: \u0026quot;medcls-MacBook.local\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;medcls-MacBook.local\u0026quot;\n  },\n  \u0026quot;bytes_in\u0026quot;: 31,\n  \u0026quot;bytes_out\u0026quot;: 115,\n  \u0026quot;client_ip\u0026quot;: \u0026quot;192.168.3.10\u0026quot;,\n  \u0026quot;client_port\u0026quot;: 53669,\n  \u0026quot;client_proc\u0026quot;: \u0026quot;\u0026quot;,\n  \u0026quot;client_server\u0026quot;: \u0026quot;\u0026quot;,\n  \u0026quot;count\u0026quot;: 1,\n  \u0026quot;direction\u0026quot;: \u0026quot;out\u0026quot;,\n  \u0026quot;dns\u0026quot;: {\n    \u0026quot;additionals_count\u0026quot;: 0,\n    \u0026quot;answers\u0026quot;: [\n      {\n        \u0026quot;class\u0026quot;: \u0026quot;IN\u0026quot;,\n        \u0026quot;data\u0026quot;: \u0026quot;www.a.shifen.com\u0026quot;,\n        \u0026quot;name\u0026quot;: \u0026quot;sp2.baidu.com\u0026quot;,\n        \u0026quot;ttl\u0026quot;: 333,\n        \u0026quot;type\u0026quot;: \u0026quot;CNAME\u0026quot;\n      }\n    ],\n    \u0026quot;answers_count\u0026quot;: 1,\n    \u0026quot;authorities\u0026quot;: [\n      {\n        \u0026quot;class\u0026quot;: \u0026quot;IN\u0026quot;,\n        \u0026quot;data\u0026quot;: \u0026quot;ns1.a.shifen.com\u0026quot;,\n        \u0026quot;expire\u0026quot;: 86400,\n        \u0026quot;minimum\u0026quot;: 3600,\n        \u0026quot;name\u0026quot;: \u0026quot;a.shifen.com\u0026quot;,\n        \u0026quot;refresh\u0026quot;: 5,\n        \u0026quot;retry\u0026quot;: 5,\n        \u0026quot;rname\u0026quot;: \u0026quot;baidu_dns_master.baidu.com\u0026quot;,\n        \u0026quot;serial\u0026quot;: 1512240003,\n        \u0026quot;ttl\u0026quot;: 12,\n        \u0026quot;type\u0026quot;: \u0026quot;SOA\u0026quot;\n      }\n    ],\n    \u0026quot;authorities_count\u0026quot;: 1,\n    \u0026quot;flags\u0026quot;: {\n      \u0026quot;authoritative\u0026quot;: false,\n      \u0026quot;recursion_allowed\u0026quot;: true,\n      \u0026quot;recursion_desired\u0026quot;: true,\n      \u0026quot;truncated_response\u0026quot;: false\n    },\n    \u0026quot;id\u0026quot;: 7435,\n    \u0026quot;op_code\u0026quot;: \u0026quot;QUERY\u0026quot;,\n    \u0026quot;question\u0026quot;: {\n      \u0026quot;class\u0026quot;: \u0026quot;IN\u0026quot;,\n      \u0026quot;name\u0026quot;: \u0026quot;sp2.baidu.com\u0026quot;,\n      \u0026quot;type\u0026quot;: \u0026quot;AAAA\u0026quot;\n    },\n    \u0026quot;response_code\u0026quot;: \u0026quot;NOERROR\u0026quot;\n  },\n  \u0026quot;ip\u0026quot;: \u0026quot;192.168.3.1\u0026quot;,\n  \u0026quot;method\u0026quot;: \u0026quot;QUERY\u0026quot;,\n  \u0026quot;port\u0026quot;: 53,\n  \u0026quot;proc\u0026quot;: \u0026quot;\u0026quot;,\n  \u0026quot;query\u0026quot;: \u0026quot;class IN, type AAAA, sp2.baidu.com\u0026quot;,\n  \u0026quot;resource\u0026quot;: \u0026quot;sp2.baidu.com\u0026quot;,\n  \u0026quot;responsetime\u0026quot;: 18,\n  \u0026quot;server\u0026quot;: \u0026quot;\u0026quot;,\n  \u0026quot;status\u0026quot;: \u0026quot;OK\u0026quot;,\n  \u0026quot;transport\u0026quot;: \u0026quot;udp\u0026quot;,\n  \u0026quot;type\u0026quot;: \u0026quot;dns\u0026quot;\n}\n2015/12/29 14:24:39.965774 preprocess.go:94: DBG  Forward preprocessed events\n2015/12/29 14:24:39.965796 async.go:42: DBG  async forward to outputers (1)\n2015/12/29 14:24:40.099973 output.go:103: DBG  output worker: publish 2 events[/code]\n然后Elasticsearch应该就会有数据进去了，我们看看：[code]curl http://localhost:9200/_cat/indices\\?pretty\\=true -u tribe_user:tribe_user\nyellow open packetbeat-2015.12.29  5 1   135  0 561.2kb 561.2kb[/code]\n至此，packetbeat源码的build成功，我们整个开发流程已经跑通了，下一节正式开始介绍SMTP协议的扩展。","title":"Packetbeat协议扩展开发教程（1）","uid":"1","views":"5447","votes":"6"},"_type":"doc"}
{"_id":"52","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452674081","category_id":"2","comments":"2","has_attach":"0","id":"52","message":"[url]https://github.com/zhongbiaodev/py-mysql-elasticsearch-sync[/url]\n这个工具用python实现，主要使用了mysqldump输出xml进行初次同步，以及binlog进行增量同步，欢迎试用以及提出修改意见。\n最近刚刚更新了中文文档。","title":"一个把数据从MySQL同步到Elasticsearch的工具","uid":"775","views":"6766","votes":"2"},"_type":"doc"}
{"_id":"60","_index":"forum-mysql","_score":1,"_source":{"addtime":"1458291089","category_id":"2","comments":"0","has_attach":"0","id":"60","message":"今天在es中对http日志的状态码status进行aggs搜索出现字段内容显示不正常的问题，记录过程：\n\nhttp日志的情况：\n1、http日志从logstash写入es时，状态码配置为status，其内容为 200 ，302 ，400 ，404等。\n2、使用kibana对该日志的索引进行查询，在discover页面中显示的status内容跟logstash的内容一致，是正常的。\n\n出现问题的场景：\n（我这里使用的是kibana的sense插件进行的查询，如果直接使用curl python-ES也是一样的）\n查询该索引：\nPOST http-2016.03.18/_search\n{\n  \u0026quot;fields\u0026quot;: [\u0026quot;status\u0026quot;],\n          \u0026quot;query\u0026quot;:{\n            \u0026quot;bool\u0026quot;:{\n              \u0026quot;must\u0026quot;: [\n                {\n                  \u0026quot;range\u0026quot; : {\n                    \u0026quot;@timestamp\u0026quot; : {\u0026quot;gte\u0026quot; : \u0026quot;now-5m\u0026quot;}\n                  }\n                }\n              ]\n            }\n          },\n          \u0026quot;_source\u0026quot;: \u0026quot;false\u0026quot;,\n          \u0026quot;size\u0026quot;: 0,\n          \u0026quot;aggs\u0026quot;: {\n            \u0026quot;status_type\u0026quot;: {\n              \u0026quot;terms\u0026quot;:{\u0026quot;field\u0026quot;:\u0026quot;status\u0026quot;}\n            }\n          }\n}\n\n查询返回的结果中aggregations部分的内容：\n\u0026quot;aggregations\u0026quot; : {\n    \u0026quot;status_type\u0026quot; : {\n      \u0026quot;doc_count_error_upper_bound\u0026quot; : 0,\n      \u0026quot;sum_other_doc_count\u0026quot; : 0,\n      \u0026quot;buckets\u0026quot; : [ {\n        \u0026quot;key\u0026quot; : -56,\n        \u0026quot;doc_count\u0026quot; : 376341\n      }, {\n        \u0026quot;key\u0026quot; : 46,\n        \u0026quot;doc_count\u0026quot; : 51439\n      }, {\n        \u0026quot;key\u0026quot; : 45,\n        \u0026quot;doc_count\u0026quot; : 5543\n      }, {\n        \u0026quot;key\u0026quot; : 48,\n        \u0026quot;doc_count\u0026quot; : 1669\n      }, {\n        \u0026quot;key\u0026quot; : -108,\n        \u0026quot;doc_count\u0026quot; : 1068\n      }, {\n        \u0026quot;key\u0026quot; : -50,\n        \u0026quot;doc_count\u0026quot; : 11\n      }, {\n        \u0026quot;key\u0026quot; : -109,\n        \u0026quot;doc_count\u0026quot; : 8\n      }, {\n        \u0026quot;key\u0026quot; : -112,\n        \u0026quot;doc_count\u0026quot; : 4\n      } \n\n寻找原因：\n起先先去掉了查询的aggs部分，单独查询query的内容：\nPOST http-2016.03.18/_search\n{\n  \u0026quot;fields\u0026quot;: [\u0026quot;status\u0026quot;],\n          \u0026quot;query\u0026quot;:{\n            \u0026quot;bool\u0026quot;:{\n              \u0026quot;must\u0026quot;: [\n                {\n                  \u0026quot;range\u0026quot; : {\n                    \u0026quot;@timestamp\u0026quot; : {\u0026quot;gte\u0026quot; : \u0026quot;now-5m\u0026quot;}\n                  }\n                }\n              ]\n            }\n          }\n}\n\n返回的结果中，hits显示的status字段内容是正常的：\n\u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 1242104,\n    \u0026quot;max_score\u0026quot;: 1,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;http-2016.03.18\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;log\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;AVOI3EiwidwPAhB1e7gQ\u0026quot;,\n        \u0026quot;_score\u0026quot;: 1,\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;status\u0026quot;: [\n            \u0026quot;200\u0026quot;\n          ]\n        }\n      }\n    ......\n\n然后查询了http索引的索引信息和模版配置：\nGET /http-2016.03.18/\nGET /_template/http\n发现其中http的status的属性type类型的内容是byte ：\n        \u0026quot;properties\u0026quot;: {\n          \u0026quot;@timestamp\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n            \u0026quot;format\u0026quot;: \u0026quot;strict_date_optional_time||epoch_millis\u0026quot;\n          },\n        ......\n        ......\n          \u0026quot;status\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;byte\u0026quot;\n          },\n        ......\n        ......\n\n原因：\n在aggs查询中发现了status字段显示错误的情况，status的type类型在es模版中定义成了byte类型，当status的值超过127后将出现溢出的情况，因此修改为short后，恢复了正常。\n（对于http的状态码status，其type类型使用short已经足够了，如果使用integer，long或默认的string类型也是可以的，这里影响的是存储空间占用的大小。）\n \n ","title":"es索引模版配置不当导致的aggs聚合查询字段显示错误的问题","uid":"739","views":"2926","votes":"1"},"_type":"doc"}
{"_id":"73","_index":"forum-mysql","_score":1,"_source":{"addtime":"1461208791","category_id":"2","comments":"1","has_attach":"0","id":"73","message":"\n  \n安装jdk\n\n下载地址\n\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html\n\n \n\n\n \n \n \n\nJAVA_HOME  :   E:\\Java\\jdk1.7.0\n\n \n\nPath   :  %JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin;\n\n \n\nCLASSPATH  : .;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar\n\n \n\n \n\n \n\n首先下载最新的elasticsearch安装版本\n\nhttps://www.elastic.co/downloads/elasticsearch\n\n \n\n安装插件\n\nelasticsearch插件elasticsearch-head安装： plugininstall mobz/elasticsearch-head\n\n \n\nelasticsearch插件bigdesk安装：plugininstall lukas-vlcek/bigdesk\n\n \n\n前台运行es\n\n在cmd命令行进入安装目录，再进入 bin目录，运行elasticsearch.bat命令： elasticsearch\n\n后台运行es\n\n进入E:\\Install_SoftWare\\elasticsearch2.2.0\\bin\n\n注册服务  service.bat install\n \n\n \n\n内存分配\n\n打开E:\\Install_SoftWare\\elasticsearch2.2.0\\bin\\service.bat\n \n\n或着修改注册表参数\n\n打开regedit\n\n \n\n \n\n全路径：hkey_local_machine/software/wow6432node/apacheSoftware foundation/procrun2.0/elasticsearch-service-x64/java\n\n \n\n启动成功如下图\n简单查询\n复杂查询\nelasticsearch.yml文件配置\n\n \n\ncluster.name: pq  es名称 \n\n \n\nnode.name: node10 节点名称 \n\n \n\nnode.master: true 设为主节点\n\nnode.master: false 不为主节点\n\n \n\nnode.data: false 不存储数据\n\nnode.data:true  存储数据\n\n \n\n组合master, data\n\nMaster=true, data=false  该节点做为主节点\n\nMaster=true, data=true  该节点既是主节点又是数据节点\n\nMaster=false, data=true  该节点做为数据节点\n\nMaster=false, data= false 该节点做为负载均衡节点\n\n \n\n \n\n \n\npath.data: G:\\es_data,F:\\es_data  数据存储路径  只有数据节点存储数据\n\n \n\npath.logs: D:\\es_logs  日志存储路径\n\n \n\nbootstrap.mlockall: true  用来锁定内存\n\n \n\nnetwork.host: 0.0.0.0  设置ip\n\nhttp.port: 9200  设置http端口\n\ntransport.tcp.port: 9300  设置tcp端口\n\ndiscovery.zen.ping.unicast.hosts:[\u0026quot;0.0.*.*\u0026quot;,\u0026quot;*.*.*.*:9300\u0026quot;]设置群集ip地址\n\n \n\n \n\n \n\n分词安装（IK分词）\n\nMaven环境配置\n\n官方下载地址：http://maven.apache.org/download.html\n \n \n \n\n\n \n\n \n\n https://github.com/medcl/elasticsearch-analysis-ik下载地址\n\n \n\n把下载的elasticsearch-analysis-ik.zip 解压。\n\n \n\n Maven 打包\n\n进入elasticsearch-analysis-ik-master/ 下，打包。注意：打包后的文件在elasticsearch-analysis-ik-master/target/目录下\n \n\n然后在elasticsearch-2.2.0/plugins下创建目录 ik\n \n\n然后将打包后的elasticsearch-analysis-ik-1.8.0.jar 放入当前目录下\n \n\n \n\nMaven 打包命令  mvn clean   package\n\n \n\n在 Elasticsearch 的config下的elasticsearch.yml文件中，添加如下代码。 设置（2.0以上可以不设置）。1.  index:  2.        analysis:                     3.          analyzer:        4.            ik:  5.               alias: [ik_analyzer]  6.                type:org.elasticsearch.index.analysis.IkAnalyzerProvider  7.            ik_max_word:  8.                type: ik 9.                use_smart: false  10.           ik_smart:  11.               type: ik  12.              use_smart: true或者简单配置：index.analysis.analyzer.ik.type : “ik”\n\n \n\n分词测试\n\n  http://127.0.0.0:9215/index/_analyze?analyzer=ik\u0026amp;pretty=true/\n\npost\n\n{\u0026quot;text\u0026quot;:\u0026quot;刑事判决书\u0026quot;}、\n \n\n \n\n \n\n详细ik分词配置网址\n\nhttp://www.sojson.com/blog/82","title":"elasticearch,jdk,maven安装","uid":"1121","views":"3397","votes":"0"},"_type":"doc"}
{"_id":"79","_index":"forum-mysql","_score":1,"_source":{"addtime":"1464096113","category_id":"12","comments":"0","has_attach":"0","id":"79","message":" 公司介绍：NobleProg（诺波中国），公司成立于2005年，总部设在英国伦敦并在欧洲和美国建立了特许经营和分公司。2015年来到中国，面对国内企业提供人工智能、IT、统计、管理、编程的培训和咨询服务。\n 聘[b]Machine Learning/Elasticserach/Ducker and kubemetes[/b]三个方向兼职培训师/讲师。\n基本要求如下：\n1、具有丰富的理论知识和技能；\n2、有一定的项目经验（这包括你是项目leader或项目组成员）；\n3、有培训师或讲师的经验最佳； \n4、可以依据我们提供的培训大纲结合客户需求做出培训计划；  \n5、可授受出差（视项目决定）；\n6、可接受兼职；\n7、薪资待遇请与我们商谈。\n \n公司网站：http://www.nobleprog.cn/training\n对以上招聘信息感兴趣，请与我们联系。\n \nTina\n手机：18610650025\nQQ：1575119117","title":"【招聘】ML/ES/DOCKER方向兼职培训师/讲师","uid":"1249","views":"1180","votes":"0"},"_type":"doc"}
{"_id":"84","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466737243","category_id":"15","comments":"3","has_attach":"0","id":"84","message":"Lucene板块好冷清，这里将我之前的入门的博文搬过来，填不下空白，欢迎拍砖[code]认识Lucene\n\n下面是百科对Lucene的描述：\n\nLucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。\n\nLucene突出的优点\n\nLucene作为一个全文检索引擎，其具有如下突出的优点：\n（1）索引文件格式独立于应用平台。Lucene定义了一套以8位字节为基础的索引文件格式，使得兼容系统或者不同平台的应用能够共享建立的索引文件。\n（2）在传统全文检索引擎的倒排索引的基础上，实现了分块索引，能够针对新的文件建立小文件索引，提升索引速度。然后通过与原有索引的合并，达到优化的目的。\n（3）优秀的面向对象的系统架构，使得对于Lucene扩展的学习难度降低，方便扩充新功能。\n（4）设计了独立于语言和文件格式的文本分析接口，索引器通过接受Token流完成索引文件的创立，用户扩展新的语言和文件格式，只需要实现文本分析的接口。\n（5）已经默认实现了一套强大的查询引擎，用户无需自己编写代码即可使系统可获得强大的查询能力，Lucene的查询实现中默认实现了布尔操作、模糊查询（Fuzzy Search[11]）、分组查询等等。\n面对已经存在的商业全文检索引擎，Lucene也具有相当的优势。\n首先，它的开发源代码发行方式（遵守Apache Software License[12]），在此基础上程序员不仅仅可以充分的利用Lucene所提供的强大功能，而且可以深入细致的学习到全文检索引擎制作技术和面向对象编程的实践，进而在此基础上根据应用的实际情况编写出更好的更适合当前应用的全文检索引擎。在这一点上，商业软件的灵活性远远不及Lucene。\n其次，Lucene秉承了开放源代码一贯的架构优良的优势，设计了一个合理而极具扩充能力的面向对象架构，程序员可以在Lucene的基础上扩充各种功能，比如扩充中文处理能力，从文本扩充到HTML、PDF[13]等等文本格式的处理，编写这些扩展的功能不仅仅不复杂，而且由于Lucene恰当合理的对系统设备做了程序上的抽象，扩展的功能也能轻易的达到跨平台的能力。\n最后，转移到apache软件基金会后，借助于apache软件基金会的网络平台，程序员可以方便的和开发者、其它程序员交流，促成资源的共享，甚至直接获得已经编写完备的扩充功能。最后，虽然Lucene使用Java语言写成，但是开放源代码社区的程序员正在不懈的将之使用各种传统语言实现（例如.net framework[14]），在遵守Lucene索引文件格式的基础上，使得Lucene能够运行在各种各样的平台上，系统管理员可以根据当前的平台适合的语言来合理的选择。[/code][code]入门前的准备\n\n了解一些关键字的概念：\nDocument   \nDocument 是用来描述文档的，这里的文档可以指一个 HTML 页面，一封电子邮件，或者是一个文本文件。一个 Document 对象由多个 Field 对象组成的。可以把一个 Document 对象想象成数据库中的一个记录，而每个 Field 对象就是记录的一个字段。 \nField  \nField 对象是用来描述一个文档的某个属性的，比如一封电子邮件的标题和内容可以用两个 Field 对象分别描述。  \nAnalyzer   \n在一个文档被索引之前，首先需要对文档内容进行分词处理，这部分工作就是由 Analyzer 来做的。Analyzer 类是一个抽象类，它有多个实现。针对不同的语言和应用需要选择适合的 Analyzer。Analyzer 把分词后的内容交给 IndexWriter 来建立索引。  \nIndexWriter   \nIndexWriter 是 Lucene 用来创建索引的一个核心的类，他的作用是把一个个的 Document 对象加到索引中来。  \nDirectory   \n这个类代表了 Lucene 的索引的存储的位置，这是一个抽象类，它目前有两个实现，第一个是 FSDirectory，它表示一个存储在文件系统中的索引的位置。第二个是 RAMDirectory，它表示一个存储在内存当中的索引的位置。 \nQuery  \n这是一个抽象类，他有多个实现，比如 TermQuery, BooleanQuery, PrefixQuery. 这个类的目的是把用户输入的查询字符串封装成 Lucene 能够识别的 Query。 \nIndexSearcher   \nIndexSearcher 是用来在建立好的索引上进行搜索的。它只能以只读的方式打开一个索引，所以可以有多个 IndexSearcher 的实例在一个索引上进行操作。\nHits  \nHits 是用来保存搜索结果的。     \n\n我的浅显理解\n使用Lucene分为几个步骤，都是围绕索引展开的：\n1.写索引 IndexWriter\n2.读索引 IndexReader\n3.查索引 IndexSearcher\n4.封装查询条件，想到于写数据库的sql  QueryParser\n5.查询已查到的索引得到结果集 TopDocs ，可以得到Document的一个集合  [/code][code]正式入门，直接上代码                               \n\n写索引：\n\npackage com.kl.luceneDemo;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.FSDirectory;\nimport org.apache.lucene.store.RAMDirectory;\nimport java.io.File;\nimport java.io.FileReader;\nimport java.nio.file.Paths;\n/**\n * @author kl by 2016/3/14\n * @boke www.kailing.pub\n */\npublic class Indexer {\n    public  IndexWriter writer;\n    /**\n     * 实例化写索引\n     */\n    public Indexer(String indexDir)throws Exception{\n        Analyzer analyzer=new StandardAnalyzer();//分词器\n        IndexWriterConfig writerConfig=new IndexWriterConfig(analyzer);//写索引配置\n        //Directory ramDirectory= new RAMDirectory();//索引写的内存\n        Directory directory= FSDirectory.open(Paths.get(indexDir));//索引存储磁盘位置\n        writer=new IndexWriter(directory,writerConfig);//实例化一个写索引\n    }\n    /**\n     * 关闭写索引\n     * @throws Exception\n     */\n    public void close()throws Exception{\n        writer.close();\n    }\n    /**\n     * 添加指定目录的所有文件的索引\n     * @param dataDir\n     * @return\n     * @throws Exception\n     */\n    public int index(String dataDir)throws Exception{\n        File files=new File(dataDir).listFiles();//得到指定目录的文档数组\n        for(File file:files){\n            indexFile(file);\n        }\n        return writer.numDocs();\n    }\n    public void indexFile(File file)throws Exception{\n        System.out.println(\u0026quot;索引文件:\u0026quot;+file.getCanonicalPath());//打印索引到的文件路径信息\n        Document document=getDocument(file);//得到一个文档信息，相对一个表记录\n        writer.addDocument(document);//写入到索引，相当于插入一个表记录\n    }\n\n    /**\n     * 返回一个文档记录\n     * @param file\n     * @return\n     * @throws Exception\n     */\n    public Document getDocument(File file)throws Exception{\n        Document document=new Document();//实例化一个文档\n        document.add(new TextField(\u0026quot;context\u0026quot;,new FileReader(file)));//添加一个文档信息，相当于一个数据库表字段\n        document.add(new TextField(\u0026quot;fileName\u0026quot;,file.getName(), Field.Store.YES));//添加文档的名字属性\n        document.add(new TextField(\u0026quot;filePath\u0026quot;,file.getCanonicalPath(),Field.Store.YES));//添加文档的路径属性\n        return document;\n    }\n    public static void main(String ages){\n        String indexDir=\u0026quot;E:\\\\LuceneIndex\u0026quot;;\n        String dataDir=\u0026quot;E:\\\\LuceneTestData\u0026quot;;\n        Indexer indexer=null;\n        int indexSum=0;\n        try {\n            indexer=new Indexer(indexDir);\n            indexSum= indexer.index(dataDir);\n            System.out.printf(\u0026quot;完成\u0026quot;+indexSum+\u0026quot;个文件的索引\u0026quot;);\n\n        }catch (Exception e){\n            e.printStackTrace();\n        }finally {\n            try {\n                indexer.close();\n            }catch (Exception e){\n                e.printStackTrace();\n            }\n\n        }\n\n    }\n\n}\n读查索引\n\npackage com.kl.luceneDemo;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.queryparser.classic.QueryParser;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.FSDirectory;\nimport java.nio.file.Paths;\n/**\n * @author kl by 2016/3/14\n * @boke www.kailing.pub\n */\npublic class Searcher {\n    public static void search(String indexDir,String q)throws Exception{\n        Directory dir= FSDirectory.open(Paths.get(indexDir));//索引地址\n        IndexReader reader= DirectoryReader.open(dir);//读索引\n        IndexSearcher is=new IndexSearcher(reader);\n        Analyzer analyzer=new StandardAnalyzer(); // 标准分词器\n        QueryParser parser=new QueryParser(\u0026quot;context\u0026quot;, analyzer);//指定查询Document的某个属性\n        Query query=parser.parse(q);//指定查询索引内容，对应某个分词\n        TopDocs hits=is.search(query, 10);//执行搜索\n        System.out.println(\u0026quot;匹配 \u0026quot;+q+\u0026quot;查询到\u0026quot;+hits.totalHits+\u0026quot;个记录\u0026quot;);\n        for(ScoreDoc scoreDoc:hits.scoreDocs){\n            Document doc=is.doc(scoreDoc.doc);\n            System.out.println(doc.get(\u0026quot;fileName\u0026quot;));//打印Document的fileName属性\n        }\n        reader.close();\n    }\n    public static void main(String args) {\n        String indexDir=\u0026quot;E:\\\\LuceneIndex\u0026quot;;\n        String q=\u0026quot;Muir\u0026quot;;\n        try {\n            search(indexDir,q);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n以下图片是我的文件目录和Lucene生成的索引文件[/code]原文地址：[url]http://www.kailing.pub/article/index/arcid/71.html[/url]\n社区的富文本编辑器太low了，能不能换啊","title":"Lucene5.5入门第一篇——hello World","uid":"1032","views":"2870","votes":"0"},"_type":"doc"}
{"_id":"89","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738319","category_id":"15","comments":"0","has_attach":"0","id":"89","message":"[code]前言\n\n对于中文分词这个字眼，百科是这么描述的：\n\n中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂的多、困难的多。\n\n简单的说，就是把一个句子拆分成多个词，有废话的赶脚，呵呵\n\n之前几篇博文，笔者都是用的Lucene里的StandardAnalyzer来做的分词处理，虽然在后面的Lucene版本中，\n\n准备工作\n\n这里先把这两个分词器加入到我们的项目中来\n\nIKAnalyzer：IKAnalyzer是一个国人开发的开源的分词工具，下载地址：https://code.google.com/archive/p/ik-analyzer/downloads?page=1，GItHub地址：https://github.com/wks/ik-analyzer。推荐到GitHub上下载源码然后自己打包，项目是maven构建的，打成jar，然后在我们的项目中引用。\n\nps:打包项目的时候记得去掉test\n\npaoding：paoding也是一个开源的i项目，下载地址：https://code.google.com/archive/p/paoding/downloads，下载下来是一个压缩文件，里面有源码也有打包好可以直接用的jar\n\nps:下载paoding的时候请自行翻墙吧，这里推荐一个翻墙神器Lantern\n\n进入正文\n\n笔者在测试过程中并不是一番风顺啊，好多坑，下面我们来看看这些坑\n\nIKAnlyzer的问题：\n\n1.最新的项目也是基于Lucene3.0.3版本的，而笔者一直都是使用的最新的Lucene5.5，所以一测试就报了如下的错误\n\nException in thread \u0026quot;main\u0026quot; java.lang.VerifyError: class org.wltea.analyzer.lucene.IKAnalyzer overrides final method tokenStream.(Ljava/lang/String;Ljava/io/Reader;)Lorg/apache/lucene/analysis/TokenStream;\n\n解决：笔者有试着将IKAnlyzer项目的Lucene版本换成5.5的重新打包，然后发现行不通，改动的地方太多了，虽然IKAnlyzer项目不大，文件不多。笔者还没达到重写IKAnlyzer项目的能力，有时间可以研究研究源码，最后只有降级自己的Lucene版本了，幸好有maven，降级只要改下pom.xml就行了\n\npaoding的问题\n\n1.项目首先会依赖apache的commons-logging，笔者测试1.1版本通过。\n\n2.然后就是下面的这个了 问题了，其实这个问题paoding自己的使用文档中类似的说明，（Paoding中文分词参考手册.htm）这个文档包含在了下载的压缩包中了\n\nnet.paoding.analysis.exception.PaodingAnalysisException: please set a system env PAODING_DIC_HOME or Config paoding.dic.home in paoding-dic-home.properties point to the dictionaries!\n\n解决：就是指定paoding的一个字典文件目录，这个文件在下载下来的压缩包中的dic中，\n\n三种解决方案：\n\n(1).你可以解压缩jar，然后把paoding-dic-home.properties文件中的paoding.dic.home指定你的doc目录，重新压缩，把后缀换成jar就行了。\n\n(2).就是参照官方的说明，把doc目录添加到环境变量中\n\n(3).把doc放在项目目录下\n\n3.paoding还有个问题就是Lucene3.0.3都不兼容了，笔者只好又把Lucene版本降到2.2.0来测试了\n\n越过那些沟沟坎坎终于要见真功夫了，不多说，直接上代码，上图\n\n\npackage com.kl.Lucene;\nimport net.paoding.analysis.analyzer.PaodingAnalyzer;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.Token;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.tokenattributes.TermAttribute;\nimport org.junit.Test;\nimport org.wltea.analyzer.lucene.IKAnalyzer;\nimport java.io.StringReader;\n/**\n * @author kl by 2016/3/14\n * @boke www.kailing.pub\n */\npublic class AnalyzerTest {\n    //测试数据\n    public static String testData=\u0026quot;中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一\u0026quot; +\n            \u0026quot;一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。\u0026quot;;\n    /**\n     * 得到IKAnalyzer分词器\n     * @return\n     */\n    public static Analyzer getIKAnalyzer(){\n        return  new IKAnalyzer();\n    }\n    /**\n     * 得到Paoding分词器\n     * @return\n     */\n    public static Analyzer getPaoding(){\n        return new PaodingAnalyzer();\n    }\n    /**\n     * 测试IKAnalyzer\n     * @throws Exception\n     */\n    @Test\n    public void TestIKAnalyzer()throws Exception{\n        Analyzer analyzer =getIKAnalyzer();\n        TokenStream tokenStream = analyzer.tokenStream(\u0026quot;\u0026quot;, new StringReader(testData));\n        tokenStream.addAttribute(TermAttribute.class);\n        System.out.println(\u0026quot;分词数据：\u0026quot;+testData);\n        System.out.println(\u0026quot;=====IKAnalyzer的分词结果====\u0026quot;);\n        while (tokenStream.incrementToken()) {\n            TermAttribute termAttribute = tokenStream.getAttribute(TermAttribute.class);\n            System.out.println(new String(termAttribute.term()));\n            termAttribute.termLength();\n        }\n\n    }\n    /**\n     * 测试Paoding\n     * @throws Exception\n     */\n    @Test\n    public void TestPaoding()throws  Exception{\n        Analyzer analyzer =getPaoding();\n        TokenStream ts = analyzer.tokenStream(\u0026quot;\u0026quot;,  new StringReader(testData));\n        System.out.println(\u0026quot;分词数据：\u0026quot;+testData);\n        System.out.println(\u0026quot;=====Paoding的分词结果====\u0026quot;);\n        Token t;\n//        while ((t = ts.next()) != null) {\n//            System.out.println(t.termText());\n//        }\n    }\n\n\n}\n测试数据：中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。\n\n测试结果如下：\n\n\n\n\n\n从结果上看，IKAnalyzer和paoding的分词相差无几，IKAnlyzer比paoding的分词粒度更细，这个可以查看他们的分词字典文件去分析\n\n后记:除了上面介绍的两种分词，常用的还有中日韩二元分词器CJKAnalyzer，以及lucene基于中科院分词实现的SmartChineseAnalyzer，其中cjk在lucene-common的jar包里了，SmartChineseAnalyzer需要另外引入jar，如下pom依赖\n\n        \u0026lt;!--公共的分词器，包含大多数的语言分词--\u0026gt;\n        \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.apache.lucene\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;lucene-analyzers-common\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;5.5.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n        \u0026lt;!--基于中科院的中文分词--\u0026gt;\n        \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.apache.lucene\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;lucene-analyzers-smartcn\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;5.5.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n\n\n原文地址：[url]http://www.kailing.pub/article/index/arcid/76.html[/url]\n[/code]","title":"Lucene5.5入门第六篇——Analyzer中文分词","uid":"1032","views":"6632","votes":"0"},"_type":"doc"}
{"_id":"92","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738747","category_id":"15","comments":"0","has_attach":"0","id":"92","message":"[code]前言\n\n任何数据量大的情况下，取数据的时候都需要做分页的处理，比如我们百度的时候，结果往往有上千万的结果，而当前呈现在的只有几页的内容，这就是分页的场景，lucene也提供了分页查询的支持\n\n认识searchafter\n\n使用IndexSearcher的searchafter方法可以轻松实现分页查询，如下图\n\n\n\nsearchafter有多个重载的方法，其中有些searchafter方法Lucene已不推荐使用了，用的多的就searchAfter(final ScoreDoc after, Query query, int numHits)\n\n它有三个形参，分别是\n\nafter:上一页最后一个ScoreDoc；\n\nquery：query接口实现类的对象，query对象可以通过QueryParser类来创建，也可以自己new Query接口的某一个特定接口实现类；\n\nnumHits:每页显示的条数\n\nsearchafter官方文档说明地址\n\n重点在下面\n\n/**\n * Created by 小陈 on 2016/3/25.\n */\npublic class IndexerPaging {\n    //测试数据，模拟数据库表结构\n    private static String[] ids={\u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot;,\u0026quot;4\u0026quot;,\u0026quot;5\u0026quot;,\u0026quot;6\u0026quot;}; //用户ID\n    private static String [] names={\u0026quot;kl\u0026quot;,\u0026quot;kl\u0026quot;,\u0026quot;kl\u0026quot;,\u0026quot;kl\u0026quot;,\u0026quot;kl\u0026quot;,\u0026quot;fds\u0026quot;};\n    private static String [] describes={\u0026quot;shi yi ge mei nan zi\u0026quot;,\u0026quot;Don't know\u0026quot;,\u0026quot;Is an idiot\\n\u0026quot;,\u0026quot;Is an idiot\\n\u0026quot;,\u0026quot;Is an idiot\\n\u0026quot;,\u0026quot;Is an idiot\\n\u0026quot;};\n    //索引存储地址\n    private static String indexDir=\u0026quot;E:\\\\javaEEworkspace\\\\LuceneDemo\\\\LuceneIndex\u0026quot;;\n\n    /**\n     * 获取操作索引实体,并添加测试数据\n     * @param indexDir 索引存储位置\n     * @return\n     * @throws Exception\n     */\n    public static void getIndexWriter(String indexDir)throws Exception{\n        IndexWriterConfig writerConfig=new IndexWriterConfig(getAnalyzer());\n        IndexWriter indexWriter=new IndexWriter(FSDirectory.open(Paths.get(indexDir)),writerConfig);\n        Document document=new Document();\n        //Field.Store.YES或者NO(存储域选项)\n        //设置为YES表示或把这个域中的内容完全存储到文件中，方便进行文本的还原\n        //设置为NO表示把这个域的内容不存储到文件中，但是可以被索引，此时内容无法完全还原(doc.get)\n        for(int i=0;i1){\n                 int pageIndexLast=(pageIndex-1)*pageSize-1;\n                 TopDocs hits=searcher.search(query,pageIndexLast);\n                 if(hits.totalHits\u0026gt;=pageIndexLast)\n                     return hits.scoreDocs[pageIndexLast];\n\n             }\n             return null;\n    }\n\n    public static void searcher(String indexDir,String q,int pageIndex,int pageSize)throws Exception{\n        Directory directory= FSDirectory.open(Paths.get(indexDir));\n        IndexReader reader= DirectoryReader.open(directory);\n        IndexSearcher indexSearcher=new IndexSearcher(reader);\n        QueryParser queryParser=new QueryParser(\u0026quot;names\u0026quot;,new StandardAnalyzer());\n        Query query=queryParser.parse(q);\n        //分页查询\n        TopDocs hits=  indexSearcher.searchAfter(getPageLastScoreDoc(pageIndex,pageSize,query,indexSearcher),query,pageSize);//查询首次的30条\n        System.out.println(\u0026quot;匹配 \u0026quot;+q+\u0026quot;查询到\u0026quot;+hits.totalHits+\u0026quot;个记录\u0026quot;);\n        for (ScoreDoc scoreDoc:hits.scoreDocs){\n            Document doc=indexSearcher.doc(scoreDoc.doc);\n            System.out.println(doc.get(\u0026quot;describes\u0026quot;));//打印Document的fileName属性\n        }\n        reader.close();\n        directory.close();//关闭连接\n    }\n    /**\n     * 得到默认分词器\n     * @return\n     */\n    public static Analyzer getAnalyzer(){\n        return new StandardAnalyzer();\n    }\n\n    @Test\n    public void  Test()throws Exception{\n//     getIndexWriter(indexDir);\n        searcher(indexDir,\u0026quot;kl\u0026quot;,1,10);//查询测试\n    }\n\n}[/code]原文地址：[url]http://www.kailing.pub/article/index/arcid/80.html[/url]","title":"Lucene5.5入门第九篇——使用searchafter方法实现分页查询","uid":"1032","views":"3996","votes":"0"},"_type":"doc"}
{"_id":"98","_index":"forum-mysql","_score":1,"_source":{"addtime":"1469458760","category_id":"4","comments":"7","has_attach":"0","id":"98","message":"最近被催着要在kibana里加入关系图（社交网络类似的），然后百度的echarts支持关系图。之前一直以为修改kibana加入echarts会很难（因为node我不会，angularjs我也不会。。。），直到今天被逼要在几天之内加入关系图，我发现，加入echarts真的不太难！\n我的做法是\n①cd 进kibana的根目录，然后vim package.json,在dependencies中加入\u0026quot;echarts\u0026quot;:\u0026quot;3.2.2\u0026quot;(key value结构，3.2.2是echarts最新版本)\n②在kibana根目录使用npm update命令，会自动下载echats.\n③npm start 开启debug模式\n④在要修改的js 文件中加入let echarts=requrie(\u0026quot;echarts\u0026quot;);即可调用echarts进行开发了！\n ","title":"kibana使用echarts","uid":"310","views":"5542","votes":"0"},"_type":"doc"}
{"_id":"99","_index":"forum-mysql","_score":1,"_source":{"addtime":"1470728073","category_id":"2","comments":"1","has_attach":"1","id":"99","message":"[b]Elastic中文社区技术沙龙【深圳站】  [/b]\n[list]\n[*]主办方：elastic中文社区        [url]http://elasticsearch.cn/article/99[/url] [/*]\n[*]协办方：vivo移动互联网中心 [url=http://www.vivo.com.cn?from=elasticsearch.cn]http://www.vivo.com.cn [/url][/*]\n[/list]\n[attach]277[/attach]\n\n\nPPT 下载： [url]https://github.com/node/esmeetup-shenzhen2016[/url] \n\n活动现场：\n[attach]280[/attach]\n\n\n[b]活动信息：[/b]\n[list]\n[*]活动时间：[b]2016年9月10日 下午13:00[/b][/*]\n[*]活动地点：深圳市福田区上梅林地铁站 安得街89号步步高大楼1楼[/*]\n[*]场地容量：[b]100人[/b][/*]\n[*]活动费用：[b]免费 ( 现场有福利派发 : )[/b][/*]\n[*]交通信息：地铁4号龙华线 上梅林站 ，公交 万科大厦站[/*]\n[*]参考地标：梅林天虹西侧，卓越城对面[/*]\n[/list]\n\n[b]报名方式：[/b]\n[list]\n[*]报名链接：[url]http://biaodan100.com/web/formview/57a98d000cf2e5aae034e1e4[/url][/*]\n[*]或者扫码二维码：[/*]\n[/list]\n[attach]261[/attach]\n\n[i][b]真诚邀请对elastic技术栈，搜索引擎技术，大数据存储索引可视化，日志分析等技术感兴趣的朋友前来交流和分享。[/b][/i]\n\n[b]分享主题：[/b]\n[list]\n[*][b]ElasticStack V5 新特性与变化[/b]              By[b] 曾勇[/b]@elastic  Elastic开发工程师与技术布道师\nElasticStack包括Elasticsearch、Logstash、Kibana和Beats，ElasticStack将在过段时间发布一个V5.0全新版本，这次的分享将给大家介绍一下5.0版里面各个产品的一些新的特性和改进。\n\n曾勇是Elasticsearch国内首批用户，自2010年起就开始接触Elasticsearch并投入到生产环境中使用，并编写过一系列的中文处理相关的插件，是Elasticsearch中文社区发起人，筹办了一系列线上线下的Elasticsearch技术分享与交流活动，出于对Elasticsearch的喜爱，目前已全职加入Elasticsearch项目背后的Elastic公司。\n[/*]\n[*][b]ELK应用 --- 一卡易实时日志分析平台[/b]   By [b]夏小成[/b]@一卡易   一线码农\n\n目前一卡易实时日志分析平台汇集了包括windows事务日志、linux日志、haproxy访问日志、业务数据库审计日志和大数据平台日志，为一卡易数十个产品线提供了便捷的日志检索和分析服务。未来我们会把elasticsearch逐渐引入到我们的业务系统，更深层次挖掘她的魅力。\n[/*]\n[*][b]构建数据驱动的动画工作室 - es及ELK实践 [/b]         By[b] 赵昆[/b]@东方梦工厂   IT与数据系统工程师\n[/*]\n[*][b]京东日志系统es运维经验分享及es源码改造实践[/b]   By [b]成睿 [/b]@京东\n\n曾负责京东日志系统的搜索平台，目前负责京东到家商品搜索平台。介绍京东日志系统es的一些运维经验和我2次改es源代码的实践。[/*]\n[/list]\n\n\n\n----------------------------------------------------------------------------------\n联络邮件： nodexy@qq.com 或者直接站内私信。----------------------------------------------------------------------------------\n\n ","title":"Elastic中文社区【深圳】第一次线下活动  开始报名啦！","uid":"54","views":"4780","votes":"2"},"_type":"doc"}
{"_id":"105","_index":"forum-mysql","_score":1,"_source":{"addtime":"1476366543","category_id":"2","comments":"3","has_attach":"0","id":"105","message":"版本分别支持到最新的 es v2.4.1和 es v5.0.0-rc1\n新增若干特性，支持多种选项配置，支持 pinyin 的切分，比之前需要结合 ngram 的方式更加准确，\n如：liudehuaalibaba13zhuanghan-\u0026gt;liu,de,hua,a,li,ba,ba,13,zhuang,han，\n具体配置参加文档：\n[url]https://github.com/medcl/elasticsearch-analysis-pinyin[/url]\n \n下载：\n[url]https://github.com/medcl/elasticsearch-analysis-pinyin/releases[/url]\n \n欢迎测试：\n[code]curl -XPUT http://localhost:9200/medcl/ -d'\n{\n    \u0026quot;index\u0026quot; : {\n        \u0026quot;analysis\u0026quot; : {\n            \u0026quot;analyzer\u0026quot; : {\n                \u0026quot;pinyin_analyzer\u0026quot; : {\n                    \u0026quot;tokenizer\u0026quot; : \u0026quot;my_pinyin\u0026quot;\n                    }\n            },\n            \u0026quot;tokenizer\u0026quot; : {\n                \u0026quot;my_pinyin\u0026quot; : {\n                    \u0026quot;type\u0026quot; : \u0026quot;pinyin\u0026quot;,\n                    \u0026quot;keep_separate_first_letter\u0026quot; : false,\n                    \u0026quot;keep_full_pinyin\u0026quot; : true,\n                    \u0026quot;keep_original\u0026quot; : false,\n                    \u0026quot;limit_first_letter_length\u0026quot; : 16,\n                    \u0026quot;lowercase\u0026quot; : true\n                }\n            }\n        }\n    }\n}'\n\ncurl http://localhost:9200/medcl/_analyze?text=%e5%88%98%e5%be%b7%e5%8d%8eabcdliudehuawobuzhidaoshishui\u0026amp;analyzer=pinyin_analyzer\n{\n  \u0026quot;tokens\u0026quot; : [ {\n    \u0026quot;token\u0026quot; : \u0026quot;liu\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 1,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 0\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;de\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 1,\n    \u0026quot;end_offset\u0026quot; : 2,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;hua\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 3,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 2\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;a\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 3\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;b\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 4\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;c\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 5\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;d\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 6\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;liu\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 7\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;de\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 8\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;hua\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 9\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;wo\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 10\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;bu\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 11\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;zhi\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 12\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;dao\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 13\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;shi\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 14\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;shui\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 31,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 15\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;ldhabcdliudehuaw\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 16,\n    \u0026quot;type\u0026quot; : \u0026quot;word\u0026quot;,\n    \u0026quot;position\u0026quot; : 16\n  } ]\n}[/code]\n ","title":"elasticsearch-analysis-pinyin更新至es2.4.1和5.0.0-rc1","uid":"1","views":"1565","votes":"3"},"_type":"doc"}
{"_id":"108","_index":"forum-mysql","_score":1,"_source":{"addtime":"1478599376","category_id":"2","comments":"0","has_attach":"0","id":"108","message":"[url]https://github.com/onesuper/pandasticsearch[/url]\n \n[code]# Create a DataFrame object\nfrom pandasticsearch import DataFrame\ndf = DataFrame.from_es('http://localhost:9200', index='people')\n\n# Print the schema(mapping) of the index\ndf.print_schema()\n# company\n# |-- employee\n#   |-- name: {'index': 'not_analyzed', 'type': 'string'}\n#   |-- age: {'type': 'integer'}\n#   |-- gender: {'index': 'not_analyzed', 'type': 'string'}\n\n# Inspect the columns\ndf.columns\n#['name', 'age', 'gender']\n\n# Get the column\ndf.name\n# Column('name')\n\n# Filter\ndf.filter(df.age \u0026lt; 13).collect()\n# [Row(age=12,gender='female',name='Alice'), Row(age=11,gender='male',name='Bob')]\n\n# Project\ndf.filter(df.age \u0026lt; 25).select('name', 'age').collect()\n# [Row(age=12,name='Alice'), Row(age=11,name='Bob'), Row(age=13,name='Leo')]\n\n# Print the rows into console\ndf.filter(df.age \u0026lt; 25).select('name').show(3)\n# +------+\n# | name |\n# +------+\n# | Alice|\n# | Bob  |\n# | Leo  |\n# +------+\n\n# Sort\ndf.sort(df.age.asc).select('name', 'age').collect()\n#[Row(age=11,name='Bob'), Row(age=12,name='Alice'), Row(age=13,name='Leo')]\n\n# Aggregate\ndf[df.gender == 'male'].agg(df.age.avg).collect()\n# [Row(avg(age)=12)]\n\n# Groupby\ndf.groupby('gender').collect()\n# [Row(doc_count=1), Row(doc_count=2)]\n\n# Groupby and then aggregate\ndf.groupby('gender').agg(df.age.max).collect()\n# [Row(doc_count=1, max(age)=12), Row(doc_count=2, max(age)=13)]\n\n# Convert to Pandas object for subsequent analysis\ndf[df.gender == 'male'].agg(df.age.avg).to_pandas()\n#    avg(age)\n# 0        12[/code]","title":"Pandasticsearch: An Elasticsearch client exposing DataFrame API","uid":"1884","views":"2031","votes":"1"},"_type":"doc"}
{"_id":"110","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480644434","category_id":"14","comments":"82","has_attach":"0","id":"110","message":"【携程旅行网 吴晓刚】\n ElasticSearch目前在互联网公司主要用于两种应用场景，其一是用于构建业务的搜索功能模块且多是垂直领域的搜索，数据量级一般在千万至数十亿这个级别；其二用于大规模数据的实时OLAP，经典的如ELKStack，数据规模可能达到千亿或更多。 这两种场景的数据索引和应用访问模式上差异较大，在硬件选型和集群优化方面侧重点也会有所不同。一般来说后一种场景属于大数据范畴，数据量级和集群规模更大，在管理方面也更有挑战。\n\n应Medcl大大的邀请，为ES中文社区做今年的Advent开篇，分享一下我在管理自家公司用于日志分析的ES集群方面的一点心得，蜻蜓点水，泛泛而谈，希望大方向上能对大家提供一些帮助。\n\n这里的自家，即是携程旅行网。从2013年开始接触ES，我们团队先后实践过0.9.x -\u0026gt; 5.0.0中间各个版本，从最初只用于运维内部IIS日志的分析，到如今支持IT、呼叫中心、安全、测试、业务研发等多个部门超过200种日志型数据的实时检索与分析。 一路走来，愉悦了大家，也死磕了自己。\n\n目前我们最大的日志单集群有120个data node，运行于70台物理服务器上。数据规模如下:\n[list]\n[*]单日索引数据条数600亿，新增索引文件25TB (含一个复制片则为50TB)[/*]\n[*]业务高峰期峰值索引速率维持在百万条/秒[/*]\n[*]历史数据保留时长根据业务需求制定，从10天 - 90天不等[/*]\n[*]集群共3441个索引、17000个分片、数据总量约9300亿, 磁盘总消耗1PB[/*]\n[*]Kibana用户600多人, 每日来自Kibana和第三方的API调用共63万次[/*]\n[*]查询响应时间百分位 75%:0.160s  90%:1.640s 95%:6.691s 99%:14.0039s[/*]\n[/list]\n\n运维这样大规模的ES集群，有哪些值得注意的地方？\n\n一. 必不可少的工具\n工欲善其事必先利其器，从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提升会凸显。 官方提供了ES Puppet Module和Chef Cookbook，熟悉这两个工具的同学可以直接拿过来用。 我们自己则是采用的Ansible，编写了一套Playbook来达到类似的效果。 用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。\n第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里面，sense已经成为一个内置的控制台，无需额外安装。\n\n二. 硬件配置\n我们采用的是32vcoreCPU + 128GB RAM的服务器，磁盘配置大部分服务器是12块4TB SATA机械磁盘做的Raid0，少部分机器是刚上了不久的6块800GB SSD raid0，主要目的是想做冷热数据分离，后面谈到集群架构的时候，再进一步解释一下如何利用硬件资源。\n\n三. 集群的管理\n[list=1]\n[*]首先很有必要对ES的结点做角色划分和隔离。大家知道ES的data node除了放数据以外，也可以兼任master和client的角色，多数同学会将这些角色混入到data node。然而对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。[/*]\n[*]避免过高的并发，包括控制shard数量和threadpool的数量。在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。分片过多会带来诸多负面影响，例如：每次查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢[url=https://github.com/elastic/elasticsearch/issues/18776]Issue#18776[/url]; 过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。 配置过大的threadpool更是会产生很多诡异的性能问题[url=https://github.com/elastic/elasticsearch/issues/18161]Issue#18161[/url]里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。[/*]\n[*]冷热数据最好做分离。对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据，那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。所以我们用了一部分机器来做冷数据的存储，利用ES可以给结点配置自定义属性的功能，为冷结点加上\u0026quot;boxtype\u0026quot;:\u0026quot;weak\u0026quot;的标识，每晚通过维护脚本更新冷数据的索引路由设置[i]index.routing.allocation.{require|include|exclude}[/i]，让数据自动向冷结点迁移。 冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。[/*]\n[*]不同数据量级的shard最好隔离到不同组别的结点。 大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。其一同一索引下的shard尽量分散到不同的结点;其二每个结点上的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。 实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就是如何能比较平衡并充分的利用所有节点的资源。 针对这个问题，我们还是通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制。尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡。[/*]\n[*]定期做索引的force merge，并且最好是每个shard merge成一个segment。前面提到过，heap消耗与segment数量也有关系，force merge可以显著降低这种消耗。 如果merge成一个segment还有一个好处，就是对于terms aggregation，搜索时无需构造Global Ordinals，可以提升聚合速度。[/*]\n[/list]\n\n四. 版本选择\n我们在2.4版本上稳定跑了很长时间，比较保守的同学可以上2.4，激进有精力折腾的可以考虑最新的5.0。 我们集群两周前从v2.4.0升级到了v5.0.0这个版本，除了升级第一周遇到一个不稳定的问题以外，感觉新版本带来的以下特性还是非常值得去升级的:\n[list]\n[*]结点启动的Bootstrap过程加入了很多关键系统参数设置的核验，比如Max File Descriptors, Memory Lock, Virtual Memory设置等等，如果设置不正确会拒绝启动并抛出异常。 与其带着错误的系统参数启动，并在日后造成性能问题，不如启动失败告知用户问题，是个很好的设计！[/*]\n[*]索引性能提升。升级后在同样索引速率下，我们看到cpu消耗下降非常明显，除了对索引速率提升有帮助，也会一定程度提升搜索速率。[/*]\n[*]新的数值型数据结构，存储空间更小，Range和地理位置计算更快速[/*]\n[*]Instant Aggregation对于类似now-7d to now这样的范围查询聚合能够做cache了，实际使用下来，效果明显，用户在Kibana上跑个过去一周数据的聚合，头2次刷新慢点，之后有cache了几乎就瞬间刷出！[/*]\n[*]更多的保护措施保证集群的稳定，比如对一次搜索hit的shard数量做了限制，增强了circuit breaker的特性，更好的防护集群资源被坏查询耗尽。[/*]\n[/list]\n\n升级第一周，我们的冷数据结点出现间歇性不响应问题，从而刨出3个issue提交给官方:\n[url=https://github.com/elastic/elasticsearch/issues/21595]Issue#21595[/url] [url=https://github.com/elastic/elasticsearch/issues/21612]Issue#21612[/url] [url=https://github.com/elastic/elasticsearch/issues/21611]Issue#21611[/url]\n第一个问题确认为Bug，将在5.0.2修复，其他两个目前还不清楚根源，看起来也只在我们的应用场景里遇到了。所幸问题都找到了了规避措施，实施这些措施以后，最近一周我们的集群重新回到以前2.4版本时期的稳定状态。\n\n\n五. 监控\n不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。 那么多监控指标，最最关键的还是以下几类:\n[list=1]\n[*]各类Thread pool的使用情况，active/queue/reject可视化出来。 判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。[/*]\n[*]JVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。[/*]\n[*]Segment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。[/*]\n[*]很有必要记录用户的访问记录。我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。[/*]\n[/list]\n\n最后就是多上手实践，遇到问题多查官方资料，多Google看是否有其他人遇到同类问题，精力充足有编程背景的同学也可以多刨刨源码。","title":"Day1: 大规模Elasticsearch集群管理心得","uid":"81","views":"32008","votes":"53"},"_type":"doc"}
{"_id":"116","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480950018","category_id":"14","comments":"0","has_attach":"1","id":"116","message":"Beats这个项目的确很好用，几行命令下来，一个成型的Agent就出来了。使用者只需要关注采集什么数据就好，后续的事情libbeat基本都处理完了。不过值得吐槽的是，Beat太散了，管理起来东一个西一个的，产品化的时候对客户说，我们要在机器上放n个Agent不知道客户会是什么样的表情。\n\n\n[attach]356[/attach]\n\n\n不过轻量级、已部署的特点还是极大的吸引了我，于是就有了后面的事情了。\n\n[b]PacketBeat不明原因的OOM[/b]\n\n某天我把PacketBeat放到了我的服务器上面，这台服务器上面有个MongoDB，MongoDB主要是拿来存放ES的元数据的。ES2.x的时候并没有很好的元数据管理，为了能让ES的索引分配的比较均匀，并且有元数据辅助查询，设计好一个元数据管理的仓库是必要的。然后我打开了对MongoDB的抓包功能，恩，一切都很好，接着我打开了日志管理页面，看到了一条一条的MongoDB的包被抓回来，解码，然后塞到了ES。可是第二天一看，咦？？Packet跪了？不是吧，ElasticSearch做的产品这么不稳定么。我不信。\n\n\n[attach]357[/attach]\n\n\n然后我又启动了第二次，紧接着熟练的top了一下，观察了PacketBeat半个多小时，在被观察的这段时间里面，PacketBeat的表现非常的正常，看不出有什么异样。好吧，那上一次的OOM可能只是个意外，Windows也经常蓝屏嘛，OOM一次也正常。结果第二天我再次打开终端，发现这货居然又OOM了！！\n\n\n[attach]358[/attach]\n\n\n好吧好吧，我感觉我已经踩到Bug了，拿了开源社区这么多东西，总得贡献一下的，好吧，提个Issue去 https://github.com/elastic/beats/issues/2867\n\n[b]真相只有一个[/b]\n\n微信群里面聊起这个奇妙的OOM，Medcl大神问是不是因为采集了ES的日志，（我的这台服务器和日志服务器有关系）然后导致滚雪球把PacketBeat给滚死了。咦？说不定真的是这个原因耶！但是看了看PacketBeat，我并没有抓ES的包，而且假如我采集了ES的包，应该一下就OOM掉了，不应该等那么久。不过这么一说，却仿佛打开了新世界的大门\n\n\n[attach]359[/attach]\n\n\n我把这台服务器在日志服务器中的角色重新梳理了下，终于发现了这次OOM的原因了。。\n\n由于2.X的ES没有比较好的元数据信息，所以当日志送到LogServer的时候，我做了些额外的操作，让LogServer持久化到ES一定量的时候就会往Mongo写一下元数据信息（当然也有其他服务会往里面做CRUD啦），开始的时候访问Mongo的次数其实是很少的，假设按1W来算。那么问题来了，由于我们的PacketBeat抓了Mongo的包，那么LogServer往ES的CRUD操作都会被PacketBeat给抓走，然后再送回给LogServer\n\n\n[attach]360[/attach]\n\n\n那么一个隐藏的滚雪球事件就产生了，刚开始的那段时间，Mongo被抓包的次数只有1W，然后就往LogServer多送了1W条日志，不。。应该多很多，毕竟网络包嘛，然后就导致LogServer因为要管理元数据的频率开始逐渐地提高，逐渐提高CRUD的频率后抓包的内容也越来越多，紧接着到这发生到LogServer的频率也越来越高。。。。。每次PacketBeat崩掉的时候，都送了80W左右的日志量出去，然后它就OOM掉了（因为我那台机器就只剩下2G的空闲内存给它用，被系统给干掉了）。。我居然发现了这样的场景\n\n\n[attach]361[/attach]\n\n\n[b]结论[/b]\n\n使用PacketBeat的时候，记得要留意一下有没这种反馈型滚雪球的情况，多发生在自己的日志服务器上面。当然那种直接抓ES的就没什么好说了，估计启动了之后没多久就崩溃掉了","title":"Day5: 《PacketBeat奇妙的OOM小记》","uid":"1866","views":"2809","votes":"4"},"_type":"doc"}
{"_id":"300","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506585256","category_id":"4","comments":"6","has_attach":"1","id":"300","message":"最近公司有开发kibana plugin 需求，正好有时间研究这块。现将自己学习过程及官方资源写成一个浅显易懂的kibana plugin 开发教程[url=https://kibana.gitbook.io/kibana-plugin-development-tutorial/]书籍[/url]\n \n \n[url=https://kibana.gitbook.io/kibana-plugin-development-tutorial/]在线阅读地址[/url]\n \n \n内容还在持续增加，欢迎有这方面经验的人加入我们。\n \n \n \n案例一下 [url=http://trumandu.github.io/]博客[/url]，欢迎follower,欢迎交流！\n \n ","title":"Kibana 插件开发教程","uid":"5051","views":"3739","votes":"5"},"_type":"doc"}
{"_id":"302","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506637504","category_id":"18","comments":"0","has_attach":"0","id":"302","message":"1、profiling 工具 | 一眼看透慢查询！\n[url]http://t.cn/RInoI4c[/url] \n2、ElasticSearch的实时日志系统架构与总结。\n[url]http://t.cn/RaX2lMm[/url] \n3、你早该知道的Elasticsearch性能指标！\n[url]http://t.cn/R0Nn3KK[/url] \n4、P2P领域ES实战经验分享！\n[url]http://t.cn/R0NmyhU[/url] \n\n编辑：laoyang360\n归档：[url]https://www.elasticsearch.cn/article/302[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":" Elastic日报 第62期 (2017-09-29)","uid":"1341","views":"583","votes":"0"},"_type":"doc"}
{"_id":"313","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507942576","category_id":"18","comments":"0","has_attach":"0","id":"313","message":"1、使用nested结构如何进行个性化的排序\nhttp://t.cn/RONaiTA\n2、从es2.3.4升级到es5.4.1,性能提升30-40%的案例\nhttp://t.cn/RONXHBr\n3、java9在es6上的简单测评报告，喜欢尝鲜的可以试试\nhttp://t.cn/RONC5Fk\n编辑：bsll\n归档：https://www.elasticsearch.cn/article/313\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第69期 (2017-10-14)","uid":"1874","views":"474","votes":"0"},"_type":"doc"}
{"_id":"314","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508022977","category_id":"18","comments":"0","has_attach":"0","id":"314","message":"1.(自备梯子)如何在避免停机的情况下远程迁移Elasticsearch集群。\nhttp://t.cn/ROlVXTV\n2.(自备梯子)每个软件工程师都应该知道的关于如何改进搜索体验的理论知识。\nhttp://t.cn/Rp0DO48\n3.一个在线旅游服务业IT主管讲述Elasticsearch对企业改进搜索和自动数据分析方面的帮助。\nhttp://t.cn/ROWKRkJ\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/314\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第70期 (2017-10-15)","uid":"4460","views":"470","votes":"0"},"_type":"doc"}
{"_id":"322","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508406268","category_id":"5","comments":"0","has_attach":"1","id":"322","message":"[size=18]上海普翔信息科技发展有限公司是 Elastic 在中国的 Partner ，负责 X-Pack 的销售、咨询服务，今天上线了业务网站 [url]http://elastictech.cn[/url] 。[/size]\r\n[size=18]从官网介绍可以看出，主要业务都是和 Elastic 相关的，分别是：[/size]\r\n[list]\r\n[*][size=18]X-Pack License 购买服务[/size][/*]\r\n[*][size=18]Elastic 本地咨询服务[/size][/*]\r\n[*][size=18]Elastic 本地培训服务[/size][/*]\r\n[/list]\r\n\r\n[size=18][size=18]对X-Pack 刚兴趣的可以去留言咨询了！当然也可以私信和我沟通哦！[/size][/size]\r\n\r\n\r\n[attach]1161[/attach]\r\n ","title":"Elastic 中国 Partner 的网站 elastictech.cn 上线了！对 X-Pack 付费功能感兴趣的可以聊起来了！","uid":"6028","views":"863","votes":"0"},"_type":"doc"}
{"_id":"343","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509328452","category_id":"18","comments":"0","has_attach":"0","id":"343","message":"1.kibana dashborad嵌入式时间选择器插件。\nhttp://t.cn/RWmjISQ\n\n2.玩儿透日志分析集群搭建，调优，管理。\nhttp://t.cn/RWmYDJv\n\n3.现在就可以预约十一月一号的elastic官方kibana可视化教程。\nhttp://t.cn/RWmRcgA\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/343\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第85期 (2017-10-30)","uid":"4063","views":"407","votes":"0"},"_type":"doc"}
{"_id":"332","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508939194","category_id":"3","comments":"1","has_attach":"0","id":"332","message":"https://github.com/neal1991/articles-translator/blob/master/%E4%BD%A0%E5%BA%94%E8%AF%A5%E4%BA%86%E8%A7%A3%E7%9A%845%E4%B8%AA%20Logstash%20Filter%20%E6%8F%92%E4%BB%B6.md","title":"你应该了解的5个 Logstash Filter 插件","uid":"4198","views":"1047","votes":"0"},"_type":"doc"}
{"_id":"335","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509017492","category_id":"2","comments":"0","has_attach":"0","id":"335","message":"[b]一，模板简述：[/b]template大致分成setting和mappings两部分：\n索引可使用预定义的模板进行创建,这个模板称作Index templates。模板设置包括settings和mappings，通过模式匹配的方式使得多个索引重用一个模板。 \n1. settings主要作用于index的一些相关配置信息，如分片数、副本数，tranlog同步条件、refresh等。\n \n2. mappings主要是一些说明信息，大致又分为_all、_source、prpperties这三部分：\n \n     (1) _all：主要指的是AllField字段，我们可以将一个或多个都包含进来，在进行检索时无需指定字段的情况下检索多个字段。设置“_all\u0026quot; : {\u0026quot;enabled\u0026quot; : true}\n \n     (2) _source：主要指的是SourceField字段，Source可以理解为ES除了将数据保存在索引文件中，另外还有一份源数据。_source字段在我们进行检索时相当重要，如果在{\u0026quot;enabled\u0026quot; : false}情况下默认检索只会返回ID， 你需要通过Fields字段去到索引中去取数据，效率不是很高。但是enabled设置为true时，索引会比较大，这时可以通过Compress进行压缩和inclueds、excludes来在字段级别上进行一些限制，自定义哪些字段允许存储。\n \n     (3) properties：这是最重要的步骤，主要针对索引结构和字段级别上的一些设置。\n3.咱们通常在elasticsearch中 post mapping信息，每重新创建索引便到设置mapping，分片，副本信息。非常繁琐。强烈建议大家通过设置template方式设置索引信息。设置索引名，通过正则匹配的方式匹配到相应的模板。ps:直接修改mapping的优先级\u0026gt;索引template。索引匹配了多个template，当属性等配置出现不一致的，以order的最大值为准，order默认值为0\n[b]二，创建模板：[/b]\n例如：\n [code]{\n  \u0026quot;template\u0026quot;: \u0026quot;pmall*\u0026quot;,\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;index.number_of_shards\u0026quot;: 1,\n    \u0026quot;number_of_replicas\u0026quot;: 4,\n    \u0026quot;similarity\u0026quot;: {\n      \u0026quot;IgnoreTFSimilarity\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;IgoreTFSimilarity\u0026quot;\n      }\n    }\n  },\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;_default_\u0026quot;: {\n      \u0026quot;_source\u0026quot;: {\n        \u0026quot;enabled\u0026quot;: false\n      }\n    },\n    \u0026quot;commodity\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;sold\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n        },\n        \u0026quot;online_time\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n        },\n        \u0026quot;price\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n        },\n        \u0026quot;publish_time\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n        },\n        \u0026quot;id\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n        },\n        \u0026quot;catecode\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n        },\n        \u0026quot;title\u0026quot;: {\n          \u0026quot;search_analyzer\u0026quot;: \u0026quot;ikSmart\u0026quot;,\n          \u0026quot;similarity\u0026quot;: \u0026quot;IgnoreTFSimilarity\u0026quot;,\n          \u0026quot;analyzer\u0026quot;: \u0026quot;ik\u0026quot;,\n          \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n        },\n        \u0026quot;content\u0026quot;: {\n          \u0026quot;index\u0026quot;: false,\n          \u0026quot;store\u0026quot;: true,\n          \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n        },\n        \u0026quot;status\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n        }\n      }\n    }\n  }\n}[/code]\n \n\n[b]三，删除模板：[/b][code]\nDELETE /_template/template_1[/code]\n\n\n\n[b]四，查看模板：[/b]\n [code]GET /_template/template_1[/code]\n\n也可以通过模糊匹配得到多个模板信息[code]GET /_template/temp* [/code]\n\n可以批量查看模板[code]GET /_template/template_1,template_2[/code]\n\n验证模板是否存在：\n [code]HEAD _template/template_1[/code]\n\n[b]五：多个模板同时匹配，以order顺序倒排，order越大，优先级越高[/b]\n [code]\n \nPUT /_template/template_1\n{\n    \u0026quot;template\u0026quot; : \u0026quot;*\u0026quot;,\n    \u0026quot;order\u0026quot; : 0,\n    \u0026quot;settings\u0026quot; : {\n        \u0026quot;number_of_shards\u0026quot; : 1\n    },\n    \u0026quot;mappings\u0026quot; : {\n        \u0026quot;type1\u0026quot; : {\n            \u0026quot;_source\u0026quot; : { \u0026quot;enabled\u0026quot; : false }\n        }\n    }\n}\n\nPUT /_template/template_2\n{\n    \u0026quot;template\u0026quot; : \u0026quot;te*\u0026quot;,\n    \u0026quot;order\u0026quot; : 1,\n    \u0026quot;settings\u0026quot; : {\n        \u0026quot;number_of_shards\u0026quot; : 1\n    },\n    \u0026quot;mappings\u0026quot; : {\n        \u0026quot;type1\u0026quot; : {\n            \u0026quot;_source\u0026quot; : { \u0026quot;enabled\u0026quot; : true }\n        }\n    }\n}[/code]\n\n \n[b]六，模板版本号：[/b]\n \n模板可以选择添加版本号，这可以是任何整数值，以便简化外部系统的模板管理。版本字段是完全可选的，它仅用于模板的外部管理。要取消设置版本，只需替换模板即可\n\n \n创建模板：[code]PUT /_template/template_1\n{\n    \u0026quot;template\u0026quot; : \u0026quot;*\u0026quot;,\n    \u0026quot;order\u0026quot; : 0,\n    \u0026quot;settings\u0026quot; : {\n        \u0026quot;number_of_shards\u0026quot; : 1\n    },\n    \u0026quot;version\u0026quot;: 123\n}[/code]\n\n查看模板版本号：[code]GET /_template/template_1?filter_path=*.version[/code]\n\n\n响应如下：[code]{\n  \u0026quot;template_1\u0026quot; : {\n    \u0026quot;version\u0026quot; : 123\n  }\n}[/code]\n\n[b]七，参考：[/b]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/indices-templates.html]indices-templates[/url]","title":"【基础篇】elasticsearch之索引模板Template","uid":"6245","views":"12259","votes":"2"},"_type":"doc"}
{"_id":"338","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509019138","category_id":"2","comments":"0","has_attach":"0","id":"338","message":"[b]一、软件环境[/b]\nIntellij Idea:2017.1版本\nElasticsearch源码版本:5.3.1\nJDK:1.8.0_111 \nGradle :建议3.3及以上版本。官网：https://gradle.org/\n[b]二、下载Elasticsearch源码[/b]\n到github clone源码，https://github.com/elastic/elasticsearch.git，建议选择稳定版本分支。\n\n[b]三、导入idea[/b]\n1，[b][size=8]编译执行gradle build.gradle，报错：[/size][/b]\nyou must run gradle idea from the root of elasticsearch before importing into intellij\n解决办法：运行命令：gradle idea。同理如使用eclipse编译器，运行gradle eclipse。该过程会向mvn仓库下载响应的jar包，视网络情况，大概会持续20分钟。\n\n \n[b][size=8]2，运行org.elasticsearch.bootstrap.Elasticsearch 方法，报错：[/size][/b]\n\u0026quot;path.home is not configured\u0026quot; when starting ES in transport and client mode“，\n解决办法：在VM options中加入配置：-Des.path.home=/home/jiangtao/code/elasticsearch/core，即指向相应的core模块的路径。\n\n[b][size=8]3，报错：org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException[/size][/b]\n  [code]Exception in thread \u0026quot;main\u0026quot; org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config Likely root cause: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n   at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n   at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n   at java.nio.file.Files.readAttributes(Files.java:1737)\n   at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:225)\n   at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)\n   at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)\n   at java.nio.file.Files.walkFileTree(Files.java:2662)[/code]\n解决办法：将distribution模块src路径下的config整个文件copy到core模块中\n\n[b][size=8]4，报错： ERROR Could not register mbeans java.security.AccessControlException[/size][/b][code]2017-06-06 09:52:08,007 main ERROR Could not register mbeans java.security.AccessControlException: access denied (\u0026quot;javax.management.MBeanTrustPermission\u0026quot; \u0026quot;register\u0026quot;)\n             at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\n            at java.lang.SecurityManager.checkPermission(SecurityManager.java:585)\n            at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(DefaultMBeanServerInterceptor.java:1848)\n            at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:322)\n            at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)\n             ........\n           at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91)\n           at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84)[/code]\n       解决办法：禁用jmx,在VM options中继续添加配置：  -Dlog4j2.disable.jmx=true。注意：在VM options中多个配置中间用空格分隔。\n\n[b][size=8]5，报错： java.lang.IllegalStateException: Unsupported transport.type [/size][/b]\n错误栈如下：[code][2017-06-06T10:04:21,327][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler]  uncaught exception in thread [main]\norg.elasticsearch.bootstrap.StartupException: java.lang.IllegalStateException: Unsupported transport.type \nat org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?]\nat org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?]\nat org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?]\nat org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]\nCaused by: java.lang.IllegalStateException: Unsupported transport.type \nat org.elasticsearch.common.network.NetworkModule.getTransportSupplier(NetworkModule.java:213) ~[main/:?]\nat org.elasticsearch.node.Node.\u0026lt;init\u0026gt;(Node.java:421) ~[main/:?]\nat org.elasticsearch.node.Node.\u0026lt;init\u0026gt;(Node.java:242) ~[main/:?]\nat org.elasticsearch.bootstrap.Bootstrap$6.\u0026lt;init\u0026gt;(Bootstrap.java:242) ~[main/:?]\nat org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:242) ~[main/:?]\nat org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:360) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:123) ~[main/:?]\n... 6 more[/code]\n这个是由于依赖的transport等jar并没有找到，可以在项目根目录找到models模块，然后将下面目录打包，然后copy到distribution/src/main/models目录下，\n也可以直接去官网（https://www.elastic.co/downloads/elasticsearch）下载zip包，解压后直接copy。\n我直接去官网下载的zip包：从官网下载完毕zip包后，具体解决办法请看：错误 6。\n\n\n[b][size=8]6，copy module版本冲突[/size][/b]\n错误栈如下： [code]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1]\n at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?]\n at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?]\n at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?]\n at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?]\n at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]\nat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]\nCaused by: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1][/code]\n解决办法：修改es当前版本\n将core模块中的Version.java类由\npublic static final Version CURRENT = V_5_3_4_UNRELEASED;\n修改为：\npublic static final Version CURRENT = V_5_3_1;","title":"【环境篇】Intellij Idea编译Elasticsearch源码","uid":"6245","views":"2825","votes":"0"},"_type":"doc"}
{"_id":"340","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509057413","category_id":"18","comments":"0","has_attach":"0","id":"340","message":"1、基于HBase+ ElasticSearch的车联网的应用\n[url]http://t.cn/RWoD1x8[/url] \n2、携程大数据实践：高并发应用架构及推荐系统案例\n[url]http://t.cn/RWoDFX8[/url] \n3、Elasticsearch相关度计算原理\n[url]http://t.cn/RWK4SQN[/url] \n4、搞清楚logstash、filebeat到底什么区别？\n[url]http://t.cn/RWKPDDj[/url] \n\n编辑：laoyang360\n归档：https://elasticsearch.cn/article/340\n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n ","title":" Elastic日报 第82期 (2017-10-27)","uid":"1341","views":"473","votes":"0"},"_type":"doc"}
{"_id":"349","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509586657","category_id":"18","comments":"0","has_attach":"0","id":"349","message":"1.ES集群服务器CPU负载瞬间飚高分析\nhttps://elasticsearch.cn/article/348\n2.elasticsearch api 101\nhttp://t.cn/RlZ1PND\n3.一个免费的支持kibana多租户、加密、认证、授权、审计的Elasticsearch和Kibana安全插件\nhttp://t.cn/RZpF03g\n活动预告：Elastic 武汉交流会 \nhttps://elasticsearch.cn/article/344\n\n感谢社区well的投稿\n编辑：金桥\n归档：https://elasticsearch.cn/article/349\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第88期 (2017-11-02)","uid":"668","views":"460","votes":"0"},"_type":"doc"}
{"_id":"351","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509661618","category_id":"18","comments":"0","has_attach":"0","id":"351","message":"1、Elasticsearch unassigned shards 应急处理方案\nhttp://t.cn/Rlwub5s\n2、可行 | 解决Unassigned Shards大探讨\nhttp://t.cn/RlwuVFn\n3、快照\u0026amp;重新存储数据方案\nhttp://t.cn/RlwuXmm\n活动预告：Elastic 武汉交流会 \n[url]https://elasticsearch.cn/article/344[/url] \n\n编辑：laoyang360\n归档：https://elasticsearch.cn/article/351\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第89期 (2017-11-03)","uid":"1341","views":"449","votes":"1"},"_type":"doc"}
{"_id":"356","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509986499","category_id":"2","comments":"3","has_attach":"0","id":"356","message":"原文地址：http://www.54tianzhisheng.cn/2017/10/15/ElasticSearch-cluster-health-metrics/\n \n\n![](http://ohfk1r827.bkt.clouddn.com/cb5.jpeg-1)\n\n最近在做 ElasticSearch 的信息（集群和节点）监控，特此稍微整理下学到的东西。这篇文章主要介绍集群的监控。\n\n\n### 要监控哪些 ElasticSearch metrics\n\n![](https://datadog-prod.imgix.net/img/blog/monitor-elasticsearch-performance-metrics/elasticsearch-dashboard-final2.png?fit=max)\n\nElasticsearch 提供了大量的 Metric，可以帮助您检测到问题的迹象，在遇到节点不可用、out-of-memory、long garbage collection times 的时候采取相应措施。但是指标太多了，有时我们并不需要这么多，这就需要我们进行筛选。\n\n### 集群健康\n\n一个 Elasticsearch 集群至少包括一个节点和一个索引。或者它 可能有一百个数据节点、三个单独的主节点，以及一小打客户端节点——这些共同操作一千个索引（以及上万个分片）。\n\n不管集群扩展到多大规模，你都会想要一个快速获取集群状态的途径。`Cluster Health` API 充当的就是这个角色。你可以把它想象成是在一万英尺的高度鸟瞰集群。它可以告诉你安心吧一切都好，或者警告你集群某个地方有问题。\n\n让我们执行一下 `cluster-health` API 然后看看响应体是什么样子的：\n\n```\nGET _cluster/health\n```\n\n和 Elasticsearch 里其他 API 一样，`cluster-health` 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息：\n\n```json\n{\n   \u0026quot;cluster_name\u0026quot;: \u0026quot;elasticsearch_zach\u0026quot;,\n   \u0026quot;status\u0026quot;: \u0026quot;green\u0026quot;,\n   \u0026quot;timed_out\u0026quot;: false,\n   \u0026quot;number_of_nodes\u0026quot;: 1,\n   \u0026quot;number_of_data_nodes\u0026quot;: 1,\n   \u0026quot;active_primary_shards\u0026quot;: 10,\n   \u0026quot;active_shards\u0026quot;: 10,\n   \u0026quot;relocating_shards\u0026quot;: 0,\n   \u0026quot;initializing_shards\u0026quot;: 0,\n   \u0026quot;unassigned_shards\u0026quot;: 0\n}\n```\n\n响应信息中最重要的一块就是 `status` 字段。状态可能是下列三个值之一 :\n\n| status |                    含义                    |\n| :----: | :--------------------------------------: |\n| green  |     所有的主分片和副本分片都已分配。你的集群是 100% 可用的。      |\n| yellow | 所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。 |\n|  red   | 至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。 |\n\n- `number_of_nodes` 和 `number_of_data_nodes` 这个命名完全是自描述的。\n- `active_primary_shards` 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。\n- `active_shards` 是涵盖了所有索引的所有分片的汇总值，即包括副本分片。\n- `relocating_shards` 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。\n- `initializing_shards` 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 `initializing` 状态。这通常会是一个临时事件，分片不应该长期停留在 `initializing`状态。你还可能在节点刚重启的时候看到 `initializing` 分片：当分片从磁盘上加载后，它们会从`initializing` 状态开始。\n- `unassigned_shards` 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 `red` 状态，也会长期保有未分配分片（因为缺少主分片）。\n\n\n### 集群统计\n\n集群统计信息包含 集群的分片数，文档数，存储空间，缓存信息，内存作用率，插件内容，文件系统内容，JVM 作用状况，系统 CPU，OS 信息，段信息。\n\n查看全部统计信息命令：\n\n```\ncurl -XGET 'http://localhost:9200/_cluster/stats?human\u0026amp;pretty'\n```\n\n返回 JSON 结果：\n\n```json\n{\n   \u0026quot;timestamp\u0026quot;: 1459427693515,\n   \u0026quot;cluster_name\u0026quot;: \u0026quot;elasticsearch\u0026quot;,\n   \u0026quot;status\u0026quot;: \u0026quot;green\u0026quot;,\n   \u0026quot;indices\u0026quot;: {\n      \u0026quot;count\u0026quot;: 2,\n      \u0026quot;shards\u0026quot;: {\n         \u0026quot;total\u0026quot;: 10,\n         \u0026quot;primaries\u0026quot;: 10,\n         \u0026quot;replication\u0026quot;: 0,\n         \u0026quot;index\u0026quot;: {\n            \u0026quot;shards\u0026quot;: {\n               \u0026quot;min\u0026quot;: 5,\n               \u0026quot;max\u0026quot;: 5,\n               \u0026quot;avg\u0026quot;: 5\n            },\n            \u0026quot;primaries\u0026quot;: {\n               \u0026quot;min\u0026quot;: 5,\n               \u0026quot;max\u0026quot;: 5,\n               \u0026quot;avg\u0026quot;: 5\n            },\n            \u0026quot;replication\u0026quot;: {\n               \u0026quot;min\u0026quot;: 0,\n               \u0026quot;max\u0026quot;: 0,\n               \u0026quot;avg\u0026quot;: 0\n            }\n         }\n      },\n      \u0026quot;docs\u0026quot;: {\n         \u0026quot;count\u0026quot;: 10,\n         \u0026quot;deleted\u0026quot;: 0\n      },\n      \u0026quot;store\u0026quot;: {\n         \u0026quot;size\u0026quot;: \u0026quot;16.2kb\u0026quot;,\n         \u0026quot;size_in_bytes\u0026quot;: 16684,\n         \u0026quot;throttle_time\u0026quot;: \u0026quot;0s\u0026quot;,\n         \u0026quot;throttle_time_in_millis\u0026quot;: 0\n      },\n      \u0026quot;fielddata\u0026quot;: {\n         \u0026quot;memory_size\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;memory_size_in_bytes\u0026quot;: 0,\n         \u0026quot;evictions\u0026quot;: 0\n      },\n      \u0026quot;query_cache\u0026quot;: {\n         \u0026quot;memory_size\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;memory_size_in_bytes\u0026quot;: 0,\n         \u0026quot;total_count\u0026quot;: 0,\n         \u0026quot;hit_count\u0026quot;: 0,\n         \u0026quot;miss_count\u0026quot;: 0,\n         \u0026quot;cache_size\u0026quot;: 0,\n         \u0026quot;cache_count\u0026quot;: 0,\n         \u0026quot;evictions\u0026quot;: 0\n      },\n      \u0026quot;completion\u0026quot;: {\n         \u0026quot;size\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;size_in_bytes\u0026quot;: 0\n      },\n      \u0026quot;segments\u0026quot;: {\n         \u0026quot;count\u0026quot;: 4,\n         \u0026quot;memory\u0026quot;: \u0026quot;8.6kb\u0026quot;,\n         \u0026quot;memory_in_bytes\u0026quot;: 8898,\n         \u0026quot;terms_memory\u0026quot;: \u0026quot;6.3kb\u0026quot;,\n         \u0026quot;terms_memory_in_bytes\u0026quot;: 6522,\n         \u0026quot;stored_fields_memory\u0026quot;: \u0026quot;1.2kb\u0026quot;,\n         \u0026quot;stored_fields_memory_in_bytes\u0026quot;: 1248,\n         \u0026quot;term_vectors_memory\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;term_vectors_memory_in_bytes\u0026quot;: 0,\n         \u0026quot;norms_memory\u0026quot;: \u0026quot;384b\u0026quot;,\n         \u0026quot;norms_memory_in_bytes\u0026quot;: 384,\n         \u0026quot;doc_values_memory\u0026quot;: \u0026quot;744b\u0026quot;,\n         \u0026quot;doc_values_memory_in_bytes\u0026quot;: 744,\n         \u0026quot;index_writer_memory\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;index_writer_memory_in_bytes\u0026quot;: 0,\n         \u0026quot;version_map_memory\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;version_map_memory_in_bytes\u0026quot;: 0,\n         \u0026quot;fixed_bit_set\u0026quot;: \u0026quot;0b\u0026quot;,\n         \u0026quot;fixed_bit_set_memory_in_bytes\u0026quot;: 0,\n         \u0026quot;file_sizes\u0026quot;: {}\n      },\n      \u0026quot;percolator\u0026quot;: {\n         \u0026quot;num_queries\u0026quot;: 0\n      }\n   },\n   \u0026quot;nodes\u0026quot;: {\n      \u0026quot;count\u0026quot;: {\n         \u0026quot;total\u0026quot;: 1,\n         \u0026quot;data\u0026quot;: 1,\n         \u0026quot;coordinating_only\u0026quot;: 0,\n         \u0026quot;master\u0026quot;: 1,\n         \u0026quot;ingest\u0026quot;: 1\n      },\n      \u0026quot;versions\u0026quot;: [\n         \u0026quot;5.6.3\u0026quot;\n      ],\n      \u0026quot;os\u0026quot;: {\n         \u0026quot;available_processors\u0026quot;: 8,\n         \u0026quot;allocated_processors\u0026quot;: 8,\n         \u0026quot;names\u0026quot;: [\n            {\n               \u0026quot;name\u0026quot;: \u0026quot;Mac OS X\u0026quot;,\n               \u0026quot;count\u0026quot;: 1\n            }\n         ],\n         \u0026quot;mem\u0026quot; : {\n            \u0026quot;total\u0026quot; : \u0026quot;16gb\u0026quot;,\n            \u0026quot;total_in_bytes\u0026quot; : 17179869184,\n            \u0026quot;free\u0026quot; : \u0026quot;78.1mb\u0026quot;,\n            \u0026quot;free_in_bytes\u0026quot; : 81960960,\n            \u0026quot;used\u0026quot; : \u0026quot;15.9gb\u0026quot;,\n            \u0026quot;used_in_bytes\u0026quot; : 17097908224,\n            \u0026quot;free_percent\u0026quot; : 0,\n            \u0026quot;used_percent\u0026quot; : 100\n         }\n      },\n      \u0026quot;process\u0026quot;: {\n         \u0026quot;cpu\u0026quot;: {\n            \u0026quot;percent\u0026quot;: 9\n         },\n         \u0026quot;open_file_descriptors\u0026quot;: {\n            \u0026quot;min\u0026quot;: 268,\n            \u0026quot;max\u0026quot;: 268,\n            \u0026quot;avg\u0026quot;: 268\n         }\n      },\n      \u0026quot;jvm\u0026quot;: {\n         \u0026quot;max_uptime\u0026quot;: \u0026quot;13.7s\u0026quot;,\n         \u0026quot;max_uptime_in_millis\u0026quot;: 13737,\n         \u0026quot;versions\u0026quot;: [\n            {\n               \u0026quot;version\u0026quot;: \u0026quot;1.8.0_74\u0026quot;,\n               \u0026quot;vm_name\u0026quot;: \u0026quot;Java HotSpot(TM) 64-Bit Server VM\u0026quot;,\n               \u0026quot;vm_version\u0026quot;: \u0026quot;25.74-b02\u0026quot;,\n               \u0026quot;vm_vendor\u0026quot;: \u0026quot;Oracle Corporation\u0026quot;,\n               \u0026quot;count\u0026quot;: 1\n            }\n         ],\n         \u0026quot;mem\u0026quot;: {\n            \u0026quot;heap_used\u0026quot;: \u0026quot;57.5mb\u0026quot;,\n            \u0026quot;heap_used_in_bytes\u0026quot;: 60312664,\n            \u0026quot;heap_max\u0026quot;: \u0026quot;989.8mb\u0026quot;,\n            \u0026quot;heap_max_in_bytes\u0026quot;: 1037959168\n         },\n         \u0026quot;threads\u0026quot;: 90\n      },\n      \u0026quot;fs\u0026quot;: {\n         \u0026quot;total\u0026quot;: \u0026quot;200.6gb\u0026quot;,\n         \u0026quot;total_in_bytes\u0026quot;: 215429193728,\n         \u0026quot;free\u0026quot;: \u0026quot;32.6gb\u0026quot;,\n         \u0026quot;free_in_bytes\u0026quot;: 35064553472,\n         \u0026quot;available\u0026quot;: \u0026quot;32.4gb\u0026quot;,\n         \u0026quot;available_in_bytes\u0026quot;: 34802409472\n      },\n      \u0026quot;plugins\u0026quot;: [\n        {\n          \u0026quot;name\u0026quot;: \u0026quot;analysis-icu\u0026quot;,\n          \u0026quot;version\u0026quot;: \u0026quot;5.6.3\u0026quot;,\n          \u0026quot;description\u0026quot;: \u0026quot;The ICU Analysis plugin integrates Lucene ICU module into elasticsearch, adding ICU relates analysis components.\u0026quot;,\n          \u0026quot;classname\u0026quot;: \u0026quot;org.elasticsearch.plugin.analysis.icu.AnalysisICUPlugin\u0026quot;,\n          \u0026quot;has_native_controller\u0026quot;: false\n        },\n        {\n          \u0026quot;name\u0026quot;: \u0026quot;ingest-geoip\u0026quot;,\n          \u0026quot;version\u0026quot;: \u0026quot;5.6.3\u0026quot;,\n          \u0026quot;description\u0026quot;: \u0026quot;Ingest processor that uses looksup geo data based on ip adresses using the Maxmind geo database\u0026quot;,\n          \u0026quot;classname\u0026quot;: \u0026quot;org.elasticsearch.ingest.geoip.IngestGeoIpPlugin\u0026quot;,\n          \u0026quot;has_native_controller\u0026quot;: false\n        },\n        {\n          \u0026quot;name\u0026quot;: \u0026quot;ingest-user-agent\u0026quot;,\n          \u0026quot;version\u0026quot;: \u0026quot;5.6.3\u0026quot;,\n          \u0026quot;description\u0026quot;: \u0026quot;Ingest processor that extracts information from a user agent\u0026quot;,\n          \u0026quot;classname\u0026quot;: \u0026quot;org.elasticsearch.ingest.useragent.IngestUserAgentPlugin\u0026quot;,\n          \u0026quot;has_native_controller\u0026quot;: false\n        }\n      ]\n   }\n}\n```\n\n#### 内存使用和 GC 指标\n\n在运行 Elasticsearch 时，内存是您要密切监控的关键资源之一。 Elasticsearch 和 Lucene 以两种方式利用节点上的所有可用 RAM：JVM heap 和文件系统缓存。 Elasticsearch 运行在Java虚拟机（JVM）中，这意味着JVM垃圾回收的持续时间和频率将成为其他重要的监控领域。\n\n上面返回的 JSON监控的指标有我个人觉得有这些：\n\n+ nodes.successful\n+ nodes.failed\n+ nodes.total\n+ nodes.mem.used_percent\n+ nodes.process.cpu.percent\n+ nodes.jvm.mem.heap_used\n\n可以看到 JSON 文件是很复杂的，如果从这复杂的 JSON 中获取到对应的指标（key）的值呢，这里请看文章 ：[JsonPath —— JSON 解析神器](http://www.54tianzhisheng.cn/2017/10/13/JsonPath/)\n\n### 最后\n\n这里主要讲下 ES 集群的一些监控信息，有些监控指标是个人觉得需要监控的，但是具体情况还是得看需求了。下篇文章主要讲节点的监控信息。转载请注明地址：[http://www.54tianzhisheng.cn/2017/10/15/ElasticSearch-cluster-health-metrics/](http://www.54tianzhisheng.cn/2017/10/15/ElasticSearch-cluster-health-metrics/)\n\n###  参考资料\n\n1、[How to monitor Elasticsearch performance](https://www.datadoghq.com/blog/monitor-elasticsearch-performance-metrics/)\n\n2、[ElasticSearch 性能监控](http://www.oneapm.com/ci/elasticsearch.html)\n\n3、[cluster-health](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html)\n\n4、[cluster-stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-stats.html)\n\n### 相关阅读\n\n1、[Elasticsearch 默认分词器和中分分词器之间的比较及使用方法](http://www.54tianzhisheng.cn/2017/09/07/Elasticsearch-analyzers/)\n\n2、[全文搜索引擎 Elasticsearch 集群搭建入门教程](http://www.54tianzhisheng.cn/2017/09/09/Elasticsearch-install/)","title":"ElasticSearch 集群监控","uid":"6576","views":"3631","votes":"2"},"_type":"doc"}
{"_id":"365","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510267066","category_id":"18","comments":"0","has_attach":"0","id":"365","message":"1、源码解析 | elasticsearch 索引创建和更新\nhttp://t.cn/RlHuOKx\n2、业界良心 |  《Elasticsearch5.6.3 Java API 中文手册》\nhttps://elasticsearch.cn/article/362\n3、PPT | 基于 Mesos/Docker 的 Elasticsearch 容器化私有云\n[url]http://t.cn/RlHuTQR[/url] \n4、只等你来 | Elastic Meetup 广州交流会\nhttps://elasticsearch.cn/article/364\n\n编辑：laoyang360\n归档：https://elasticsearch.cn/article/365\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第96期 (2017-11-10)","uid":"1341","views":"443","votes":"0"},"_type":"doc"}
{"_id":"366","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510306594","category_id":"1","comments":"4","has_attach":"1","id":"366","message":"\u0026gt; 为了改善大家的创作体验，提高大家的写作和分享热情！?，经过两天的不懈奋斗，终于把 Markdown 编辑器搬上来了。\n\u0026gt; 目前只支持文章的发布，可以通过切换编辑器来选择 Markdown 编辑模式。\n\u0026gt; 希望不要再以编辑器作为理由发只有链接的文章了。\n\u0026gt; ???????????\n\n\n* 支持 Github 风格的 Markdown 格式\n* 支持本站附件功能\n* 支持 emoj 符号\n* 支持自动的页面导航\n* 以前的文章可再次编辑，切换 Markdown 模式然后修改保存\n\n### 如何使用？\n1. 点击【发起】，选择文章\n2. 切换绿色按钮，将编辑器切换到 Markdown，然后在文本框内输入 Markdown 格式的内容即可。\n\n\n在线 Markdown 脚本编辑预览工具：https://elasticsearch.cn/static/js/editor/markdown/\n\n----\n\n以下为样式测试参考，忽略其意义。\n\n[attach]1250[/attach]\n\n----------- 常用格式-----------------\n\n```\n\n# 标题1\n## 标题2\n### 标题3\n#### 标题4\n##### 标题5\n###### 标题6\n超大标题   //等于号写于文字下方\n===\n标题      //同超大标题\n---\n\n`短代码`\n_ 注：长代码块，用三个: `  _\n\n\u0026gt; This is the first level of quoting.\n\u0026gt;\n\u0026gt; \u0026gt; This is nested blockquote.\n\u0026gt;\n\u0026gt; Back to the first level.\n\n\n* Red\n* Green\n* Blue\n\n- Red\n- Green\n- Blue\n\n+ Red\n+ Green\n+ Blue\n\n1. 这是第一个\n1. 这是第二个\n1. 这是第三个\n\n* * *\n***\n*****\n- - -\n---\n\n[markdown-syntax](http://daringfireball.net/projects/markdown/syntax)\n\n[id]: http://example.com/  \u0026quot;Optional Title Here\u0026quot;\nThis is [an example][id] reference-style link.\n\n*内容*\n**内容**\n_内容_\n__内容__\n\n\n![这是张外链图片](https://static-www.elastic.co/assets/bltbfcd44f1256d8c88/blog-swifttype-thumb.jpg?q=845)\n\n\n\u0026lt;http://elastic.co/\u0026gt;\n\n\u0026lt;info@elastic.o\u0026gt;\n\n\n    四个空格\n    一个tab\n\n\n```\n----------- 样式预览-----------------\n\n# 标题1\n## 标题2\n### 标题3\n#### 标题4\n##### 标题5\n###### 标题6\n\n超大标题   //等于号写于文字下方\n===\n标题      //同超大标题\n---\n\n`短代码`\n\n\n\u0026gt; This is the first level of quoting.\n\u0026gt;\n\u0026gt; \u0026gt; This is nested blockquote.\n\u0026gt;\n\u0026gt; Back to the first level.\n\n\n* Red\n* Green\n* Blue\n\n- Red\n- Green\n- Blue\n\n+ Red\n+ Green\n+ Blue\n\n1. 这是第一个\n1. 这是第二个\n1. 这是第三个\n\n* * *\n***\n*****\n- - -\n---\n\n[markdown-syntax](http://daringfireball.net/projects/markdown/syntax)\n\n[id]: http://example.com/  \u0026quot;Optional Title Here\u0026quot;\nThis is [an example][id] reference-style link.\n\n*内容*\n**内容**\n_内容_\n__内容__\n\n\n![这是张外链图片](https://static-www.elastic.co/assets/bltbfcd44f1256d8c88/blog-swifttype-thumb.jpg?q=845)\n\n\n\u0026lt;http://elastic.co/\u0026gt;\n\n\u0026lt;info@elastic.o\u0026gt;\n\n\n    四个空格\n    一个tab\n\n\n---------\n\n\nhttps://github.com/infinitbyte/gopa 的 README 内容\n\n---------\n\u0026lt;img width=\u0026quot;200\u0026quot; alt=\u0026quot;What a Spider!\u0026quot; src=\u0026quot;https://raw.githubusercontent.com/infinitbyte/gopa/master/static/assets/img/logo.svg?sanitize=true\u0026quot;\u0026gt;\n\nGOPA, A Spider Written in Go.\n\n[![Travis](https://travis-ci.org/infinitbyte/gopa.svg?branch=master)](https://travis-ci.org/infinitbyte/gopa)\n[![Go Report Card](https://goreportcard.com/badge/github.com/infinitbyte/gopa)](https://goreportcard.com/report/github.com/infinitbyte/gopa)\n[![Coverage Status](https://coveralls.io/repos/github/infinitbyte/gopa/badge.svg?branch=master)](https://coveralls.io/github/infinitbyte/gopa?branch=master)\n[![Join the chat at https://gitter.im/infinitbyte/gopa](https://badges.gitter.im/infinitbyte/gopa.svg)](https://gitter.im/infinitbyte/gopa?utm_source=badge\u0026amp;utm_medium=badge\u0026amp;utm_campaign=pr-badge\u0026amp;utm_content=badge)\n\n\n## Goal\n\n* Light weight, low footprint, memory requirement should \u0026lt; 100MB\n* Easy to deploy, no runtime or dependency required\n* Easy to use, no programming or scripts ability needed, out of box features\n\n\n## Screenshoot\n\n\u0026lt;img width=\u0026quot;800\u0026quot; alt=\u0026quot;What a Spider! GOPA Spider!\u0026quot; src=\u0026quot;https://raw.githubusercontent.com/infinitbyte/gopa/master/docs/assets/img/screenshot/2017.10.20_v0.9.gif\u0026quot;\u0026gt;\n\n\n---\n\n\n- [How to use](#how-to-use)\n  - [Setup](#setup)\n    - [Download Pre Built Package](#download-pre-built-package)\n    - [Compile The Package Manually](#compile-the-package-manually)\n  - [Optional Config](#optional-config)\n  - [Start](#start)\n  - [Stop](#stop)\n- [Configuration](#configuration)\n- [UI](#ui)\n- [API](#api)\n- [Contributing](#contributing)\n- [License](#license)\n\n\n\n## How to use\n\n### Setup\n\nFirst of all, get it, two opinions: download the pre-built package or compile it yourself.\n\n#### Download Pre Built Package\n\nGo to [Release](https://github.com/infinitbyte/gopa/releases) or [Snapshot](https://github.com/infinitbyte/gopa-snapshot/releases) page, download the right package for your platform.\n\n_Note: Darwin is for Mac_\n\n#### Compile The Package Manually\n\n- Mac/Linux: Run `make build` to build the Gopa. \u0026lt;br/\u0026gt;\n- Windows:  Checkout this wiki page - [How to build GOPA on windows](https://github.com/infinitbyte/gopa/wiki/How-to-build-GOPA-on-windows).\n\nSo far, we have:\n\n\u0026gt; `gopa`, the main program, a single binary.\u0026lt;br/\u0026gt;\n\u0026gt; `config/`, elasticsearch related scripts etc.\u0026lt;br/\u0026gt;\n\u0026gt; `gopa.yml`, main configuration for gopa.\u0026lt;br/\u0026gt;\n\n\n### Optional Config\n\nBy default, Gopa works well except indexing, if you want to use elasticsearch as indexing, follow these steps:\n\n- Create a index in elasticsearch with script `config/gopa-index-mapping.sh`\n\u0026lt;p\u0026gt;\u0026lt;details\u0026gt;\n  \u0026lt;summary\u0026gt;Example\u0026lt;/summary\u0026gt;\n  \u0026lt;pre\u0026gt;curl -XPUT \u0026quot;http://localhost:9200/gopa-index\u0026quot; -H 'Content-Type: application/json' -d'\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;doc\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;host\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n            \u0026quot;ignore_above\u0026quot;: 256\n        },\n        \u0026quot;snapshot\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;bold\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;url\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;content_type\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;file\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;h1\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;h2\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;h3\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;h4\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;hash\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;id\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;images\u0026quot;: {\n              \u0026quot;properties\u0026quot;: {\n                \u0026quot;external\u0026quot;: {\n                  \u0026quot;properties\u0026quot;: {\n                    \u0026quot;label\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                    },\n                    \u0026quot;url\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n                      \u0026quot;ignore_above\u0026quot;: 256\n                    }\n                  }\n                },\n                \u0026quot;internal\u0026quot;: {\n                  \u0026quot;properties\u0026quot;: {\n                    \u0026quot;label\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                    },\n                    \u0026quot;url\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n                      \u0026quot;ignore_above\u0026quot;: 256\n                    }\n                  }\n                }\n              }\n            },\n            \u0026quot;italic\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;links\u0026quot;: {\n              \u0026quot;properties\u0026quot;: {\n                \u0026quot;external\u0026quot;: {\n                  \u0026quot;properties\u0026quot;: {\n                    \u0026quot;label\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                    },\n                    \u0026quot;url\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n                      \u0026quot;ignore_above\u0026quot;: 256\n                    }\n                  }\n                },\n                \u0026quot;internal\u0026quot;: {\n                  \u0026quot;properties\u0026quot;: {\n                    \u0026quot;label\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                    },\n                    \u0026quot;url\u0026quot;: {\n                      \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n                      \u0026quot;ignore_above\u0026quot;: 256\n                    }\n                  }\n                }\n              }\n            },\n            \u0026quot;path\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;sim_hash\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;lang\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;size\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n            },\n            \u0026quot;text\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n            },\n            \u0026quot;title\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n              \u0026quot;fields\u0026quot;: {\n                \u0026quot;keyword\u0026quot;: {\n                  \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                }\n              }\n            },\n            \u0026quot;version\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n            }\n          }\n        },\n        \u0026quot;task\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;breadth\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n            },\n            \u0026quot;created\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;\n            },\n            \u0026quot;depth\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n            },\n            \u0026quot;id\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;original_url\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;reference_url\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;schema\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            },\n            \u0026quot;status\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n            },\n            \u0026quot;updated\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;\n            },\n            \u0026quot;url\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n              \u0026quot;ignore_above\u0026quot;: 256\n            }\n          }\n        }\n      }\n    }\n  }\n}'\u0026lt;/pre\u0026gt;\n\u0026lt;/details\u0026gt;\u0026lt;/p\u0026gt;\n\n_Note: Elasticsearch version should \u0026gt; v5.0_\n\n- Enable index module in `gopa.yml`, update the elasticsearch's setting:\n```\n  - module: index\n    enabled: true\n    ui:\n      enabled: true\n    elasticsearch:\n      endpoint: http://dev:9200\n      index_prefix: gopa-\n      username: elastic\n      password: changeme\n```\n\u0026lt;/details\u0026gt;\u0026lt;/p\u0026gt;\n\n\n### Start\n\nGopa doesn't require any dependencies, simply run `./gopa` to start the program.\n\nGopa can be run as daemon(_Note: Only available on Linux and Mac_):\n\u0026lt;p\u0026gt;\u0026lt;details\u0026gt;\n  \u0026lt;summary\u0026gt;Example\u0026lt;/summary\u0026gt;\n  \u0026lt;pre\u0026gt;\n➜  gopa git:(master) ✗ ./bin/gopa --daemon\n  ________ ________ __________  _____\n /  _____/ \\_____  \\\\______   \\/  _  \\\n/   \\  ___  /   |   \\|     ___/  /_\\  \\\n\\    \\_\\  \\/    |    \\    |  /    |    \\\n \\______  /\\_______  /____|  \\____|__  /\n        \\/         \\/                \\/\n[gopa] 0.10.0_SNAPSHOT\n///last commit: 99616a2, Fri Oct 20 14:04:54 2017 +0200, medcl, update version to 0.10.0 ///\n\n[10-21 16:01:09] [INF] [instance.go:23] workspace: data/gopa/nodes/0\n[gopa] started.\u0026lt;/pre\u0026gt;\n\u0026lt;/details\u0026gt;\u0026lt;/p\u0026gt;\n\nAlso run `./gopa -h` to get the full list of command line options.\n\u0026lt;p\u0026gt;\u0026lt;details\u0026gt;\n  \u0026lt;summary\u0026gt;Example\u0026lt;/summary\u0026gt;\n  \u0026lt;pre\u0026gt;\n➜  gopa git:(master) ✗ ./bin/gopa -h\n  ________ ________ __________  _____\n /  _____/ \\_____  \\\\______   \\/  _  \\\n/   \\  ___  /   |   \\|     ___/  /_\\  \\\n\\    \\_\\  \\/    |    \\    |  /    |    \\\n \\______  /\\_______  /____|  \\____|__  /\n        \\/         \\/                \\/\n[gopa] 0.10.0_SNAPSHOT\n///last commit: 99616a2, Fri Oct 20 14:04:54 2017 +0200, medcl, update version to 0.10.0 ///\n\nUsage of ./bin/gopa:\n  -config string\n    \tthe location of config file (default \u0026quot;gopa.yml\u0026quot;)\n  -cpuprofile string\n    \twrite cpu profile to this file\n  -daemon\n    \trun in background as daemon\n  -debug\n    \trun in debug mode, wi\n  -log string\n    \tthe log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;)\n  -log_path string\n    \tthe log path (default \u0026quot;log\u0026quot;)\n  -memprofile string\n    \twrite memory profile to this file\n  -pidfile string\n    \tpidfile path (only for daemon)\n  -pprof string\n    \tenable and setup pprof/expvar service, eg: localhost:6060 , the endpoint will be: http://localhost:6060/debug/pprof/ and http://localhost:6060/debug/vars\u0026lt;/pre\u0026gt;\n\u0026lt;/details\u0026gt;\u0026lt;/p\u0026gt;\n\n\n### Stop\n\nIt's safety to press `ctrl+c` stop the current running Gopa, Gopa will handle the rest,saving the checkpoint,\nyou may restore the job later,the world is still in your hand.\n\nIf you are running `Gopa` as daemon, you may stop it like this:\n\n```\n kill -QUIT `pgrep gopa`\n```\n\n## Configuration\n\n## UI\n\n* Search Console `http://127.0.0.1:9001/`\n* Admin Console  `http://127.0.0.1:9001/admin/`\n\n## API\n\n* TBD\n\n\n## Contributing\n\nYou are sincerely and warmly welcomed to play with this project,\nfrom UI style to core features,\nor just a piece of document,\nwelcome! let's make it better.\n\n\nLicense\n=======\nReleased under the [Apache License, Version 2.0](https://github.com/infinitbyte/gopa/blob/master/LICENSE) .\n\n\nAlso XSS Test\n\u0026lt;script\u0026gt;\nalert('XSS test');\n\u0026lt;/script\u0026gt;","title":"社区支持 Markdown 编辑器","uid":"1","views":"1262","votes":"3"},"_type":"doc"}
{"_id":"369","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510374862","category_id":"2","comments":"0","has_attach":"0","id":"369","message":"elasticsearch的dsl开发工具sense被google下架了，kibana console是很好的替代品。但是，我们的es集群前些日子因为应付安全检查改为https+basic auth方式（详细配置过程见本人博文：http://blog.csdn.net/jiashiwen/article/details/76914374），kibana需要进行若干配置才能工作。另外老系统中还有elasticsearch2.3.3遗留，需要kibana4.5.1+sense。\n\n\n\n\n一、elasticsearch5.5.2+kibana5.5.2\n\n1.下载与elasticsearch版本号一致的kibana安装包，笔者目前开发环境5.5.2，对应kibana版本也为5.5.2（最新的5.6版本会报不兼容错误，不能运行）。\n\n\n\n\n2.配置config/kibana.yml文件，主要配置项如下 \n# The URL of the Elasticsearch instance to use for all your queries.\n#elasticsearch.url: \u0026quot;http://localhost:9200\u0026quot;\nelasticsearch.url: \u0026quot;https://192.168.1.1:9281/\u0026quot;\n​\n​\n# If your Elasticsearch is protected with basic authentication, these settings provide\n# the username and password that the Kibana server uses to perform maintenance on the Kibana\n# index at startup. Your Kibana users still need to authenticate with Elasticsearch, which\n# is proxied through the Kibana server.\n#elasticsearch.username: \u0026quot;user\u0026quot;\n#elasticsearch.password: \u0026quot;pass\u0026quot;\nelasticsearch.username: \u0026quot;admin\u0026quot;\nelasticsearch.password: \u0026quot;admin\u0026quot;\n​\n​\n# Optional settings that provide the paths to the PEM-format SSL certificate and key files.\n# These files validate that your Elasticsearch backend uses the same key files.\n#elasticsearch.ssl.certificate: /path/to/your/client.crt\n#elasticsearch.ssl.key: /path/to/your/client.key\nelasticsearch.ssl.certificate: /home/develop/kibana-5.6.3-linux-x86_64/config/crts/eshttp.crt\nelasticsearch.ssl.key: /home/develop/kibana-5.6.3-linux-x86_64/config/crts/eshttp.key\n​\n​\n# To disregard the validity of SSL certificates, change this setting's value to 'none'.\n#elasticsearch.ssl.verificationMode: full\nelasticsearch.ssl.verificationMode: none各项配置看文件内说明，写的很清楚，这里就不翻译了，其中最重要的是这两样elasticsearch.ssl.certificate和elasticsearch.ssl.key，一定要与服务端保持一致。由于证书是自己生成的，校验项elasticsearch.ssl.verificationMode的值需要改为none。\n\n\n\n\n启动kibana后，通过http://localhose:5601访问即可","title":"sense不能用了改用kibana吧","uid":"6713","views":"1278","votes":"0"},"_type":"doc"}
{"_id":"372","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510536047","category_id":"18","comments":"1","has_attach":"0","id":"372","message":"1、使用于商业智能的复杂模型建模教程\nhttp://t.cn/Rj2uLh9\n2、logstash配置文件的vscode插件，从其编辑配置文件不再发愁。\nhttp://t.cn/Rj21ncE\n3、elk告警插件sentinl。随着版本的更新,目前已经可以媲美x-pack的reporter以及watcher。\nhttp://t.cn/Rj216Ef\n4、只等你来 | Elastic Meetup 广州交流会\n[url]https://elasticsearch.cn/article/364[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/372\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第99期 (2017-11-13)","uid":"4063","views":"600","votes":"0"},"_type":"doc"}
{"_id":"512","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519792976","category_id":"5","comments":"0","has_attach":"1","id":"512","message":"\n[attach]1823[/attach]\n\n#### 嘉奖 Elastic 社群促进全球福祉的杰出项目\n\n旧金山，2018 年 2 月 27 日 - （GLOBE NEWSWIRE）--（Elastic{ON} 2018） - Elasticsearch 和 Elastic Stack 幕后公司 Elastic 今日在 Elastic {ON} 2018 开幕礼主题演讲中宣布第二届 Elastic Cause Awards 的获奖者。为表彰Elastic 社群的热情、创新和奉献精神，2018 年 Elastic Cause Awards 嘉奖了四个推动 Elastic 软件发展并造福全球的项目。今年的获奖者包括：Dimagi、Libraries Without Borders (Bibliothèques Sans Frontières) 、Refugee Datathon Munich 和 Thorn: Digital Defenders of Children。\n\nElastic Cause Awards 是 Elastic 不断扩展的慈善使命之一，该公司将继续致力于慈善事业，以进一步惠及使用Elastic Stack 的非牟利组织。第二届 Cause Awards 覆盖数十家组织提名，致力改善人类状况，改善环境或协助当地、地区或全球有需要的人口。评审包括 Elastic 创始人兼首席执行官 Shay Banon、人力资源部副总裁Leah Sutton，以及由 Elastic 开发人员、产品和客户专家组成的小组，他们根据其影响、利他主义和影响力评估入围者。每个获选的项目团队均可获得最多两位项目成员的免费会议门票和酒店住宿，并将在 Elastic {ON} 2018 的各项活动中亮相。\nBanon 表示﹕“在我们开始使用 Elastic 时，我知道我们的软件产品可用来帮助开发人员解决组织内的重要实用范例，但我从来没有预料到它会对解决全球人道主义和环境问题带来影响。我的灵感来自我们通过今年的 Elastic Cause Awards 了解到改变生计的举措，并为我们实现这一目标所作出的微不足道的努力而感到谦卑。”\n\n* Dimagi\nDimagi 正在印度帮助打击肺结核（tuberculosis / TB）流行病，该流行病占全球肺结核病例的 23%，并通过集成的移动和网络应用程序帮助医护人员追踪结核病患者。在 Dimagi 的软件平台 CommCare 基础上，该应用程序利用 Elastic Stack 从初步诊断以至整个护理过程中追踪获治疗者，并在整个过程中提供可操作的数据。 该应用程序目前能够实时汇总数据，以追踪选定地区的 150,000 名患者。\nDimagi 高级工程师 Farid Rener 表示﹕“印度每三分钟便有两人死于肺结核。这是一种需要实时关注和需要创新解决方案的流行病。我们相信移动解决方案可改变服务交付计划的效率、质量和影响力。通过将我们的移动数据收集平台与 Elastic Stack 的强大功能互相结合，我们正在提高医护人员追踪患者的效率，并让政府决策者更准确、及时地掌握当前计划的效果。”\n\n* Libraries Without Borders (Bibliothèques Sans Frontières)\nLibraries Without Borders 促进自由开放的信息和教育，为全球弱势社群提供学习和发展的工具和技能。该组织正在推出数字图书馆（KoomBook）以及便携式“弹出式”数字媒体中心（Ideas Box），为需要帮助的小区提供教育和文化资源，包括全球难民和流离失所的人群，以及发达国家中服务不足的小区。通过 Elastic Stack 提供的日志分析和仪表板可实时了解数字资源的使用情况以及用户的浏览习惯和兴趣，从而令组织能更有效地评估影响和相关性，并改善用户体验。\nBibliothèques Sans Frontières 数字项目经理 Steven Walliman 表示﹕“Elastic Stack 能够处理各种原始日志，同时也能产生具有吸引力的视觉效果，这种功能完全符合我们的需求。通过让 IT 团队更好地了解性能和稳定性，以及能够衡量图书馆员的选择的相关性，Elastic Stack 增强了我们项目的影响力。我们期待着深化两个组织之间的联系，因为我们具有实现增强弱势社群能力和改善全球数以百万计人口生计的愿景。”\n\n* Refugee Datathon Munich\nRefugee Datathon Munich 于 2015 年秋季成立，在慕尼黑为难民提供大规模支持，并为欧洲难民活动家提供最新和可靠的数据。该组织的软件从官方网站提取寻求庇护者的统计数据，然后依靠 Elastic Stack 在发布信息之前分析数据。该软件帮助活动家实时掌握当前庇护趋势（如各原籍国的批准率），同时通过驳回错误陈述和难民偏见报告为公众提供服务。\nRefugee Datathon Munich 数据架构师 Suny Kim 表示﹕“当我们看到活动家难以使用 Excel 以解释难民情况时，我们意识到有必要给予他们更多的探索能力，为其提供更多最新的数据和减少工作量。Elastic Stack 帮助我们从欧盟统计局的统计数据中获取大量数据，并以交互方式来进行分析。对我们来说，这就是民主所在：获得信息，参与其中。全球难民形势是我们这个时代的重大挑战之一，我们的项目是通过体面和充分的方式应对这一挑战的民主进程的一部分。”\n\n* Thorn: Digital Defenders of Children\nThorn 由 Ashton Kutcher 和 Demi Moore 共同创立，通过技术开发来保护儿童免遭性虐待。对于寻找和救援更多孩子而言，必须做到分秒必争。Thorn 在其产品中使用 Elastic Stack 来简化功能，帮助执法机构搜索数以百万条记录，并快速找到识别儿童的小片信息。2016 年和 2017 年，加快识别性交易受害儿童的 Spotlight 帮助确定了 5,791 名儿童性贩运受害者（每天8名）。Thorn 的另一个产品 Solis 已被 17 个国家的执法部门使用，并已救出 72 名儿童性虐待受害者，这些儿童的照片在暗网上散布。\nThorn 首席执行官 Julie Cordua 表示﹕“通过与 Elastic 这样的领先技术公司合作，我们成功建立了能更快找到儿童性虐待受害者的尖端工具，使网络环境更安全，并阻止犯罪行为。在通过技术打击儿童性虐待犯罪的过程中，我们意识到技术的强大之处，我们选择善用有关技术，以成功打击儿童性贩卖和其他网上贩卖活动。”\n\nElastic Cause Award 最终入围名单包括﹕\n\n* Action Network：帮助进步组织进行有针对性的宣传和外展\n* CBC Radio：能发掘各类型的新兴音乐艺术家\n* Factr：通过共建情报流促进解决全球问题\n* Mark43：通过更好的软件减少暴力犯罪\n* Internet of Things for Disaster Risk Reduction (IoT-DRR)：通过监测和分析智能雨水箱和河流水位来减少灾害风险\n* University of Bristol：促进应用门德尔随机化\n* US NAVY：通过网络安全保护美国海军的水兵和士兵\n* 弗吉尼亚理工学院和州立大学（Virginia Polytechnic Institute and State University / Virginia Tech ）：为环境和农业利益相关者监测流域\n* weblyzard Technology：为联合国环境规划署（UNEP）创建环境网页情报门户，以确定意见领袖并根据主题和地理位置构建公众辩论途径\n* Zebra Medical Vision：策划临床和算法数据集\n\n\n### 关于Elastic\nElastic 致力于构建大规模实时数据处理软件，场景主要涵盖搜索、日志、安全与数据分析等领域。公司成立于 2012 年，旗下拥有产品包括开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、 X-Pack （商业特性）和 Elastic Cloud （一种托管服务）。迄今为止，这些产品的累积下载次数已超过 2.25 亿。Elastic 由 Benchmark Capital、Index Ventures 及 NEA 投资，投资额超过 1 亿美金。Elastic 拥有超过 800 位员工，分布于世界上 30 多个国家和地区。欲了解详情请访问：elastic.co。\n\n### 媒体联系人：\n\nMichael Lindenberger\n\nReidy Communications for Elastic\n\nMichael@reidycommunications.com\n\n(415) 531-1449\n\n亚太地区\nJeff Yoshimura\n\nCommunications @ Elastic\n\npr@elastic.co","title":"Elastic 宣布 2018 年 Elastic Cause Awards 的获奖者","uid":"1","views":"683","votes":"1"},"_type":"doc"}
{"_id":"520","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520299620","category_id":"18","comments":"0","has_attach":"0","id":"520","message":"1.亚马逊AWS官方博客-基于ECS的容器日志解决方案。\n[url]http://t.cn/RElYPUV[/url] \n2.从Elasticsearch集群及数据层架构，看阿里少强谈分布式系统设计。\n[url]http://t.cn/REiAZ6H[/url] \n3.Filebeat和Logstash收集Nginx日志到Elasticsearch详解姊妹篇。\n[url]http://t.cn/RElYzIa[/url] \n[url]http://t.cn/RElYAo6[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/520[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第202期 (2018-03-06)","uid":"3788","views":"331","votes":"0"},"_type":"doc"}
{"_id":"531","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520958585","category_id":"2","comments":"2","has_attach":"0","id":"531","message":"一直以来官方手册都是零散的阅读，没有完整的看过，导致对es很多功能还有使用细节并不是非常了解。\n \n然后最近也是在debug 看源码，顺便想把官方文档也刷了，决定开始自己翻译 elasticsearch 官方参考手册。看到之前网上有人在翻译但是没有翻译完，自己也尝试一下。\n \n公司用的是2.2版本的所以我就从这个版本开始翻译了，译文中会有一些批注，后续会持续关注高版本并把特性以批注的方式补上说明。\n \n在线阅读： [url=http://www.code4j.tech]www.code4j.tech[/url]\n \ngithub地址：[url]https://github.com/rpgmakervx/elasticsearch-reference-translation[/url]\n \n掘金翻译计划：[url]https://github.com/xitu/gold-miner[/url]\n \n计划每周翻译两三篇吧，看情况。\n \n英语只有六级啦，有些地方翻译起来也很笨拙，有翻译不恰当之处大家可以提issue呀！","title":"elasticsearch参考手册 (译文)","uid":"6299","views":"1175","votes":"7"},"_type":"doc"}
{"_id":"533","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521000059","category_id":"2","comments":"4","has_attach":"0","id":"533","message":"[b][size=18]1. 模拟字符串数据存储[/size][/b][code]localhost:9200/yigo-redist.1/_analyze?analyzer=default\u0026amp;text=全能片(前)---TRW-GDB7891AT刹车片自带报警线，无单独报警线号码,卡仕欧,卡仕欧,乘用车,刹车片[/code]上面的url表示\n[list]\n[*]    索引为`yigo-redist.1`[/*]\n[*]    使用了索引`yigo-redist.1`中的分词器(`analyzer`) `default`[/*]\n[*]    解析的字符串(`text`)为\u0026quot;全能片(前)---TRW-GDB7891AT刹车片自带报警线，无单独报警线号码,卡仕欧,卡仕欧,乘用车,刹车片\u0026quot;[/*]\n[/list]\n\n如果结果为:[code]{\n  \u0026quot;tokens\u0026quot; : [ {\n    \u0026quot;token\u0026quot; : \u0026quot;全能\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 2,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;片\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 2,\n    \u0026quot;end_offset\u0026quot; : 3,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 2\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;前\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 4,\n    \u0026quot;end_offset\u0026quot; : 5,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 3\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;trw-gdb7891at\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 9,\n    \u0026quot;end_offset\u0026quot; : 22,\n    \u0026quot;type\u0026quot; : \u0026quot;LETTER\u0026quot;,\n    \u0026quot;position\u0026quot; : 4\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;刹车片\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 22,\n    \u0026quot;end_offset\u0026quot; : 25,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 5\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;自带\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 25,\n    \u0026quot;end_offset\u0026quot; : 27,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 6\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;报警\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 27,\n    \u0026quot;end_offset\u0026quot; : 29,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 7\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;线\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 29,\n    \u0026quot;end_offset\u0026quot; : 30,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 8\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;无\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 31,\n    \u0026quot;end_offset\u0026quot; : 32,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 9\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;单独\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 32,\n    \u0026quot;end_offset\u0026quot; : 34,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 10\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;报警\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 34,\n    \u0026quot;end_offset\u0026quot; : 36,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 11\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;线\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 36,\n    \u0026quot;end_offset\u0026quot; : 37,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 12\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;号码\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 37,\n    \u0026quot;end_offset\u0026quot; : 39,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 13\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;卡\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 40,\n    \u0026quot;end_offset\u0026quot; : 41,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 14\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;仕\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 41,\n    \u0026quot;end_offset\u0026quot; : 42,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 15\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;欧\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 42,\n    \u0026quot;end_offset\u0026quot; : 43,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 16\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;卡\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 44,\n    \u0026quot;end_offset\u0026quot; : 45,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_CHAR\u0026quot;,\n    \u0026quot;position\u0026quot; : 17\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;仕\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 45,\n    \u0026quot;end_offset\u0026quot; : 46,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 18\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;欧\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 46,\n    \u0026quot;end_offset\u0026quot; : 47,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 19\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;乘用车\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 48,\n    \u0026quot;end_offset\u0026quot; : 51,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 20\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;刹车片\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 52,\n    \u0026quot;end_offset\u0026quot; : 55,\n    \u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\n    \u0026quot;position\u0026quot; : 21\n  } ]\n}[/code]\n[size=18][b]2. 关键词查询[/b][/size][code]localhost:9200//yigo-redist.1/_analyze?analyzer=default_search\u0026amp;text=gdb7891[/code]\n[list]\n[*]    索引为`yigo-redist.1`[/*]\n[*]    使用了索引`yigo-redist.1`中的分词器(`analyzer`) `default_search`[/*]\n[*]    解析的字符串(`text`)为\u0026quot;gdb7891\u0026quot;[/*]\n[/list]\n返回结果：[code]{\n  \u0026quot;tokens\u0026quot; : [ {\n    \u0026quot;token\u0026quot; : \u0026quot;gdb7891\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;LETTER\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  } ]\n}[/code]\n[size=18][b]3. 关键词使用存储的分词器查询[/b][/size][code]localhost:9200//yigo-redist.1/_analyze?analyzer=default\u0026amp;text=gdb7891[/code]\n[list]\n[*]    索引为`yigo-redist.1`[/*]\n[*]    使用了索引`yigo-redist.1`中的分词器(`analyzer`) `default_search`[/*]\n[*]    解析的字符串(`text`)为\u0026quot;gdb7891\u0026quot;[/*]\n[/list]\n返回结果：[code]{\n  \u0026quot;tokens\u0026quot; : [ {\n    \u0026quot;token\u0026quot; : \u0026quot;gdb7891\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;LETTER\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;LETTER\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;gdb7891\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;LETTER\u0026quot;,\n    \u0026quot;position\u0026quot; : 1\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 3,\n    \u0026quot;type\u0026quot; : \u0026quot;ENGLISH\u0026quot;,\n    \u0026quot;position\u0026quot; : 2\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;gdb\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 3,\n    \u0026quot;type\u0026quot; : \u0026quot;ENGLISH\u0026quot;,\n    \u0026quot;position\u0026quot; : 2\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;gdb\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 0,\n    \u0026quot;end_offset\u0026quot; : 3,\n    \u0026quot;type\u0026quot; : \u0026quot;ENGLISH\u0026quot;,\n    \u0026quot;position\u0026quot; : 2\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;7891\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 3,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;ARABIC\u0026quot;,\n    \u0026quot;position\u0026quot; : 3\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;7891\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 3,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;ARABIC\u0026quot;,\n    \u0026quot;position\u0026quot; : 3\n  }, {\n    \u0026quot;token\u0026quot; : \u0026quot;\u0026quot;,\n    \u0026quot;start_offset\u0026quot; : 3,\n    \u0026quot;end_offset\u0026quot; : 7,\n    \u0026quot;type\u0026quot; : \u0026quot;ARABIC\u0026quot;,\n    \u0026quot;position\u0026quot; : 3\n  } ]\n}[/code]\n[b][size=18]总结[/size][/b]\n[list]\n[*]    通过步骤1可以看出,存储的数据\u0026quot;全能片(前)---TRW-GDB7891AT刹车片自带报警线，无单独报警线号码,卡仕欧,卡仕欧,乘用车,刹车片\u0026quot;,被拆分成了很多词组碎片,然后存储在了索引数据中[/*]\n[*]    通过步骤2可以看出,当关键词输入\u0026quot;gdb7891\u0026quot;,这个在检索分词器(`default_search`)下,没有拆分,只一个可供查询的碎片就是\u0026quot;gdb7891\u0026quot;,但是步骤1,拆分的碎片里不存在\u0026quot;gb7891\u0026quot;的词组碎片,唯一相近的就是\u0026quot;trw-gdb7891at\u0026quot;,所以使用普通的match-query是无法匹配步骤1输入的索引数据[/*]\n[*]    通过步骤3,可以看出如果使用相同的分词器,\u0026quot;gdb7891\u0026quot;能够拆分成\u0026quot;gdb\u0026quot;,\u0026quot;7891\u0026quot;等等,通过这2个碎片都能找到步骤1输入的索引数据,但是因为关键词被拆分了,所以会查询到更多的匹配的数据,比如:与\u0026quot;gdb\u0026quot;匹配的,与\u0026quot;7891\u0026quot;匹配的,与\u0026quot;gdb7891\u0026quot;匹配的[/*]\n[*]    如果说想通过分词器(`default_search`)检索出步骤1的数据,需要使用wildcard-query,使用\u0026quot;*gdb7891*\u0026quot;,就可以匹配[code]  {\n      \u0026quot;query\u0026quot;: {\n          \u0026quot;wildcard\u0026quot; : { \u0026quot;description\u0026quot; : \u0026quot;*gdb7891*\u0026quot; }\n      }\n  }[/code][/*]\n[/list]\n\n  ","title":"elasticsearch分词检索的match-query匹配过程分析","uid":"5030","views":"1162","votes":"0"},"_type":"doc"}
{"_id":"535","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521078168","category_id":"18","comments":"0","has_attach":"0","id":"535","message":"1. 使用elasticsearch提高hbase基于列的查询效率。\n[http://t.cn/Rn73PTv](http://t.cn/Rn73PTv) \n\n2. Spark Streaming + Elasticsearch构建App异常监控平台。\n[http://t.cn/RNb9Qcn](http://t.cn/RNb9Qcn) \n\n3. 开放分布式追踪（OpenTracing）入门与 Jaeger 实现。\n[http://t.cn/RE8ZEyW](http://t.cn/RE8ZEyW) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/535 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第211期 (2018-03-15)","uid":"668","views":"601","votes":"0"},"_type":"doc"}
{"_id":"555","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522543937","category_id":"18","comments":"0","has_attach":"0","id":"555","message":"1.使用ELK跟踪Bitcoin和Cryptocurrency。\nhttp://t.cn/Rn15a5J\n2.(自备梯子)让机器获取你关心的东西。 查看Elasticsearch X-Pack ML API。\nhttp://t.cn/Rn14XUA\n3.(自备梯子)为什么所有关于Cambridge Analytica “黑客攻击”Facebook的报道都是错误的。\nhttp://t.cn/Rn1qja3\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/555\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第228期 (2018-04-01)","uid":"4460","views":"295","votes":"0"},"_type":"doc"}
{"_id":"559","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522808862","category_id":"18","comments":"0","has_attach":"0","id":"559","message":"1. 你有算过在云平台上搭建 Elastic Stack 的成本吗？不妨借鉴下这篇文章的计算思路\nhttp://t.cn/Rm7r18S\n2. 如果你要在 kibana 中显示 object 类型数据时遇到问题了，不妨试试这个插件\nhttps://github.com/istresearch/kibana-object-format\n3. Elastic{ON} 大会上的 Canvas 技术作品展示细节大曝光！\nhttp://t.cn/Rm7dILR\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/559\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第231期 (2018-04-04)","uid":"86","views":"330","votes":"0"},"_type":"doc"}
{"_id":"571","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523525523","category_id":"2","comments":"0","has_attach":"0","id":"571","message":"[url]https://jinleileiking.github.io/post/es6/[/url]\n \n希望 wood 大佬能点评一下 @kennywu76","title":"终于把2升到6了，分享一下","uid":"1573","views":"375","votes":"1"},"_type":"doc"}
{"_id":"572","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523572521","category_id":"18","comments":"0","has_attach":"0","id":"572","message":"1、活久见 | 手机上查询Elasticsearch集群状态\nhttp://t.cn/RmoY9w1\n2、Elasticsearch高CPU消耗原因探究\nhttp://t.cn/RmoYNPZ\n3、Elasticsearch 写入速度优化到极限\nhttp://t.cn/RWs8yvS\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/572\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第240期 (2018-04-13)","uid":"1341","views":"368","votes":"0"},"_type":"doc"}
{"_id":"575","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523667389","category_id":"18","comments":"0","has_attach":"0","id":"575","message":"1. 使用ELK和AspectJ监控Spring应用(需翻墙)\n[http://t.cn/RmCeqvP](http://t.cn/RmCeqvP) \n\n2. 视频：手把手教你在AWS平台部署基于容器的ES(需翻墙）\n[http://t.cn/RmCkJze](http://t.cn/RmCkJze) \n\n3. ES使用机器学习优化排序的插件。\n[ http://t.cn/RJu5cw5]( http://t.cn/RJu5cw5) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/575 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第241期 (2018-04-14)","uid":"1874","views":"384","votes":"0"},"_type":"doc"}
{"_id":"582","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524140036","category_id":"12","comments":"0","has_attach":"0","id":"582","message":"##职位描述\n1. 构建基于ElasticSearch（ES）的实时数据分析平台；\n1. 负责个性化搜索、个性化推荐系统的架构和服务；\n\n\n##岗位要求\n1. 熟悉Java开发，包括常用中间件：Dubbo、Zookeeper、MySQL、Redis、MongoDB等；\n2. 熟悉ElasticSearch(ES)/Solr/Lucence原理；\n3. 有ElasticSearch(ES)/Solr/Lucence 工程应用经验丰富；\n4. 有搜索相关功能性能调优优先；\n\n##工作地址\n杭州 - 西湖区 - 文一西路崇义路口公元里13幢2楼\n\n##联系我\n* 官网：http://www.idongjia.cn/\n* zhouxiangjun@idongjia.cn","title":"【东家·守艺人】ElasticSearch (ELK) 资深开发工程师（杭州）","uid":"8333","views":"961","votes":"0"},"_type":"doc"}
{"_id":"588","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524462258","category_id":"2","comments":"2","has_attach":"0","id":"588","message":"https://forum.huaweicloud.com/thread-8391-1-1.html\n\n不想看介绍的可以直接点击链接，免费在线使用  \nhttp://fe2e6fd859034d40a3269f7b541e31de.apigw.cn-north-1.huaweicloud.com/\n ","title":"看到一个词语提取小工具，分享给有标签、词库需求的TX们","uid":"8279","views":"522","votes":"0"},"_type":"doc"}
{"_id":"591","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524612384","category_id":"5","comments":"6","has_attach":"0","id":"591","message":"几个小时前, Elastic 商业插件 X-Pack 的源代码已正式 Merge 进 Master，作为一家开源软件公司，能够将商业部分的代码也公开，实在是需要很大的勇气（我深感自豪），这一切都是为了更好的打造一个更加好用的产品：Elastic Stack，只有开放才能走的更远！\n\n想了解更多关于 X-Pack 代码公开背后的介绍，可以看 Elastic 创始人 Shay 的这篇博客：[https://elasticsearch.cn/article/513](https://elasticsearch.cn/article/513)\n\n相关代码已在 github 上面可以找到：\n\n[Elasticsearch](https://github.com/elastic/elasticsearch/tree/master/x-pack)\n\n[Kibana](https://github.com/elastic/kibana/tree/master/x-pack)\n\n[Logstash](https://github.com/elastic/logstash/tree/master/x-pack)\n\n[Beats](https://github.com/elastic/beats/tree/master/x-pack)\n\n有关问题可以在此回复，我会一一解答。","title":"X-Pack 代码已公开并上线","uid":"1","views":"3555","votes":"9"},"_type":"doc"}
{"_id":"595","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524889033","category_id":"18","comments":"0","has_attach":"0","id":"595","message":"1、在docker上搭建Elasticsearch全文索引应用\nhttp://t.cn/REh0ucW\n2、Elasticsearch写入优化\nhttp://t.cn/Ruazvzt\n3、关于分词器的各个方面\nhttp://t.cn/Rua7iMu \n\n编辑：wt\n归档：https://elasticsearch.cn/article/595\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第255期 (2018-04-28)","uid":"3851","views":"400","votes":"0"},"_type":"doc"}
{"_id":"610","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525924245","category_id":"18","comments":"0","has_attach":"0","id":"610","message":"1. Elasticsearch 在高盛的使用(需翻墙)。\n[http://t.cn/R3wBRIZ](http://t.cn/R3wBRIZ) \n\n2. Elasticsearch IngestNode 与 Logstash 性能对比。\n[http://t.cn/R3wBuwd](http://t.cn/R3wBuwd) \n\n3. ElasticSearch 6.x 配置IK 扩展字典及同义词配置。\n[http://t.cn/R3wB1cO](http://t.cn/R3wB1cO) \n[http://t.cn/R3wBrT2](http://t.cn/R3wBrT2) \n\n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/610\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第267期 (2018-05-10)","uid":"668","views":"372","votes":"0"},"_type":"doc"}
{"_id":"681","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529799357","category_id":"18","comments":"0","has_attach":"0","id":"681","message":"1.为SIEM使用ELK Stack。\nhttp://t.cn/RrGFxIr\n2.5大商业SIEM工具。\nhttp://t.cn/RrGFBEa\n3.(自备梯子)作为数据科学家不被聘用的4种错误方法？\n[url]http://t.cn/RrGDSGi[/url] \n \n活动预告：\n1.6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647 \n2.7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655 \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/681\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第312期 (2018-06-24)","uid":"4460","views":"278","votes":"0"},"_type":"doc"}
{"_id":"672","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529112691","category_id":"18","comments":"0","has_attach":"0","id":"672","message":"1、Logstash  更高效的Java 执行引擎可以来测试了\nhttp://t.cn/RBOaaNs\n2、elastic common schema: elastic 数据建模的一些最佳实践，不妨来参考\nhttp://t.cn/RBOaW8e\n3、Logstash Webinar:入门者不要错过哦，快来注册下\nhttp://t.cn/RBOaHAH\n\n活动预告\n \n1. 6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647\n2. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/672\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第304期 (2018-06-16)","uid":"86","views":"282","votes":"0"},"_type":"doc"}
{"_id":"617","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526090013","category_id":"18","comments":"0","has_attach":"0","id":"617","message":"1. es可用插件整理及分析\npart1:[http://t.cn/R35Zpuk](http://t.cn/R35Zpuk) \npart2:[http://t.cn/R35Z8L2](http://t.cn/R35Z8L2)\n\n2. ES工程师使用Elastic Stack记录弟弟的旅行轨迹\n[http://t.cn/R35zHsz](http://t.cn/R35zHsz) \n\n3. 一周热点：技术人最重要的能力是什么？\n[http://t.cn/RuglePq](http://t.cn/RuglePq) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/{}\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第269期 (2018-05-12)","uid":"1874","views":"422","votes":"0"},"_type":"doc"}
{"_id":"618","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526165297","category_id":"18","comments":"0","has_attach":"0","id":"618","message":"1.(自备梯子)Elasticsearch中，如何改变index的名字。\nhttp://t.cn/R3c2zwj\n2.(自备梯子)如何在5天内，同一个Elasticsearch集群中，对360亿份文档重建索引。\nhttp://t.cn/R3cyakP\n3.Duplex通过了图灵测试。\nhttp://t.cn/R3Aj4ij\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/618\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第270期 (2018-05-13)","uid":"4460","views":"352","votes":"0"},"_type":"doc"}
{"_id":"630","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526865872","category_id":"18","comments":"0","has_attach":"0","id":"630","message":"1.如何在linux上离线安装es TLS配置。\nhttp://t.cn/R3EorzN\n\n2.谈谈ES 的Recovery。\nhttps://elasticsearch.cn/article/38\n\n3.如何让es集群崩溃？学会好了这些你就可以避免集群崩溃了\n[url]http://t.cn/RQxkfQH[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/630\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第278期 (2018-05-21)","uid":"4063","views":"310","votes":"0"},"_type":"doc"}
{"_id":"449","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515568819","category_id":"16","comments":"9","has_attach":"1","id":"449","message":"## 活动介绍\n\n本期邀请了几位ES大咖做主题分享，并以Demo show和Workshop的形式介绍Elastisearch及其相关组件在搜索、日志分析和监控领域的应用，帮助用户更好的理解Elastisearch及其相关组件，在更多的搜索和分析场景中应用。Workshop环节请务必携带个人电脑参加。\n\n## 活动安排\n##### 时间：2018年1月20日周六 13：30-17：00\n##### 地点：北京市海淀区中关村大街46号院-众海加速器（阿里巴巴创新中心）\n\n## 活动主题\n* 13:30—14:00 签到\n* 14:00—14:30 主题分享《Elasticsearch在智能运维领域的应用》 Elastic布道师 曾勇\n* 14:30—14:40 Q\u0026amp;A\n* 14:40—15:10 Demo show《使用X-Pack和Kibana实现Elasticsearch 的监控与报警》 阿里云技术专家 李靖威\n* 15:10—15:20 Q\u0026amp;A\n* 15:20—15:50 Workshop《基于阿里云Elasticsearch构建网站日志处理系统》 阿里云产品专家 洪阳\n* 15:50—16:00 Q\u0026amp;A\n* 16:00—16:30 主题分享《ELK在运维工作中应用两三事》 上海安畅运维专家 韩军辉\n* 16:30—17:00 现场快闪分享\n* 17:00—17:30 现场专家一对一交流\n\n##报名通道\n活动报名通道：\n\nhttps://yq.aliyun.com/event/193/join\n\n可提前报名现场快闪分享(5分钟/位），讲讲自己的ELK实践心得，报名链接：\n\nhttps://survey.aliyun.com/survey/kMXx0zCfB\n\n也可使用钉钉扫描，加入Elasticsearch技术交流群：\n\n\u0026lt;p style=\u0026quot;text-align:center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://img.alicdn.com/tfs/TB1v57PjOqAXuNjy1XdXXaYcVXa-100-100.jpg\u0026quot; width = \u0026quot;100\u0026quot; height = \u0026quot;100\u0026quot; alt=\u0026quot;QR\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;\n\n##嘉宾介绍\n##### 曾勇 Elastic布道师\n\nElastic开发工程师与布道师，在分布式搜索、高性能、高可用架构、自动化运维等方面积累了超过七年的经验。曾勇是Elasticsearch国内首批用户，自2010年起就开始接触Elasticsearch并投入到生产环境中使用，并编写过一系列的中文处理相关的插件。\n\n演讲主题：《Elasticsearch在智能运维领域的应用》\n\n分享Elasticsearch和X-Pack组件在智能运维领域的技术原理和应用实践，如非监督型机器学习在自动的异常检测、高级关联和分类、根源问题诊断、早期故障预测等方面的应用等。\n\n##### 李靖威 阿里云技术专家\n\n全栈程序员，精通前后端，在Web微服务系统架构上有深入研究。3年搜索产品相关经验，现负责阿里云Elasticsearch的产品业务部分的开发。\n\n演讲主题：《使用X-Pack和Kibana实现Elasticsearch 的监控与报警》\n\n以开源 Elasticsearch、阿里云 Elasticsearch和X-Pack的Demo show的形式， 对 Elasticsearch 集群监控和报警的内部原理进行讲解和使用方法演示。 \n\n##### 洪阳 阿里云产品专家\n阿里云搜索产品经理，从事多年大数据及搜索相关产品工作，在离线数据加工、离线调度系统、在线搜索等场景深入研究，对大数据和搜索相关产品有丰富的经验。\n\n演讲主题：《基于阿里云Elasticsearch构建网站日志处理系统》\n\n基于阿里云的Elasticsearch，离线数仓加工工具，数据同步工具等一些列产品来快速构建一个日志处理系统，从离线数据加工到在线数据搜索和分析展现诠释数据加工在阿里云产品上如何快速展开。\n\n##### 韩军辉 上海安畅运维专家\n上海安畅网络运维主管，热衷于开源技术的学习和深入研究，从事多年的ELK运维相关工作，对ELK Stack有深入研究，对ELK相关运维有丰富的经验。\n\n演讲主题：《ELK在运维工作中应用两三事》\n\n基于ELK Stack、sflow技术、sflowtool工具、kafka消息队列等开源技术构建一套流量分析、DDOS告警系统。从流量收集、分析、存储、展现、告警一套流程来诠释ELK在流量分析中的应用。\n\n\n\n\n\n\n","title":"【阿里云 Meetup】如何使用Elasticsearch进行智能运维 ","uid":"6977","views":"1655","votes":"3"},"_type":"doc"}
{"_id":"450","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515573287","category_id":"2","comments":"0","has_attach":"0","id":"450","message":"能有影响elasticsearch  score的方法有很多，官方推荐的是使用内置的painless脚本语言结合function_score来重新定义score。由于本人开发的项目其算法是由java语言开发的，于是决定尝试原生脚本开发。\nelasticsearch脚本由plugin-descriptor.properties文件以及运行jar包组成，plugin-descriptor.properties主要用来定义版本信息、对应es的版本信息等属性。\n\n官方的例子\n\n```\npublic class ExpertScriptPlugin extends Plugin implements ScriptPlugin {\n    @Override\n    public ScriptEngineService getScriptEngineService(Settings settings) {\n        return new MyExpertScriptEngine();\n    }\n    /** An example {@link ScriptEngineService} that uses Lucene segment details to implement pure document frequency scoring. */\n    // tag::expert_engine\n    private static class MyExpertScriptEngine implements ScriptEngineService {\n        @Override\n        public String getType() {\n            return \u0026quot;expert_scripts\u0026quot;;\n        }\n        @Override\n        public Function\u0026lt;Map\u0026lt;String,Object\u0026gt;,SearchScript\u0026gt; compile(String scriptName, String scriptSource, Map\u0026lt;String, String\u0026gt; params) {\n            // we use the script \u0026quot;source\u0026quot; as the script identifier\n            if (\u0026quot;pure_df\u0026quot;.equals(scriptSource)) {\n                return p -\u0026gt; new SearchScript() {\n                    final String field;\n                    final String term;\n                    {\n                        if (p.containsKey(\u0026quot;field\u0026quot;) == false) {\n                            throw new IllegalArgumentException(\u0026quot;Missing parameter [field]\u0026quot;);\n                        }\n                        if (p.containsKey(\u0026quot;term\u0026quot;) == false) {\n                            throw new IllegalArgumentException(\u0026quot;Missing parameter [term]\u0026quot;);\n                        }\n                        field = p.get(\u0026quot;field\u0026quot;).toString();\n                        term = p.get(\u0026quot;term\u0026quot;).toString();\n                    }\n                    @Override\n                    public LeafSearchScript getLeafSearchScript(LeafReaderContext context) throws IOException {\n                        PostingsEnum postings = context.reader().postings(new Term(field, term));\n                        if (postings == null) {\n                            // the field and/or term don't exist in this segment, so always return 0\n                            return () -\u0026gt; 0.0d;\n                        }\n                        return new LeafSearchScript() {\n                            int currentDocid = -1;\n                            @Override\n                            public void setDocument(int docid) {\n                                // advance has undefined behavior calling with a docid \u0026lt;= its current docid\n                                if (postings.docID() \u0026lt; docid) {\n                                    try {\n                                        postings.advance(docid);\n                                    } catch (IOException e) {\n                                        throw new UncheckedIOException(e);\n                                    }\n                                }\n                                currentDocid = docid;\n                            }\n                            @Override\n                            public double runAsDouble() {\n                                if (postings.docID() != currentDocid) {\n                                    // advance moved past the current doc, so this doc has no occurrences of the term\n                                    return 0.0d;\n                                }\n                                try {\n                                    return postings.freq();\n                                } catch (IOException e) {\n                                    throw new UncheckedIOException(e);\n                                }\n                            }\n                        };\n                    }\n                    @Override\n                    public boolean needsScores() {\n                        return false;\n                    }\n                };\n            }\n            throw new IllegalArgumentException(\u0026quot;Unknown script name \u0026quot; + scriptSource);\n        }\n\n        @Override\n        @SuppressWarnings(\u0026quot;unchecked\u0026quot;)\n        public SearchScript search(CompiledScript compiledScript, SearchLookup lookup, @Nullable Map\u0026lt;String, Object\u0026gt; params) {\n          Function\u0026lt;Map\u0026lt;String,Object\u0026gt;,SearchScript\u0026gt; scriptFactory = (Function\u0026lt;Map\u0026lt;String,Object\u0026gt;,SearchScript\u0026gt;) compiledScript.compiled();\n          return scriptFactory.apply(params);\n        }\n\n        @Override\n        public ExecutableScript executable(CompiledScript compiledScript, @Nullable Map\u0026lt;String, Object\u0026gt; params) {\n            throw new UnsupportedOperationException();\n        }\n\n        @Override\n        public boolean isInlineScriptEnabled() {\n            return true;\n        }\n\n        @Override\n        public void close() {}\n    }\n}\n```\n\n代码解读：\n本例在elasticsearch源码中，https://github.com/elastic/elasticsearch/tree/master/plugins/examples/script-expert-scoring\n\nMyExpertScriptEngine类是其中最重要的类，用于实现脚本参数定义，编译，以及打分机制的实现。其中compile方法返回我们定义好打分逻辑的java function。search方法用于我们在搜索过程中实施定义好的打分逻辑。\n怎奈笔者对于函数式编程知道的不多（后续需要补课），其实评分逻辑也可以在search方法中实现，于是有了下面的一段代码。\n\n```\npublic class fieldaddScriptPlugin extends Plugin implements ScriptPlugin {\n    @Override\n    public ScriptEngineService getScriptEngineService(Settings settings) {\n        return new MyExpertScriptEngine();\n    }\n    private static class MyExpertScriptEngine implements ScriptEngineService {\n        @Override\n        public String getType() {\n            return \u0026quot;expert_scripts\u0026quot;;\n        }\n\n        @Override\n        public Object compile(String scriptName, String scriptSource, Map\u0026lt;String, String\u0026gt; params) {\n            if (\u0026quot;example_add\u0026quot;.equals(scriptSource)) {\n                return scriptSource;\n            }\n            throw new IllegalArgumentException(\u0026quot;Unknown script name \u0026quot; + scriptSource);\n        }\n\n        @Override\n        @SuppressWarnings(\u0026quot;unchecked\u0026quot;)\n        public SearchScript search(CompiledScript compiledScript, SearchLookup lookup, @Nullable Map\u0026lt;String, Object\u0026gt; vars) {\n\n            /**\n             * 校验输入参数，DSL中params 参数列表\n             */\n            final long inc;\n            final String fieldname;\n            if (vars == null || vars.containsKey(\u0026quot;inc\u0026quot;) == false) {\n                inc = 0;\n            } else {\n                inc = ((Number) vars.get(\u0026quot;inc\u0026quot;)).longValue();\n            }\n\n            if (vars == null || vars.containsKey(\u0026quot;fieldname\u0026quot;) == false) {\n                throw new IllegalArgumentException(\u0026quot;Missing parameter [fieldname]\u0026quot;);\n            } else {\n                fieldname = (String) vars.get(\u0026quot;fieldname\u0026quot;);\n            }\n\n            return new SearchScript() {\n                @Override\n                public LeafSearchScript getLeafSearchScript(LeafReaderContext context) throws IOException {\n                    final LeafSearchLookup leafLookup = lookup.getLeafSearchLookup(context);\n\n\n                    return new LeafSearchScript() {\n                        @Override\n                        public void setDocument(int doc) {\n                            if (leafLookup != null) {\n                                leafLookup.setDocument(doc);\n                            }\n                        }\n\n                        @Override\n                        public double runAsDouble() {\n                            long values = 0;\n                            /**\n                             * 获取document中字段内容\n                             */\n                            for (Object v : (List\u0026lt;?\u0026gt;) leafLookup.doc().get(fieldname)) {\n                                values = ((Number) v).longValue() + values;\n                            }\n                            return values + inc;\n                        }\n                    };\n                }\n\n                @Override\n                public boolean needsScores() {\n                    return false;\n                }\n            };\n        }\n```\n\n         这段代码的逻辑是把给定的字段(字段类型long)的每个元素相加后再加上给定的增量参数最后形成score分值。为了实现上述逻辑需要实现参数获取、根据给定的字段名获取内容列表量的关键件。下面结合代码说说这两个步骤如何实现的。\nsearch方法中Map\u0026lt;String, Object\u0026gt; vars参数对应DSL中\u0026quot;params\u0026quot;参数，用于接受实际给定的运行时参数。SearchLookup lookup参数由系统传入，通过lookup.getLeafSearchLookup(context)获取LeafSearchLookup通过该对象可以获取给定字段的值。\n\n对于elasticsearch 2.x以前的版本可以通过NativeScriptFactory实现原生脚本。\n\n```\npublic class MyNativeScriptPlugin extends Plugin implements ScriptPlugin {\n    private final static Logger LOGGER = LogManager.getLogger(MyFirstPlugin.class);\n\n\n    public MyNativeScriptPlugin() {\n        super();\n        LOGGER.warn(\u0026quot;This is MyNativeScriptPlugin\u0026quot;);\n    }\n    \n    @Override\n    public List\u0026lt;NativeScriptFactory\u0026gt; getNativeScripts() {\n        return Collections.singletonList(new MyNativeScriptFactory());\n    }\n\n\n    public static class MyNativeScriptFactory implements NativeScriptFactory {\n        @Override\n        public ExecutableScript newScript(@Nullable Map\u0026lt;String, Object\u0026gt; params) {\n\n\n//            return new MyNativeScript();\n            return new AbstractDoubleSearchScript(){\n\n\n                @Override\n                public double runAsDouble() {\n                    int b=0;\n                    if(params.get(\u0026quot;add\u0026quot;)!=null){\n                        b= (int) params.get(\u0026quot;add\u0026quot;);\n                    }\n\n\n                    String s =  source().get(\u0026quot;last\u0026quot;).toString();\n                    double a = s.length()+b;\n                    return a;                }\n            };\n        }\n\n\n        @Override\n        public boolean needsScores() {\n            return false;\n        }\n\n\n        @Override\n        public String getName() {\n            return \u0026quot;my_script\u0026quot;;\n        }\n    }\n}\n```\n\n工程组织\nelasticsearch工程使用gradle进行依赖管理和生命周期管理，为此es项目自己也开发了esplugin的gradle插件，但不兼容gradle4.2以上的版本。参考github中的成熟插件，使用maven组织工程。\n\n主要涉及两个文件\npom.xml\nplugin.xml\n工程利用maven-assembly-plugin打包jar。\n\n本例github地址：https://github.com/jiashiwen/elasticsearchpluginsample\n欢迎点赞或拍砖","title":"elasticsearch java原生打分插件开发","uid":"6713","views":"2779","votes":"3"},"_type":"doc"}
{"_id":"452","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515711755","category_id":"18","comments":"0","has_attach":"0","id":"452","message":"1、 Elasticsearch java原生打分插件开发\nhttps://elasticsearch.cn/article/450\n2、Elasticsearch query 解析器（梯子）\nhttp://t.cn/RQLzKJo\n3、图解Elasticsearch基础属性\nhttp://t.cn/RQLhVzS\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/452\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第156期 (2018-01-12)","uid":"1341","views":"360","votes":"0"},"_type":"doc"}
{"_id":"460","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516315472","category_id":"18","comments":"0","has_attach":"0","id":"460","message":"1、ElasticSearch集群迁移和升级总结 \nhttp://t.cn/RQoQv2k\n2、年后跳一跳|ES面试基础知识要点\nhttp://t.cn/RQoHTLU\n3、ES实践总结\nhttp://t.cn/RHHczic\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/460\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第163期 (2018-01-19)","uid":"1341","views":"373","votes":"0"},"_type":"doc"}
{"_id":"458","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516160436","category_id":"18","comments":"0","has_attach":"0","id":"458","message":"1. Kafka 同步数据到 Elasticsearch\n[url]http://t.cn/RHfAzdh[/url] \n2. 5种 Logstash 替代者对比\n[url]http://t.cn/RQiwTSZ[/url] \n3. Elasticsearch Tutorial \u0026amp; Getting Started（YouTuBe）\n[url]http://t.cn/RQiZ8jc[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/458[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第161期 (2018-01-17)","uid":"3828","views":"293","votes":"0"},"_type":"doc"}
{"_id":"468","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516770855","category_id":"18","comments":"0","has_attach":"0","id":"468","message":"1. Elasticsearch 性能监控（一）\n[url]http://t.cn/RQncDxy[/url] \n2. AIOps 时代下的利器：ELK\n[url]http://t.cn/RQnVo4r[/url] \n3. Elasticsearch 使用 optimize 强制合并 segment 测试\n[url]http://t.cn/RQnfz71[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/468[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第168期 (2018-01-24)","uid":"3828","views":"290","votes":"0"},"_type":"doc"}
{"_id":"469","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516844221","category_id":"18","comments":"0","has_attach":"0","id":"469","message":"1. 如何运行一个elasticsearch集群。\n[https://elasticsearch.cn/article/465](https://elasticsearch.cn/article/465) \n\n2. Elasticsearch自定义过滤插件实现复杂逻辑过滤。\n[http://t.cn/RQ10N3J](http://t.cn/RQ10N3J) \n\n3. Elasticsearch refresh 和flush 操作指南。\n[http://t.cn/RQ10Ttw](http://t.cn/RQ10Ttw) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/469\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第169期 (2018-01-25)","uid":"668","views":"334","votes":"0"},"_type":"doc"}
{"_id":"470","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516888075","category_id":"11","comments":"1","has_attach":"1","id":"470","message":"## 序\n\n本文为系列文章第一篇，主要介绍如何把 Elastic 中文社区的网站服务器监控起来，对有同样想了解如何使用 Elastic Stack 来做运维监控的同学，可以作为一个很好的参考和入门资料，学习门槛定义为入门级。\n\n首先，我们要监控的网站，也就是大家现在正在访问的 Elastic 官方中文社区，网址：[elasticsearch.cn](https://elasticsearch.cn/)，这个网站基于开源的 [WeCenter](https://github.com/wecenter/wecenter/) 搭建，开发语言是 PHP，后端数据库是 MySQL，目前只有一台服务器，由 [ConvertLab](http://convertlab.com/) 友情无偿赞助，大写的赞！再次感谢！\n\n服务器部署环境是 Ubuntu 16.04.2，部署了以下服务及软件：\n\n* Nginx - Http 反向代理，不要介绍了吧\n* PHP-FPM - 一个常用的 PHP FastCGI 管理\n* Elasticsearch - Elasticsearch 服务，用于社区的垂直搜索服务 [Elastic  情报局](https://index.elasticsearch.cn)  服务\n* GOPA - 可以说是为社区而写的，一个轻量级的爬虫，用于爬取 Elatic 周边相关相关资料，创建索引存放到 Elasticsearch 里面，提供垂直搜索服务，[代码地址](https://github.com/infinitbyte/gopa)\n* Grok Debugger -  一个 Java 的 Grok pattern 调试服务，方便大家调试 Grok 日志解析规则，访问地址：[grok.elasticsearch.cn](http://grok.elasticsearch.cn/)\n\n服务器上所有的财产就这些了，一个平淡无奇的网站，基本上所有的东西都能公开访问到，这个网站的目的就是为所有 Elastic 爱好者服务的，供大家交流和沟通的专属平台，所以请各位黑客大侠不要再扫描和攻击啦，画一个简单的拓扑图如下所示：\n\n[attach]1598[/attach]\n\n作为一个合格的网管，除了重启服务器之外，还必须要保证网站的正常运行，所以了解网站的运行情况就变成了一个需要解决的首要问题，我们可以先把任务具体列一下：\n\n* 网站是否正常访问，各项服务有没有挂\n* 网站访问情况如何，用户访问速度如何\n* 网站访客统计分析，访客相关数据分析\n* 服务器的各项指标，详细指标监控分析\n* 服务器的各项服务，日志集中分析处理\n* 服务器是否很安全，有没有黑客来造访\n* 数据是否安全备份，有没有定期测试过\n\n实在编不下去了（话说对的还蛮齐），说人话就是监控起服务器的各项指标和收集服务的日志，然后出几个分析的 Dashboard，监控报警整起来。\n\n我们这次需要用到的工具主要就是 Elastic Stack 啦，Elastic Stack 包括 Elasticsearch、Logstash、Beats 和 Kibana，版本都用最新的 6.x，再结合我们实际的数据和实际的需求，在后面的文章里面，我会具体介绍它们是什么以及如何使用。\n\n今天先写到这里，明天写监控指标的收集，此系列文章暂且定为需要 100 期完成。（开个玩笑，哈哈）。\n","title":"Elastic 中文社区运维监控实战 (1) - 序","uid":"1","views":"1430","votes":"5"},"_type":"doc"}
{"_id":"478","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517477376","category_id":"2","comments":"1","has_attach":"0","id":"478","message":"索引相关\n[b]一、映射与分析[/b]\n[b]Elasticsearch 中的数据可以概括的分为两类：[/b]精确值和全文。\n为了促进在全文域中的匹配查询，Elasticsearch 首先 分析 文档，之后根据结果创建 倒排索引;\n\n[b]倒排索引：[/b]倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包\n括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来\n确定记录的位置，因而称为倒排索引(inverted index)。带有倒排索引的文件我们称为倒排索引文\n件,简称倒排文件(inverted file)。\n\n[b]分析器：[/b]字符过滤器\n首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。\n一个字符过滤器可以用来去掉HTML，或者将 \u0026amp; 转化成 `and`。\n\n[b]分词器:[/b]\n其次，字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时\n候，可能会将文本拆分成词条。\n\n[b]Token 过滤器:[/b]\n最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小\n写化 Quick ），删除词条（例如， 像 a`， `and`， `the 等无用词），或者增加\n词条（例如，像 jump 和 leap 这种同义词）\n当我们 索引 一个文档时使用分析器，它的全文域被分析成词条以用来创建倒排索引当你查询一个 全文 域时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。\n当你查询一个 精确值 域时，不会分析查询字符串， 而是搜索你指定的精确值。\n\n[b]elastic内置的分析器：[/b]standard,whitespace,simple,english\n\n[b]创建一个自定义分析器编辑：[/b]\nPUT /my_index\n{\n\u0026quot;settings\u0026quot;: {\n//配置自定义的分析器\n \u0026quot;analysis\u0026quot;: { \u0026quot;char_filter\u0026quot;: {\n                                           \u0026quot;\u0026amp;_to_and\u0026quot;: {\n                                                                \u0026quot;type\u0026quot;: \u0026quot;mapping\u0026quot;,\n                                                                \u0026quot;mappings\u0026quot;: [ \u0026quot;\u0026amp;=\u0026gt; and \u0026quot;]\n                                                               }\n                                         },\n                    \u0026quot;filter\u0026quot;: {\n                                    \u0026quot;my_stopwords\u0026quot;: {\n                                                                  \u0026quot;type\u0026quot;: \u0026quot;stop\u0026quot;,\n                                                                  \u0026quot;stopwords\u0026quot;: [ \u0026quot;the\u0026quot;, \u0026quot;a\u0026quot; ]\n                                                                 }\n                                 },\n \u0026quot;analyzer\u0026quot;: {\n//自定义的分析器\n\u0026quot;my_analyzer\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\n//字符过滤器\n\u0026quot;char_filter\u0026quot;: [ \u0026quot;html_strip\u0026quot;, \u0026quot;\u0026amp;_to_and\u0026quot; ],\n//分词器\n\u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\n//Token过滤器\n\u0026quot;filter\u0026quot;: [ \u0026quot;lowercase\u0026quot;, \u0026quot;my_stopwords\u0026quot; ] }}\n     }\n   }\n}\n\n[b]应用分析器：[/b]\nPUT /my_index/_mapping/my_type\n { \u0026quot;properties\u0026quot;: { \u0026quot;title\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;my_analyzer\u0026quot; } } }\n\n[b]映射：[/b]让elasticsearch知道索引的据类型\n[b]基本类型：[/b]\n字符串: string\n整数 : byte, short, integer, long\n浮点数: float, double\n布尔型: boolean\n日期: date\n\n[b]查看映射：[/b]GET /gb/_mapping/tweet\n     取得索引 gb 中类型 tweet 的映射\n\n域最重要的属性是 type 。对于不是 string 的域，你一般只需要设置 type；\nstring 域映射的两个最重要 属性是 index 和 analyzer\n[b]index:[/b]\nanalyzed\n首先分析字符串，然后索引它。换句话说，以全文索引这个域。\nnot_analyzed\n  索引这个域，所以它能够被搜索，但索引的是精确值。不会对它进行分析。\nno\n不索引这个域。这个域不会被搜索到\nanalyzer:指定在搜索和索引时使用的分析器,可以使用内置的分析器或者自定义的分析器\n\n[b]自定义映射:[/b]\nPUT /gb\n{ \u0026quot;mappings\u0026quot;: {\n                       \u0026quot;tweet\u0026quot; : {\n                                      \u0026quot;properties\u0026quot; : {\n                                                              \u0026quot;tweet\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;english\u0026quot; },\n                                                              \u0026quot;date\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot; },\n                                                              \u0026quot;name\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot; },\n                                                              \u0026quot;user_id\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;long\u0026quot; }\n                                                             }\n                                    }\n                     }\n }\n\n\n\n[b]二、索引别名和零宕机[/b]\nA.PUT /my_index_v1\nB.PUT /my_index_v1/_alias/my_index\nA创建索引，B建立别名\n修改索引字段时，可以新建索引，然后将就索引数据导入新建索引，将别名指向新建索引即可实现\n0宕机变更索引了\n\n参考官方文档:https://www.elastic.co/guide/cn/elasticsearch/guide/current/index-aliases.html#index-aliases\n\n\n\n\n ","title":"索引映射与分析整理","uid":"7681","views":"563","votes":"0"},"_type":"doc"}
{"_id":"491","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518129900","category_id":"18","comments":"0","has_attach":"0","id":"491","message":"1、上新 | 社区新增的PPT分享功能和100个PPT上传ok\nhttps://elasticsearch.cn/slides/\n2、Elasticsearch理性加速清单\nhttp://t.cn/RRv93KH\n3、Elasticsearch这5个错误，要避免！\n[url]http://t.cn/RRv9dw9[/url] \n \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/491\n订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第184期 (2018-02-09)","uid":"1341","views":"433","votes":"1"},"_type":"doc"}
{"_id":"486","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517895909","category_id":"2","comments":"1","has_attach":"1","id":"486","message":"本期邀请[b]阿里云MVP \u0026amp; Elastic中文社区发起人[/b][size=16][b]曾勇[/b][/size]进行专访！\n[size=16][b][url=http://click.aliyun.com/m/41775/]详细专访请戳这里[/url]或扫描下图中二维码查看[/b][/size]，谢谢！\n\n曾勇用专业传递技术能量，分享自身技术发展之路，从技术人转型到技术管理者的历程，创新的技术能量希望对你有所启发！\n[attach]1644[/attach]\n\n\n\n ","title":"【阿里云】专访阿里云 MVP \u0026amp; Elastic中文社区发起人 曾勇—— 做你想做的事情，培养解决问题的能力","uid":"7740","views":"623","votes":"3"},"_type":"doc"}
{"_id":"487","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517966741","category_id":"18","comments":"0","has_attach":"0","id":"487","message":"1. XPack6.1引入数据可视化和机器学习模块。\n[http://t.cn/R8utVL8](http://t.cn/R8utVL8) \n\n2. 从Elasticsearch来看分布式系统架构设计。\n[http://t.cn/R8utVLR](http://t.cn/R8utVLR) \n\n3. 通过Function Score Query优化Elasticsearch搜索结果。\n[http://t.cn/R6rrjOt](http://t.cn/R6rrjOt) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/487 \n\n* 订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第182期 (2018-02-07)","uid":"1874","views":"344","votes":"0"},"_type":"doc"}
{"_id":"499","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518393610","category_id":"18","comments":"0","has_attach":"0","id":"499","message":"1.Scrapy分布式爬虫打造搜索引擎系列。\n[url]http://t.cn/RR5w7uJ[/url] \n2.kibana-6建立可视化图表前的前期准备工作。\n[url]http://t.cn/RR5Z4du[/url] \n3.使用Curator管理Elasticsearch的索引。\n[url]http://t.cn/RR5Zxso[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/499[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第187期 (2018-02-12)","uid":"3788","views":"345","votes":"0"},"_type":"doc"}
{"_id":"526","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520643967","category_id":"18","comments":"0","has_attach":"0","id":"526","message":"1. 使用物联网设备,Node.js,ELK,MQTT追踪展示空气污染状况。\n[http://t.cn/RE3UL0w](http://t.cn/RE3UL0w) \n\n2. 新手营：ES中索引模板的运用。\n[http://t.cn/RE3V6Mk](http://t.cn/RE3V6Mk) \n\n3. 人是怎么废掉的？\n[http://t.cn/RE3VCCh](http://t.cn/RE3VCCh) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/526 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第206期 (2018-03-10)","uid":"1874","views":"508","votes":"0"},"_type":"doc"}
{"_id":"14","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449288793","category_id":"14","comments":"0","has_attach":"0","id":"14","message":"昨天我们通过 nested aggregation 计算出来，视频卡顿次数最多的是北京。不过这个结论似乎也没有什么奇怪的，北京的网民本身就多嘛。\n\nElasticsearch 还有一个有趣的聚合方式，叫 significant_terms。这时候就可以派上用场了！\n\n我们把昨天的 query JSON 中，最后一段 sub agg 改成这样：\n[code]    \u0026quot;city_terms\u0026quot; : {\n        \u0026quot;significant_terms\u0026quot; : {\n            \u0026quot;field\u0026quot; : \u0026quot;geoip.city\u0026quot;,\n            \u0026quot;size\u0026quot; : \u0026quot;4\u0026quot;\n        }\n    }[/code]重新运行请求，得到的响应结果是这样的：\n[code]\u0026quot;city_terms\u0026quot; : {\n  \u0026quot;doc_count\u0026quot; : 2521720,\n  \u0026quot;buckets\u0026quot; : [ {\n    \u0026quot;key\u0026quot; : \u0026quot;武汉\u0026quot;,\n    \u0026quot;doc_count\u0026quot; : 85980,\n    \u0026quot;score\u0026quot; : 0.1441705001066121,\n    \u0026quot;bg_count\u0026quot; : 15347191\n    }, {\n    \u0026quot;key\u0026quot; : \u0026quot;北京\u0026quot;,\n    \u0026quot;doc_count\u0026quot; : 142761,\n    \u0026quot;score\u0026quot; : 0.11808069152203737,\n    \u0026quot;bg_count\u0026quot; : 43176384\n    }, {\n    \u0026quot;key\u0026quot; : \u0026quot;广州\u0026quot;,\n    \u0026quot;doc_count\u0026quot; : 104677,\n    \u0026quot;score\u0026quot; : 0.10716870365361204,\n    \u0026quot;bg_count\u0026quot; : 27274482\n    }, {\n    \u0026quot;key\u0026quot; : \u0026quot;郑州\u0026quot;,\n    \u0026quot;doc_count\u0026quot; : 59234,\n    \u0026quot;score\u0026quot; : 0.09915501610550795,\n    \u0026quot;bg_count\u0026quot; : 10587590\n  } ]\n}[/code]大家一定发现了：第一名居然变成了武汉！\n\n而且每个结果后面，还多出来了 score 和 bg_count 两个数据。这个 bg_count 是怎么回事呢？\n\n这就是 significant_terms 的作用了。这个 agg 的大概计算步骤是这样：\n[list=1]\n[*]计算一个 term 在整个索引中的比例，作为背景计数(background)，这里是 15347191 / 2353406423；[/*]\n[*]计算一个 term 在 parent agg 中的比例，作为前景计数(foreground)，这里是 85980 / 2521720；[/*]\n[*]用 fgpercent 除以 bgpercent，得到这个 term 在 parent agg 的条件下比例凸显的可能性。[/*]\n[/list]\n\n由于两个作分母的总数其实大家都是相等的，其实比较的就是各 term 的 doc_count / bg_count 了。\n\n当然，实际的 score 不只是这么简单，还有其他综合因素。毕竟也不能给出来本身就没啥关注度的数据嘛。\n\n我们还可以来验证一下『武汉』的 bg_count 是不是这个意思：\n[code]curl -XPOST 'http://10.19.0.67:9200/logstash-mweibo-2015.12.02/_count?pretty' -d '{\n  \u0026quot;query\u0026quot; : {\n    \u0026quot;match\u0026quot; : {\n      \u0026quot;geoip.city\u0026quot; : \u0026quot;武汉\u0026quot;\n    }\n  }\n}'\n[/code]结果如下：\n[code]{\n  \u0026quot;count\u0026quot; : 15347191,\n  \u0026quot;_shards\u0026quot; : {\n    \u0026quot;total\u0026quot; : 100,\n    \u0026quot;successful\u0026quot; : 100,\n    \u0026quot;failed\u0026quot; : 0\n  }\n}[/code]数值完全对上了。没错，bg_count 就是『武汉』在整个索引里的总数。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day4: significant_terms聚合","uid":"7","views":"3530","votes":"1"},"_type":"doc"}
{"_id":"19","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449650409","category_id":"2","comments":"4","has_attach":"1","id":"19","message":"ELK的架构：\nlogstash==\u0026gt;redis==\u0026gt;logstash==\u0026gt;elasticsearch==\u0026gt;kibana开始我自己在ES上建索引，\n建索引语句如下：\ncurl -XPUT \u0026quot;http://localhost:9200/qn-service\u0026quot; -d '{\u0026quot;mappings\u0026quot;:{\u0026quot;_default_\u0026quot;:{\u0026quot;properties\u0026quot;:{\u0026quot;speaker\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;not_analyzed\u0026quot;},\u0026quot;play_name\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot;:\u0026quot;not_analyzed\u0026quot;},\u0026quot;line_id\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;integer\u0026quot;},\u0026quot;speech_number\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;integer\u0026quot;}}}}}'\n然后通过logstash导数据到ES后，却发现查询不到数据，然后用\ncurl [url]http://localhost:9200/_cat/indices?v[/url]  命令发现索引的数据为空；\n[attach]49[/attach]\n发现es自动建的索引有数据，而我自己的索引数据为空。\n找了半天原因没找到，然后就将es中得数据删除，\n curl -XDELETE [url]http://localhost:9200/*[/url]\n用上述方法重建索引；\n然后按照书上《ELK权威指南》上得方法，直接导入数据到es，\ncurl -XPUT http://localhost:9200/_bulk --data-binary @shakespeare.json\n却发现自己建的索引还是没有数据，es却多了一个叫shakespeare得索引，这个索引中有数据，那么我有两点疑问1：为什么我用书上建索引的方法建立索引(shakespeare名字被我改成qn-service)却没有数据？\n2：shakespeare这个索引是哪里来得？\n \nlogstash shipper.conf\ninput {\n        file {\n                path =\u0026gt; [\u0026quot;/data/logs/superErpLog/trace/shakespeare.json\u0026quot;]\n                start_position =\u0026gt; \u0026quot;beginning\u0026quot;\n                sincedb_path =\u0026gt; \u0026quot;/dev/null\u0026quot;\n        }\n}\nfilter{\n        json{\n                source=\u0026gt;\u0026quot;message\u0026quot;\n                remove_field =\u0026gt; [\u0026quot;message\u0026quot;]\n        }\n}\noutput {\n        stdout{}\n        redis {\n                host =\u0026gt; \u0026quot;localhost\u0026quot;\n                port =\u0026gt; 6379\n                data_type =\u0026gt; \u0026quot;list\u0026quot;\n                key =\u0026gt; \u0026quot;performance\u0026quot;\n        }\n} \nlogstash center.conf\ninput {\n        redis {\n                host =\u0026gt; \u0026quot;localhost\u0026quot;\n                port =\u0026gt; 6379 \n                type =\u0026gt; \u0026quot;redis-input\u0026quot;\n                data_type =\u0026gt; \u0026quot;list\u0026quot;\n                key =\u0026gt; \u0026quot;performance\u0026quot;\n        }   \n}\n\noutput {\n        stdout {}\n        elasticsearch {\n                cluster =\u0026gt; \u0026quot;elasticsearch\u0026quot;\n                host =\u0026gt; \u0026quot;localhost\u0026quot;\n                port =\u0026gt; 9200\n                codec =\u0026gt; \u0026quot;json\u0026quot; \n                protocol =\u0026gt; \u0026quot;http\u0026quot;\n        }   \n}","title":"自建的索引没数据？","uid":"640","views":"3824","votes":"0"},"_type":"doc"}
{"_id":"22","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450242253","category_id":"2","comments":"4","has_attach":"0","id":"22","message":"前端时间折腾了一下源码调试的问题，简单总结以下。\n---------------------\n调试环境是window（linux理论上通用）\n用到的工具类：\n1:mvn：https://maven.apache.org/\nelasticsearch的源码是用mvn工具管理的，根据pom.xml来下载一些依赖包非常方便。\n（当然也可以用gradle，由于不太熟悉，就没研究）\n安装mvn，注意配置后环境变量即可。官方文档写的很明白。\n最好自己修改一下mvn的setting.xml文件中的本地repo\n\u0026lt;!-- localRepository\n   | The path to the local repository maven will use to store artifacts.\n   |\n   | Default: ${user.home}/.m2/repository\n  \u0026lt;localRepository\u0026gt;/path/to/local/repo\u0026lt;/localRepository\u0026gt;\n--\u0026gt;\n我设置成了：\n\u0026lt;localRepository\u0026gt;E:/m2/repository\u0026lt;/localRepository\u0026gt;\nmvn -v 测试以下\n2:eclipse：编辑器，应用应该还比较广泛的。我用的最新版的mars。\n（intellij idea据说这是一个很牛逼的编辑器，也是因为暂时不熟悉，还没研究）\n----------------------\n步骤：\n1: 去github上选择一个tag版本，我用的是2.1.0.\nhttps://github.com/elastic/elasticsearch/tree/v2.1.0 \n直接DownloadZip文件即可\n（也可以用git clone下来）\n解压缩。\n假设目录为E:/elasticsearch-2.1.0\n2: 编译源代码\ncmd 打开命令行\n进入源文件目录 E:/elasticsearch-2.1.0\n执行 mvn package命令\n这个时间段耗时比较长，当然也得根据网速情况。\n会出现失败，大多是因为拉取不到依赖包。可以根据提示信息，手动去下载失败的jar，然后拷贝到本地repo对应的文件夹下边即可。\n等出现build success信息的时候代表成功了。\n可以到core/target目录下看到elasticsearch-2.1.0-SNAPSHOT.jar。\n3:转为eclipse工程\n可能习惯了eclipse工程，所以这里就直接用mvn转成了eclipse的工程，生成.classpath和.project文件。\n进入core目录执行以下指令\nmvn eclipse:eclipse\n这一步也会消耗一些时间，通常的错误也是jar包下载不成功，根据终端打印的错误信息，把对应jar包直接下载下来，放到本地的repo对应目录下边即可，然后重新运行命令。直到成功。\n之后，就会发现出现了.classpath和.project文件了。\n然后打开eclipse 直接带入core中的工程即可。\n4: 设置运行参数\n打开刚刚导入成功的工程：\nRun As----Run Configution---Args\n设置ProgramArgument 为 start\n设置VMArgument为 -Des.path.home=E:\\elasticsearch-2.1.0\\core\\\n完毕\n-------\n现在就就可以运行+调试了。\n\n","title":"elasticsearch源码调试环境小结","uid":"146","views":"12513","votes":"0"},"_type":"doc"}
{"_id":"24","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450278093","category_id":"14","comments":"0","has_attach":"0","id":"24","message":"ES2.0 开始提供了一个崭新的 pipeline aggregation 特性，但是 Kibana 似乎并没有立刻跟进这方面的意思，相反，Elastic 公司推出了另一个实验室产品：Timelion。\ntimelion 的用法在官博里已经有介绍。尤其是最近两篇如何用 timelion 实现异常告警的文章，更是从 ES 的 pipeline aggregation 细节和场景一路讲到 timelion 具体操作，我这里几乎没有再重新讲一遍 timelion 操作入门的必要了。不过，官方却一直没有列出来 timelion 支持的请求语法的文档，而是在页面上通过点击图标的方式下拉帮助。\n[img]http://logstash.es/images/timelion.png[/img]\ntimelion 页面设计上，更接近 Kibana3 而不是 Kibana4。比如 panel 分布是通过设置几行几列的数目来固化的；query 框是唯一的，要修改哪个 panel 的 query，鼠标点选一下 panel，query 就自动切换成这个 panel 的了。\n\n为了方便大家在上手之前了解 timelion 能做到什么，今天特意把 timelion 的请求语法所支持的函数分为几类，罗列如下：\n\n可视化效果类：[code]    .bars($width): 用柱状图展示数组\n    .lines($width, $fill, $show, $steps): 用折线图展示数组\n    .points(): 用散点图展示数组\n    .color(\u0026quot;#c6c6c6\u0026quot;): 改变颜色\n    .hide(): 隐藏该数组\n    .label(\u0026quot;change from %s\u0026quot;): 标签\n    .legend($position, $column): 图例位置\n    .yaxis($yaxis_number, $min, $max, $position): 设置 Y 轴属性，.yaxis(2) 表示第二根 Y 轴[/code]\n数据运算类：[code]    .abs(): 对整个数组元素求绝对值\n    .precision($number): 浮点数精度\n    .testcast($count, $alpha, $beta, $gamma): holt-winters 预测\n    .cusum($base): 数组元素之和，再加上 $base\n    .derivative(): 对数组求导数\n    .divide($divisor): 数组元素除法\n    .multiply($multiplier): 数组元素乘法\n    .subtract($term): 数组元素减法\n    .sum($term): 数组元素加法\n    .add(): 同 .sum()\n    .plus(): 同 .sum()\n    .first(): 返回第一个元素\n    .movingaverage($window): 用指定的窗口大小计算移动平均值\n    .mvavg(): .movingaverage() 的简写\n    .movingstd($window): 用指定的窗口大小计算移动标准差\n    .mvstd(): .movingstd() 的简写[/code]数据源设定类：[code]    .elasticsearch(): 从 ES 读取数据\n    .es(q=\u0026quot;querystring\u0026quot;, metric=\u0026quot;cardinality:uid\u0026quot;, index=\u0026quot;logstash-*\u0026quot;, offset=\u0026quot;-1d\u0026quot;): .elasticsearch() 的简写\n    .graphite(metric=\u0026quot;path.to.*.data\u0026quot;, offset=\u0026quot;-1d\u0026quot;): 从 graphite 读取数据\n    .quandl(): 从 quandl.com 读取 quandl 码\n    .worldbank_indicators(): 从 worldbank.org 读取国家数据\n    .wbi(): .worldbank_indicators() 的简写\n    .worldbank(): 从 worldbank.org 读取数据\n    .wb(): .worldbanck() 的简写[/code]以上所有函数，都在 series_functions 目录下实现，每个 js 文件实现一个 TimelionFunction 功能。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day11: timelion请求语法","uid":"7","views":"8575","votes":"4"},"_type":"doc"}
{"_id":"25","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450278233","category_id":"14","comments":"0","has_attach":"0","id":"25","message":"很多从 MySQL 转过来的 Elasticsearch 用户总是很习惯的问一个问题：『怎么在 ES 里实现 join 操作？』过去，我们的回答一般都是：通过类似宽表的思路，将数据平铺在一个索引里。不过，最近另一家 Lucene 开发商给出了另一个方案，他们开发了一个 Elasticsearch 插件，实现了 filter 层面的 join，GitHub 项目地址见：https://github.com/sirensolutions/siren-join\n\n不过需要提醒一下的是：filter 层面的意思，就是只相当于是 SQL 里的 exists 操作。所以目前对这个插件也不要抱有太大期望。今天我们来稍微演示一下。\n\n安装和其他 ES 插件一样：[code]# bin/plugin -i solutions.siren/siren-join/1.0[/code][i]注意 siren-join v1.0 只支持 ES 1.7 版本，2.0 版本支持据说正在开发中。[/i]\n\n我们 bulk 上传这么一段数据：[code]{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;1\u0026quot;}}\n{\u0026quot;id\u0026quot;:1, \u0026quot;foreign_key\u0026quot;:\u0026quot;13\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;2\u0026quot;}}\n{\u0026quot;id\u0026quot;:2}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;3\u0026quot;}}\n{\u0026quot;id\u0026quot;:3, \u0026quot;foreign_key\u0026quot;: \u0026quot;2\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;4\u0026quot;}}\n{\u0026quot;id\u0026quot;:4, \u0026quot;foreign_key\u0026quot;: \u0026quot;14\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index1\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;5\u0026quot;}}\n{\u0026quot;id\u0026quot;:5, \u0026quot;foreign_key\u0026quot;: \u0026quot;2\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index2\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;1\u0026quot;}}\n{\u0026quot;id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;tag\u0026quot;: \u0026quot;aaa\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index2\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;2\u0026quot;}}\n{\u0026quot;id\u0026quot;:\u0026quot;2\u0026quot;, \u0026quot;tag\u0026quot;: \u0026quot;aaa\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index2\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;3\u0026quot;}}\n{\u0026quot;id\u0026quot;:\u0026quot;3\u0026quot;, \u0026quot;tag\u0026quot;: \u0026quot;bbb\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;index2\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;type\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;4\u0026quot;}}\n{\u0026quot;id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;tag\u0026quot;: \u0026quot;ccc\u0026quot;}[/code]注意，siren-join 要求用来 join 的字段必须数据类型一致。所以，当我们要用 index2 的 id 和 index1 的foreign_key 做 join 的时候，这两个字段就要保持一致，这里为了演示，特意都改成字符串。那么我们发起一个请求如下：[code]# curl -s -XPOST 'http://localhost:9200/index1/_coordinate_search?pretty' -d '\n{\n    \u0026quot;query\u0026quot;:{\n        \u0026quot;filtered\u0026quot;:{\n            \u0026quot;query\u0026quot;:{\n                \u0026quot;match_all\u0026quot;:{}\n            },\n            \u0026quot;filter\u0026quot;:{\n                \u0026quot;filterjoin\u0026quot;:{\n                    \u0026quot;foreign_key\u0026quot;:{\n                        \u0026quot;index\u0026quot;:\u0026quot;index2\u0026quot;,\n                        \u0026quot;type\u0026quot;:\u0026quot;type\u0026quot;,\n                        \u0026quot;path\u0026quot;:\u0026quot;id\u0026quot;,\n                        \u0026quot;query\u0026quot;:{\n                            \u0026quot;terms\u0026quot;:{\n                                \u0026quot;tag\u0026quot;:[\u0026quot;aaa\u0026quot;]\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    },\n    \u0026quot;aggs\u0026quot;:{\n        \u0026quot;avg\u0026quot;:{\n            \u0026quot;avg\u0026quot;:{\n                \u0026quot;field\u0026quot;:\u0026quot;id\u0026quot;\n            }\n        }\n    }\n}'[/code]意即：从 index2 中搜索 q=tag:aaa 的数据的 id，查找 index1 中对应 foreign_key 的文档的 id 数据平均值。响应结果如下：[code]{\n    \u0026quot;coordinate_search\u0026quot; : {\n        \u0026quot;actions\u0026quot; : [ {\n            \u0026quot;relations\u0026quot; : {\n                \u0026quot;from\u0026quot; : {\n                    \u0026quot;indices\u0026quot; : [ ],\n                    \u0026quot;types\u0026quot; : [ ],\n                    \u0026quot;field\u0026quot; : \u0026quot;id\u0026quot;\n                },\n                \u0026quot;to\u0026quot; : {\n                    \u0026quot;indices\u0026quot; : null,\n                    \u0026quot;types\u0026quot; : null,\n                    \u0026quot;field\u0026quot; : \u0026quot;foreign_key\u0026quot;\n                }\n            },\n            \u0026quot;size\u0026quot; : 2,\n            \u0026quot;size_in_bytes\u0026quot; : 20,\n            \u0026quot;is_pruned\u0026quot; : false,\n            \u0026quot;cache_hit\u0026quot; : true,\n            \u0026quot;took\u0026quot; : 0\n        } ]\n    },\n    \u0026quot;took\u0026quot; : 2,\n    \u0026quot;timed_out\u0026quot; : false,\n    \u0026quot;_shards\u0026quot; : {\n        \u0026quot;total\u0026quot; : 5,\n        \u0026quot;successful\u0026quot; : 5,\n        \u0026quot;failed\u0026quot; : 0\n    },\n    \u0026quot;hits\u0026quot; : {\n        \u0026quot;total\u0026quot; : 2,\n        \u0026quot;max_score\u0026quot; : 1.0,\n        \u0026quot;hits\u0026quot; : [ {\n            \u0026quot;_index\u0026quot; : \u0026quot;index1\u0026quot;,\n            \u0026quot;_type\u0026quot; : \u0026quot;type\u0026quot;,\n            \u0026quot;_id\u0026quot; : \u0026quot;5\u0026quot;,\n            \u0026quot;_score\u0026quot; : 1.0,\n            \u0026quot;_source\u0026quot;:{\u0026quot;id\u0026quot;:5, \u0026quot;foreign_key\u0026quot;: \u0026quot;2\u0026quot;}\n        }, {\n            \u0026quot;_index\u0026quot; : \u0026quot;index1\u0026quot;,\n            \u0026quot;_type\u0026quot; : \u0026quot;type\u0026quot;,\n            \u0026quot;_id\u0026quot; : \u0026quot;3\u0026quot;,\n            \u0026quot;_score\u0026quot; : 1.0,\n            \u0026quot;_source\u0026quot;:{\u0026quot;id\u0026quot;:3, \u0026quot;foreign_key\u0026quot;: \u0026quot;2\u0026quot;}\n        } ]\n    },\n    \u0026quot;aggregations\u0026quot; : {\n        \u0026quot;avg\u0026quot; : {\n            \u0026quot;value\u0026quot; : 4.0\n        }\n    }\n}[/code]响应告诉我们：从 index2 中搜索到 2 条参与 join 的文档，在 index1 中命中 2 条数据，最后求平均值为 4.0。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day12: siren-join简介","uid":"7","views":"3999","votes":"0"},"_type":"doc"}
{"_id":"26","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450278304","category_id":"14","comments":"1","has_attach":"0","id":"26","message":"Geo 定位在 ELK 应用中是非常重要和有用的一个环节。不幸的是：GeoIP 本身在国内的准确度实在堪忧。高春辉近年成立了一个项目，专注收集细化 IP 地址在国内的数据：http://www.ipip.net。数据分为免费版和收费版两种。项目提供了不少客户端，有趣的是，有社区贡献了一个 Logstash 插件：https://github.com/bittopaz/logstash-filter-ipip。\n\n用法很简单：[code]filter {\n    ipip {\n        source =\u0026gt; \u0026quot;clientip\u0026quot;\n        target =\u0026gt; \u0026quot;ipip\u0026quot;\n    }\n}[/code]生成的 JSON 数据结构类似下面这样：[code]{\n    \u0026quot;clientip\u0026quot; : \u0026quot;\u0026quot;,\n    \u0026quot;ipip\u0026quot; : {\n        \u0026quot;country\u0026quot; : \u0026quot;\u0026quot;,\n        \u0026quot;city\u0026quot; : \u0026quot;\u0026quot;,\n        \u0026quot;carrier\u0026quot; : \u0026quot;\u0026quot;,\n        \u0026quot;province\u0026quot; : \u0026quot;\u0026quot;\n    }\n}[/code]不过这个插件只实现了收费版的数据库基础格式。免费版的支持，收费版高级的经纬度、基站位置等，都没有随着更新。事实上，我们可以通过 ipip 官方的 Java 库，实现一个更灵活的 logstash-filter-ipip_java 插件出来，下期见。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day13: ipip.net介绍","uid":"7","views":"3325","votes":"0"},"_type":"doc"}
{"_id":"29","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450427848","category_id":"14","comments":"1","has_attach":"0","id":"29","message":"看到前一天, Medcl 介绍了Beat, 我想今天我就介绍一下算是同一个领域的, 我们的一个小产品吧, 同样也基于elastic旗下的logstash-forwarder. 我真的不是来打广告的, 就是第一次写, 没经验, 看着前一天的文章, 顺手就想到了.\n\n在日志收集系统中, 从kafkf到ES这条路是没问题了, 但散布在各个服务器上采集日志的agent用logstash实在是太重了, 而且效率也低. 特别是我们有大量的windows服务器, 找一个合适的agent居然不是想象中的容易.\n\nlogstash-forwarder对于日志文件的探测和offset记录, deadtime等配置都非常适合我们, 但惟一不支持吐数据到kafak,对我们来说是一个遗憾. 我和oliver(https://github.com/oliveagle)做过一点改造之后, 让她支持了这个功能.\n\n目前我们所有iis服务器已经部署了这个应用, 效率高, 占资源小, 可以数据压缩, 支持简单的格式切割, 实乃windows居家必备(我真不是来打广告的). golang客户端, 还能直接发送到kafka, 想想就很贴心~\n\n贴上一段配置瞅瞅先, 启一个进程采集nginx和tomcat日志, 分别吐到kafka的2个topic中.[code]{\n    \u0026quot;files\u0026quot;: [\n    {\n        \u0026quot;paths\u0026quot;: [\n            \u0026quot;/var/log/nginx/*.log\u0026quot;\n            ],\n        \u0026quot;Fields\u0026quot;:{\n            \u0026quot;type\u0026quot;:\u0026quot;nginx\u0026quot;\n        },\n        \u0026quot;DeadTime\u0026quot;: \u0026quot;30m\u0026quot;\n    },\n    {\n        \u0026quot;paths\u0026quot;: [\n            \u0026quot;/var/log/tomcat/*.log\u0026quot;,\n            \u0026quot;/var/log/tomcat/*/*.log\u0026quot;\n            ],\n        \u0026quot;Fields\u0026quot;:{\n            \u0026quot;type\u0026quot;:\u0026quot;tomcat\u0026quot;\n        },\n        \u0026quot;DeadTime\u0026quot;: \u0026quot;30m\u0026quot;\n    }\n    ],\n    \u0026quot;kafka\u0026quot;: {\n        \u0026quot;broker_list\u0026quot;: [\u0026quot;10.0.0.1:9092\u0026quot;,\u0026quot;10.0.0.2:9092\u0026quot;],\n        \u0026quot;topic_id\u0026quot;: \u0026quot;topic_name_change_it_{{.type}}\u0026quot;,\n        \u0026quot;compression_codec\u0026quot;: \u0026quot;gzip\u0026quot;\n    }\n}[/code]\n再简单介绍一下参数吧,\n[list]\n[*]DeadTime:30m 是说超过30分钟没有更新, 就不会再继续跟踪这个文件了(退出goroutine)[/*]\n[*]“Fields”:{ “type”:”tomcat” } , 会在每条日志中增加配置的字段[/*]\n[*]path目前就是用的golang官方库, 好像是还不支持递归多层目录查找, 反正我翻了一下文档, 没有找到.[/*]\n[/list]\n\ngrok还不支持, 但简单的分割是可以的[code]\u0026quot;files\u0026quot;: [\n        {\n            \u0026quot;paths\u0026quot;: [\n                \u0026quot;d:\\\\target.txt\u0026quot;\n                ],\n            \u0026quot;FieldNames\u0026quot;: [\u0026quot;datetime\u0026quot;, \u0026quot;datetime\u0026quot;, \u0026quot;s_ip\u0026quot;, \u0026quot;cs_method\u0026quot;, \u0026quot;cs_uri_stem\u0026quot;, \u0026quot;cs_uri_query\u0026quot;, \u0026quot;s_port\u0026quot;, \u0026quot;time_taken\u0026quot;],\n            \u0026quot;Delimiter\u0026quot;: \u0026quot;\\\\s+\u0026quot;,\n            \u0026quot;QuoteChar\u0026quot;: \u0026quot;\\\u0026quot;\u0026quot;\n        }\n][/code]\n以上配置就是说按空白符把日志切割来, 塞到对应的字段中去. 第一个第二个合在一起, 放在datetime字段中.\n\n其实还是有不少要完善的地方, 比如说没有带上机器的Hostname, 以及日志的路径. 在很多时候, 这些信息还是很有用的, 我们也会继续完善.\n\n现在放在了https://github.com/childe/logstash-forwarder/tree/kafka, 有需要的同学,可以去看下.","title":"day16 logstash-forwader To Kakfa!","uid":"666","views":"3067","votes":"2"},"_type":"doc"}
{"_id":"374","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510612250","category_id":"18","comments":"1","has_attach":"0","id":"374","message":"1.使用Logstash将email索引至Elasticsearch。\n[url]http://t.cn/RjyNLge[/url] \n2.Elasticsearch选主流程详细分析。\n[url]http://t.cn/RjyNPLT[/url] \n3.手把手教你如何使用ES提高WordPress的搜索速度。\n[url]http://t.cn/RjbD1QK[/url] \n4.只等你来 | Elastic Meetup 广州交流会\n[url]https://elasticsearch.cn/article/364[/url] \n\n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/374[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第100期 (2017-11-14)","uid":"3788","views":"515","votes":"1"},"_type":"doc"}
{"_id":"383","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510823395","category_id":"12","comments":"1","has_attach":"0","id":"383","message":"[b] 招聘职位：测试开发工程师  简历注明(来自elastic 中文社区)[/b]\n \n[b]工作内容：[/b]\n[b] [/b]\n[b]   负责jd安全产品的测试： WAF、感知、加解密等项目的性能、功能的测试[/b]\n\n[b]职位要求：[/b]\n[b]  快到碗里来， 据说内推有奖哦  如果合适 肯定会第一时间联系[/b]\n \n欢迎投递简历至：qinpengfei@jd.com 小编也是rd，所以职位工资等都不清楚，只是帮助部门进行招聘","title":"【北京-JD安全-北辰】招聘测试开发工程师","uid":"232","views":"942","votes":"0"},"_type":"doc"}
{"_id":"385","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510966561","category_id":"18","comments":"0","has_attach":"0","id":"385","message":"1、使用IP2Location插件过滤位置数据\nhttp://t.cn/RjOc0Rh\n2、ES6.0只支持单个mapping type了\nhttp://t.cn/RjOgAPZ\n3、利用haystack库，用python对ES进行索引和查询操作\nhttp://t.cn/RjO9yvi\n4、只等你来 | Elastic Meetup 广州交流会\nhttps://elasticsearch.cn/article/364\n\n编辑：bsll\n归档：https://elasticsearch.cn/article/385\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第104期 (2017-11-18)","uid":"1874","views":"433","votes":"0"},"_type":"doc"}
{"_id":"386","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511050015","category_id":"18","comments":"0","has_attach":"0","id":"386","message":"1.Mapper attachment，快速且强大的PDF索引查询插件。\nhttp://t.cn/RjQuE5x\n2.深入理解cluster allocation API，准确找到shard未正确分配的原因。\nhttp://t.cn/RlrzTsD\n3.(自备梯子)项目经理和程序猿如何能够愉快的达成一致的项目周期\nhttp://t.cn/RjQueTd\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/386\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第105期 (2017-11-19)","uid":"4460","views":"376","votes":"0"},"_type":"doc"}
{"_id":"387","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511144110","category_id":"18","comments":"0","has_attach":"0","id":"387","message":"1.elasticsearch URL分词器，帮你更好解决URL搜索难题。\nhttp://t.cn/RjualK1\n\n2.来看看logstash 6.0令人激动的改进：可视化、性能分析以及多管道支持。\nhttp://t.cn/RjuoRuT\n\n3.深入理解直方图\n[url]http://t.cn/RKgkOo1[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/387\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第106期 (2017-11-20)","uid":"4063","views":"430","votes":"0"},"_type":"doc"}
{"_id":"400","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511920046","category_id":"18","comments":"0","has_attach":"0","id":"400","message":"1、适用于初学者的ES视频教程（自备梯子）\n\nhttp://t.cn/RYIGFGb\n\n2、推荐一款针对ES的UI插件dejavu\n\nhttp://t.cn/R9DZheQ\n\n3、老生常谈，关于集群配置的基本知识\n\nhttp://t.cn/RYI6fRj\n\n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/400\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第115期 (2017-11-29)","uid":"1874","views":"429","votes":"0"},"_type":"doc"}
{"_id":"397","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511746642","category_id":"18","comments":"0","has_attach":"0","id":"397","message":"1.使用es作为存储的调用链跟踪系统，开箱即用。\nhttp://t.cn/RqbXsDC\n\n2.为什么es会出现bluk拒绝错误？来听听老司机的解析\nhttp://t.cn/RY5BJy7\n\n3.来自社区的讨论：如何使用es来作为一个主数据库\n[url]http://t.cn/RY5rPuA[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/397\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第113期 (2017-11-27)","uid":"4063","views":"417","votes":"0"},"_type":"doc"}
{"_id":"485","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517881396","category_id":"18","comments":"0","has_attach":"0","id":"485","message":"1.安装配置elastic-stack-6并分析nginx日志之图文详解。\n[url]http://t.cn/R8YF5nv[/url] \n2.使用logstash分析腾讯cdn日志的配置文件详解。\n[url]http://t.cn/R8Ykegn[/url] \n3.（自备梯子）视频讲解大数据分析利器之Spark与Elasticsearch。\n[url]http://t.cn/R8YklfE[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/485[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第181期 (2018-02-06)","uid":"3788","views":"324","votes":"0"},"_type":"doc"}
{"_id":"407","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512437594","category_id":"18","comments":"0","has_attach":"0","id":"407","message":"1.Elasticsearch Pipeline 详解。\n[url]http://t.cn/RYHvUB2[/url]  \n2.一套分布式实时日志分析解决方案的ELK部署架构。\n[url]http://t.cn/RYYmMoG[/url]  \n3.Elasticsearch图功能综述。\n[url]http://t.cn/RYHvipV[/url]  \n4.(法语)Elastic Advent Calendar, Day 4:ES高级java客户端。\n[url]http://t.cn/RY8GsmL[/url]\n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/407[/url]  \n订阅： [url]https://tinyletter.com/elastic-daily[/url] ","title":" Elastic日报 第121期 (2017-12-05)","uid":"3788","views":"421","votes":"0"},"_type":"doc"}
{"_id":"408","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512521142","category_id":"18","comments":"0","has_attach":"0","id":"408","message":"1. 深入理解 ElasticSearch Doc Values\n[url]http://t.cn/RYJKyA3[/url] \n2. 基于ES的异常检测之指数平滑\n[url]http://t.cn/RYvhr2O[/url] \n3. Elasticsearch学习总结--原理篇（旧闻）\n[url]http://t.cn/RqWRkV0[/url] \n4. (英语)Elastic Advent Calendar, Day 5:Painless 在6.0的新玩法\n[url]http://t.cn/RYntvWk[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/408[/url]\n订阅： [url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第122期 (2017-12-06)","uid":"3828","views":"512","votes":"0"},"_type":"doc"}
{"_id":"415","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513041149","category_id":"18","comments":"0","has_attach":"0","id":"415","message":"1.中小型研发团队架构实践之集中式日志ELK。\n[url]http://t.cn/RTGlt4p[/url] \n2.使用Amazon Rekognition and Elasticsearch进行机器学习。\n[url]http://t.cn/RTGl6OA[/url] \n3.ELK教程，挖掘、分析、可视化数据的高效解决之道。\n[url]http://t.cn/RTqOKYy[/url] \n4.(葡文)Elastic Advent Calendar, Day 11:父子文档的索引顺序。\n[url]http://t.cn/RTqohCw[/url] \n招聘：[上海-平安银行-招聘]招聘elasticsearch工程师。\n[url]https://elasticsearch.cn/question/3086[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/415[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第128期 (2017-12-12)","uid":"3788","views":"483","votes":"1"},"_type":"doc"}
{"_id":"423","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513561322","category_id":"18","comments":"0","has_attach":"0","id":"423","message":"1.Elastic 现在提供14天的ELK Stack云服务试用，还在犹豫不决的同学快来体验吧。\nhttp://t.cn/RTlWVit\n\n2.filebeat 5.X关于使用通配符的性能讨论。\nhttp://t.cn/RTlEsRp\n\n3.(英语)Elastic Advent Calendar, Day 17:  运维Elastic Cloud Enterprise的各种要点\n[url]http://t.cn/RTlTIYF[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/423\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第134期 (2017-12-18)","uid":"4063","views":"432","votes":"0"},"_type":"doc"}
{"_id":"222","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502499848","category_id":"18","comments":"0","has_attach":"0","id":"222","message":"1. Text Classification made easy with Elasticsearch  http://t.cn/RahB79C\n\n   你可能不知道,es也可以做文本分类哦！\n\n2. ES内存那点事 http://t.cn/R9uJcWg\n\n   有关es内存的问题一网打尽，感谢wood在社区的分享\n\n3. Solr VS Elasticsearch  http://t.cn/zjZ9f80\n\n   同样都是基于Apache Lucene，Solr 和 Elasticsearch 究竟差在哪 \n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/222\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第14期 (2017-08-12)","uid":"1874","views":"628","votes":"0"},"_type":"doc"}
{"_id":"229","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503015297","category_id":"18","comments":"1","has_attach":"0","id":"229","message":"1.阮一峰老师也来推荐 elasticsearch 了，还不赶紧用起来！http://t.cn/RCZ7g3x\n\n2.想引入SSD来提升es的读写性能，但又不是土豪，来看看冷热分离的方案吧！http://t.cn/RCAnz4Y\n\n3.推荐油管上的一个视频：用Elastic Stack 来收集和分析网络数据，各种炫酷可视化UI（请自备梯子）http://t.cn/RCAnXiA\n\n编辑：rockybean\n\n归档：https://elasticsearch.cn/article/229\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第20期 (2017-08-18)","uid":"86","views":"684","votes":"1"},"_type":"doc"}
{"_id":"240","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503609257","category_id":"18","comments":"0","has_attach":"0","id":"240","message":" 1. es基础入门知识图谱——让你少走半年弯路！\n[url]http://t.cn/RC0RJBB[/url] \n\n2.  ES java API选型看过来 | ES java API深入详解\n[url]http://t.cn/RC088PO[/url] \n\n3.  携程技术中心干货 | Elasticsearch相关性打分机制\n[url]http://t.cn/RCS5CGR[/url] \n \n\n编辑：laoyang360\n\n归档：https://elasticsearch.cn/article/240\n订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第27期 (2017-08-25)","uid":"1341","views":"1871","votes":"0"},"_type":"doc"}
{"_id":"253","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504313045","category_id":"18","comments":"0","has_attach":"0","id":"253","message":"1. es的各种关系索引、查询你清楚吗？\nhttp://t.cn/RNXpc2Y\n2. 手把手教你用Lassie从互联网搜集收据，并导入到es\nhttp://t.cn/RNXWeGk\n3. 如何利用painless更好的完成你的个性化需求，这篇文章带你入门。\nhttp://t.cn/RNXjWeG\n \n编辑：bsll\n归档：https://elasticsearch.cn/article/253\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第35期 (2017-09-02)","uid":"1874","views":"592","votes":"0"},"_type":"doc"}
{"_id":"254","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504401775","category_id":"18","comments":"0","has_attach":"0","id":"254","message":"1.Snaptrip使用Elasticsearch改善客户体验：\nhttp://t.cn/RNKFisR\n2. 手把手教你在Windows上安装Elasticsearch v5.5.0：\nhttp://t.cn/RNKFCpg\n3.基于Mesos的当当作业云Elastic-Job-Cloud：\nhttp://t.cn/RfCBHZt\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/254\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第36期 (2017-09-03)","uid":"4460","views":"535","votes":"0"},"_type":"doc"}
{"_id":"256","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504573927","category_id":"18","comments":"0","has_attach":"0","id":"256","message":"1.系统扩容导致的的ES故障和解决方法，你是否用的上？\n[url]http://t.cn/RC7iMym[/url] \n2.聊聊ES5.0以上版本的磁盘优化策略和建议。\n[url]http://t.cn/RN0g6bh[/url] \n3.如何定义ES集群的生命周期，可以参考一下Ebay给出的方案！\n[url]http://t.cn/RXlwIqQ[/url] \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/256\n订阅：https://tinyletter.com/elastic-daily \n ","title":"Elastic日报 第38期 (2017-09-05)","uid":"3788","views":"566","votes":"0"},"_type":"doc"}
{"_id":"259","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504749368","category_id":"18","comments":"1","has_attach":"0","id":"259","message":"1.elasticsearch的heap区设置详解: http://t.cn/RpPxEEO\n2.一条命令构建全栈elastic stack: http://t.cn/RpPxDo4\n3.怎么监控elasticsearch的性能: http://t.cn/RpPJh7u\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/259\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第40期 (2017-09-07)","uid":"668","views":"621","votes":"0"},"_type":"doc"}
{"_id":"260","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504824037","category_id":"18","comments":"0","has_attach":"0","id":"260","message":"[size=14]1.Elasticsearch 最常见的Top10面试题及答案。\n[url]http://t.cn/Rp7Z2Zg[/url] [/size]\n[size=14]2.5分钟，让你的Elasitcsearch更安全！\n[url]http://t.cn/R9SQJlK[/url] \n3. Elasticsearch复杂数据存储方式实战。\n[url]http://t.cn/RphsfBJ[/url] [/size]\n\n[size=14]编辑：laoyang360\n归档：[url]https://www.elasticsearch.cn/article/260[/url] [/size]\n[size=14]订阅：[url]https://tinyletter.com/elastic-daily[/url] [/size]\n ","title":"Elastic日报 第41期 (2017-09-08)","uid":"1341","views":"755","votes":"0"},"_type":"doc"}
{"_id":"264","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504918791","category_id":"18","comments":"4","has_attach":"0","id":"264","message":"1.正确使用bool语法,你做到了吗:\n[url]http://t.cn/RpGg46z[/url] \n\n2.有时候scripts并不是最佳选择：\n[url]http://t.cn/RpGg9kw[/url] \n\n3.手把手教你用docker部署es：\n[url]http://t.cn/RpGeJ5U[/url] \n\n编辑：bsll\n归档：https://elasticsearch.cn/article/264\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第42期 (2017-09-09)","uid":"1874","views":"720","votes":"1"},"_type":"doc"}
{"_id":"270","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505177532","category_id":"18","comments":"0","has_attach":"0","id":"270","message":"1.如何使用Elasticsearch构建企业级搜索方案。[url]http://t.cn/RpJP4fB[/url] \n2.你知道game day么，一次Elasticsearch game day收获的三个经验，先睹为快。[url]http://t.cn/RNQjU0a[/url] \n3.官方教程，教你如何使用Metricbeat 和Elastic Cloud监控集群。[url]http://t.cn/Rpx9cSr[/url] \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/270\n订阅：https://tinyletter.com/elastic-daily \n ","title":" Elastic日报 第45期 (2017-09-12)","uid":"3788","views":"637","votes":"0"},"_type":"doc"}
{"_id":"295","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506388690","category_id":"18","comments":"0","has_attach":"0","id":"295","message":"1.如何用亚马逊S3存储一个ES服务索引。\n[url]http://t.cn/R0fAJwK[/url] \n2.ELK实战 - 利用Nginx日志分析API耗时。\n[url]http://t.cn/R6sgQfU[/url] \n3.Kibana中的地区分布图和仪表盘工具，强大而又实用。\n[url]http://t.cn/Rpry9fv[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/295[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n ","title":"Elastic日报 第59期 (2017-09-26)","uid":"3788","views":"488","votes":"0"},"_type":"doc"}
{"_id":"206","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501658423","category_id":"5","comments":"2","has_attach":"1","id":"206","message":"消息来自：[url]https://medium.com/@SergiuSechel/over-5-000-kibana-instances-exposed-on-the-internet-7455a014af48[/url]\n因为这个网址不存在，所以搬过来大家一起看看，请自查自家服务器是不是快乐的在裸奔，嘿，要管管了啊。\n试试：\nhttps://www.zoomeye.org/search?q=app%3Akibana+country%3AChina\u0026amp;t=host \nhttps://www.shodan.io/search?query=kibana​ \n \n\n[b]Over 5,000 Kibana instances exposed on the internet[/b]\n\nI’m not a big fan of writing articles so I’ll keep it short… I was using Shodan.io recently for research purposes and while searching for different devices I came across 5,591 Kibana instances exposed over the internet. A significant number of those instances didn’t use any authentication mechanisms and several had +100 million log events recorded.\n\nThe query syntax that I used was the following: kibana port:”5601\u0026quot;.\n\n[attach]851[/attach]\n \nRisk: Kibana is deployed alone or together with Elasticsearch and Logstash (the ELK Stack) for log management purposes and it gained notoriety in the last couple of years as an open source alternative to more expensive commercial solutions. Log management solutions usually contain sensitive info and should not be exposed over the internet… (people who are familiar with information security know what I’m talking about).\n\nSolution: For all the entities affected please refer to the following link and enable authentication on your Kibana implementations: [url]https://www.elastic.co/guide/en/kibana/current/xpack-security.html[/url]\n\n[attach]852[/attach]\n \n去年的大规模勒索事件，大家应该还记得吧，什么，ES你也裸奔着，你。。。\n ","title":"超过5千以上的Kibana实例裸奔在互联网上，国内第二！","uid":"1","views":"1836","votes":"3"},"_type":"doc"}
{"_id":"208","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501724906","category_id":"2","comments":"11","has_attach":"1","id":"208","message":"日常使用中的一些经验，给使用ES的筒子们一些建议，如有错误，请多多包含..\n \n[attach]877[/attach]\n\n[attach]869[/attach]\n\n[attach]868[/attach]\n\n[attach]866[/attach]\n\n[attach]865[/attach]\n\n[attach]867[/attach]\n\n[attach]874[/attach]\n\n[attach]870[/attach]\n\n[attach]873[/attach]\n\n[attach]871[/attach]\n\n[attach]872[/attach]\n\n[attach]875[/attach]\n\n[attach]880[/attach]\n\n[attach]876[/attach]\n\n[attach]878[/attach]\n\n[attach]879[/attach]\n\n ","title":"elasticsearch日常使用经验分享","uid":"1609","views":"1633","votes":"7"},"_type":"doc"}
{"_id":"635","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527040960","category_id":"18","comments":"0","has_attach":"0","id":"635","message":"1. Elasticsearch 集群\n[url]http://t.cn/R3eBpR0[/url] \n2. ElasticSearch的搭建与数据统计\n[url]http://t.cn/R3eBB2S[/url] \n3. Filebeat 源码分析\n[url]http://t.cn/Rtxs35p[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/635[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第280期 (2018-05-23)","uid":"3828","views":"350","votes":"0"},"_type":"doc"}
{"_id":"644","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527558482","category_id":"18","comments":"0","has_attach":"0","id":"644","message":"1.深入理解 Elasticsearch 的批操作。\n[url]http://t.cn/R1tuJMq[/url] \n2.SpringBoot整合ElasticSearch实现多版本的兼容。\n[url]http://t.cn/R3VlVu7[/url] \n3.Elasticsearch learning to rank 详细入门文档。\n[url]http://t.cn/R1tu9Nw[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/644[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第286期 (2018-05-29)","uid":"3788","views":"331","votes":"0"},"_type":"doc"}
{"_id":"645","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527645928","category_id":"18","comments":"0","has_attach":"0","id":"645","message":"1. 利用ES完成文本标注。\n[http://t.cn/R1Idxmd](http://t.cn/R1Idxmd) \n\n2. 利用ES进行图像相似搜索。\n[http://t.cn/Rq9AvuD](http://t.cn/Rq9AvuD) \n\n3. refresh与flush的区别。\n[http://t.cn/R1Idxmg](http://t.cn/R1Idxmg) \n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/645\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第287期 (2018-05-30)","uid":"1874","views":"358","votes":"1"},"_type":"doc"}
{"_id":"646","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527738265","category_id":"18","comments":"0","has_attach":"0","id":"646","message":"1. 七个更好的Elasticsearch基准测试技巧。\n[http://t.cn/R16rZXS](http://t.cn/R16rZXS) \n\n2. ElasticSearch的搭建与数据统计。\n[http://t.cn/R3eBB2S](http://t.cn/R3eBB2S) \n\n3. Elasticsearch的选举机制。\n[http://t.cn/R3COV8R](http://t.cn/R3COV8R) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/646\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第288期 (2018-05-31)","uid":"668","views":"391","votes":"0"},"_type":"doc"}
{"_id":"651","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527903428","category_id":"18","comments":"0","has_attach":"0","id":"651","message":"1. 使用es索引pdf、doc文档。\n[http://t.cn/R10v3v2](http://t.cn/R10v3v2) \n\n2. mapping中store属性该如何使用?\n[http://t.cn/R10v3vy](http://t.cn/R10v3vy) \n\n3. 如何手动分配未分配的分片?\n[http://t.cn/R10v3vL](http://t.cn/R10v3vL) \n\n* 编辑:  bsll\n\n* 归档：https://elasticsearch.cn/article/651 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第290期 (2018-06-02)","uid":"1874","views":"365","votes":"0"},"_type":"doc"}
{"_id":"656","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528261542","category_id":"18","comments":"0","has_attach":"0","id":"656","message":"1.Filebeat 源码分析\n服务启动 http://t.cn/R1rt77d\n数据采集 http://t.cn/R1r5Em1\n2. Filebeat 源码流程分析\nhttp://t.cn/R1rt5dX\n3. 一步步排查基于业务场景的Elasticsearch难题\nhttp://t.cn/R1rt9oo\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/656[/url]\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第294期 (2018-06-06)","uid":"3828","views":"320","votes":"0"},"_type":"doc"}
{"_id":"665","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528854568","category_id":"18","comments":"0","has_attach":"0","id":"665","message":"1.Elasticsearch 团队开发章程（中文版）\n[url]http://t.cn/RBMHmUT[/url] \n2.PB级海量数据服务平台架构设计实践\n[url]http://t.cn/ROy5UyN[/url] \n3.知识库全文检索的最佳实践\n[url]http://t.cn/RBM8Mca[/url] \n \n活动预告：\n1.6月30日南京meetup参会报名中\n[url]https://elasticsearch.cn/m/article/647[/url] \n2.7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/665[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第301期 (2018-06-13)","uid":"3828","views":"304","votes":"0"},"_type":"doc"}
{"_id":"684","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529975059","category_id":"18","comments":"0","has_attach":"0","id":"684","message":"1.亿级Elasticsearch的性能优化。\n[url]http://t.cn/RrMM9zJ[/url] \n2.优化搜索引擎相关性的一些方案。\n[url]http://t.cn/RrMMjmj[/url] \n3.（自备翻墙）使用Elasticsearch构建一个真实应用。\n[url]http://t.cn/RrMMpdf[/url] \n\n活动预告\n1. 6月30日南京meetup参会报名中\n[url]https://elasticsearch.cn/m/article/647[/url] \n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/684[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第314期 (2018-06-26)","uid":"3788","views":"276","votes":"0"},"_type":"doc"}
{"_id":"687","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530107668","category_id":"2","comments":"9","has_attach":"1","id":"687","message":"最近发布的 Elasticsearch 6.3 包含了大家期待已久的 SQL 特性，今天给大家介绍一下具体的使用方法。\n\n## 首先看看接口的支持情况\n\n目前支持的 SQL 只能进行数据的查询只读操作，不能进行数据的修改，所以我们的数据插入还是要走之前的常规索引接口。\n\n目前 Elasticsearch 的支持 SQL 命令只有以下几个：\n\n| 命令 | 说明 | \n| --- | --- | \n| DESC table  | 用来描述索引的字段属性 | \n| SHOW COLUMNS  | 功能同上，只是别名 |\n| SHOW FUNCTIONS  | 列出支持的函数列表，支持通配符过滤 |\n| SHOW TABLES  | 返回索引列表 |\n| SELECT .. FROM table_name WHERE .. GROUP BY .. HAVING .. ORDER BY .. LIMIT .. | 用来执行查询的命令 |\n\n我们分别来看一下各自怎么用，以及有什么效果吧，自己也可以动手试一下，看看。\n\n首先，我们创建一条数据：\n\n```\nPOST twitter/doc/\n{\n  \u0026quot;name\u0026quot;:\u0026quot;medcl\u0026quot;,\n  \u0026quot;twitter\u0026quot;:\u0026quot;sql is awesome\u0026quot;,\n  \u0026quot;date\u0026quot;:\u0026quot;2018-07-27\u0026quot;,\n  \u0026quot;id\u0026quot;:123\n}\n```\n\n## RESTful下调用SQL\n\n在 ES 里面执行 SQL 语句，有三种方式，第一种是 RESTful 方式，第二种是 SQL-CLI 命令行工具，第三种是通过 JDBC 来连接 ES，执行的 SQL 语句其实都一样，我们先以 RESTful 方式来说明用法。\n\nRESTful 的语法如下：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SELECT * FROM twitter\u0026quot;\n}\n```\n\n因为 SQL 特性是 xpack 的免费功能，所以是在 `_xpack` 这个路径下面，我们只需要把 SQL 语句传给 query 字段就行了，注意最后面不要加上 `;` 结尾，注意是不要！\n\n我们执行上面的语句，查询返回的结果如下：\n\n```\n          date          |      id       |     name      |    twitter    \n------------------------+---------------+---------------+---------------\n2018-07-27T00:00:00.000Z|123            |medcl          |sql is awesome \n```\n\nES 俨然已经变成 SQL 数据库了，我们再看看如何获取所有的索引列表：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SHOW tables\u0026quot;\n}\n```\n\n返回如下：\n\n```\n              name               |     type      \n---------------------------------+---------------\n.kibana                          |BASE TABLE     \n.monitoring-alerts-6             |BASE TABLE     \n.monitoring-es-6-2018.06.21      |BASE TABLE     \n.monitoring-es-6-2018.06.26      |BASE TABLE     \n.monitoring-es-6-2018.06.27      |BASE TABLE     \n.monitoring-kibana-6-2018.06.21  |BASE TABLE     \n.monitoring-kibana-6-2018.06.26  |BASE TABLE     \n.monitoring-kibana-6-2018.06.27  |BASE TABLE     \n.monitoring-logstash-6-2018.06.20|BASE TABLE     \n.reporting-2018.06.24            |BASE TABLE     \n.triggered_watches               |BASE TABLE     \n.watcher-history-7-2018.06.20    |BASE TABLE     \n.watcher-history-7-2018.06.21    |BASE TABLE     \n.watcher-history-7-2018.06.26    |BASE TABLE     \n.watcher-history-7-2018.06.27    |BASE TABLE     \n.watches                         |BASE TABLE     \napache_elastic_example           |BASE TABLE     \nforum-mysql                      |BASE TABLE     \ntwitter      \n```\n\n有点多，我们可以按名称过滤，如 twitt 开头的索引，注意通配符只支持 `%`和 `_`，分别表示多个和单个字符（什么，不记得了，回去翻数据库的书去！）：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SHOW TABLES 'twit%'\u0026quot;\n}\n\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SHOW TABLES 'twitte_'\u0026quot;\n}\n```\n\n上面返回的结果都是：\n\n```\n     name      |     type      \n---------------+---------------\ntwitter        |BASE TABLE     \n\n```\n\n如果要查看该索引的字段和元数据，如下：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;DESC twitter\u0026quot;\n}\n```\n\n返回：\n\n```\n    column     |     type      \n---------------+---------------\ndate           |TIMESTAMP      \nid             |BIGINT         \nname           |VARCHAR        \nname.keyword   |VARCHAR        \ntwitter        |VARCHAR        \ntwitter.keyword|VARCHAR        \n```\n\n都是动态生成的字段，包含了 .keyword 字段。\n还能使用下面的命令来查看，主要是兼容 SQL 语法。\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SHOW COLUMNS IN twitter\u0026quot;\n}\n```\n\n另外，如果不记得 ES 支持哪些函数，只需要执行下面的命令，即可得到完整列表：\n\n```\nSHOW FUNCTIONS\n```\n\n返回结果如下，也就是当前6.3版本支持的所有函数，如下：\n\n```\n      name      |     type      \n----------------+---------------\nAVG             |AGGREGATE      \nCOUNT           |AGGREGATE      \nMAX             |AGGREGATE      \nMIN             |AGGREGATE      \nSUM             |AGGREGATE      \nSTDDEV_POP      |AGGREGATE      \nVAR_POP         |AGGREGATE      \nPERCENTILE      |AGGREGATE      \nPERCENTILE_RANK |AGGREGATE      \nSUM_OF_SQUARES  |AGGREGATE      \nSKEWNESS        |AGGREGATE      \nKURTOSIS        |AGGREGATE      \nDAY_OF_MONTH    |SCALAR         \nDAY             |SCALAR         \nDOM             |SCALAR         \nDAY_OF_WEEK     |SCALAR         \nDOW             |SCALAR         \nDAY_OF_YEAR     |SCALAR         \nDOY             |SCALAR         \nHOUR_OF_DAY     |SCALAR         \nHOUR            |SCALAR         \nMINUTE_OF_DAY   |SCALAR         \nMINUTE_OF_HOUR  |SCALAR         \nMINUTE          |SCALAR         \nSECOND_OF_MINUTE|SCALAR         \nSECOND          |SCALAR         \nMONTH_OF_YEAR   |SCALAR         \nMONTH           |SCALAR         \nYEAR            |SCALAR         \nWEEK_OF_YEAR    |SCALAR         \nWEEK            |SCALAR         \nABS             |SCALAR         \nACOS            |SCALAR         \nASIN            |SCALAR         \nATAN            |SCALAR         \nATAN2           |SCALAR         \nCBRT            |SCALAR         \nCEIL            |SCALAR         \nCEILING         |SCALAR         \nCOS             |SCALAR         \nCOSH            |SCALAR         \nCOT             |SCALAR         \nDEGREES         |SCALAR         \nE               |SCALAR         \nEXP             |SCALAR         \nEXPM1           |SCALAR         \nFLOOR           |SCALAR         \nLOG             |SCALAR         \nLOG10           |SCALAR         \nMOD             |SCALAR         \nPI              |SCALAR         \nPOWER           |SCALAR         \nRADIANS         |SCALAR         \nRANDOM          |SCALAR         \nRAND            |SCALAR         \nROUND           |SCALAR         \nSIGN            |SCALAR         \nSIGNUM          |SCALAR         \nSIN             |SCALAR         \nSINH            |SCALAR         \nSQRT            |SCALAR         \nTAN             |SCALAR         \nSCORE           |SCORE          \n```\n\n同样支持通配符进行过滤：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SHOW FUNCTIONS 'S__'\u0026quot;\n}\n```\n\n结果：\n\n```\n     name      |     type      \n---------------+---------------\nSUM            |AGGREGATE      \nSIN            |SCALAR         \n```\n\n那如果要进行模糊搜索呢，Elasticsearch 的搜索能力大家都知道，强！在 SQL 里面，可以用 match 关键字来写，如下：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SELECT SCORE(), * FROM twitter WHERE match(twitter, 'sql is') ORDER BY id DESC\u0026quot;\n}\n```\n\n最后，还能试试 SELECT 里面的一些其他操作，如过滤，别名，如下：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SELECT SCORE() as score,name as myname FROM twitter as mytable where name = 'medcl' OR name ='elastic' limit 5\u0026quot;\n}\n```\n结果如下：\n\n```\n     score     |    myname     \n---------------+---------------\n0.2876821      |medcl          \n```\n\n或是分组和函数计算：\n\n```\nPOST /_xpack/sql?format=txt\n{\n    \u0026quot;query\u0026quot;: \u0026quot;SELECT name,max(id) as max_id FROM twitter as mytable group by name limit 5\u0026quot;\n}\n```\n\n结果如下：\n\n```\n     name      |    max_id     \n---------------+---------------\nmedcl          |123.0          \n```\n\n## SQL-CLI下的使用\n\n上面的例子基本上把 SQL 的基本命令都介绍了一遍，很多情况下，用 RESTful 可能不是很方便，那么可以试试用 CLI 命令行工具来执行 SQL 语句，妥妥的 SQL 操作体验。\n\n切换到命令行下，启动 cli 程序即可进入命令行交互提示界面，如下：\n\n```\n➜  elasticsearch-6.3.0 ./bin/elasticsearch-sql-cli\n\n\n     .sssssss.`                     .sssssss.\n  .:sXXXXXXXXXXo`                `ohXXXXXXXXXho.\n .yXXXXXXXXXXXXXXo`            `oXXXXXXXXXXXXXXX-\n.XXXXXXXXXXXXXXXXXXo`        `oXXXXXXXXXXXXXXXXXX.\n.XXXXXXXXXXXXXXXXXXXXo.    .oXXXXXXXXXXXXXXXXXXXXh\n.XXXXXXXXXXXXXXXXXXXXXXo``oXXXXXXXXXXXXXXXXXXXXXXy\n`yXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.\n `oXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXo`\n   `oXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXo`\n     `oXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXo`\n       `oXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXo`\n         `oXXXXXXXXXXXXXXXXXXXXXXXXXXXXo`\n           .XXXXXXXXXXXXXXXXXXXXXXXXXo`\n         .oXXXXXXXXXXXXXXXXXXXXXXXXo`\n       `oXXXXXXXXXXXXXXXXXXXXXXXXo`   `odo`\n     `oXXXXXXXXXXXXXXXXXXXXXXXXo`   `oXXXXXo`\n   `oXXXXXXXXXXXXXXXXXXXXXXXXo`   `oXXXXXXXXXo`\n `oXXXXXXXXXXXXXXXXXXXXXXXXo`   `oXXXXXXXXXXXXXo`\n`yXXXXXXXXXXXXXXXXXXXXXXXo`    oXXXXXXXXXXXXXXXXX.\n.XXXXXXXXXXXXXXXXXXXXXXo`   `oXXXXXXXXXXXXXXXXXXXy\n.XXXXXXXXXXXXXXXXXXXXo`     /XXXXXXXXXXXXXXXXXXXXX\n.XXXXXXXXXXXXXXXXXXo`        `oXXXXXXXXXXXXXXXXXX-\n -XXXXXXXXXXXXXXXo`            `oXXXXXXXXXXXXXXXo`\n  .oXXXXXXXXXXXo`                `oXXXXXXXXXXXo.\n    `.sshXXyso`        SQL         `.sshXhss.`\n\nsql\u0026gt; \n```\n\n当你看到一个硕大的创口贴，表示 SQL 命令行已经准备就绪了，查看一下索引列表，不，数据表的列表：\n\n[attach]2546[/attach]\n\n各种操作妥妥的，上面已经测试过的命令就不在这里重复了，只是体验不一样罢了。\n\n如果要连接远程的 ES 服务器，只需要启动命令行工具的时候，指定服务器地址，如果有加密，指定 keystone 文件，完整的帮助如下:\n\n```\n➜  elasticsearch-6.3.0 ./bin/elasticsearch-sql-cli --help\nElasticsearch SQL CLI\n\nNon-option arguments:\nuri                  \n\nOption                   Description                                           \n------                   -----------                                           \n-c, --check \u0026lt;Boolean\u0026gt;    Enable initial connection check on startup (default:  \n                           true)                                               \n-d, --debug              Enable debug logging                                  \n-h, --help               show help                                             \n-k, --keystore_location  Location of a keystore to use when setting up SSL. If \n                           specified then the CLI will prompt for a keystore   \n                           password. If specified when the uri isn't https then\n                           an error is thrown.                                 \n-s, --silent             show minimal output                                   \n-v, --verbose            show verbose output  \n```\n\n## JDBC 对接\n\nJDBC 对接的能力，让我们可以与各个 SQL 生态系统打通，利用众多现成的基于 SQL 之上的工具来使用 Elasticsearch，我们以一个工具来举例。\n\n和其他数据库一样，要使用 JDBC，要下载该数据库的 JDBC 的驱动，我们打开： https://www.elastic.co/downloads/jdbc-client\n\n[attach]2547[/attach]\n\n\n只有一个 zip 包下载链接，下载即可。\n\n然后，我们这里使用 DbVisualizer 来连接 ES 进行操作，这是一个数据库的操作和分析工具，DbVisualizer 下载地址是：https://www.dbvis.com/。\n\n下载安装启动之后的程序主界面如下图：\n\n[attach]2548[/attach]\n\n我们如果要使用 ES 作为数据源，我们第一件事需要把 ES 的 JDBC 驱动添加到 DbVisualizer 的已知驱动里面。我们打开 DbVisualizer 的菜单【Tools】-\u0026gt; 【Driver Manager】，打开如下设置窗口：\n\n[attach]2549[/attach]\n\n点击绿色的加号按钮，新增一个名为 `Elasticsearch-SQL` 的驱动，url format 设置成 `jdbc:es:`，如下图：\n\n\n[attach]2551[/attach]\n\n\n然后点击上图黄色的文件夹按钮，添加我们刚刚下载好且解压之后的所有 jar 文件，如下：\n\n\n[attach]2550[/attach]\n\n\n添加完成之后，如下图：\n\n[attach]2555[/attach]\n\n就可以关闭这个 JDBC 驱动的管理窗口了。下面我们来连接到 ES 数据库。\n\n选择主程序左侧的新建连接图标，打开向导，如下:\n\n[attach]2554[/attach]\n\n选择刚刚加入的 Elasticsearch-SQL 驱动:\n\n[attach]2553[/attach]\n\n设置连接字符串，此处没有登录信息，如果有可以对应的填上：\n\n[attach]2556[/attach]\n\n点击 `Connect`，即可连接到 ES，左侧导航可以展开看到对应的 ES 索引信息：\n\n[attach]2557[/attach]\n\n同样可以查看相应的库表结果和具体的数据：\n\n[attach]2558[/attach]\n\n用他自带的工具执行 SQL 也是不在话下：\n\n[attach]2559[/attach]\n\n\n同理，各种 ETL 工具和基于 SQL 的 BI 和可视化分析工具都能把 Elasticsearch 当做 SQL 数据库来连接获取数据了。\n\n最后一个小贴士，如果你的索引名称包含横线，如 logstash-201811，只需要做一个用双引号包含，对双引号进行转义即可，如下：\n\n```\nPOST /_xpack/sql?format=txt\n{\n\u0026quot;query\u0026quot;:\u0026quot;SELECT COUNT(*) FROM \\\u0026quot;logstash-*\\\u0026quot;\u0026quot;\n}\n```\n\n关于 SQL 操作的文档在这里：\n\n[https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-jdbc.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-jdbc.html)\n\nEnjoy!\n","title":"玩转 Elasticsearch 的 SQL 功能","uid":"1","views":"10480","votes":"7"},"_type":"doc"}
{"_id":"688","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530149423","category_id":"44","comments":"2","has_attach":"1","id":"688","message":"Elastic Podcast 改名为 Elastic 社区电台了！\r\n\r\n[attach]2560[/attach]\r\n \r\n欢迎来到 Elastic 社区电台的第三期节目，本期嘉宾是来自上海的饿了么的两位技术负责人，饿了么是中国专业的网上订餐平台，饿了么最早从 2.3 版本开始使用 ES，从最早的 12 个集群 100个节点，每天 400 万单，到如今达到 32 个集群，300 多个节点，千万个索引，总数据量达到 60 TB，共 10 几个业务系统的接入，每天高峰处理超 800 万单数据，搜索推荐、用户交易、后台营销等都是通过 ES 来实现，欢迎收听本期节目来了解饿了么具体是如何应用 ES 以及在规模化过程中遇到的挑战。\r\n\r\n[b]主持人：[/b]\r\nElastic 技术布道师，曾勇（Medcl）。\r\n\r\n[b]嘉宾：[/b]\r\n张延明，饿了么运维专家，主要 ES 的部署、运维、JVM 性能优化。曾供职于腾讯等大公司，在业务和基础运维方面有十年的工作经验，对 ES、Kafka 等分布式技术具有强烈的兴趣，一直负责核心业务场景的运维部署。\r\n\r\n徐胜，饿了么 ES 的负责人，主要是负责 ES 的平台化研发，ES 集群和查询性能优化。负责基于 ES 构建通用搜索引擎平台。对分布式计算、大数据具有浓厚的兴趣，在 ES 分布式搜索、大数据计算、聚合统计分析、性能优化等业务场景积累了三年经验。\r\n\r\n可以点击下面的任意链接来收听（时长约 50 分钟）：\r\n[list]\r\n[*]SoundCloud：https://soundcloud.com/elastic-cn/episode-3-xusheng_zhangyanmingeleme[/*]\r\n[*]喜马拉雅：http://www.ximalaya.com/keji/14965410/94803743[/*]\r\n[*]蜻蜓 FM：http://share.qingting.fm/vchannels/244978/programs/9312932[/*]\r\n[/list]\r\n\r\n[b]关于 Elastic 社区电台[/b]\r\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\r\n\r\n[b]关于饿了么[/b]\r\n“饿了么”是中国专业的餐饮O2O平台，由拉扎斯网络科技（上海）有限公司开发运营。 作为中国餐饮业数字化领跑者，“饿了么”秉承激情、极致、创新之信仰，以建立全面完善的数字化餐饮生态系统为使命，为用户提供便捷服务极致体验，为餐厅提供一体化运营解决方案，推进整个餐饮行业的数字化发展进程。","title":"Elastic 社区电台第三期，嘉宾：徐胜/张延明@饿了么","uid":"1","views":"288","votes":"1"},"_type":"doc"}
{"_id":"693","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530408164","category_id":"18","comments":"0","has_attach":"0","id":"693","message":"1.Kibana6.3的新功能。\nhttp://t.cn/RrElkfG\n2.使用Vagrant和Ansible配置ELK Stack 。\nhttp://t.cn/RrEYfEp\n3.(自备梯子)怎么避免成为一个平庸的开发者。\nhttp://t.cn/RrEjgHw\n\n活动预告\n7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/693\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第319期 (2018-07-01)","uid":"4460","views":"284","votes":"0"},"_type":"doc"}
{"_id":"696","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530673677","category_id":"4","comments":"7","has_attach":"1","id":"696","message":"今天介绍一下 Kibana 的里程碑插件的使用，这个是一个相对还比较新的可视化插件，可以用来对具有时间上下文相关的数据，以里程碑的方式来展现这些数据点在时间轴上的关联性。\n\u0026lt;!--more--\u0026gt;\n\n这样说可能比较抽象，举个荔枝，你在 Elasticsearch 里面存的是服务器日志信息，然后有一天，老板说网站很慢，帮忙重启一下，（老板听说重启可以解决问题，反正他说他的笔记本重启之后就老快了），这个是一个已知的维护动作，所以你默默的在后台记录了重启的时间和是谁叫你重启的（这里是老板），到了月底的时候，老板让你把这个月的服务器运行数据给他看，然后问你为什么某一个时间服务器请求都为0，你打开 Kibana，指着其中一个时间点说，诺，这里，你让我重启了服务器。\n\n是的，你可以对数据进行注解，用来解释数据和异常，这个是一个很好的场景，另外，还可以关联持续集成工具，每次谁代码提交了，你把这个作为一个事件，存到 es 里面，然后用里程碑可视化显示，那么这个提交造成的服务运行指标的变化，比如性能提升和下降，就会非常直观的关联到这次代码提交，同理，软件版本的发布也是一个里程碑事件，也可以展示并关联起来。然后，在使用的时候，还可以根据时间定位到感兴趣的地方，查看该段时间都发生了哪些自定义的事件和日志，方便分析。做安全方面的分析也可以用来跟踪和做入侵事后复盘的注解。\n\n是不是，很多地方都能使用这个插件呢。\n\n插件地址：[https://github.com/walterra/kibana-milestones-vis/](https://github.com/walterra/kibana-milestones-vis/)\n\n演示截图：\n\n[attach]2592[/attach]\n\n\n关于如何使用，其实在该项目的 README 里面已经比较详细了。\n\n1.首先找到对应的 Kibana 插件的版本，如果没有可能需要手动编译插件，有的话，直接找到下载地址。\n[https://github.com/walterra/kibana-milestones-vis/releases](https://github.com/walterra/kibana-milestones-vis/releases)\n\n2.使用 Kibana 的插件安装命令下载安装\n\n```\n➜  kibana-6.2.4-darwin-x86_64 bin/kibana-plugin install https://github.com/walterra/kibana-milestones-vis/releases/download/v6.2.4/kibana-milestones-vis-6.2.4.zip\nFound previous install attempt. Deleting...\nAttempting to transfer from https://github.com/walterra/kibana-milestones-vis/releases/download/v6.2.4/kibana-milestones-vis-6.2.4.zip\nTransferring 1353656 bytes....................\nTransfer complete\nRetrieving metadata from plugin archive\nExtracting plugin archive\nExtraction complete\nOptimizing and caching browser bundles...\n\n```\n\n3.启动 Kibana，然后进入 Visualize 面板，应该就能找到这个新的 Milestone 类型的可视化组件了。\n\n\n[attach]2593[/attach]\n\n[attach]2595[/attach]\n\n加两个维护日志\n[attach]2596[/attach]\n\n[attach]2594[/attach]\n\n[attach]2597[/attach]\n\n和日志关联分析\n[attach]2598[/attach]\n\n4.还有一个隐藏的秘籍，就是可以支持图片作为标注\n[attach]2599[/attach]\n\n[attach]2600[/attach]\n\n用图片代替文字，是不是更直观，如果你的数据是电影相关的，你可以放一个电影海报替代，如果你的是历史人物相关的，比如，可以换成人物头像，地点等等。\n\n好了，是不是很炫，快去自己试试吧。","title":"Kibana 里程碑插件的使用","uid":"1","views":"1213","votes":"3"},"_type":"doc"}
{"_id":"698","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530688091","category_id":"2","comments":"0","has_attach":"1","id":"698","message":"# 内存占用\nES的JVM heap按使用场景分为可GC部分和常驻部分。\n可GC部分内存会随着GC操作而被回收；\n常驻部分不会被GC，通常使用LRU策略来进行淘汰；\n内存占用情况如下图：\n\n[attach]2601[/attach]\n\n\n\n**common space**包括了indexing buffer和其他ES运行需要的class。indexing buffer由indices.memory.index_buffer_size参数控制， 默认最大占用10%，当full up后，该部分数据被刷入磁盘对应的Segments中。这部分空间是可以被回收反复利用的。\n\n**queryCache** 是node级别的filter过滤器结果缓存，大小由indices.queries.cache.size 参数控制，默认10%。使用LRU淘汰策略。\n\n**requestCache**是shard级别的query result缓存，通常 only requests of size 0 such as aggregations, counts and suggestions will be cached。使用LRU淘汰策略。通过indices.requests.cache.size参数控制，默认1%。设置后整个NODE都生效。\n\n**fieldDataCache**，针对text字段，没有docValues属性(相当于列存储)，当对text类型字段进行sort,agg时，需要将对应的字段内容全部加载到内存，这部分数据就放在fieldDataCache。通过indices.fielddata.cache.size 参数限制大小，默认不限制。这种情况下，占用内存会逐渐增多，直到触发熔断；新数据无法加载。\n\n**segmentsMemory** ，缓存段信息，包括FST,Dimensional points for numeric range filters，Deleted documents bitset ，Doc values and stored fields codec formats等数据。这部分缓存是必须的，不能进行大小设置，通常跟index息息相关，close index、force merge均会释放部分空间。\n可以通过命令\n```js\nGET _cat/nodes?v\u0026amp;h=id,ip,port,r,ramPercent,ramCurrent,heapMax,heapCurrent,fielddataMemory,queryCacheMemory,requestCacheMemory,segmentsMemory\n```  \n\n查看当前各块的使用情况。\n\n# 熔断器\nElasticsearch 有一系列的断路器，它们都能保证内存不会超出限制：\n\n- indices.breaker.fielddata.limit\nfielddata 断路器默认设置堆的 60% 作为 fielddata 大小的上限。\n- indices.breaker.request.limit\nrequest 断路器估算需要完成其他请求部分的结构大小，例如创建一个聚合桶，默认限制是堆内存的 60%。它实际上是node level的一个统计值，统计的是这个结点上，各类查询聚合操作，需要申请的Bigarray的空间大小总和。 所以如果有一个聚合需要很大的空间，同时在执行的聚合可能也会被break掉。\n- indices.breaker.total.limit\n父熔断，inflight、request(agg)和fielddata不会使用超过堆内存的 70%。\n- network.breaker.inflight\nrequests.limit 限制当前通过HTTP等进来的请求使用内存不能超过Node内存的指定值。这个内存主要是限制请求内容的长度。 默认100%。\n- script.max_compilations_per_minute\n- 限制script并发执行数，默认值为15。\n\n\n参考文档\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.3/circuit-breaker.html#fielddata-circuit-breaker\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/cn/_limiting_memory_usage.html\nhttp://zhengjianglong.leanote.com/post/ES%E8%AE%BE%E7%BD%AE\n","title":"ES内存使用分析及熔断器设置","uid":"1629","views":"1028","votes":"4"},"_type":"doc"}
{"_id":"701","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530754726","category_id":"4","comments":"0","has_attach":"1","id":"701","message":"昨天介绍了 Kibana 的里程碑插件，举了个用里程碑来展示数据的注解，写完之后，还是觉得这个例子有点不是太好，\r\n\u0026lt;!--more--\u0026gt;\r\n\r\n第一，里程碑时间轴还是比较独立，和其他时序图形的时间轴对不上，所以看起来，很不好进行参考，虽然可以首先对时间过滤到出现异常的范围，然后再看里程碑图表的信息，不过，这个实在是体验太差了，用里程碑显示独立的里程信息应该是很好的，如果要做数据的注解，有没有更好的办法呢？\r\n\r\n答案是有的，以上一个图形展示的 TSVB 来说，TSVB 本来就自带了数据注解的功能，今天我来给大家介绍一下怎么使用。\r\n\r\n1. 打开 TSVB 的编辑，转到 Annotations 选项卡\r\n\r\n2. 在 Index Patterns 里面设置你要引用的数据，然后设置一个时间字段，此处为 `@timestamp`\r\n\r\n3. 设置要显示的 Tag 字段，支持多个，用逗号分隔\r\n\r\n4. 设置显示的标签，支持模板, `{{字段名}}`\r\n\r\n最后的效果及设置的截图，如下所示：\r\n\r\n\r\n[attach]2603[/attach]\r\n\r\n\r\n是不是很简单。","title":"Kibana TSVB 注解的使用","uid":"1","views":"477","votes":"0"},"_type":"doc"}
{"_id":"705","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531019168","category_id":"18","comments":"0","has_attach":"0","id":"705","message":"1.5个托管Kubernetes平台。\nhttp://t.cn/RdVVkPF\n2.ElasticSearch与Apache Spark一起使用。\nhttp://t.cn/Rdo7bX9\n3.(自备梯子)关于代词的错误辩论。\nhttp://t.cn/RdVbm9W\n\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/705\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第326期 (2018-07-08)","uid":"4460","views":"324","votes":"0"},"_type":"doc"}
{"_id":"708","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531230962","category_id":"2","comments":"0","has_attach":"1","id":"708","message":"[size=20][b]Part4：如何解决ES的性能问题[/b][/size]\r\n[size=14]本文是对一篇外文博客的翻译[/size]\r\n\r\nThis post is the final part of a 4-part series on monitoring Elasticsearch performance. Part 1 provides an overview of Elasticsearch and its key performance metrics, Part 2 explains how to collect these metrics, and Part 3describes how to monitor Elasticsearch with Datadog.\r\n\r\n这篇文章是监控ES性能系列文章的最后一部分。第1部分概述了ES及其关键性能指标，第2部分解释了如何收集这些指标，第3部分描述了如何使用Datadog监视ES。\r\n\r\nLike a car, Elasticsearch was designed to allow its users to get up and running quickly, without having to understand all of its inner workings. However, it’s only a matter of time before you run into engine trouble here or there. This article will walk through five common Elasticsearch challenges, and how to deal with them.\r\n\r\n就像汽车一样，用户可以在无需了解其所有内部工作原理的情况下，快速地站起来并运行。然而，在这里或那里遇到引擎故障只是时间问题。本文将介绍五种常见的ES的挑战，以及如何处理它们。\r\n\r\n[b][size=16]Problem #1: My cluster status is red or yellow. What should I do?\r\n问题#1：我的集群状态是红色或黄色。我应该做什么?[/size][/b]\r\n\r\n[attach]2650[/attach]\r\n\r\nIf you recall from Part 1, cluster status is reported as red if one or more primary shards (and its replicas) is missing, and yellow if one or more replica shards is missing. Normally, this happens when a node drops off the cluster for whatever reason (hardware failure, long garbage collection time, etc.). Once the node recovers, its shards will remain in an initializing state before they transition back to active status.\r\n\r\n回顾第1部分，如果丢失一个或多个主分片(及其副本)，集群状态将报告为红色；如果丢失一个或多个副本分片，则报告为黄色。通常，这种情况发生在节点出于某些原因(硬件故障、长时间的垃圾收集时间等)退出集群时。一旦节点恢复，它的分片在转换会活跃状态之前将保持初始化状态。\r\n\r\nThe number of initializing shards typically peaks when a node rejoins the cluster, and then drops back down as the shards transition into an active state, as shown in the graph below.\r\n\r\n初始化碎片的数量通常在节点重新加入集群时达到峰值，然后随着分片转换为活跃状态而下降，如下图所示。\r\n\r\n[attach]2645[/attach]\r\n\r\nDuring this initialization period, your cluster state may transition from green to yellow or red until the shards on the recovering node regain active status. In many cases, a brief status change to yellow or red may not require any action on your part.\r\n\r\n在此初始化期间，集群状态可能从绿色转变为黄色或红色，直到恢复节点上的分片重新恢复到活跃状态。在很多情况下，一个简短的状态变化为黄色或红色可能不需要你的任何行动。\r\n\r\n[attach]2648[/attach]\r\n\r\nHowever, if you notice that your cluster status is lingering in red or yellow state for an extended period of time, verify that the cluster is recognizing the correct number of Elasticsearch nodes, either by consulting Datadog’s dashboard or by querying the Cluster Health API detailed in Part 2.\r\n\r\n但是，如果您注意到您的集群状态在红色或黄色状态中徘徊了很长一段时间，请通过查阅Datadog的仪表板或查询第2部分中详细介绍的集群健康API来验证集群是否识别了正确的ES节点数量。\r\n\r\n[attach]2647[/attach]\r\n\r\nIf the number of active nodes is lower than expected, it means that at least one of your nodes lost its connection and hasn’t been able to rejoin the cluster. To find out which node(s) left the cluster, check the logs (located by default in the logs folder of your Elasticsearch home directory) for a line similar to the following:\r\n\r\n如果活动节点的数量低于预期，则意味着至少有一个节点失去了连接，无法重新加入集群。要找出离开集群的节点，请检查日志(默认位于您的Elasticsearch home目录的logs文件夹中)，查找与以下内容类似的行:：[code][TIMESTAMP] ... Cluster health status changed from [GREEN] to [RED][/code]\r\nReasons for node failure can vary, ranging from hardware or hypervisor failures, to out-of-memory errors. Check any of the monitoring tools outlined here for unusual changes in performance metrics that may have occurred around the same time the node failed, such as a sudden spike in the current rate of search or indexing requests. Once you have an idea of what may have happened, if it is a temporary failure, you can try to get the disconnected node(s) to recover and rejoin the cluster. If it is a permanent failure, and you are not able to recover the node, you can add new nodes and let Elasticsearch take care of recovering from any available replica shards; replica shards can be promoted to primary shards and redistributed on the new nodes you just added.\r\n\r\n节点失败的原因可能不同，从硬件失败，管理程序失败到内存不足的错误。检查监视工具，这些工具可能是在节点失败的同时出现的性能指标的异常变化，比如当前搜索或索引请求的速度突然激增。一旦您知道可能发生了什么，如果是临时故障，您可以尝试让断开连接的节点恢复并重新加入集群。如果是永久性故障，您无法恢复节点，您可以添加新节点，并让Elasticsearch负责从任何可用的副本分片中恢复，副本分片可以提升到主分片，并在刚刚添加的新节点上重新分布。\r\n\r\nHowever, if you lost both the primary and replica copy of a shard, you can try to recover as much of the missing data as possible by using Elasticsearch’s snapshot and restore module. If you’re not already familiar with this module, it can be used to store snapshots of indices over time in a remote repository for backup purposes.\r\n\r\n但是，如果您同时丢失了分片的主分片和副本，那么您可以使用ES的快照和恢复模块尽可能多地恢复丢失的数据。如果您还不熟悉这个模块，那么可以使用它在远程存储库中存储索引的快照，以便进行备份。\r\n\r\n[b][size=16]Problem #2: Help! Data nodes are running out of disk space\r\n问题#2：数据节点空间将要耗尽[/size][/b]\r\n\r\n[attach]2646[/attach]\r\n\r\nIf all of your data nodes are running low on disk space, you will need to add more data nodes to your cluster. You will also need to make sure that your indices have enough primary shards to be able to balance their data across all those nodes.\r\n\r\n如果所有数据节点的磁盘空间都很低，那么将需要向集群添加更多的数据节点。你还需要确保您的索引拥有足够的主分片，以便能够跨所有这些节点能够平衡它的数据。\r\n\r\nHowever, if only certain nodes are running out of disk space, this is usually a sign that you initialized an index with too few shards. If an index is composed of a few very large shards, it’s hard for Elasticsearch to distribute these shards across nodes in a balanced manner.\r\n\r\n但是，如果只有特定的节点耗尽了磁盘空间，这通常是你用了太多的分片在初始化索引的时候。如果一个索引是由一些非常大的分片组成的，那么用ES很难以一种平衡的方式在节点之间分布这些分片。\r\n\r\nElasticsearch takes available disk space into account when allocating shards to nodes. By default, it will not assign shards to nodes that have over 85 percent disk in use. In Datadog, you can set up a threshold alert to notify you when any individual data node’s disk space usage approaches 80 percent, which should give you enough time to take action.\r\n\r\n当master将分片分配给节点时，ES会考虑到节点可用的磁盘空间。默认情况下，它不会将分片分配给使用超过85%磁盘的节点。在Datadog中，您可以设置一个阈值警报，当任何单个数据节点的磁盘空间使用量接近80%时通知您，这应该会给您足够的时间采取行动。\r\n\r\nThere are two remedies for low disk space. One is to remove outdated data and store it off the cluster. This may not be a viable option for all users, but, if you’re storing time-based data, you can store a snapshot of older indices’ data off-cluster for backup, and update the index settings to turn off replication for those indices.\r\n\r\n对于低磁盘空间有两种补救方法。一种是删除过时的数据并将其存储在集群之外。对于所有用户来说，这可能不是一个可行的选择，但是，如果您正在存储基于时间的数据，您可以将旧索引的数据快照存储到集群之外进行备份，并更新索引设置，以关闭对这些索引的复制。\r\n\r\nThe second approach is the only option for you if you need to continue storing all of your data on the cluster: scaling vertically or horizontally. If you choose to scale vertically, that means upgrading your hardware. However, to avoid having to upgrade again down the line, you should take advantage of the fact that Elasticsearch was designed to scale horizontally. To better accommodate future growth, you may be better off reindexing the data and specifying more primary shards in the newly created index (making sure that you have enough nodes to evenly distribute the shards).\r\n\r\n如果需要继续将所有数据存储在集群上，那么第二种方法是惟一的选择：垂直或横向地伸缩集群。如果选择垂直伸缩，就意味着升级硬件。然而，为了避免再次升级，最好使用ES的横向伸缩。为了更好地适应未来的增长，你最好对数据进行索引重建，并在新创建的索引中指定更多的主碎片(确保您有足够的节点来均匀分布碎片)。\r\n\r\nAnother way to scale horizontally is to roll over the index by creating a new index, and using an alias to join the two indices together under one namespace. Though there is technically no limit to how much data you can store on a single shard, Elasticsearch recommends a soft upper limit of 50 GB per shard, which you can use as a general guideline that signals when it’s time to start a new index.\r\n\r\n横向扩展的另一种方法是创建一个新索引，并使用别名滚动改变索引。虽然从技术上讲，您可以在一个分片上存储多少数据没有限制，但Elasticsearch建议在每个碎片上设置一个50 GB的软上限，您可以将其作为一个通用指南，在开始创建新索引时发出信号。\r\n\r\n[b][size=16]Problem #3: My searches are taking too long to execute\r\n问题#3：我的搜索执行时间太长了[/size][/b]\r\n\r\nSearch performance varies widely according to what type of data is being searched and how each query is structured. Depending on the way your data is organized, you may need to experiment with a few different methods before finding one that will help speed up search performance. We’ll cover two of them here: custom routing and force merging.\r\n\r\n根据搜索的数据类型以及每个查询的结构，搜索性能会有很大的不同。根据您的数据的组织方式，您可能需要在找到一个有助于提高搜索性能的方法之前尝试一些不同的方法。我们将介绍其中的两个：自定义路由和强制合并。\r\n\r\nTypically, when a node receives a search request, it needs to communicate that request to a copy (either primary or replica) of every shard in the index. Custom routing allows you to store related data on the same shard, so that you only have to search a single shard to satisfy a query.\r\n\r\n通常，当一个节点收到一个搜索请求时，它需要将该请求传递给索引中的每个分片的副本(主分片和副本分片)。自定义路由允许你将相关数据存储在同一个shard上，这样您只需要搜索一个分片来满足查询。\r\n\r\nFor example, you can store all of blogger1’s data on the same shard by specifying a _routing value in the mapping for the blogger type within your index, blog_index.\r\n\r\n例如，你可以在索引blog_index中为blogger类型指定一个_routing值，从而将blogger1的所有数据存储在相同的分片上。\r\n\r\nFirst, make sure _routing is required so that you don’t forget to specify a custom routing value whenever you index information of the blogger type.\r\n\r\n首先，确保需要_routing，以便在索引blogger类型的信息时不会忘记指定一个定制的路由值。\r\n[code]curl -XPUT \u0026quot;localhost:9200/blog_index\u0026quot; -d '\r\n{\r\n  \u0026quot;mappings\u0026quot;: {\r\n    \u0026quot;blogger\u0026quot;: {\r\n      \u0026quot;_routing\u0026quot;: {\r\n        \u0026quot;required\u0026quot;: true \r\n      }\r\n    }\r\n  }\r\n}'[/code]\r\n当您准备索引与blogger1相关的文档时，请指定路由值:\r\n[code]curl -XPUT \u0026quot;localhost:9200/blog_index/blogger/1?routing=blogger1\u0026quot; -d '\r\n{\r\n  \u0026quot;comment\u0026quot;: \u0026quot;blogger1 made this cool comment\u0026quot;\r\n}'[/code]\r\nNow, in order to search through blogger1’s comments, you will need to remember to specify the routing value in the query like this:\r\n\r\n现在，为了搜索blogger1的评论，您需要记住在查询中指定如下的路由值:\r\n[code]curl -XGET \u0026quot;localhost:9200/blog_index/_search?routing=blogger1\u0026quot; -d '\r\n{\r\n  \u0026quot;query\u0026quot;: {\r\n    \u0026quot;match\u0026quot;: {\r\n      \u0026quot;comment\u0026quot;: {\r\n        \u0026quot;query\u0026quot;: \u0026quot;cool comment\u0026quot;\r\n      }\r\n    }\r\n  }\r\n}'[/code]\r\nIn Elasticsearch, every search request has to check every segment of each shard it hits. So once you have reduced the number of shards you’ll have to search, you can also reduce the number of segments per shard by triggering the Force Merge API on one or more of your indices. The Force Merge API (or Optimize API in versions prior to 2.1.0) prompts the segments in the index to continue merging until each shard’s segment count is reduced to max_num_segments (1, by default). It’s worth experimenting with this feature, as long as you account for the computational cost of triggering a high number of merges.\r\n\r\n在ES中，每个搜索请求都必须检查它所命中的每个分片的每一段。一旦你可以减少了搜索的分片数量，你也可以通过在一个或多个索引上触发Force Merge API来减少每个分片的段数量。强制合并API(或在2.1.0之前的版本中优化API)提示索引中的段合并，直到每个分片的段计数减少到max_num_segment(默认为1)。考虑一下这个成本和查询的时间成本，值得对该特性进行试验。\r\n\r\nWhen it comes to shards with a large number of segments, the force merge process becomes much more computationally expensive. For instance, force merging an index of 10,000 segments down to 5,000 segments doesn’t take much time, but merging 10,000 segments all the way down to one segment can take hours. The more merging that must occur, the more resources you take away from fulfilling search requests, which may defeat the purpose of calling a force merge in the first place. In any case, it’s usually a good idea to schedule a force merge during non-peak hours, such as overnight, when you don’t expect many search or indexing requests.\r\n\r\n当涉及到索引具有大量的段，段合并过程的计算开销就会大得多。例如，强制合并10000个段的索引到5000个段并不需要花费太多时间，但是将10000个段一直合并到一个段需要花费数小时。合并越多，搜索请求越快，这是调用force merge的目的。在任何情况下，通常最好在非高峰时间(比如在一夜之间)安排一个force merge，这样就不会有太多的搜索或索引请求。\r\n\r\n[b][size=16]Problem #4: How can I speed up my index-heavy workload?\r\n问题#4：怎样才能加快我的索引沉重的工作量?[/size][/b]\r\n\r\nElasticsearch comes pre-configured with many settings that try to ensure that you retain enough resources for searching and indexing data. However, if your usage of Elasticsearch is heavily skewed towards writes, you may find that it makes sense to tweak certain settings to boost indexing performance, even if it means losing some search performance or data replication. Below, we will explore a number of methods to optimize your use case for indexing, rather than searching, data.\r\n\r\nES具有许多预先配置的设置，这些设置试图确保您保留足够的资源用于搜索和索引数据。但是，如果您对ES的使用严重偏向于写操作，可能会发现调整某些设置以提高索引性能是有意义的，即使这意味着丢失一些搜索性能或数据副本。下面，我们将探索一些方法来优化索引而不是优化搜索性能。\r\n\r\nShard allocation: As a high-level strategy, if you are creating an index that you plan to update frequently, make sure you designate enough primary shards so that you can spread the indexing load evenly across all of your nodes. The general recommendation is to allocate one primary shard per node in your cluster, and possibly two or more primary shards per node, but only if you have a lot of CPU and disk bandwidth on those nodes. However, keep in mind that shard overallocation adds overhead and may negatively impact search, since search requests need to hit every shard in the index. On the other hand, if you assign fewer primary shards than the number of nodes, you may create hotspots, as the nodes that contain those shards will need to handle more indexing requests than nodes that don’t contain any of the index’s shards.\r\n\r\n分片分配：作为一种高级策略，如果你正在创建频繁更新索引的集群，请确保指定了足够的主分片，这样你就可以将索引负载均匀地分布到所有节点上。一般的建议是为集群中的每个节点分配一个主分片，可能为每个节点分配两个或多个主分片，但前提是这些节点上有大量的CPU和磁盘带宽。但是，请记住，分片过度分配会增加开销，并可能对搜索产生负面影响，因为搜索请求需要命中索引中的每个分片。另一方面，如果你分配的主碎片数量少于节点数量，那么您可能会创建热点（热节点），因为包含这些分片的节点将需要处理更多的索引请求，而不包含索引分片的节点将不做什么操作。\r\n\r\nDisable merge throttling: Merge throttling is Elasticsearch’s automatic tendency to throttle indexing requests when it detects that merging is falling behind indexing. It makes sense to update your cluster settings to disable merge throttling (by setting indices.store.throttle.type to “none”) if you want to optimize indexing performance, not search. You can make this change persistent (meaning it will persist after a cluster restart) or transient (resets back to default upon restart), based on your use case.\r\n\r\n禁用合并节流：合并节流是ES在检测到合并落后于索引时自动抑制索引请求的趋势。更新集群设置以禁用合并节流是有意义的（设置index .store.throttle.type为none）。这样做可以优化索引性能，而不是搜索。根据你的用例，你可以使这个设置为persist(意味着在集群重新启动之后它将持续)或transient(在重新启动时重新设置为默认)。\r\n\r\nIncrease the size of the indexing buffer: This setting (indices.memory.index_buffer_size) determines how full the buffer can get before its documents are written to a segment on disk. The default setting limits this value to 10 percent of the total heap in order to reserve more of the heap for serving search requests, which doesn’t help you if you’re using Elasticsearch primarily for indexing.\r\n\r\n增加索引缓冲区的大小：此设置(indices.memory.index_buffer_size)确定将文档写到磁盘上的段之前缓冲区的容量。默认设置限制为总堆的10%，以便为服务搜索请求保留更多的堆，如果您主要是在使用Elasticsearch进行索引，这对你是没有帮助。\r\n\r\nIndex first, replicate later: When you initialize an index, specify zero replica shards in the index settings, and add replicas after you’re done indexing. This will boost indexing performance, but it can be a bit risky if the node holding the only copy of the data crashes before you have a chance to replicate it.\r\n\r\n*先索引，后复制：初始化索引时，在索引设置中指定0个复制碎片，索引完成后添加副本。这将提高索引性能，但如果拥有数据惟一副本的节点在您有机会复制数据之前崩溃，则可能存在一些风险。\r\n\r\nRefresh less frequently: Increase the refresh interval in the Index Settings API. By default, the index refresh process occurs every second, but during heavy indexing periods, reducing the refresh frequency can help alleviate some of the workload.\r\n\r\n不经常刷新：增加索引设置API中的刷新间隔。默认情况下，索引refresh过程每秒钟发生一次，但是在索引不断更新的时期，减少刷新频率可以帮助减轻一些工作负载。\r\n\r\nTweak your translog settings: As of version 2.0, Elasticsearch will flush translog data to disk after every request, reducing the risk of data loss in the event of hardware failure. If you want to prioritize indexing performance over potential data loss, you can change index.translog.durability to async in the index settings. With this in place, the index will only commit writes to disk upon every sync_interval, rather than after each request, leaving more of its resources free to serve indexing requests.\r\n\r\n调整您的translog设置：在2.0版本中，弹性搜索将在每次请求之后将translog数据刷新到磁盘，从而在硬件故障时降低数据丢失的风险。如果希望将索引性能优先于潜在的数据丢失，可以更改index.translog.durability为async。有了这一点，索引将在sync_interval上提交对磁盘的写操作，而不是在每个请求之后，从而使更多的资源可以用于索引请求。\r\n\r\nFor more suggestions on boosting indexing performance, check out this guide from Elastic.\r\n\r\n有关提高索引性能的更多建议，请参阅《ES》。\r\n\r\n[b][size=16]Problem #5: What should I do about all these bulk thread pool rejections?\r\n问题#5：对于所有这些大容量线程池拒绝，我应该怎么做?[/size][/b]\r\n\r\n[attach]2649[/attach]\r\n\r\nThread pool rejections are typically a sign that you are sending too many requests to your nodes, too quickly. If this is a temporary situation (for instance, you have to index an unusually large amount of data this week, and you anticipate that it will return to normal soon), you can try to slow down the rate of your requests. However, if you want your cluster to be able to sustain the current rate of requests, you will probably need to scale out your cluster by adding more data nodes. In order to utilize the processing power of the increased number of nodes, you should also make sure that your indices contain enough shards to be able to spread the load evenly across all of your nodes.\r\n\r\n线程池的拒绝通常表明向节点发送了过多的请求或者请求速度太快。如果这是一个临时的情况（例如，本周必须索引超大量的数据，并且预期它将很快恢复正常），可以尝试降低请求的速度。但是，如果您希望集群能够维持当前的请求速率，您可能需要通过添加更多的数据节点来扩展集群。为了利用增加的节点数量的处理能力，还应该确保索引包含足够的分片，以便能够在所有节点上均匀地分配负载。\r\n\r\nGo forth and optimize!\r\n优化\r\n\r\nEven more performance tips are available in Elasticsearch’s learning resources and documentation. Since results will vary depending on your particular use case and setup, you can test out different settings and indexing/querying strategies to determine which approaches work best for your clusters.\r\n\r\n在ES的学习资源和文档中可以找到更多的性能技巧。由于结果将根据您的特定用例和设置而变化，您可以测试不同的设置和索引/查询策略，以确定哪种方法最适合您的集群。\r\n\r\nAs you experiment with these and other optimizations, make sure to watch your Elasticsearch dashboards closely to monitor the resulting impact on your clusters’ key Elasticsearch performance metrics.\r\n\r\n当您尝试这些优化和其他优化时，请确保密切关注您的ES仪表盘，以监视由此对集群的关键ES性能指标的影响。\r\n\r\nWith a built-in Elasticsearch dashboard that highlights key cluster metrics, Datadog enables you to effectively monitor Elasticsearch in real-time. If you already have a Datadog account, you can set up the Elasticsearch integrationin minutes. If you don’t yet have a Datadog account, sign up for a free trialtoday.\r\n\r\n有了一个内置的ES仪表盘，它突出关键的集群指标，Datadog使您能够实时监控弹性搜索。如果您已经有了一个Datadog帐户，那么您可以在几分钟内设置Elasticsearch集成。如果你还没有一个Datadog帐户，那么今天就注册一个免费试用。\r\n\r\nSource Markdown for this post is available on GitHub. Questions, corrections, additions, etc.? Please let us know.","title":"如何解决ES的性能问题","uid":"8625","views":"2014","votes":"1"},"_type":"doc"}
{"_id":"712","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531434336","category_id":"18","comments":"0","has_attach":"0","id":"712","message":"1、elasticAlert使用指南\nhttp://t.cn/RdDZL7C\n2、Elasticsearch must_not为什么相对较慢？\nhttp://t.cn/RdDZtfq\n3、Function Score Query优化Elasticsearch搜索结果\nhttp://t.cn/RdDZJRP\n\n活动预告\n1. 7月21日上海meetup倒计时（更大场地，等您来！）\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/712\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第331期 (2018-07-13)","uid":"1341","views":"257","votes":"0"},"_type":"doc"}
{"_id":"713","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531528067","category_id":"8","comments":"13","has_attach":"1","id":"713","message":"Elastic 官方在6月29日推出了认证服务，即 elastic certified engineer([url=https://www.elastic.co/training/certification]官方网页[/url])，在7月9日我参加了认证考试，并顺利通过拿到了这枚官方认证的徽章。\n \n\n[attach]2661[/attach]\n \n考试还是有一定难度的，需要你对 elastic 的知识面有比较全面的掌握，由于是面向 engineer 的认证，所以只是在应用层面，不会考理论深度层面，感兴趣的同学可以根据官方的考纲重点来准备考试了，下周我会和大家再详细分享下该认证考试的方式和建议。\n \nGood Luck!","title":"Elastic Certified Engineer 徽章到手！Elastic 官方认证考试","uid":"86","views":"771","votes":"4"},"_type":"doc"}
{"_id":"728","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532306013","category_id":"8","comments":"0","has_attach":"1","id":"728","message":"大家好，ElasticTalk 第4次直播将于本周进行，主题是关于 [size=18][b]Elastic 官方认证考试[/b][/size]的。\n \n我于7月初成功通过了 Elastic Certified Engineer 的考试，拿到下面的徽章。\n\n[attach]2695[/attach]\n \n感兴趣的同学可以扫下面海报中的二维码或者搜索 [b]elastic-talk[/b] 微信号，添加好友后进入直播群。\n \n\n[attach]2696[/attach]\n ","title":"【直播预告】ElasticTalk #4 Elastic 官方认证考试那些事儿","uid":"86","views":"439","votes":"2"},"_type":"doc"}
{"_id":"731","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532491799","category_id":"18","comments":"0","has_attach":"0","id":"731","message":"1. 基于 Filebeat 的容器日志采集方案\nhttp://t.cn/Re7s171\n2. Spark Streaming 实时计算在甜橙金融监控系统中的应用及优化\nhttp://t.cn/R1IILjQ\n3. 关于 Elasticsearch 属性 not_analyzed\nhttp://t.cn/Rezvf65\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/731[/url]\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第343期 (2018-07-25)","uid":"3828","views":"307","votes":"0"},"_type":"doc"}
{"_id":"734","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532649394","category_id":"5","comments":"2","has_attach":"0","id":"734","message":"Elastic 在今年6月29日推出了面向 Elasticsearch 工程师的认证考试，官方描述如下：\n\nThe Elastic Certification Program was created to recognize individuals who have demonstrated a high-level of knowledge, competence and expertise with Elasticsearch. Elastic Certified Professionals demonstrate these skills by completing challenging and relevant real-world tasks on a live Elastic Stack cluster in our hands-on, performance-based certification exams.\n\n我们此次直播便邀请中国第1位通过该认证的工程师 rockybean 来分享下认证考试的一些信息，通过这次直播，你可以了解如下信息：\n[list=1]\n[*]如何注册考试？费用？[/*]\n[*]如何准备考试？[/*]\n[*]考试的形式是怎样的？有哪些类型的考题？[/*]\n[/list]\n\n本次直播由于设备问题，声音有些卡顿，大家见谅！\n视频链接如下：\nhttp://v.qq.com/x/page/f073779epxd.html\n \n[img]http://p8z8qq24s.bkt.clouddn.com/img微信号二维码.jpeg[/img]","title":"【视频】ElasticTalk#4 Elastic认证考试那些事儿","uid":"86","views":"689","votes":"0"},"_type":"doc"}
{"_id":"741","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533248792","category_id":"18","comments":"0","has_attach":"0","id":"741","message":"1、LUCENE索引结构漫谈\nhttp://t.cn/Re1Dp6g\n2、用Elasticsearch构建电商搜索平台\nhttp://t.cn/Re1DBee\n3、ElasticSearch 监控实战\nhttp://t.cn/ReLSsjr\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/741\n订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第352期 (2018-08-03)","uid":"1341","views":"224","votes":"0"},"_type":"doc"}
{"_id":"742","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507824000","category_id":"5","comments":"0","has_attach":"1","id":"742","message":"[转载 http://www.infoq.com/cn/articles/let-data-talk-itself-shaybanon](http://www.infoq.com/cn/articles/let-data-talk-itself-shaybanon)\r\n\r\n嘉宾｜Shay Banon  ,  作者｜谢然／ InfoQ\r\n\r\n随着互联网数据规模的爆炸式增长，如何从海量的历史、实时数据中快速获取有用的信息，变得越来越具有挑战性。而这其中，搜索作为获取信息最高效的途径之一，已经越来越受到人们的青睐。\r\n\r\n一款优秀的搜索引擎，它连接了普通用户和网站网页，用户可以轻而易举且免费地搜索到想看的网站和内容，而这些网站的内容被搜索引擎检索到，通过搜索引擎技术呈现给用户。\r\n\r\n10 月 13 日，在 2017 杭州云栖大会上，Elasticsearch 与阿里云宣布达成战略合作，共同研发及发布阿里云上提供托管的 Elasticsearch，为中国市场提供崭新的用户体验。Elasticsearch 挺进中国市场面临的机遇和挑战如何？阿里云 Elasticsearch 为中国用户提供了哪些新服务？为此，InfoQ 采访了 Elasticsearch 的创始人兼首席执行官 Shay Banon。\r\n\r\n经过短短一个小时的交流，能明显感觉 Shay Banon 有着灵敏的商业嗅觉。他在搜索的领域深耕了 18 年，差不多 8 年前创立了 Elasticsearch，他说，创业最重要的是找到自己擅长的地方，并且保持激情和热爱，创业，意味着你要寻找生活中的问题，然后用创造性思维去解决它们。\r\n\r\n## Elasticsearch 源于一个食谱的应用\r\n\r\n在谈及当年接触 Lucene 并开发 Elasticsearch 的初衷的时候， Shay Banon 认为自己参与 Lucene 完全是一种偶然，当年他还是一个待业工程师，跟随自己的新婚妻子来到伦敦，妻子想在伦敦学习做一名厨师，而自己则想为妻子开发一个方便搜索菜谱的应用，所以才接触到 Lucene。直接使用 Lucene 构建搜索有很多问题，包含大量重复性的工作，所以 Shay Banon 便在 Lucene 的基础上不断地进行抽象，让 Java 程序嵌入搜索变得更容易，经过一段时间的打磨便诞生了他的第一个开源作品“Compass”，中文即“指南针”的意思。之后，他找到了一份面对高性能分布式开发环境的新工作，在工作中他渐渐发现越来越需要一个易用的、高性能、实时、分布式搜索服务，于是决定重写 Compass，将它从一个库打造成了一个独立的 server，并创建了开源项目。\r\n\r\n第一个公开版本出现在 2010 年 2 月，在那之后 Elasticsearch 已经成为 Github 上最受欢迎的项目之一。\r\n\r\n## Elasticsearch 的成功源自开源\r\n\r\n经过八年，Elasticsearch 在中国也颇受广大工程师欢迎， Shay Banon 说 Elasticsearch 成功的关键因素就是开源还有除了搜索之外的不同用例，如 日志管理、安全和分析。\r\n\r\n他认为，开放源代码搜索引擎为人们学习、研究并掌握搜索技术提供了极好的途径与素材，推动了搜索技术的普及与发展，使越来越多的人开始了解并推广使用搜索技术。使用开源搜索引擎，可以大大缩短构建搜索应用的周期，并可根据应用需求打造个性化搜索应用，甚至构建符合特定需求的搜索引擎系统。搜索引擎的开源，无论是对技术人员还是普通用户，都是一个福音。\r\n\r\nShay Banon 有一个愿景，使世界上每个开发人员能够使用搜索作为基础来简单地解决他们最复杂的用例。通过实时和大规模提供数据，Elastic 的产品已经下载了超过 1.5 亿次累积的时间，用于构建现代搜索，日志记录，安全性，指标和分析应用程序。\r\n\r\n## 技术助推力量\r\n\r\n当今世界，技术的日新月异加剧了市场竞争力的此消彼涨过程，企业越来越重视技术创新所带来的竞争力量的增强以及由此创造的短期和长期市场利益，逐步形成以技术创新为核心的发展战略。企业之间的竞争，不仅仅是规模上的竞争，更重要的是企业间的技术创新实力的较量。\r\n\r\n马云在云栖大会上演讲时，谈到技术对于未来的重要性，“在未来面前我们都是孩子，未来没有专家”，他认为未来发展得好的公司一定是能将互联网技术用得最好的公司。\r\n\r\n任何一种新兴技术，都必然要经历螺旋式上升的发展轨迹，也必须符合技术生命周期的发展规律，即从概念提出、泡沫、破灭、冷静、成熟、应用兴起，再到重生与再创新。对于企业来讲，在企业方向和研发战略上，一定要把握和尊重技术产业领域的发展规律。\r\n\r\nShay Banon 介绍了 Elasticsearch 里的几项关键技术处于的趋势。\r\n\r\n[attach]2763[/attach]\r\n\r\nShay Banon 说他及他的团队会不断在技术之路上不断创新，让 Elasticsearch 争取可以为不同的用户解决各种问题。\r\n\r\n## Elasticsearch 和阿里云合作 大步迈进中国市场\r\n\r\n当谈及 Elasticsearch 挺进中国市场的战略时， Shay Banon 表示：“中国对我们来说是一个不断增长的市场，过去几年间，我们看到 Elasticsearch 的社区版图扩展至超过 5000 多位开发人员。中国也是全球最大的市场之一，差不多有 1.9 亿的开发者，希望这 1.9 亿开发者都能用到开源的 Elasticsearch 的产品，并且取得成功。今天 Elasticsearch 选择与阿里云合作，并配合 Elasticsearch 的实时处理能力、强大的 X-Pack 功能，如 security，alerting 和 machine learning，共同加快中国广大开发者生态的创新步伐，构建、托管及管理更多不同的应用。”除此之外，Shay Banon 认为 Elasticsearch 接下来会针对中国市场，大力推广其商业化产品 X－Pack，让越来越多的人了解与使用。\r\n\r\n“阿里云 Elasticsearch” 现已正式上线，简单配置即可添加到客户的云计算服务之上。通过 Elasticsearch 实时搜索的能力与客户应用相结合，以 Logstash 或 Beats 将数据导入阿里云 Elasticsearch 里，使用 Kibana 仪表板把实时及历史数据可视化，加上 X-Pack 的一系列功能如 security、alerting、monitoring、reporting、Graph 分析及 machine learning，为开发人员提供一站式产品的体验。\r\n\r\n阿里云 Elasticsearch 的新服务能让阿里巴巴的客户随心所欲地运用 Elasticserach 强大的实时搜索、采集及数据分析功能，是一站式而且主导性的解决方案。\r\n\r\n此外，阿里云和 Elasticsearch会着力于技术提升，确保阿里云 Elasticsearch 与时并进，拥有最新的功能。在未来，日志导入功能及其他服务也将相继可用。\r\n\r\n## 搜索引擎的数据挖掘优势\r\n\r\n大数据时代，也是信息爆炸的时代，是否拥有信息已经不再重要，重要的是如何能够快速的找到所需信息，而搜索引擎在这方面有着天然优势，搜索引擎的数据挖掘将产生更加明显的效果。\r\n\r\n很多搜索技术的改进都离不开大数据技术。搜索引擎从本质上看，就是一种典型的大数据应用。目前，搜索在大数据领域已经跨进了一大步，人们可以实时搜索到想要的信息。\r\n\r\n根据最新的数据库引擎排名显示，Elasticsearch，Solr 和 Splunk 分别占据了数据库搜索引擎的前三位。\r\n\r\n[attach]2765[/attach]\r\n\r\n从趋势上来看，Elasticsearch 和 Splunk 上升明显，Elasticsearch 更是表现出了非常强劲的势头。\r\n\r\n[attach]2764[/attach]\r\n\r\n在生产环境记录应用的运行日志已经成为惯例，但日志需要经过处理和分析才有意义，第三方日志管理工具的出现正旨在解决这个问题。当下比较有代表性的日志管理工具有 Splunk 和 Logstash （注：Logstash 用途在于将数据插入到 Elasticsearch 和 Kibana 中可视化日志）。\r\n\r\nShay Banon 表示在日志分析领域，Elasticsearch 最大的竞争对手就是 Splunk ，在商业软件付钱与开源软件免费之间选择，Elasticsearch 是全世界最受欢迎的开源解决方案，而且会以灵活性，实时能力和规模地处理大量数据，所以如果你在内地问开发者，大部分开发者倾向于 Elastic Stack。\r\n\r\n他举例, 类似于 Netflix，Facebook，Microsoft 以及 Linkedln 公司在日志基础架构上会选择运行大型 Elasticsearch 集群。此外，Elastic Stack 能够在不同范畴使用，比如欺诈检测和特定领域的业务分析，这将使 Elastic 不继扩张。\r\n\r\n## 机器学习赋能用户解决复杂问题\r\n\r\n云计算的发展，使得数据的采集、处理和分析都变得容易，大数据得以存在于各行各业各种数据体系中，人工智能因此成为了一个火爆的领域。\r\n\r\n而其中的机器学习就是基于搜索技术建立起来的，而搜索带来的海量数据积累，又能够构建一套基于海量数据的数据统计分析，从而能够为一些应用场景下的关键决策带来指导和支撑。\r\n\r\nShay Banon 强调机器学习在数据搜索领域的重要价值：“以后不是跟数据讲我们要什么，而是数据主动告诉我们这边有什么，这就是机器学习的力量。\r\n\r\n## 一点小小的担忧\r\n\r\n搜索引擎知道我们的出行路线、地理位置、工作信息、日常行为模式和交际圈子，它比任何保险公司或银行都了解我们的风险状况，随着可穿戴智能设备的兴起，它也可能比医生更了解我们自身的身体状况。或者说，搜索引擎将变得比我们自己更了解自己。\r\n\r\n这是信息时代独特的背景，对于效率的追求使我们不可避免的享受互联网搜索引擎等服务带给我们的信息服务，同时也不可避免的享受个人信息外泄的苦恼。搜索引擎的机器学习势必需要越来越多的用户信息，这与我们的隐私权存在本质上的冲突。或许，我们已经意识到这一点，但在效率面前对此无能为力。\r\n\r\n## 给广大工程师的建议：\r\n\r\n计算机世界变化的速度是惊人的。程序员被认为是最接近计算机世界的职业，几乎所有的科技新产品都得由程序员来写代码。\r\n\r\nShay Banon 建议广大程序员要不断地学习新的技能，并且铭记在过往使用那些技能时得到的经验。有激情，并且热爱这份职业，时刻站在终端用户的角度去评估自己所编写的软件，而不是在封闭的空间里编写代码。\r\n\r\n除此之外，程序员还要擅于借助工具，开发过程中选择适合自己和项目开发所需要的工具。正所谓工欲善其事, 必先利其器。\r\n\r\n## 写在最后：\r\n\r\nShay Banon 非常喜欢马云说过的这句话，“帮助年轻人，帮助弱小的人，因为小树苗也可能成长为参天大树。你将种子埋入这些年轻人的脑中，等他们成长起来，就可以改变世界。”\r\n\r\n帮助别人，让别人强大，你才能更强大。这才是生命的意义。\r\n\r\n-END-","title":"Elasticsearch 创始人 Shay Banon：让数据自己说话","uid":"1","views":"192","votes":"0"},"_type":"doc"}
{"_id":"752","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534039107","category_id":"18","comments":"0","has_attach":"0","id":"752","message":"1.(自备梯子)ELK Stack 详细配置。\nhttp://t.cn/RDWHBvW\n2.Elasticsearch安全性：身份验证，加密，备份。\nhttp://t.cn/RDWl15I\n3.(自备梯子)数据科学中必备的数学知识。\nhttp://t.cn/RDWYsfF\n\n活动预告：\nElastic 中国开发者大会预热票发售进行中 \nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/752\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第361期 (2018-08-12)","uid":"4460","views":"298","votes":"0"},"_type":"doc"}
{"_id":"754","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534153979","category_id":"2","comments":"2","has_attach":"0","id":"754","message":"在一年多以前，我写过[url=https://elasticsearch.cn/article/120]Elasticsearch 5 入坑指南[/url]一文，其中提到将生产的某个ES集群从2.4升级到5.0以后， 冷数据结点搜索性能变差，对大索引进行搜索的时候，io read会长时间飙高，导致系统load很重，甚至到无法响应的程度。\n \n通过进一步分析，用Linux下的[b]Sar -B[/b]命令，可以看到有大量的数据被pagein到内存。 虽然通过“试”的方法，定位到这个问题和5.0开始使用的mmap fs有关联，并且通过更改为nio fs以后得到解决，但问题的底层根源一直没找到。 \n \n近期有空重新去看了一下这个问题， 在Github上发现一个对os底层更熟悉的人提交并分析了类似的问题 [url=https://github.com/elastic/elasticsearch/issues/27748]Avoid file cache trashing on Linux with mmapfs by using madvise[/url] 。  细读之后，感觉该文抓到了问题的本质，以下基于该文做个总结:\n[list=1]\n[*]mmap fs对比nio fs，省去了磁盘io上的系统调用，并且不需要在jvm内部做io缓存，也减轻了GC压力。 所以通常来说，mmapfs的性能应该更高。 这也是为什么lucene推荐使用mmap fs，并且ES从5.0开始做为默认的store配置的原因。[/*]\n[*]然而，mmap系统调用，在内核层面默认会有一个2MB的预读大小设置，也就是说，当映射了一个大文件以后，即使读取其中1k个字节，mmap也会预读取2MB的数据到缓存。 这种策略是基于文件的访问大多数是顺序的假设。[/*]\n[*]在ES这个特定的应用场景，如果某数据结点上索引不是很大，系统剩余缓存也足够，一般不会有问题。但是如果是大数据应用场景，典型的如海量的日志ELK应用，则可能对大索引的搜索聚合，产生较多的随机磁盘访问。 从而mmap的预读策略，可能会导致大量的无用数据从磁盘读取到系统缓存。 在系统可用的缓存不是非常宽裕的情况下，某些极端场景下，会导致热数据被过于频繁的踢出内存，再反复读入，让磁盘IO不堪重负。[/*]\n[*]Lucene有一个[b]NativePosixUtil.madvise(buffer,NativePosixUtil.RANDOM)[/b]的native调用，可以用于指导内核对mmap过的文件做读取的时候，禁用预读。 上文作者将该调用hack进lucene代码，做搜索对比测试。 结论是对于磁盘io和cache的消耗，niofs都要好于mmapfs，而patch过的mmapfs则比niofs更好。[/*]\n[*]作者的测试仅限于搜索，对于其他类型的io操作，如写入，merge没有做过详尽测试，因此不清楚利弊。[/*]\n[*]ES官方开发人员认为这是一个有趣的发现，值得深入去探究。对于用户报告的mmap fs性能比nio fs更差的问题，猜测可能是在大索引读取的场景下，预读带来的额外开销，抵消了相对niofs节省的系统调用等开销。 [/*]\n[*]ES官方提到Lucene已经有一种类似功能的store，叫做NativeUnixDirectory（显然ES目前还没有对这种store的支持)，用户动手能力强的话，应该可以利用这个store自己写一个ES plugin。 另外提到JAVA 10提供了O_DIRECT to streams / channels ，似乎官方打算等这个出来以后再看怎么处理这个问题。[/*]\n[*]要注意，这个预读是mmap层面的，和块设备的预读是两回事。 我们曾经尝试过使用 [b]blockdev --setra[/b] 这个linux命令取消块设备预读，证实无法解决这个问题。[/*]\n[/list]\n \n结论: 如果ES结点上会存放海量的索引数据，经常会有大索引（如1TB+)的搜索聚合操作，使用NIOFS会更安全，可以避免很多怪异的性能问题。\n ","title":"Mmap fs可能让大索引访问变得缓慢","uid":"81","views":"728","votes":"17"},"_type":"doc"}
{"_id":"755","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534211224","category_id":"18","comments":"0","has_attach":"0","id":"755","message":"1.你应该在MadCap Flare中使用Elasticsearch进行模糊匹配吗？\nhttp://t.cn/RDRY7EB\n2.使用Elasticsearch 6.3 Rollup 合并旧日志。\nhttp://t.cn/Rdr8LIZ\n3.Ub​untu 搭建 Elasticsearch 6 集群流程​。\nhttp://t.cn/RDRYbjM\n\n活动预告：\nElastic 中国开发者大会预热票发售进行中\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url]\n \n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/755\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第363期 (2018-08-14)","uid":"3788","views":"260","votes":"1"},"_type":"doc"}
{"_id":"759","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534413473","category_id":"16","comments":"15","has_attach":"1","id":"759","message":"\r\n[attach]2853[/attach]\r\n 时间：9月8日\r\n地点：北京市海淀区上地西路6号，联想研究院圆楼三层报告厅\r\n活动页面：[url]https://meetup.elasticsearch.cn/2018/beijing.html[/url] \r\n\r\n议题：征集中，等你来投稿\r\n[list]\r\n[*]58到家搜索服务化实践和演进  -- 邢天宇/五八到家[/*]\r\n[*]Elasticsearch在百度aladdin日志系统的应用  -- 王鹏/百度[/*]\r\n[*]elasticsearch 在58集团信息安全部的应用 -- 亢伟楠/五八集体[/*]\r\n[*]Waterdrop：构建在Spark之上的简单高效数据处理系统  -- 霍晨/新浪网[/*]\r\n[*]基于 ElasticSearch 构建个性化推荐和高级搜索  -- 周金阳/果壳网/在行[/*]\r\n[/list]\r\n \r\n报名地址：[url]http://elasticsearch.mikecrm.com/fUqiv0T[/url] \r\n\r\n演讲主题介绍\r\n \r\n[size=14][b]#1 基于 ElasticSearch 构建个性化推荐和高级搜索[/b][/size]\r\n[周金阳]周金阳果壳网/在行 算法工程师\r\n使用 ES 来构建一个简易却行之有效的个性化推荐系统，以及一些高级搜索排序的实践。\r\n搜索排序主要是分享一些机器学习工具与 ES 配合的实践心得。\r\n \r\n[b][size=14]#2 elasticsearch 在58集团信息安全部的应用[/size][/b]\r\n\r\n[亢伟楠]亢伟楠58集团 资深开发工程师\r\n全面介绍 ELK Stack 在58集团信息安全部的落地，升级，优化以及应用。\r\n包括如下等方面：接入背景，存储选型，性能挑战，master node以及data node优化，安全实践，高吞吐量以及低延迟搜索优化；kibana 的落地，本地化使其更方便产品、运营使用。\r\n \r\n[b][size=14]#3 58到家搜索服务化实践和演进[/size][/b]\r\n\r\n[邢天宇]邢天宇北京五八到家信息技术有限公司 java工程师\r\n介绍58到家搜索服务体系的构建和普及，elasticsearch在到家中的各种应用以及优化等等。\r\n \r\n[size=14][b]#4 Waterdrop：构建在Spark之上的简单高效数据处理系统[/b][/size]\r\n\r\n[霍晨]霍晨新浪网,大数据研发工程师\r\n大数据时代，随着Spark等工具的出现，数据处理能力在逐渐提升。\r\n但是Spark本身的开发和运维具有一定的成本，为此我们开源了Waterdrop，通过配置文件的形式配置Spark任务，企图降低Spark的使用门槛，减小开发和运维成本\r\n- 什么是waterdrop\r\n- Waterdrop架构介绍\r\n- Waterdrop VS Spark\r\n- Waterdrop VS Logstash\r\n- Waterdrop的优势\r\n- Waterdrop使用场景\r\n- Roadmap\r\n \r\n[b][size=14]#5 elasticsearch在百度aladdin日志系统的应用[/size][/b]\r\n\r\n[王鹏]王鹏百度,研发工程师\r\n背景：aladdin建库问题相关的case追查，日志统计分析，问题需要解决。\r\n方案：使用ES（es版本： 6.0.0）做存储和检索系统，日志以json格式，抽取重要字段建索引，每天一个index，index名字包含时间后缀，保存三天内的数据；建库10个模块，每天有100亿条记录，20T左右数据；使用20个容器做集群。\r\n效果：毫秒级返回查询结果，利用kibana实时分析建库情况，同时能方便按需提供数据给业务方。\r\n\r\n \r\n报名地址：http://elasticsearch.mikecrm.com/fUqiv0T \r\n \r\n \r\nElastic 中国开发者大会 2018，阵容强大，正在火热售票中 ?\r\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url]","title":"9月8日 Elastic Meetup 北京线下沙龙报名中","uid":"1","views":"2294","votes":"2"},"_type":"doc"}
{"_id":"767","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535027893","category_id":"18","comments":"0","has_attach":"0","id":"767","message":"1.Elasticsearch 6.x Mapping设置\nhttp://t.cn/RkK4iEb\n2.你真的理解grok吗？\nhttp://t.cn/RkK4NwF\n3.如何在Elasticsearch中使用排名评估API\nhttp://t.cn/RkK4nQx\n[b]活动预告：[/b]\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/767\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第372期 (2018-08-23)","uid":"3851","views":"211","votes":"0"},"_type":"doc"}
{"_id":"773","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535337856","category_id":"18","comments":"0","has_attach":"0","id":"773","message":"1、elastic 官方韩语分析器\nhttp://t.cn/RkdWBXP\n2、（自备梯子）运行和扩展巨大的es集群\nhttp://t.cn/RkgA6dF\n3、跟随elastic解决方案架构团队成员，了解elastic stack架构最佳实践\nhttp://t.cn/RkdT4CC\n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/773\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第376期 (2018-08-27)","uid":"4063","views":"260","votes":"0"},"_type":"doc"}
{"_id":"778","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535636571","category_id":"18","comments":"0","has_attach":"0","id":"778","message":"1.OTTO Motors: 使用elastic stack扩展物联网环境\nhttp://t.cn/RF5H9OG\n2.ELK构建MySQL慢日志收集平台详解\nhttp://t.cn/Rk7zKT7\n3.千亿级数量下日志分析系统的技术架构选型\nhttp://t.cn/RF5HEhS\n\n活动预告：\n1.Elastic 中国开发者大会最后一波早鸟票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2.Elastic Meetup 9月8日 北京线下沙龙正在报名中\n[url]https://elasticsearch.cn/article/759[/url]\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/778\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第379期 (2018-08-30)","uid":"668","views":"316","votes":"0"},"_type":"doc"}
{"_id":"782","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535848847","category_id":"18","comments":"0","has_attach":"0","id":"782","message":"1.如何将Heroku日志导入到Logsene / Managed ELK Stack。\nhttp://t.cn/RFSfTz6\n2.5分钟将CoreOS日志导入到ELK。\nhttp://t.cn/RFSxz0S\n3.苹果圈：iPhone XS推出9月12日确认，新iPhone SE 2泄漏，苹果公司的恐慌方案。\nhttp://t.cn/RFS9bWj\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/782\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第382期 (2018-09-02)","uid":"4460","views":"260","votes":"0"},"_type":"doc"}
{"_id":"784","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535961625","category_id":"12","comments":"0","has_attach":"1","id":"784","message":"[attach]2861[/attach]\nElasticsearch 的排名又升了，要不要加入这么一家蒸蒸日上的全球领先的开源软件公司？\n\n职位链接及描述如下：\n[https://boards.greenhouse.io/elastic/jobs/1272161](https://boards.greenhouse.io/elastic/jobs/1272161?gh_src=76e502301)\n\nAt Elastic, we have a simple goal: to solve the world's data problems with products that delight and inspire. As the company behind the popular open source projects — Elasticsearch, Kibana, Logstash, and Beats — we help people around the world do great things with their data. From stock quotes to Twitter streams, Apache logs to WordPress blogs, our products are extending what's possible with data, delivering on the promise that good things come from connecting the dots. The Elastic family unites employees across 32 countries into one coherent team, while the broader community spans across over 100 countries.\n\nFor all of us at Elastic, community matters. Our users and contributors have helped to ensure that Elasticsearch, Kibana, Logstash, and Beats are more than just code — they are open source projects that people love to use, and love to talk about! As our Community Advocate you will champion our Elastic community.\n\n## What You Will Be Doing:\n\nAre you that kind of person who is invigorated by sharing juicy technology goodness with the world? Do you feel at home connecting with the community members: in person, on blogs, in forums, via social channels, and at events? Is presenting at local meetups your jam and are you passionate about the Elastic Stack?\n\n## Well, this might just be your dream job.\n\nAs a Community Advocate at Elastic, you will be based in China. You will wake up each morning eager to design and deliver presentations at a wide-variety of events from customer meetings, meetups, tradeshows, and other events to help showcase technology. You will do this while traveling the region and, at times, the world, representing Elastic. Maintaining the trust of our community, as well as the respect and trust within the team, is foundational.\n\n## What You Bring Along:\n\n- Bachelor’s degree in a technical field (e.g. CS, CSE, EE) or relevant work experience as a software developer (mandatory)\n- Demonstrated ability to craft compelling content - including speaking engagements, blog posts, demos, messaging, etc. (mandatory)\n- You are comfortable presenting, whether it's at a local meetup or to the office of a C-suite member\n- Familiarity with, and real passion for, the Elastic Stack\n- Comfort working with a globally distributed team\n- Fluency or high working proficiency in Mandarin (mandatory)\n- Excellent spoken and written English communication skills, since this is our company's language (mandatory)\n\n## Please send us your CV in English. Things We'd Be Stoked to See on Your CV:\n\n- Conversations in person, on blogs, in forums, via social channels, at events give you energy and you have a proven publication history to show that\n- Experience working for a startup or an early stage company\n- Experience with open source software and/or commercial open source companies\n- Technical background and abilities in APM, PHP, node.js, JS, and/or security (nice-to-have, not mandatory)\n- Other languages\n\n## Additional Information:\n\n- Competitive pay based on the work you do here and not your previous salary\n- Stock options\n- Global minimum of 16 weeks of paid parental leave (moms and dads)\n- Generous vacation time and one week of volunteer time off\n- An environment in which you can balance great work with a great life\n- Your age is only a number. It doesn't matter if you're just out of college or your children are; we need you for what you can do.\n- Distributed-first company with Elasticians in over 30 countries, spread across 18 time zones, and speaking over 30 languages!\n\n## LI-KE1\n\nTarget locations: Beijing, China; Shanghai, China; Hangzhou, China\n\nElastic is an Equal Employment employer committed to the principles of equal employment opportunity and affirmative action for all applicants and employees. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status or any other basis protected by federal, state or local law, ordinance or regulation. Elastic also makes reasonable accommodations for disabled employees consistent with applicable law.","title":"[招聘] Community Advocate - China","uid":"1","views":"554","votes":"0"},"_type":"doc"}
{"_id":"805","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537338496","category_id":"1","comments":"0","has_attach":"0","id":"805","message":"社区最近迁移到了阿里巴巴的服务器，默认屏蔽了25端口，并且申请也不给开，所以一段时间以来，大家的邮件都不能正常收到，不过经过两天努力，最终还是想办法解决了。?\n新注册的用户可以重新发送确认邮件。?\n \n最后，为 Elastic 开发者大会打个 call，阔别2年的大会今年回来了，众多精彩的分享，不管您是 Elasticsearch 初学者还是资深的用户，都不要错过哦， 最后，送上 8 折优惠码一张：[url=https://www.bagevent.com/event/1654662?discountCode=F183f3d]F183f3d[/url] 。","title":"社区邮件服务器已恢复","uid":"1","views":"152","votes":"0"},"_type":"doc"}
{"_id":"785","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536036086","category_id":"18","comments":"0","has_attach":"0","id":"785","message":"1.Bulk 异常引发的 Elasticsearch 内存泄漏排查。\nhttp://t.cn/RFBHC1p\n2.使用elastichq监控Elasticsearch机器。\nhttp://t.cn/RFBHHLy\n3.使用ELK分析应用事件和日志。\nhttp://t.cn/RFBHnLN\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/785\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第384期 (2018-09-04)","uid":"3788","views":"245","votes":"0"},"_type":"doc"}
{"_id":"786","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536038267","category_id":"3","comments":"0","has_attach":"0","id":"786","message":"从Logstash 1.5开始，我们可以在logstash配置中使用metadata。metadata不会在output中被序列化输出，这样我们便可以在metadata中添加一些临时的中间数据，而不需要去删除它。\n\n我们可以通过以下方式来访问metadata:\n\n```\n[@metadata][foo]\n```\n\n\n\n# 用例\n\n假设我们有这样一条日志：\n\n```\n[2017-04-01 22:21:21] production.INFO: this is a test log message by leon\n```\n\n\n\n我们可以在filter中使用grok来做解析:\n\n```ruby\ngrok {\n      match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;\\[%{TIMESTAMP_ISO8601:timestamp}\\] %{DATA:env}\\.%{DATA:log_level}: %{DATA:content}\u0026quot; }\n    }\n```\n\n解析的结果为\n\n```ruby\n{\n      \u0026quot;env\u0026quot; =\u0026gt; \u0026quot;production\u0026quot;,\n      \u0026quot;timestamp\u0026quot; =\u0026gt; \u0026quot;2017-04-01 22:21:21\u0026quot;,\n      \u0026quot;log_level\u0026quot; =\u0026gt; \u0026quot;INFO\u0026quot;,\n      \u0026quot;content\u0026quot; =\u0026gt; \u0026quot;{\\\u0026quot;message\\\u0026quot;:\\\u0026quot;[2017-04-01 22:21:21] production.INFO: this is a test log message by leon\\\u0026quot;}\u0026quot;\n}\n```\n\n\n\n假设我们希望\n\n1. 能把log_level为INFO的日志丢弃掉，但又不想让该字段出现在最终的输出中\n2. 输出的索引名中能体现出env，但也不想让该字段出现在输出结果里\n\n对于1，一种方案是在输出之前通过mutate插件把不需要的字段删除掉，但是一旦这样的处理多了，会让配置文件变得“不干净”。\n\n通过 metadata，我们可以轻松地处理这些问题：\n\n```ruby\ngrok {\n    match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;\\[%{TIMESTAMP_ISO8601:timestamp}\\] %{DATA:[@metadata][env]}\\.%{DATA:[@metadata][log_level]}: %{DATA:content}\u0026quot; }\n}\n\nif [@metadata][log_level] == \u0026quot;INFO\u0026quot;{\n    drop{}    \n}\n    \noutput{\n    elasticsearch {\n        hosts =\u0026gt; [\u0026quot;127.0.0.1:9200\u0026quot;]\n        index =\u0026gt; \u0026quot;%{[@metadata][env]}-log-%{+YYYY.MM}\u0026quot;\n        document_type =\u0026gt; \u0026quot;_doc\u0026quot;\n    }\n}\n```\n\n除了简化我们的配置文件、减少冗余字段意外，同时也能提高logstash的处理速度。\n\n\n\n\n\n# Elasticsearch input插件\n\n有些插件会用到metadata这个特性，比如elasticsearch input插件：\n\n```ruby\ninput {\n  elasticsearch {\n    host =\u0026gt; \u0026quot;127.0.0.1\u0026quot;\n    # 把 ES document metadata (_index, _type, _id) 包存到 @metadata 中\n    docinfo_in_metadata =\u0026gt; true\n  }\n}\n\nfilter{\n    ......\n}\n\noutput {\n  elasticsearch {\n    document_id =\u0026gt; \u0026quot;%{[@metadata][_id]}\u0026quot;\n    index =\u0026gt; \u0026quot;transformed-%{[@metadata][_index]}\u0026quot;\n    type =\u0026gt; \u0026quot;%{[@metadata][_type]}\u0026quot;\n  }\n}\n```\n\n\n\n# 调试\n\n一般来说metadata是不会出现在输出中的，除非使用 rubydebug codec 的方式输出：\n\n```\noutput { \n  stdout { \n    codec  =\u0026gt; rubydebug {\n      metadata =\u0026gt; true\n    }\n  }\n}\n```\n\n日志经过处理后输出中会包含：\n\n```ruby\n{\n    ....,\n    \u0026quot;@metadata\u0026quot; =\u0026gt; {\n        \u0026quot;env\u0026quot; =\u0026gt; \u0026quot;production\u0026quot;,\n        \u0026quot;log_level\u0026quot; =\u0026gt; \u0026quot;INFO\u0026quot;\n    }\n}\n```\n\n\n\n# 总结\n\n由上可见，metadata提供了一种简单、方便的方式来保存中间数据。这样一方面减少了logstash配置文件的复杂性：避免调用`remove_field`，另一方面也减少了输出中的一些不必要的数据。通过这篇对metadata的介绍，希望能对大家有所帮助。\n\n![elasticTalk,qrcode](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)","title":"通过 metadata 使logstash配置更简洁","uid":"9765","views":"626","votes":"3"},"_type":"doc"}
{"_id":"787","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536110615","category_id":"4","comments":"0","has_attach":"0","id":"787","message":"# Cleaner\n\n\u0026gt; 这是一个管理index TTL 插件，精美UI，高效运维管理elasticsearch index助手\n\n[https://github.com/TrumanDu/cleaner](https://github.com/TrumanDu/cleaner)\n---\n\n## screenshots\n\n![](https://github.com/TrumanDu/cleaner/raw/master/screenshots/demo.gif)\n\n## config\n1. scheduleTime\n\n    server job schedule period,unit second ,default value is 60 second.\n\n    you can edit it. like: ```cleaner.scheduleTime: 100```\n2. mergePattern\n\n    merge pattern,default value is ```[^a-z]+$```.\n\n    you can edit it. like: ```cleaner.mergePattern: '[\\d]{4}[-|\\.|/][\\d]{1,2}[-|\\.|/][\\d]{1,2}'```\n\n## development\n\nSee the [kibana contributing guide](https://github.com/elastic/kibana/blob/master/CONTRIBUTING.md) for instructions setting up your development environment. Once you have completed that, use the following npm tasks.\n\n  - `npm start`\n\n    Start kibana and have it include this plugin\n\n  - `npm start -- --config kibana.yml`\n\n    You can pass any argument that you would normally send to `bin/kibana` by putting them after `--` when running `npm start`\n\n  - `npm run build`\n\n    Build a distributable archive\n\n  - `npm run test:browser`\n\n    Run the browser tests in a real web browser\n\n  - `npm run test:server`\n\n    Run the server tests using mocha\n\nFor more information about any of these commands run `npm run ${task} -- --help`.\n","title":"推荐kibana插件Cleaner 管理ES index TTL","uid":"5051","views":"587","votes":"1"},"_type":"doc"}
{"_id":"789","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536120007","category_id":"44","comments":"0","has_attach":"1","id":"789","message":"[前几期忘记发了，补上]\r\n\r\n[attach]2866[/attach]\r\n\r\n 欢迎来到 Elastic 社区电台的第三期节目，本期嘉宾是来自上海饿了么公司的两位技术负责人。饿了么是中国专业的网上订餐平台，饿了么最早从 2.3 版本开始使用 Elasticsearch，从最早的 12 个集群，100 个节点，每天 400 万单，到如今达到 32 个集群，300 多个节点，千万个索引，总数据量达到 60 TB，共十几个业务系统的接入，每天高峰处理超 800 万单数据，搜索推荐、用户交易、后台营销等均通过 Elastic Stack 来实现。欢迎收听本期节目，了解饿了么应用 Elastic Stack 的具体情况、在规模化过程中遇到的挑战，以及他们的经验分享。\r\n\r\n\r\n[b]主持人：[/b]\r\n\r\nElastic 技术布道师，曾勇（Medcl）。\r\n\r\n\r\n[b]嘉宾：[/b]\r\n\r\n张延明，饿了么运维专家，主要负责 ES 的部署、运维和 JVM 性能优化。曾供职于腾讯等大公司，在业务和基础运维方面有十年的工作经验，对 ES、Kafka 等分布式技术具有强烈的兴趣，一直负责核心业务场景的运维部署。\r\n\r\n\r\n徐胜，饿了么 ES 的负责人，主要负责 ES 的平台化研发、ES 集群和查询性能优化，以及基于 ES 构建通用搜索引擎平台。对分布式计算、大数据具有浓厚的兴趣，在 ES 分布式搜索、大数据计算、聚合统计分析、性能优化等业务场景积累了三年经验。\r\n\r\n\r\n\r\n[b]可以点击下面的任意链接来收听（时长约 45 分钟）：[/b]\r\n\r\nApple iTunes：https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/id1415654232?mt=2\r\n喜马拉雅：http://www.ximalaya.com/keji/14965410/94803743\r\n蜻蜓 FM：http://share.qingting.fm/vchannels/244978/programs/9312932\r\n\r\n\r\n[b]关于 Elastic 社区电台[/b]\r\n\r\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\r\n\r\n\r\n[b]关于饿了么[/b]\r\n\r\n“饿了么”是中国专业的餐饮O2O平台，由拉扎斯网络科技（上海）有限公司开发运营。 作为中国餐饮业数字化领跑者，“饿了么”秉承激情、极致、创新之信仰，以建立全面完善的数字化餐饮生态系统为使命，为用户提供便捷服务极致体验，为餐厅提供一体化运营解决方案，推进整个餐饮行业的数字化发展进程。\r\n\r\n ","title":"Elastic 社区电台第三期，嘉宾：徐胜/张延明@饿了么","uid":"1","views":"245","votes":"0"},"_type":"doc"}
{"_id":"792","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536372366","category_id":"18","comments":"0","has_attach":"0","id":"792","message":"1. 用ElasticCloud上的ES精准分析空气质量数据\n[http://t.cn/RsIi2c0](http://t.cn/RsIi2c0) \n\n2. ES painless用法示例。\n[http://t.cn/RsIgnOF](http://t.cn/RsIgnOF) \n\n3. 一周热点：Google推出数据集搜索\n[http://t.cn/Rs2xE82](http://t.cn/Rs2xE82) \n \n\n活动预告\n\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/792\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第388期 (2018-09-08）","uid":"1874","views":"292","votes":"0"},"_type":"doc"}
{"_id":"803","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537176205","category_id":"44","comments":"0","has_attach":"1","id":"803","message":"\r\n[attach]2893[/attach]\r\n 欢迎来到 Elastic 社区电台的第四期节目，本期嘉宾是来自 eBay 中国研发中心 Pronto 团队的两位技术负责人。eBay 的 Pronto 平台是 eBay 内部用于托管 Elasticsearch 集群的平台，该平台使得 eBay 内部客户能够更加方便地部署和使用 Elasticsearch。当前 Pronto 平台管理着 50 多个 Elasticsearch 集群和超过 2000 多个数据节点。本期节目我们会聊聊 eBay如何应对这样大规模部署的挑战，介绍他们开发的各种自定义插件和相关工具，还会有非常多的经验分享。\r\n\r\n\r\n[b]嘉宾[/b]\r\n\r\n丁旻奕， 软件工程师，在eBay Pronto从事ES软件即服务云的开发工作。 \r\n阮一鸣，软件工程师，在 eBay 从事软件开发工作。\r\n\r\n[b]收听节目[/b]\r\n\r\n可以点击下面的任意链接来收听（时长约 37 分钟）：\r\n[list]\r\n[*]Apple iTunes：[url]https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/id1415654232?mt=2[/url][/*]\r\n[*]喜马拉雅：[url]https://www.ximalaya.com/keji/14965410/100939459[/url][/*]\r\n[*]蜻蜓 FM：[url]http://m.qingting.fm/vchannels/244978/programs/9501001[/url][/*]\r\n[/list]\r\n\r\n[b]主持人[/b]\r\n\r\nElastic 技术布道师，曾勇（Medcl）。\r\n\r\n[b]关于 Elastic 社区电台[/b]\r\n\r\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\r\n\r\n\r\n[b]关于 eBay[/b]\r\n\r\neBay (NASDAQ:EBAY; http://www.ebay.com) 是全球最大的网络交易平台之一。经过二十多年的发展，eBay 成长为历史上发展最快的公司之一。目前eBay在全球33个国家和地区设有分支机构，拥有超过 2.12亿注册用户，被誉为全球互联网上最受欢迎的购物网站。","title":"Elastic 社区电台第四期，嘉宾：阮一鸣/丁旻奕@eBay","uid":"1","views":"184","votes":"0"},"_type":"doc"}
{"_id":"806","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537339667","category_id":"5","comments":"0","has_attach":"0","id":"806","message":"今天 Elasticsearch 的小的bug 修复版本 v6.4.1 已经发布，主要修复了 rollover 的一个 bug，如果你在用 Rollover 功能，请尽快升级！\nElasticsearch can once again start if any shards on the node have been rolled over. [url=https://github.com/elastic/elasticsearch/pull/33394]#33394[/url]\n \n下载地址：\nhttps://www.elastic.co/downloads/elasticsearch\n \n \nElastic Stack 家族的其他部分也发布了，更新内容还不少哦。\nKibana v6.4.1：https://www.elastic.co/guide/en/kibana/6.4/release-notes-6.4.1.html\nLogstash v6.4.1: https://www.elastic.co/guide/en/logstash/6.4/logstash-6-4-1.html\nBeats v6.4.1: https://www.elastic.co/guide/en/beats/libbeat/6.4/release-notes-6.4.1.html\n \n ","title":"Elasticsearch  v6.4.1 发布","uid":"1","views":"586","votes":"2"},"_type":"doc"}
{"_id":"827","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539240696","category_id":"16","comments":"8","has_attach":"1","id":"827","message":"[attach]3015[/attach]\n \n[b]什么东西?[/b]\nElastic 官方的技能认证，官网介绍链接：\nhttps://www.elastic.co/training/certification\n \n[b]考试内容及范围：[/b]\nhttps://training.elastic.co/exam/elastic-certified-engineer\n \n绝无仅有！搭着 Elastic 开发者大会的便车，也只有中国区才有的专属福利，原价400美金的Elastic工程师认证，现在只需要1500人民币，还包含大会的VIP门票（这么多干货主题，算是赠送），一共仅限20位，现场考试（其他都是远程）。\n \nElastic 认证工程师计划才刚刚开始，全球通过的现在加起来都不过百人，机会就放在这里了，只给有准备的人。\n \n[b]考试时间及地点：[/b]\n时间：2018年11月9日，下午2点到下午5点\n地点：深圳金茂 JW 万豪酒店2层会议中心，1号会议室\n \n[b]抢票地址：[/b]\nhttps://www.bagevent.com/event/elastic\n \n[attach]3014[/attach]","title":"Elastic 官方开发者认证现场考试+ Elastic 开发者大会 VIP 门票","uid":"1","views":"1892","votes":"2"},"_type":"doc"}
{"_id":"828","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539305508","category_id":"18","comments":"0","has_attach":"0","id":"828","message":"1、Elasticsearch关键的性能指标\nhttp://t.cn/E7fLDrW\n2、Flink写入数据到ElasticSearch\nhttp://t.cn/E7fyqsy\n3、Elasticsearch+redis日志监控\nhttp://t.cn/RNHMAdY \n\n活动预告\n1、Elastic 官方开发者认证现场考试+ Elastic 开发者大会 VIP 门票\nhttps://elasticsearch.cn/article/827\n\n编辑：铭毅天下\n归档:   https://elasticsearch.cn/article/828\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第415期 (2018-10-11)","uid":"1341","views":"231","votes":"0"},"_type":"doc"}
{"_id":"829","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539399161","category_id":"18","comments":"0","has_attach":"0","id":"829","message":"1..NET使用ES必读系列：\n\n(1)[http://t.cn/E79dJoo](http://t.cn/E79dJoo) \n\n(2)[http://t.cn/E79dkDp](http://t.cn/E79dkDp) \n\n(3)[http://t.cn/E79gMfG](http://t.cn/E79gMfG) \n\n2. 管道聚合系列：\n\n(1)[http://t.cn/E79k4Nd](http://t.cn/E79k4Nd) \n\n(2)[http://t.cn/E79kOgG](http://t.cn/E79kOgG) \n\n3. 使用Kibana和SentiNL对实时数据预警。\n\n[http://t.cn/E79sSCq](http://t.cn/E79sSCq) \n\n活动预告\n1、Elastic 官方开发者认证现场考试+ Elastic 开发者大会 VIP 门票\nhttps://elasticsearch.cn/article/827   \n\n* 编辑:  bsll\n\n* 归档：https://elasticsearch.cn/article/829 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第416期 (2018-10-13）","uid":"1874","views":"227","votes":"0"},"_type":"doc"}
{"_id":"830","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539484159","category_id":"18","comments":"0","has_attach":"0","id":"830","message":"1.使用Amazon Cognito进行Kibana访问控制。\nhttp://t.cn/E7WTASh\n2.使用GuardDuty实时监控您的安全性。\nhttp://t.cn/E7WTpbr\n3.(自备梯子)如何理解任何编程任务。\nhttp://t.cn/EhkDGBF\n\n活动预告：\n1、Elastic 官方开发者认证现场考试+ Elastic 开发者大会 VIP 门票\nhttps://elasticsearch.cn/article/827\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/830\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第417期 (2018-10-14)","uid":"4460","views":"222","votes":"0"},"_type":"doc"}
{"_id":"994","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539923078","category_id":"18","comments":"0","has_attach":"0","id":"994","message":"1.spring boo boot + Elasticsearch6.4X案例分享\nhttp://t.cn/EheomUZ\n2.Elasticsearcharch .Net Demo源码\nhttp://t.cn/EzISlJk\n3.Eleaticsearcharch源码分析文档落地解读\nhttp://t.cn/EzIoSXK\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/994\n订阅: https://tinyletter.com/elastic-daily","title":"Elastic日报 第422期 (2018-10-19)","uid":"1341","views":"201","votes":"0"},"_type":"doc"}
{"_id":"995","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540002018","category_id":"18","comments":"0","has_attach":"0","id":"995","message":"1. es是不同文档id的优劣比较。\n[http://t.cn/EzXShwh](http://t.cn/EzXShwh)\n \n\n2. significant_terms和significant_text聚合详解。\n[http://t.cn/EzXdu8T](http://t.cn/EzXdu8T) \n\n\n3. 一周热点：github年度报告发布。\n[http://t.cn/EzXZ9qF](http://t.cn/EzXZ9qF) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/995 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第423期 (2018-10-20）","uid":"1874","views":"181","votes":"0"},"_type":"doc"}
{"_id":"1001","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540432625","category_id":"3","comments":"0","has_attach":"0","id":"1001","message":"最近开始研究elasticsearch例如添加geo_hash类型的坐标是这样的\n\nfilter { \n    mutate { \n        add_field =\u0026gt; {\u0026quot;location\u0026quot; =\u0026gt; \u0026quot;%{y},%{x}\u0026quot;}  --把x，y变为location属性，类型为geohash\nremove_field =\u0026gt; [\u0026quot;@version\u0026quot;,\u0026quot;@timestamp\u0026quot;,\u0026quot;qsdwmc\u0026quot;,\u0026quot;gldwmc\u0026quot;,\u0026quot;bz\u0026quot;,\u0026quot;sjly\u0026quot;,\u0026quot;rksj\u0026quot;,\u0026quot;guid\u0026quot;,\u0026quot;clsj\u0026quot;,\u0026quot; czsj\u0026quot;,\u0026quot;x\u0026quot;,\u0026quot;y\u0026quot;,\u0026quot;mjzrq\u0026quot;,\u0026quot;gxsj\u0026quot;]\n    } \n}\n \n但是我看了官网上的例子：\n PUT /example\n{\n    \u0026quot;mappings\u0026quot;: {\n        \u0026quot;doc\u0026quot;: {\n            \u0026quot;properties\u0026quot;: {\n                \u0026quot;location\u0026quot;: {\n                    \u0026quot;type\u0026quot;: \u0026quot;geo_shape\u0026quot;\n                }\n            }\n        }\n    }\n}\nPOST /example/doc?refresh\n{\n    \u0026quot;name\u0026quot;: \u0026quot;Wind \u0026amp; Wetter, Berlin, Germany\u0026quot;,\n    \u0026quot;location\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;point\u0026quot;,\n        \u0026quot;coordinates\u0026quot;: [13.400544, 52.530286]\n    }\n}\n \n请问各位大佬通过logstash怎么添加这样子的location的属性，type为point，然后还有个coordinates数组","title":"logstash怎么把csv文件中的x列和y列编程geo_shape的point导入es集群中","uid":"10326","views":"185","votes":"0"},"_type":"doc"}
{"_id":"1004","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540533537","category_id":"18","comments":"0","has_attach":"0","id":"1004","message":"1.来了解下基于 Elastic Stack 的安全解决方案\nhttp://t.cn/EZXE8mY\n\n2.AuditBeat 使用教程\nhttp://t.cn/EZXEk20\n\n3.(自备梯子)Docker 日志收集快乐指南\nhttp://t.cn/EZXnAsy\n\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/1004\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第429期 (2018-10-26)","uid":"86","views":"174","votes":"0"},"_type":"doc"}
{"_id":"1006","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540638998","category_id":"2","comments":"1","has_attach":"0","id":"1006","message":"\u0026gt; ELK Tips 主要介绍一些 ELK 使用过程中的小技巧，内容主要来源为 Elastic 中文社区。\n\n## 一、Logstash\n### 1、Logstash 字符串分割（Split）\n以下配置将 `message` 内容按照 `\\t` 进行切分，为了使 `\\t` 生效需要将 logstah.yml 中配置项 `config.support_escapes` 设置为 true，当设置为 true 时，带引号的字符串将处理转义字符，**默认值为 false**。\n```\nfilter {\n  mutate {\n    split =\u0026gt; {\u0026quot;message\u0026quot; =\u0026gt; \u0026quot;\\t\u0026quot;}\n    add_field =\u0026gt; {\n      \u0026quot;ftimeold\u0026quot; =\u0026gt; \u0026quot;%{[message][0]}\u0026quot;\n    }\n  }\n}\n```\n### 2、Logstash 按文件读取内容并存储到 ES\n下面的配置将读取`/home/txts/*`下的文件，并读取整个文件内容，然后将文件内容存储到 `test-text` 索引中，同时该条记录的 `_id` 为文档的文件名。这里需要注意的是，想读取到文档末尾时，分隔符需设置为 `EOF`。\n```\ninput {\n  file {\n    path =\u0026gt; [\u0026quot;/home/txts/*\u0026quot;]\n    start_position =\u0026gt; \u0026quot;beginning\u0026quot;\n    mode =\u0026gt; \u0026quot;read\u0026quot;\n    delimiter =\u0026gt; \u0026quot;EOF\u0026quot;\n    file_completed_action =\u0026gt; \u0026quot;log\u0026quot;\n    file_completed_log_path =\u0026gt; \u0026quot;/home/logs/file.log\u0026quot;\n  }\n}\noutput {\n  elasticsearch {\n    hosts =\u0026gt; [\u0026quot;http://192.168.3.214:9200/\u0026amp;quot;]\n    index =\u0026gt; \u0026quot;test-text\u0026quot;\n    document_id =\u0026gt; \u0026quot;%{path}\u0026quot;\n  }\n  stdout {}\n}\n```\n\n### 3、ES Ingest Node 脚本案例 \nIngest Node 可以使用多种过滤器对数据进行处理，其中 Script 脚本的功能非常强大，下面的案例实现了将一个 Json 结构进行了 Flat 化：\n```\n{\n    \u0026quot;script\u0026quot; : {\n      \u0026quot;lang\u0026quot; : \u0026quot;painless\u0026quot;,\n      \u0026quot;source\u0026quot; : \u0026quot;def dict = ['result': new HashMap()]; for (entry in ctx['json'].entrySet()) { dict['result'][entry.getKey()] = entry.getValue(); } ctx['osquery'] = dict; ctx.remove('json');\u0026quot;\n    }\n}\n```\n\n### 4、Logstash input file 插件中 sincedb 维护问题\n1. 如果不想保存 sincedb，可以使用下面配置：`sincedb_path =\u0026gt; \u0026quot;/dev/null\u0026quot;`；\n2. 如果希望被扫描的记录超过一段时间后自动被清除，可以使用 `sincedb_clean_after =\u0026gt; \u0026quot;2 weeks\u0026quot;` 来实现，`sincedb_clean_after` 表示当一个文件在设定的时间内没有发生过任何变化，则关于这个文件的扫描记录将不会存储到 sincedb 里面，简单来说就是一条记录的过期时间。\n\n\n\n## 二、Elasticsearch\n### 1、ES 查询结果的一致性\n为了保证用户每次查询结果的一致性（文档在结果中的顺序），可以在查询 url 里添加 `preference=\u0026lt;some string\u0026gt;`  这个参数，其中`\u0026lt;some string\u0026gt;`可以是用户的 session ID，这样某一个用户查询的时候，查询会被固定在某几个 shard。\n\n### 2、同义词的扩展或收缩\n- **简单扩展**，把同义词列表中的任意一个词扩展成同义词列表所有的词：`jump,hop,leap`；\n- **简单收缩**，把左边的多个同义词映射到了右边的单个词：`leap,hop =\u0026gt; jump`；\n- **类型扩展**，完全不同于简单收缩或扩张，并不是平等看待所有的同义词，而是扩大了词的意义使被拓展的词更为通用：\n```\n\u0026quot;cat    =\u0026gt; cat,pet\u0026quot;,\n\u0026quot;kitten =\u0026gt; kitten,cat,pet\u0026quot;,\n\u0026quot;dog    =\u0026gt; dog,pet\u0026quot;\n\u0026quot;puppy  =\u0026gt; puppy,dog,pet\u0026quot;\n```\n\n### 3、设置某个索引为只读状态\n`index.blocks.write` 设置为 true 来禁止对索引的写操作，但索引的 metadatra 可以正常写。\n```\nPUT indexName/_settings\n{\n    \u0026quot;index.blocks.write\u0026quot;: true\n}\n```\n\n### 4、Failed to process cluster event (put-mapping) within 30s\n这个是创建 mapping 的时候超时了，默认是 30s 应该是集群处理不过来了。**索引文件太多**，使得集群的状态数据过多过大，在每个小时新建索引和设置索引 mapping 的时候，就产生集群状态更新任务交给 master 处理，master 在变更状态数据的时候是**单线程处理**的，如果集群总的状态数据很大，master处理这些任务就容易出现超时。\n \n解决办法：\n- 控制集群的总的索引数量，shard 数量；\n- 如果同时创建的索引非常多，最好避免通过写入数据自动创建索引；\n- 可以**通过 cron 任务，预先顺序的创建好索引**。\n\n### 5、Get 查询获取不到数据，但是用 _search 就可以查询到\n这种情况一般在索引时候加入了路由字段（routing），那么在 get，delete，update 操作中都必须使用路由字段。\n\n```\nPUT my_index/my_type/1?routing=user1\u0026amp;refresh=true \n{\n  \u0026quot;title\u0026quot;: \u0026quot;This is a document\u0026quot;\n}\n\nGET my_index/my_type/1?routing=user1\n```\n\n### 6、ES 5.X 版本多个 type 的数据迁移到 6.X\n把 5.x 集群中的索引按不同 type 拆分 reindex 到 6.x 集群索引中，然后将拆分出来的多个索引使用别名进行组织；例如 5.x 集群中有索引 IndexA，该索引上有 typeA 和 typeB，reindex 到 6.x 集群`IndexA_TypeA`和`IndexB_TypeB`，reindex 语句如下所示：\n\n```\nPOST _reindex\n{\n  \u0026quot;source\u0026quot;: {\n    \u0026quot;index\u0026quot;: \u0026quot;IndexA\u0026quot;,\n    \u0026quot;type\u0026quot;: \u0026quot;TypeA\u0026quot;,\n    \u0026quot;size\u0026quot;: 10000\n  },\n  \u0026quot;dest\u0026quot;: {\n    \u0026quot;index\u0026quot;: \u0026quot;IndexA_TypeA\u0026quot;\n  }\n}\n```\n\n最后给 6.x 集群的`IndexA_TypeA`和`IndexB_TypeB`添加别名 IndexA，用户查询时使用的索引名称就不用变化。\n\n```\nPOST _aliases  \n{\n    \u0026quot;actions\u0026quot;: [\n        {\u0026quot;add\u0026quot;: {\u0026quot;index\u0026quot;: \u0026quot;IndexA_TypeA\u0026quot;, \u0026quot;alias\u0026quot;: \u0026quot;IndexA\u0026quot;}},\n        {\u0026quot;add\u0026quot;: {\u0026quot;index\u0026quot;: \u0026quot;IndexA_TypeB\u0026quot;, \u0026quot;alias\u0026quot;: \u0026quot;IndexA\u0026quot;}}\n    ]\n}\n```\n\n### 7、reindex 将多个索引合并成一个索引，需要重新设置新索引的 mapping 吗？\n需要在 reindex 之前为新索引重新设置 mapping ，reindex 只是通过类似 scroll 的方式把数据 bulk 到新的索引，不会自动同步原索引的 mappings 信息。\n\n### 8、集群的 discovery.zen.ping.unicast.hosts 配置\n只需要配置主节点（master）地址即可。\n\n```\ndiscovery.zen.ping.unicast.hosts:\n   - 192.168.1.10:9300\n   - 192.168.1.11 \n   - seeds.mydomain.com \n```\n\n### 9、ES 的 path.data 配置多个盘的路径，查询效率与单个存储盘的效率比，哪个效率高些？\n\n\u0026gt; 想最大程度发挥磁盘读写 io，还是推荐 RAID0。\n\n使用多路径不一定会提升读写速度，和集群 shard 的数量有关系；主要是因为一个 shard 对应的文件，只会放到其中一块磁盘上，不会跨磁盘存储。比如一个极端的场景，集群 shard 数量比较少，每个结点上就一个shard，那么读写只会有一块磁盘发挥作用，其他磁盘都空闲的。\n \n多路径对读写有提升比较大的场景，是每个结点上 shard 数量至少比盘的数量多，并且 shard 大小也差别不太多；shard 数量比较少，shard 大小差别太大，可能产生读写热点问题，即有的磁盘磁盘很忙，有的很闲。\n\nES 不会将一个索引的主副分片分配到同一台机器，所以即使一台机器的 RAID0 坏了，不会导致数据丢失，仅仅是副本没有了。 \n\n用 RAID0 的负面影响主要是磁盘损坏的时候，需要恢复的数据比较多；多路径磁盘，坏一块只会丢一部分数据，恢复数据会比较快；但是他也有缺陷，比如容易出现读写热点问题以及磁盘空间使用不均匀问题。\n\n### 10、查询索引分片（Shard）位置的接口\n```\n# 推荐\nGET /_cat/shards/\u0026lt;index_name\u0026gt;?v\n\nGET /_cluster/state/routing_table\n```\n\n### 11、multi_match 与 match_phrase 的区别\n- multi_match 是对 `boolQuery().should(matchQuery(field, keyword))` 的一种简化，简单说就是一个关键词，匹配多个字段，匹配方式为 matchQuery，正常的全文匹配。\n- match_phrase 简单说就是要匹配一个短语，例如你输入的文本为：中国人，如果被分词为：中国/人，那么查找时候会在指定的字段先查找到 \u0026quot;中国\u0026quot; 这个 term，然后在 \u0026quot;中国\u0026quot; 这个 term 后面去查找 \u0026quot;人\u0026quot;这个term（有顺序要求），如果匹配到则认为匹配成功；所以更像是在匹配一个短语（连贯的句子）。\n\n### 12、analyzer, tokenizer, token-filter 有什么区别\n- analyzer ：分析器，analyzer = 1 个 tokenizer + 若干个 token-filter；\n- tokenizer ：分词器，主要用于对文本进行切割；\n- token-filter ：过滤器，主要对 tokenizer 切割后的 term 进行再次处理。\n\n### 13、_source 字段的用途\n简单来说：_source 字段用于存储最原始的 JSON 文档内容（创建索引时传递的），这个字段不能被搜索，它可以在 get 或者 search 请求阶段进行返回；此外它会参与字段高亮计算、文档的更新等操作，一般不推荐关闭 _source 字段。\n\n## 三、Kibana\n### 1、kibana 表格默认排序\n在设计表格的时候直接点击需要排序的那一列，然后让它按照倒序或者正序排序，然后点击保存即可，这样这个表格默认就是按照这一列倒序或者正序排列的。\n\n![kibana 排序设置](https://user-gold-cdn.xitu.io/2018/10/27/166b4fc5f6c4fe4f?w=351\u0026amp;h=160\u0026amp;f=png\u0026amp;s=46696)\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](https://user-gold-cdn.xitu.io/2018/10/23/166a16ef32041acc?w=258\u0026amp;h=258\u0026amp;f=png\u0026amp;s=45449)","title":"ELK 使用小技巧（第 1 期）","uid":"8031","views":"624","votes":"9"},"_type":"doc"}
{"_id":"1007","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540692508","category_id":"18","comments":"0","has_attach":"0","id":"1007","message":"1.在Elasticsearch中使用管道重建索引。\nhttp://t.cn/EZQhdz5\n2.使用Yelp的数据管道和Elasticsearch进行快速订单搜索。\nhttp://t.cn/EZQzCpw\n3.(自备梯子)数据科学家最需要的技能。\nhttp://t.cn/E7jAYl9\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/1007\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第431期 (2018-10-28)","uid":"4460","views":"188","votes":"0"},"_type":"doc"}
{"_id":"6348","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548556518","category_id":"18","comments":"0","has_attach":"0","id":"6348","message":"1.在现有Elasticsearch集群中添加或删除节点。\nhttp://t.cn/EtUHo2i\n2.运行400+节点Elasticsearch集群。\nhttp://t.cn/EtUHqmF\n3.(自备梯子)亚马逊变得比你意识到的更强大。\nhttp://t.cn/EtUHBLe\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6348\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第522期 (2019-01-27)","uid":"4460","views":"29","votes":"0"},"_type":"doc"}
{"_id":"6343","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548298575","category_id":"12","comments":"0","has_attach":"1","id":"6343","message":"\r\n[attach]3457[/attach]\r\n\r\n ","title":"【绿湾科技】搜索研发工程师/架构师 30K~60K+  北京","uid":"10321","views":"116","votes":"2"},"_type":"doc"}
{"_id":"6342","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548212545","category_id":"18","comments":"0","has_attach":"0","id":"6342","message":"1.BAT 等一线大厂 Elasticsearch面试题解读\nhttp://t.cn/E5SHRTH\n2.如何监控 Kubernetes 集群日志\nhttp://t.cn/E5TrUwi\n3.Elasticsearch 布尔查询\nhttp://t.cn/E5TgM9d\n\n编辑：江水\n归档：https://elasticsearch.cn/article/6342\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第518期 (2019-01-23)","uid":"3828","views":"141","votes":"0"},"_type":"doc"}
{"_id":"6336","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547878911","category_id":"18","comments":"0","has_attach":"0","id":"6336","message":"1. Flink 写入数据到 ElasticSearch。\n[http://t.cn/E5L88Q7](http://t.cn/E5L88Q7) \n\n2.ES分布式一致性原则分析系列：节点、Meta、数据（需翻墙）。\n[http://t.cn/E5LGg4i](http://t.cn/E5LGg4i) \n\n[http://t.cn/E5LqqbD](http://t.cn/E5LqqbD) \n\n[http://t.cn/E5L57t0](http://t.cn/E5L57t0) \n\n3. 一周热点：最近刷屏的《啥是佩奇》。\n[http://t.cn/E5vkFQc](http://t.cn/E5vkFQc) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6336\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第514期 (2019-01-19）","uid":"1874","views":"147","votes":"0"},"_type":"doc"}
{"_id":"6338","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547995076","category_id":"12","comments":"0","has_attach":"0","id":"6338","message":" 岗位描述\n1、负责众云大数据平台Elasticsearch相关服务的功能设计、开发、运营和维护工作；\n2、持续优化Elasticsearch的性能，完善功能，支持各业务线检索、聚合等场景；\n3、负责众云事业部ELK平台的运营和维护工作；\n岗位要求\n1. 计算机相关专业全日制本科及以上学历，三年以上开发工作经验；\n2. 熟练掌握java语言，熟练使用linux，强悍的编码和troubleshooting能力；\n3. 深入了解Elasticsearch、Solr等开源搜索引擎，了解Lucene、Elasticsearch源码优先；\n4. 精通搜索引擎架构原理、排序算法、索引处理及分词算法，索引数据结构；\n5. 熟练掌握常见SQL数据库原理、数据库设计、查询编写和优化；\n6. 有基础框架、中间件、基础库的开发经验优先；\n7. 具有大型搜索引擎或舆情相关项目经验优先；\n8. 对linux kernel、存储、文件系统、分布式任一方向有深入研究者优先；\n9. 逻辑分析能力强，善于沟通，有良好的团队合作精神，良好的学习能力；","title":"人民在线招聘ES搜索研发工程师","uid":"10656","views":"183","votes":"2"},"_type":"doc"}
{"_id":"6334","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547774365","category_id":"18","comments":"0","has_attach":"0","id":"6334","message":"1、使用rally对Elasticsearch进行基准测试\nhttp://t.cn/E5vfSSq\n2、Django Elasticsearch检索解读\nhttp://t.cn/E5vxFXe\n3、基于Vert.X框架的Elasticsearch客户端\nhttp://t.cn/E5vJbG3\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6334\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第513期（2019-1-18）","uid":"1341","views":"191","votes":"0"},"_type":"doc"}
{"_id":"6332","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547609499","category_id":"18","comments":"0","has_attach":"0","id":"6332","message":"1.实时日志流系统\nhttp://t.cn/Eqn8swf\n2.Lucene索引结构漫谈\nhttp://t.cn/Re1Dp6g\n3.Elasticsearch让你的搜索引擎全面发展\nhttp://t.cn/EqnEwAs\n \n编辑：江水\n归档：https://elasticsearch.cn/article/6332\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第511期 (2019-01-16)","uid":"3828","views":"165","votes":"0"},"_type":"doc"}
{"_id":"6326","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547173827","category_id":"4","comments":"1","has_attach":"0","id":"6326","message":"\n正如官方文档所自豪宣称的那样。Kibana更多的是一个平台，一个可以让插件独立开发，“独立部署”的可扩展性平台，可以让我们自由的发挥自己的想象力和能力，根据自己的需求往上添加原生Kibana所不提供的功能。你可以开发一个新的app，也可以只部署一个后台服务，也可以是一个隐藏的跳转页面，这些，都有赖于plugin的方式，自由的在kibana上install, update和remove。\n\n### 问题描述\n以上。看起来是比较美好的，但硬币的反面是kibana作为一个单页应用，任何都其他功能都是\u0026quot;/\u0026quot;路径下都一个子path，任何插件的安装（除非是一个纯后台的服务，但我没有测试）都需要和主页面、所有已安装都插件产生联系，即每次插件都变动，都需要将所有的页面和js重新bundle一次。这个捆绑不是简单的捆绑，而是经过优化后的打包操作，相当耗时。**重点是，按照目前的方式，optimize(bundle)的过程必须是现场的，即必须在正在运行的kibana服务器上进行**，因此在以下情况下你可能会遇到麻烦：\n\n - 你的kibana服务作为一个生产服务，不能停\n - 你没有给kibana做双活\n - 因为只是一个前端，你给kibana分配的硬件资源很少（单核2G，双核4G）\n - 你使用的是6.3之后的版本，kibana已经默认安装了xpack。或者你是之前的版本，自己手动安装了xpack\n\n这时，你若是安装或者更新插件（包括remove插件），都可能会因为optimize过程占用大量的cpu和内存资源，而造成kibana停止服务响应。\n\n\u0026gt; 这里有一个小tips，如果你开发了多个插件，需要同时更新当时候，安装当时候请使用命令`kibana-plugin install --no-optimize file:///path_to_your_file`，当全部的插件都安装完了之后，再重启kibana，一次性的执行optimize流程，或者通过`bin/kibana --optimize`命令触发\n\n### Kibana架构简述\n如果我们的目标是**让kibana零等待时间升级插件**，找到解决方案的前提是我们能够了解Kibana的软件架构和部署方式。\n\n首先，我们需要知道的是Kibana是一个基于node的web应用，前端后端都主要使用的javascript。web后端使用的hapi作为web服务器应用程序。并且node无需安装，已经包含在了kibana目录下。（node目录）\n\n以下是kibana的目录，所有的插件都安装在plugins目录，而所有打包后的内容都放在optimize目录。\n```shell\n├── LICENSE.txt\n├── NOTICE.txt\n├── README.txt\n├── bin\n├── config\n├── data\n├── node\n├── node_modules\n├── optimize\n├── package.json\n├── plugins\n├── src\n└── webpackShims\n```\nplugins目录(这里，我有两个插件)：\n```shell\n.\n├── kibana_auth_plugin\n│   ├── index.js\n│   ├── node_modules\n│   ├── package.json\n│   ├── public\n│   ├── server\n│   └── yarn.lock\n└── system_portal\n    ├── index.js\n    ├── node_modules\n    ├── package.json\n    ├── public\n    ├── server\n    └── yarn.lock\n```\n每个插件都是类似的目录结构。`public`目录存放的是前端的页面和js，`server`目录存放的是后端的js。这里最终要的信息是，插件的开发其实也是一种 **前后端分离的架构** 。插件安装后后端主程序会调用`server`目录下的文件，而前端public目录下的文件会被压缩后打包到`optimize`目录，详见如下。\n\noptimize目录：\n```shell\n├── bundles\n│   ├── 176bcca991b07a6ec908fc4d36ac5ae0.svg\n│   ├── 45c73723862c6fc5eb3d6961db2d71fb.eot\n│   ├── 4b5a84aaf1c9485e060c503a0ff8cadb.woff2\n│   ├── 69d89e51f62b6a582c311c35c0f778aa.svg\n│   ├── 76a4f23c6be74fd309e0d0fd2c27a5de.svg\n│   ├── 7c87870ab40d63cfb8870c1f183f9939.ttf\n│   ├── apm.bundle.js\n│   ├── apm.entry.js\n│   ├── apm.style.css\n│   ├── kibana-auth-plugin.bundle.js\n│   ├── kibana-auth-plugin.entry.js\n│   ├── kibana-auth-plugin.style.css\n│   ├── canvas.bundle.js\n│   ├── canvas.entry.js\n│   ├── canvas.style.css\n│   ├── cc17a3dbad9fc4557b4d5d47a38fcc56.svg\n│   ├── commons.bundle.js\n│   ├── commons.style.css\n│   ├── dashboardViewer.bundle.js\n│   ├── dashboardViewer.entry.js\n│   ├── dashboardViewer.style.css\n│   ├── dfb02f8f6d0cedc009ee5887cc68f1f3.woff\n│   ├── fa0bbd682c66f1187d48f74b33b5bbd0.svg\n│   ├── graph.bundle.js\n│   ├── graph.entry.js\n│   ├── graph.style.css\n│   ├── infra.bundle.js\n│   ├── infra.entry.js\n│   ├── infra.style.css\n│   ├── kibana.bundle.js\n│   ├── kibana.entry.js\n│   ├── kibana.style.css\n│   ├── ml.bundle.js\n│   ├── ml.entry.js\n│   ├── ml.style.css\n│   ├── monitoring.bundle.js\n│   ├── monitoring.entry.js\n│   ├── monitoring.style.css\n│   ├── space_selector.bundle.js\n│   ├── space_selector.entry.js\n│   ├── space_selector.style.css\n│   ├── src\n│   ├── stateSessionStorageRedirect.bundle.js\n│   ├── stateSessionStorageRedirect.entry.js\n│   ├── stateSessionStorageRedirect.style.css\n│   ├── status_page.bundle.js\n│   ├── status_page.entry.js\n│   ├── status_page.style.css\n│   ├── system_portal.bundle.js\n│   ├── system_portal.entry.js\n│   ├── system_portal.style.css\n│   ├── timelion.bundle.js\n│   ├── timelion.entry.js\n│   ├── timelion.style.css\n│   ├── vendors.bundle.js\n│   └── vendors.style.css\n```\n前端浏览器在访问\u0026quot;/\u0026quot;目录的时候会最先获取到`kibana.*.js`相关的文件。我们看一下\n`kibana.entry.js`, 里面是包含了所有插件的信息的，即，每次插件的变动，这些文件也会跟着跟新\n```js\n/**\n * Kibana entry file\n *\n * This is programmatically created and updated, do not modify\n *\n * context: ä\n  \u0026quot;env\u0026quot;: \u0026quot;production\u0026quot;,\n  \u0026quot;kbnVersion\u0026quot;: \u0026quot;6.5.0\u0026quot;,\n  \u0026quot;buildNum\u0026quot;: 18730,\n  \u0026quot;plugins\u0026quot;: Ä\n    \u0026quot;apm\u0026quot;,\n    \u0026quot;apm_oss\u0026quot;,\n    \u0026quot;beats_management\u0026quot;,\n    \u0026quot;kibana_auth_plugin\u0026quot;,\n    \u0026quot;canvas\u0026quot;,\n    \u0026quot;cloud\u0026quot;,\n    \u0026quot;console\u0026quot;,\n    \u0026quot;console_extensions\u0026quot;,\n    \u0026quot;dashboard_mode\u0026quot;,\n    \u0026quot;elasticsearch\u0026quot;,\n    \u0026quot;graph\u0026quot;,\n    \u0026quot;grokdebugger\u0026quot;,\n    \u0026quot;index_management\u0026quot;,\n    \u0026quot;infra\u0026quot;,\n    \u0026quot;input_control_vis\u0026quot;,\n    \u0026quot;inspector_views\u0026quot;,\n    \u0026quot;kbn_doc_views\u0026quot;,\n    \u0026quot;kbn_vislib_vis_types\u0026quot;,\n    \u0026quot;kibana\u0026quot;,\n    \u0026quot;kuery_autocomplete\u0026quot;,\n    \u0026quot;license_management\u0026quot;,\n    \u0026quot;logstash\u0026quot;,\n    \u0026quot;markdown_vis\u0026quot;,\n    \u0026quot;metric_vis\u0026quot;,\n    \u0026quot;metrics\u0026quot;,\n    \u0026quot;ml\u0026quot;,\n    \u0026quot;monitoring\u0026quot;,\n    \u0026quot;notifications\u0026quot;,\n    \u0026quot;region_map\u0026quot;,\n    \u0026quot;reporting\u0026quot;,\n    \u0026quot;rollup\u0026quot;,\n    \u0026quot;searchprofiler\u0026quot;,\n    \u0026quot;spaces\u0026quot;,\n    \u0026quot;state_session_storage_redirect\u0026quot;,\n    \u0026quot;status_page\u0026quot;,\n    \u0026quot;system_portal\u0026quot;,\n    \u0026quot;table_vis\u0026quot;,\n    \u0026quot;tagcloud\u0026quot;,\n    \u0026quot;tile_map\u0026quot;,\n    \u0026quot;tilemap\u0026quot;,\n    \u0026quot;timelion\u0026quot;,\n    \u0026quot;vega\u0026quot;,\n    \u0026quot;watcher\u0026quot;,\n    \u0026quot;xpack_main\u0026quot;\n  Å\nå\n */\n\n// import global polyfills before everything else\nimport 'babel-polyfill';\nimport 'custom-event-polyfill';\nimport 'whatwg-fetch';\nimport 'abortcontroller-polyfill';\nimport 'childnode-remove-polyfill';\n\nimport ä i18n å from 'Ékbn/i18n';\nimport ä CoreSystem å from '__kibanaCore__'\n\nconst injectedMetadata = JSON.parse(document.querySelector('kbn-injected-metadata').getAttribute('data'));\ni18n.init(injectedMetadata.legacyMetadata.translations);\n\nnew CoreSystem(ä\n  injectedMetadata,\n  rootDomElement: document.body,\n  requireLegacyFiles: () =\u0026gt; ä\n    require('plugins/kibana/kibana');\n  å\nå).start()\n```\n### 优化部署的方案（前后端分离的部署）\n我们已经初步了解了kibana和kibana plugins的架构。那kibana插件的安装方案是怎么样的呢？\nkibana为了简化我们的工作，只需要我们将打包好的源码丢给kibana，然后执行命令：``kibana-plugin install file:///path_to_your_file``，这样貌似省事，但也把所有的工作都丢给了kibana服务器去完成。\n在kibana服务器性能不佳的情况下，这部分工作可能会造成服务中断。因此，我们要代替kibana服务器完成这部分工作，**做一个前后端分离的部署**。\n\n#### 后端部署\n后端部署的速度是极快的，只需要把文件解压缩到具体目录就可以：\n```\n`kibana-plugin install --no-optimize file:///path_to_your_file`\n```\n\n这里特别要注意: `--no-optimize `参数是必须的，这时，插件的安装只是一个解压的过程，不会让kibana服务器去做繁重的optimize工作。\n\u0026gt; **注意，执行这一步之后，不能重启kibana服务器，否则会自动做optimize**\n\n#### 前端部署\n这里说的前端，主要是指bundle之后的内容。在你的开发环境上，安装插件。当插件安装完成后，把bundles目录整体打包（bundles.zip）。将打包好之后的内容，上传到kibana服务器，删除旧的`optimize/bundles`目录，把打包好的bundles目录解压到`optimize`目录下\n\u0026gt; **注意，这里开发环境上的kibana版本，和kibana安装的插件必须是和生产环境上是一致的，否则会造成无法启动或者自动重做optimize**\n\n#### 重启kibana服务器\n当以上两步完成之后，重启kibana service即可，你会发现，内容已经更新，但是不会触发任何的optimize过程。\n\n#### 参考示例\n以下是该过程的一个ansible playbook供大家参考\n\n```yaml\n---\n\n\n- name: deploy bundles zip\n  copy: src=bundles.zip dest={{kibana_home}}/optimize force=yes mode={{file_mask}}\n\n- name: deploy system plugins zip\n  copy: src=system_portal-0.0.0.zip dest={{kibana_home}}/ force=yes mode={{file_mask}}\n\n- name: deploy auth zip\n  copy: src=kibana_auth_plugin-6.5.0.zip dest={{kibana_home}}/ force=yes mode={{file_mask}}\n\n- name: remove system plugin\n  shell: \u0026quot;{{kibana_home}}/bin/kibana-plugin remove system_portal\u0026quot;\n  ignore_errors: True\n\n- name: remove auth plugin\n  shell: \u0026quot;{{kibana_home}}/bin/kibana-plugin remove kibana_auth_plugin\u0026quot;\n  ignore_errors: True\n\n\n- name: install system plugin\n  shell: \u0026quot;{{kibana_home}}/bin/kibana-plugin install --no-optimize file://{{kibana_home}}/system_portal-0.0.0.zip\u0026quot;\n  register: install_state\n\n- name: install auth plugin\n  shell: \u0026quot;{{kibana_home}}/bin/kibana-plugin install --no-optimize file://{{kibana_home}}/kibana_auth_plugin-6.5.0.zip\u0026quot;\n  register: install_state\n#  failed_when: \u0026quot;'Extraction complete' in install_state.stdout_lines\u0026quot;\n\n- name: delete old bundls\n  file: dest={{kibana_home}}/optimize/bundles state=absent\n\n- name: delete old bundls\n  unarchive:\n     src: \u0026quot;{{kibana_home}}/optimize/bundles.zip\u0026quot;\n     dest: \u0026quot;{{kibana_home}}/optimize/\u0026quot;\n     copy: no\n     group: \u0026quot;kibana\u0026quot;\n     owner: \u0026quot;kibana\u0026quot;\n     mode: \u0026quot;{{file_mask}}\u0026quot;\n\n- name: delete zip files\n  file: dest={{kibana_home}}/optimize/bundles.zip state=absent\n  \n- name: restart kibana\n  become: yes\n  service: name={{kibana_init_script | basename}} state=restarted enabled=yes\n\n\n\n```","title":"如何让kibana零等待时间升级插件（前后端分离的部署）","uid":"5649","views":"103","votes":"1"},"_type":"doc"}
{"_id":"6324","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547012571","category_id":"18","comments":"0","has_attach":"0","id":"6324","message":"1、基于elasticsearch站内搜索引擎实战；\nhttp://t.cn/EGr5gbR\n2、基于elasticSearch的搜房网实战；\nhttp://t.cn/EGrtIi5\n3、使用elasticsearch构建一个完整的搜索引擎。\nhttp://t.cn/EGrc25K\n\n编辑：wt\n归档：https://elasticsearch.cn/article/6324\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第504期 (2019-01-09) ","uid":"3851","views":"184","votes":"0"},"_type":"doc"}
{"_id":"6325","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547132178","category_id":"18","comments":"0","has_attach":"0","id":"6325","message":"Elastic日报 第505期 (2019-01-10) \n1.基于Kafka与Spark的实时大数据质量监控平台 \nhttp://t.cn/EqhWgHG \n2.使用 Apache Spark 和 Elasticsearch 构建一个推荐系统 \nhttp://t.cn/RrdR6Hp \n3.使用ELK实时优化工程优化预测 \nhttp://t.cn/R9ZM0XJ \n \n编辑：金桥 \n归档：https://elasticsearch.cn/article/6325 \n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第505期 (2019-01-10) ","uid":"3851","views":"157","votes":"1"},"_type":"doc"}
{"_id":"6323","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546927335","category_id":"18","comments":"0","has_attach":"0","id":"6323","message":"1、ElasticSearch实战：Linux日志对接Kibana。\n​http://t.cn/EG8g30S\n2、使用Compose Transporter构建MongoDB和Elasticsearch多数据解决方案。\nhttp://t.cn/EG8gYBR\n3、5大开源云监控工具使用场景对比分析。\nhttp://t.cn/EG8gpHY\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6323\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第496期 (2019-01-08)","uid":"3788","views":"217","votes":"0"},"_type":"doc"}
{"_id":"6317","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546688070","category_id":"18","comments":"0","has_attach":"0","id":"6317","message":"1. 科普篇：ELK(ElasticSearch, Logstash, Kibana)搭建日志分析平台。\n[http://t.cn/EGMUSm2](http://t.cn/EGMUSm2) \n\n2. 怎么用vue和es构建图书搜索应用(需翻墙）。\n[http://t.cn/EGMUO9j](http://t.cn/EGMUO9j) \n\n3. 一周热点：罗振宇2018“时间的朋友”跨年演讲未删减全文。\n[http://t.cn/EGMU8Se](http://t.cn/EGMU8Se) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6317 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第500期 (2019-01-05）","uid":"1874","views":"185","votes":"0"},"_type":"doc"}
{"_id":"6310","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545999402","category_id":"18","comments":"0","has_attach":"0","id":"6310","message":"1、Kafka Connect MySQL写入Elasticsearch实现\nhttp://t.cn/EUHPscA\n2、elasticsearch 核心的http api\nhttp://t.cn/E4lC5g4\n3、使用Search Guard加固Elasticsearch：认证与授权\nhttp://t.cn/EbLSOBl\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6310\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第492期（2018-12-28）","uid":"1341","views":"189","votes":"0"},"_type":"doc"}
{"_id":"6215","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545380294","category_id":"14","comments":"0","has_attach":"1","id":"6215","message":"\n[attach]3357[/attach]  \n\n对，你一定看过一个电影，情节是这样的，他们拿着长矛去狩猎异形怪物，它们比人类强健，它们的脸部的器官布置得出奇丑陋。它们的身上总是带了一堆很先进的狩猎武器，它们喜欢在杀死猎物后将尸体剥皮，还会将猎物头骨加工成工艺品，当成战利品收藏。对，这部电影系列就叫Predator。好了，言归正传，我们今天讲的故事其实非常简单，讲述的是elasticsearch引擎在安全领域的简单应用，如何通过elasticsearch来搜索一个病毒，我们开发了一个小小的工具来帮我做跨集群查询，以及SQL-DSL转换接口，我们把这个小工具叫做predator。\n\n## 背景\n我司主要是做病毒相关工作的，近年来，数据爆炸，病毒软件也成几何级数倍数增长，大数据病毒出现自然需要对应的大数据工具来处理它们，简单来讲，就是我们可以把病毒样本的一些属性剥离到elasticsearch中，就和日志来描述一个用户的行为一样，本质来说，它们都是数据，然后，我们研究病毒的一些特征属性，通过简单的搜索，就可以快速分析出一堆可能的病毒样本，再然后，通过一系列的测试，过滤，我们就可以真正的找到我们想要的病毒样本，并且通过这些规则持续的追踪它们，是不是很简单?\n\n## 问题\n事情是那么简单，但是在使用elasticsearch作为特征库的过程中，我们也有这样的问题：  \n1，多种维度特征  \n由于存在多种维度特征的病毒，不通模块剥离出不通病毒属性，所以存在多张表来存属性，那么在query的时候就需要跨表，甚至跨集群查询。  \n2，DSL的复杂度  \n由于内部研究员们对elasticStack并不熟悉，加上DSL语言相对复杂，我们需要使用更加接近hunman特性的SQL来转换DSL语言。  \n\n## 数据处理架构\n我们有一个类似的数据处理架构  \n\n[attach]3358[/attach]  \n\n\n## Predator和它的Spear\n因此，我们开发了一个小工具，其实，这个小工具非常简单，只是简单的解决了上述2个问题：  \n使用Elasticsearch-SQL插件来包装一个restful的DSL转换SQL接口，当然，目前ES6已经完全支持SQL接口了，哈哈，早点出来我们就不用做那么工作了:) :):)。  \n简单的写个跨集群的查下聚合器就可以实现跨表查下，其实，这个功能只是简单的查下封装，只是针对特殊的业务场景，没啥参考价值。  \n至于Spear，它其实就是个predator service的客户端，哈哈，像不像铁血战士拿着长矛开着非常去狩猎的样子:) 。  \n\n[attach]3356[/attach]  \n\n\n这是一个规则：  \n\n[attach]3355[/attach]  \n\n这是规则的查询结果：  \n\n[attach]3359[/attach]  \n\n长矛的sample code:  \n```python\n# cross cluster search by dsls\nimport json\nfrom spear import Spear\nsp = Spear()      \ndsl_1 = {}\ndsl_2 = {}\nquery_dict = {    \n    json.dumps(dsl_1): {\n        \u0026quot;cluster\u0026quot;: \u0026quot;es_cluster_1\u0026quot;,\n        \u0026quot;type\u0026quot;:\u0026quot;xxx\u0026quot;\n    },\n    json.dumps(dsl_2): {\n        \u0026quot;cluster\u0026quot;: \u0026quot;es_cluster_2\u0026quot;,\n        \u0026quot;type\u0026quot;: \u0026quot;yyy\u0026quot;\n    }\n}\nsp.cross_count_by_dsl(query_dict, is_show_help=False)\n```\n当然长矛也支持SQL接口\n\n## 总结\n其实，这个只是一个user case的工程实践，可以看到的是，伟大的ElasticStack在各行各业，各种大数据领域，如果抛开领域的概念，一切都是数据，那么理论上来说我们可以使用elasticsearch处理任何类型的数据，当然目前业界典型的应用场景还是搜索，日志，甚至于APM，总之，紧跟社区可以学到很多东西啦。","title":"Day24 - Predator捕捉病毒样本","uid":"1263","views":"274","votes":"4"},"_type":"doc"}
{"_id":"6214","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545366859","category_id":"18","comments":"0","has_attach":"0","id":"6214","message":"1、Mongodb同步Elasticsearch演示\nhttp://t.cn/EUu5RI3\n2、Elasticsearch7.0计算向量距离新特性抢先看\nhttp://t.cn/EUB4vbo\n3、Kubernetes上部署高可用和可扩展的Elasticsearch\nhttp://t.cn/ELhogLr\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6214\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第485期（2018-12-21）","uid":"1341","views":"205","votes":"0"},"_type":"doc"}
{"_id":"6202","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544962234","category_id":"14","comments":"2","has_attach":"0","id":"6202","message":"因为总是看到很多同学在说elasticsearch性能不够好，集群不够稳定，询问关于elasticsearch的调优，但是每次都是一个个点的单独讲，很多时候都是case by case的解答，今天简单梳理下日常的elasticsearch使用调优，以下仅为自己日常经验之谈，如有疏漏，还请大家帮忙指正。\n\n##一、配置文件调优\n###elasticsearch.yml\n####内存锁定\nbootstrap.memory_lock：true 锁定堆内存；\n\n####zen.discovery\nES是一个P2P类型的分布式系统，使用gossip协议，集群的任意请求都可以发送到集群的任一节点，然后es内部会找到需要转发的节点，并且与之进行通信。\n在es1.x的版本，es默认是开启组播，启动es之后，可以快速将局域网内集群名称，默认端口的相同实例加入到一个大的集群，后续再es2.x之后，都调整成了单播，避免安全问题和网络风暴；\n单播discovery.zen.ping.unicast.hosts，建议写入集群内所有的节点及端口，如果新实例加入集群，新实例只需要写入当前集群的实例，即可自动加入到当前集群，之后再处理原实例的配置即可，新实例加入集群，不需要重启原有实例；\n节点zen相关配置：\n    discovery.zen.ping_timeout：判断master选举过程中，发现其他node存活的超时设置，主要影响选举的耗时，参数仅在加入或者选举 master 主节点的时候才起作用\n    discovery.zen.join_timeout：节点确定加入到集群中，向主节点发送加入请求的超时时间，默认为3s\n    discovery.zen.minimum_master_nodes：参与master选举的最小节点数，当集群能够被选为master的节点数量小于最小数量时，集群将无法正常选举。\n\n####故障检测（ fault detection ）\n两种情况下回进行故障检测，第一种是由master向集群的所有其他节点发起ping，验证节点是否处于活动状态；第二种是：集群每个节点向master发起ping，判断master是否存活，是否需要发起选举。\n故障检测需要配置以下设置使用\n形如：\ndiscovery.zen.fd.ping_interval 节点被ping的频率，默认为1s。 \ndiscovery.zen.fd.ping_timeout 等待ping响应的时间，默认为 30s，运行的集群中，master 检测所有节点，以及节点检测 master 是否正常。 \ndiscovery.zen.fd.ping_retries ping失败/超时多少导致节点被视为失败，默认为3。 \n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/modules-discovery-zen.html\n\n####队列数量\n不建议盲目加大es的队列数量，如果是偶发的因为数据突增，导致队列阻塞，加大队列size可以使用内存来缓存数据，如果是持续性的数据阻塞在队列，加大队列size除了加大内存占用，并不能有效提高数据写入速率，反而可能加大es宕机时候，在内存中可能丢失的上数据量。\n哪些情况下，加大队列size呢？GET /_cat/thread_pool，观察api中返回的queue和rejected，如果确实存在队列拒绝或者是持续的queue，可以酌情调整队列size。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/modules-threadpool.html\n \n####内存使用\n设置indices的内存熔断相关参数，根据实际情况进行调整，防止写入或查询压力过高导致OOM，\nindices.breaker.total.limit: 50%，集群级别的断路器，默认为jvm堆的70%；\nindices.breaker.request.limit: 10%，单个request的断路器限制，默认为jvm堆的60%；\nindices.breaker.fielddata.limit: 10%，fielddata breaker限制，默认为jvm堆的60%。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/circuit-breaker.html\n\n根据实际情况调整查询占用cache，避免查询cache占用过多的jvm内存，参数为静态的，需要在每个数据节点配置。\nindices.queries.cache.size: 5%，控制过滤器缓存的内存大小，默认为10%。接受百分比值，5%或者精确值，例如512mb。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/query-cache.html\n \n####创建shard\n如果集群规模较大，可以阻止新建shard时扫描集群内全部shard的元数据，提升shard分配速度。\ncluster.routing.allocation.disk.include_relocations: false，默认为true。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/disk-allocator.html\n\n\n##二、系统层面调优\n####jdk版本\n当前根据官方建议，选择匹配的jdk版本；\n####jdk内存配置\n首先，-Xms和-Xmx设置为相同的值，避免在运行过程中再进行内存分配，同时，如果系统内存小于64G，建议设置略小于机器内存的一半，剩余留给系统使用。\n同时，jvm heap建议不要超过32G（不同jdk版本具体的值会略有不同），否则jvm会因为内存指针压缩导致内存浪费，详见：\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/heap-sizing.html\n \n####交换分区\n关闭交换分区，防止内存发生交换导致性能下降（部分情况下，宁死勿慢）\nswapoff -a\n\n####文件句柄\nLucene 使用了 大量的 文件。 同时，Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字，所有这一切都需要足够的文件描述符，默认情况下，linux默认运行单个进程打开1024个文件句柄，这显然是不够的，故需要加大文件句柄数\nulimit -n 65536\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.5/setting-system-settings.html\n\n####mmap\nElasticsearch 对各种文件混合使用了 NioFs（ 注：非阻塞文件系统）和 MMapFs （ 注：内存映射文件系统）。请确保你配置的最大映射数量，以便有足够的虚拟内存可用于 mmapped 文件。这可以暂时设置：\nsysctl -w vm.max_map_count=262144\n或者你可以在 /etc/sysctl.conf 通过修改 vm.max_map_count 永久设置它。\n\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/_file_descriptors_and_mmap.html\n\n####磁盘\n如果你正在使用 SSDs，确保你的系统 I/O 调度程序是配置正确的。 当你向硬盘写数据，I/O 调度程序决定何时把数据实际发送到硬盘。 大多数默认 *nix 发行版下的调度程序都叫做 `cfq`（完全公平队列）。但它是为旋转介质优化的： 机械硬盘的固有特性意味着它写入数据到基于物理布局的硬盘会更高效。\n这对 SSD 来说是低效的，尽管这里没有涉及到机械硬盘。但是，deadline 或者 noop 应该被使用。deadline 调度程序基于写入等待时间进行优化， noop 只是一个简单的 FIFO 队列。\necho noop \u0026gt; /sys/block/sd*/queue/scheduler\n\n####磁盘挂载\n```mount -o noatime,data=writeback,barrier=0,nobh /dev/sd* /esdata*```\n其中，noatime，禁止记录访问时间戳；data=writeback，不记录journal；barrier=0，因为关闭了journal，所以同步关闭barrier；\nnobh，关闭buffer_head，防止内核影响数据IO\n \n####磁盘其他注意事项\n使用 RAID 0。条带化 RAID 会提高磁盘I/O，代价显然就是当一块硬盘故障时整个就故障了，不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。\n    另外，使用多块硬盘，并允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面。\n    不要使用远程挂载的存储，比如 NFS 或者 SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。\n\n\n##三、elasticsearch使用方式调优\n当elasticsearch本身的配置没有明显的问题之后，发现es使用还是非常慢，这个时候，就需要我们去定位es本身的问题了，首先祭出定位问题的第一个命令：\n####hot_threads\n```GET /_nodes/hot_threads\u0026amp;interval=30s```\n\n抓取30s的节点上占用资源的热线程，并通过排查占用资源最多的TOP线程来判断对应的资源消耗是否正常，一般情况下，bulk，search类的线程占用资源都可能是业务造成的，但是如果是merge线程占用了大量的资源，就应该考虑是不是创建index或者刷磁盘间隔太小，批量写入size太小造成的。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.x/cluster-nodes-hot-threads.html\n\n####pending_tasks\n```GET /_cluster/pending_tasks```\n\n有一些任务只能由主节点去处理，比如创建一个新的 索引或者在集群中移动分片，由于一个集群中只能有一个主节点，所以只有这一master节点可以处理集群级别的元数据变动。在99.9999%的时间里，这不会有什么问题，元数据变动的队列基本上保持为零。在一些罕见的集群里，元数据变动的次数比主节点能处理的还快，这会导致等待中的操作会累积成队列。这个时候可以通过pending_tasks api分析当前什么操作阻塞了es的队列，比如，集群异常时，会有大量的shard在recovery，如果集群在大量创建新字段，会出现大量的put_mappings的操作，所以正常情况下，需要禁用动态mapping。\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-pending.html\n \n####字段存储\n当前es主要有doc_values，fielddata，storefield三种类型，大部分情况下，并不需要三种类型都存储，可根据实际场景进行调整：\n当前用得最多的就是doc_values，列存储，对于不需要进行分词的字段，都可以开启doc_values来进行存储（且只保留keyword字段），节约内存，当然，开启doc_values会对查询性能有一定的影响，但是，这个性能损耗是比较小的，而且是值得的；\n \nfielddata构建和管理 100% 在内存中，常驻于 JVM 内存堆，所以可用于快速查询，但是这也意味着它本质上是不可扩展的，有很多边缘情况下要提防，如果对于字段没有分析需求，可以关闭fielddata；\n \nstorefield主要用于_source字段，默认情况下，数据在写入es的时候，es会将doc数据存储为_source字段，查询时可以通过_source字段快速获取doc的原始结构，如果没有update，reindex等需求，可以将_source字段disable；\n \n_all，ES在6.x以前的版本，默认将写入的字段拼接成一个大的字符串，并对该字段进行分词，用于支持整个doc的全文检索，在知道doc字段名称的情况下，建议关闭掉该字段，节约存储空间，也避免不带字段key的全文检索；\n\nnorms：搜索时进行评分，日志场景一般不需要评分，建议关闭；\n\n####tranlog\nElasticsearch 2.0之后为了保证不丢数据，每次 index、bulk、delete、update 完成的时候，一定触发刷新 translog 到磁盘上，才给请求返回 200 OK。这个改变在提高数据安全性的同时当然也降低了一点性能。\n如果你不在意这点可能性，还是希望性能优先，可以在 index template 里设置如下参数：\n```\n{\n    \u0026quot;index.translog.durability\u0026quot;: \u0026quot;async\u0026quot;\n}\n```\n\nindex.translog.sync_interval：对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync ，默认为5s。小于的值100ms是不允许的。\nindex.translog.flush_threshold_size：translog存储尚未安全保存在Lucene中的所有操作。虽然这些操作可用于读取，但如果要关闭并且必须恢复，则需要重新编制索引。此设置控制这些操作的最大总大小，以防止恢复时间过长。达到设置的最大size后，将发生刷新，生成新的Lucene提交点，默认为512mb。\n\n####refresh_interval\n执行刷新操作的频率，这会使索引的最近更改对搜索可见，默认为1s，可以设置-1为禁用刷新，对于写入速率要求较高的场景，可以适当的加大对应的时长，减小磁盘io和segment的生成；\n\n####禁止动态mapping\n动态mapping的坏处：\n1.造成集群元数据一直变更，导致集群不稳定；\n2.可能造成数据类型与实际类型不一致；\n3.对于一些异常字段或者是扫描类的字段，也会频繁的修改mapping，导致业务不可控。\n动态mapping配置的可选值及含义如下：\ntrue：支持动态扩展，新增数据有新的字段属性时，自动添加对于的mapping，数据写入成功\nfalse：不支持动态扩展，新增数据有新的字段属性时，直接忽略，数据写入成功\nstrict：不支持动态扩展，新增数据有新的字段时，报错，数据写入失败\n\n####批量写入\n批量请求显然会大大提升写入速率，且这个速率是可以量化的，官方建议每次批量的数据物理字节数5-15MB是一个比较不错的起点，注意这里说的是物理字节数大小。文档计数对批量大小来说不是一个好指标。比如说，如果你每次批量索引 1000 个文档，记住下面的事实：\n    1000 个 1 KB 大小的文档加起来是 1 MB 大。\n    1000 个 100 KB 大小的文档加起来是 100 MB 大。\n这可是完完全全不一样的批量大小了。批量请求需要在协调节点上加载进内存，所以批量请求的物理大小比文档计数重要得多。\n从 5–15 MB 开始测试批量请求大小，缓慢增加这个数字，直到你看不到性能提升为止。然后开始增加你的批量写入的并发度（多线程等等办法）。\n用iostat 、 top 和 ps 等工具监控你的节点，观察资源什么时候达到瓶颈。如果你开始收到 EsRejectedExecutionException ，你的集群没办法再继续了：至少有一种资源到瓶颈了。或者减少并发数，或者提供更多的受限资源（比如从机械磁盘换成 SSD），或者添加更多节点。 \n\n####索引和shard\nes的索引，shard都会有对应的元数据，且因为es的元数据都是保存在master节点，且元数据的更新是要hang住集群向所有节点同步的，当es的新建字段或者新建索引的时候，都会要获取集群元数据，并对元数据进行变更及同步，此时会影响集群的响应，所以需要关注集群的index和shard数量，建议如下：\n1.使用shrink和rollover api，相对生成合适的数据shard数；\n2.根据数据量级及对应的性能需求，选择创建index的名称，形如：按月生成索引：test-YYYYMM，按天生成索引：test-YYYYMMDD；\n3.控制单个shard的size，正常情况下，日志场景，建议单个shard不大于50GB，线上业务场景，建议单个shard不超过20GB；\n\n####segment merge\n段合并的计算量庞大， 而且还要吃掉大量磁盘 I/O。合并在后台定期操作，因为他们可能要很长时间才能完成，尤其是比较大的段。这个通常来说都没问题，因为大规模段合并的概率是很小的。\n如果发现merge占用了大量的资源，可以设置：\n```index.merge.scheduler.max_thread_count: 1```\n特别是机械磁盘在并发 I/O 支持方面比较差，所以我们需要降低每个索引并发访问磁盘的线程数。这个设置允许 max_thread_count + 2 个线程同时进行磁盘操作，也就是设置为 1 允许三个线程。\n对于 SSD，你可以忽略这个设置，默认是 Math.min(3, Runtime.getRuntime().availableProcessors() / 2) ，对 SSD 来说运行的很好。\n业务低峰期通过force_merge强制合并segment，降低segment的数量，减小内存消耗；\n关闭冷索引，业务需要的时候再进行开启，如果一直不使用的索引，可以定期删除，或者备份到hadoop集群；\n\n####自动生成_id\n当写入端使用特定的id将数据写入es时，es会去检查对应的index下是否存在相同的id，这个操作会随着文档数量的增加而消耗越来越大，所以如果业务上没有强需求，建议使用es自动生成的id，加快写入速率。\n\n####routing\n对于数据量较大的业务查询场景，es侧一般会创建多个shard，并将shard分配到集群中的多个实例来分摊压力，正常情况下，一个查询会遍历查询所有的shard，然后将查询到的结果进行merge之后，再返回给查询端。此时，写入的时候设置routing，可以避免每次查询都遍历全量shard，而是查询的时候也指定对应的routingkey，这种情况下，es会只去查询对应的shard，可以大幅度降低合并数据和调度全量shard的开销。\n\n####使用alias\n生产提供服务的索引，切记使用别名提供服务，而不是直接暴露索引名称，避免后续因为业务变更或者索引数据需要reindex等情况造成业务中断。\n \n####避免宽表\n在索引中定义太多字段是一种可能导致映射爆炸的情况，这可能导致内存不足错误和难以恢复的情况，这个问题可能比预期更常见，index.mapping.total_fields.limit ，默认值是1000\n\n####避免稀疏索引\n因为索引稀疏之后，对应的相邻文档id的delta值会很大，lucene基于文档id做delta编码压缩导致压缩率降低，从而导致索引文件增大，同时，es的keyword，数组类型采用doc_values结构，每个文档都会占用一定的空间，即使字段是空值，所以稀疏索引会造成磁盘size增大，导致查询和写入效率降低。","title":"Day 16 - Elasticsearch性能调优","uid":"668","views":"1118","votes":"9"},"_type":"doc"}
{"_id":"6201","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544926401","category_id":"18","comments":"0","has_attach":"0","id":"6201","message":"1.Elasticsearch Ingest Node 与Logstash性能对比。\nhttp://t.cn/EUQQ0EQ\n2.方法：如何将rsyslog与Kafka和Logstash集成。\nhttp://t.cn/EUQ8Lyy\n3.(自备梯子)iPhone的黄金时代即将结束。\nhttp://t.cn/EUQ86dB\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6201\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第480期 (2018-12-16)","uid":"4460","views":"207","votes":"0"},"_type":"doc"}
{"_id":"6163","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543602525","category_id":"14","comments":"1","has_attach":"0","id":"6163","message":"\u0026gt; ELK Tips 主要介绍一些 ELK 使用过程中的小技巧，内容主要来源为 Elastic 中文社区。\n\n## 一、Logstash\n### 1、Filebeat 设置多个 output\n在 6.0 之前，Filebeat 可以设置多个输出（必须是不同类型的输出）；从 6.0 开始已经禁止多输出了，只能拥有一个输出，如果想实现多输出，可以借助 logstash 等中间组件进行输出分发。\n\n\n## 二、Elasticsearch\n### 1、ES 用户占用的内存大于为 ES 设置的 heapsize\nES 是 Java 应用，底层存储引擎是基于 Lucene 的，heapsize 设置的是 Java 应用的内存；而 Lucene 建立倒排索引（Inverted Index）是先在内存里生成，然后定期以段文件（segment file）的形式刷到磁盘的，因此 Lucene 也会占用一部分内存。\n\n\u0026gt; https://elasticsearch.cn/article/32\n\n### 2、ES 使用别名插入数据\nES 可以通过索引的方式向索引插入数据，但是同时只能有一个索引可以被写入，而且需要手动设置，未设置的情况下会报错：**no write index is defined for alias [xxxx]**， The write index may be explicitly disabled using `is_write_index=false` or the alias points to multiple indices without one being designated as a write index。\n```\nPOST /_aliases\n{\n    \u0026quot;actions\u0026quot; : [\n        {\n            \u0026quot;add\u0026quot; : {\n                 \u0026quot;index\u0026quot; : \u0026quot;test\u0026quot;,\n                 \u0026quot;alias\u0026quot; : \u0026quot;alias1\u0026quot;,\n                 \u0026quot;is_write_index\u0026quot; : true\n            }\n        }\n    ]\n}\n```\n\n### 3、ES 设置 G1 垃圾回收\n修改 `jvm.options`文件，将下面几行:\n```\n-XX:+UseConcMarkSweepGC\n-XX:CMSInitiatingOccupancyFraction=75\n-XX:+UseCMSInitiatingOccupancyOnly\n```\n改为\n```\n-XX:+UseG1GC\n-XX:MaxGCPauseMillis=50\n```\n即可。\n\n其中 `-XX:MaxGCPauseMillis` 是控制预期的最高 GC 时长，默认值为 200ms，如果线上业务特性对于 GC 停顿非常敏感，可以适当设置低一些。但是这个值如果设置过小，可能会带来比较高的 cpu 消耗。 \n\n### 4、ES 和 Zipkin 集成时设置验证信息\n```\njava -DKAFKA_ZOOKEEPER=10.14.123.117:2181 \n-DSTORAGE_TYPE=elasticsearch \n-DES_HOSTS=http://10.14.125.5:9200 \nES_USERNAME=xxx ES_PASSWORD=xxx \n-jar zipkin.jar\n```\n\n### 5、ES 集群部署报错\n问题 1 报错信息如下：\n```\nReceived message from unsupported version:[2.0.0] minimal compatible version is:[5.6.0]\n```\n经排查是集群中存在低版本的 ES 实例，将低版本实例移除即可。\n\n问题 2 报错信息如下：\n```\nwith the same id but is a different node instance\n```\n删除对应节点 elsticsearch 文件夹下的 data 文件夹下的节点数据即可。\n\n### 6、海量中文分词插件\n海量分词是天津海量信息技术股份有限公司自主研发的中文分词核心，经测试分词效果还是不错的，值得一试。\n\n\u0026gt; https://github.com/HylandaOpen/elasticsearch-analysis-hlseg\n\n### 7、查询一个索引下的所有 type 名\n通过下面的 API，即可获取全部的 type，下面的例子中 doc 就是 indexName 索引下的一个 type：\n```\nGET http://es127.0.0.1:9200/indexName/_mappings\n-----------------------------------------------\n{\n    indexName: - {\n        mappings: - {\n            doc: - {\n                _all: + {... },\n                dynamic_date_formats: + [... ],\n                dynamic_templates: + [... ],\n                properties: + {... }\n            }\n        }\n    }\n}\n```\n\n### 8、索引模板中根据字段值设置别名\n设置索引模板的时候，别名可以使用 Query 条件来进行匹配。\n```\nPUT _template/template_1\n{\n    \u0026quot;index_patterns\u0026quot; : [\u0026quot;te*\u0026quot;],\n    \u0026quot;settings\u0026quot; : {\n        \u0026quot;number_of_shards\u0026quot; : 1\n    },\n    \u0026quot;aliases\u0026quot; : {\n        \u0026quot;alias2\u0026quot; : {\n            \u0026quot;filter\u0026quot; : {\n                \u0026quot;term\u0026quot; : {\u0026quot;user\u0026quot; : \u0026quot;kimchy\u0026quot; }\n            },\n            \u0026quot;routing\u0026quot; : \u0026quot;kimchy\u0026quot;\n        },\n        \u0026quot;{index}-alias\u0026quot; : {} \n    }\n}\n```\n\n### 9、索引模板设置默认时间匹配格式\nES 默认是不会将 yyyy-MM-dd HH:mm:ss 识别为时间的，可以通过在索引模板进行如下设置实现多种时间格式的识别：\n```\n\u0026quot;mappings\u0026quot;: {\n\u0026quot;doc\u0026quot;: {\n  \u0026quot;dynamic_date_formats\u0026quot;: [\u0026quot;yyyy-MM-dd HH:mm:ss||strict_date_optional_time||epoch_millis\u0026quot;],\n```\n\n### 10、ES 中 Merge 相关设置\nMerge 是非常耗费 CPU 的操作；而且如果不是 SSD 的话，推荐将  index.merge.scheduler.max_thread_count 设置为 1；否则 ES 会启动 Math.min(3, Runtime.getRuntime().availableProcessors() / 2) 个线程进行 Merge 操作；这样大部分机械硬盘的磁盘 IO 都很难承受，就可能出现阻塞。\n```\n\u0026quot;index\u0026quot;: {\n  \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot;,\n  \u0026quot;number_of_shards\u0026quot;: \u0026quot;3\u0026quot;,\n  \u0026quot;max_result_window\u0026quot;: 10000,\n  \u0026quot;translog\u0026quot;: {\n    \u0026quot;flush_threshold_size\u0026quot;: \u0026quot;500mb\u0026quot;,\n    \u0026quot;sync_interval\u0026quot;: \u0026quot;30s\u0026quot;,\n    \u0026quot;durability\u0026quot;: \u0026quot;async\u0026quot;\n  },\n  \u0026quot;merge\u0026quot;: {\n    \u0026quot;scheduler\u0026quot;: {\n      \u0026quot;max_merge_count\u0026quot;: \u0026quot;100\u0026quot;,\n      \u0026quot;max_thread_count\u0026quot;: \u0026quot;1\u0026quot;\n    }\n  },\n```\n\n### 11、mapping 中 enabled store index 参数\n- enabled：默认是true，只用于 mapping 中的 object 字段类型；当设置为 false 时，其作用是使 es 不去解析该字段，并且该字段不能被查询和 store，只有在 source 中才能看到，设置 enabled 为 false，可以不设置字段类型，默认类型为 object；\n- store：默认 false，store 参数的功能和 source 有一些相似，我们的数据默认都会在 source 中存在，但我们也可以将数据 store 起来；当我们使用 `copy_to` 参数时，`copy_to` 的目标字段并不会在 source 中存储，此时 store 就派上用场了；\n- index：默认是 true，当设置为 false，表明该字段不能被查询，如果查询会报错。\n\n### 12、ES 图片搜索\n- 可以借助局部敏感 LSH 或者 pHash 来实现：https://stackoverflow.com/questions/32785803\n- Github 也有一个开源项目使用了多种 Hash 算法借助 ES 来实现图片搜索：https://github.com/usc-isi-i2/elasticsearch-image-features\n\n### 13、Term 聚合根据子聚合结果排序\n```\nGET /_search\n{\n    \u0026quot;aggs\u0026quot; : {\n        \u0026quot;genres\u0026quot; : {\n            \u0026quot;terms\u0026quot; : {\n                \u0026quot;field\u0026quot; : \u0026quot;genre\u0026quot;,\n                \u0026quot;order\u0026quot; : { \u0026quot;playback_stats.max\u0026quot; : \u0026quot;desc\u0026quot; }\n            },\n            \u0026quot;aggs\u0026quot; : {\n                \u0026quot;playback_stats\u0026quot; : { \u0026quot;stats\u0026quot; : { \u0026quot;field\u0026quot; : \u0026quot;play_count\u0026quot; } }\n            }\n        }\n    }\n}\n```\n\n## 三、社区文章精选\n- [ET007 ElasticStack 6.5 介绍](https://elasticsearch.cn/article/6144)\n- [CentOS 7.4 下安装 ES 6.5.1 搜索集群](https://elasticsearch.cn/article/6152)\n- [Elastic Stack v6.5 新特性解读](https://elasticsearch.cn/article/6156)\n- [Elasticsearch 史上最全最常用工具清单](https://mp.weixin.qq.com/s/s2ema4tIXKcqTNUUhjGt1w)\n","title":"Day 1 - ELK 使用小技巧（第 3 期）","uid":"8031","views":"962","votes":"5"},"_type":"doc"}
{"_id":"6165","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543713973","category_id":"18","comments":"0","has_attach":"0","id":"6165","message":"1.NoSQL vs SQL：有什么区别以及如何选择。\nhttp://t.cn/ELDJY7y\n2.什么是软件工程中的管道？ Deployment，CI和CD管道简介。\nhttp://t.cn/ELDcM82\n3.(自备梯子)现在是时候认真对待Regulating Tech了。\nhttp://t.cn/ELOozoo\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6165\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第466期 (2018-12-02)","uid":"4460","views":"186","votes":"0"},"_type":"doc"}
{"_id":"6174","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543982107","category_id":"2","comments":"0","has_attach":"0","id":"6174","message":"#10001-log\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/10001/logs/mstore.log\n  fields:\n    env: uat-10001-log\n  include_lines: ['ERROR']\n#10001-catalina\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/10001/logs/catalina.out\n  fields:\n    env: uat-10001-catalina\n  include_lines: ['ERROR']\n#11001-log\n- type: log\n  enabled: true\n  paths:\n    - /mkt/tomcat/8.5.32/11001/logs/delivery.log\n  include_lines: ['ERROR']\n  fields:\n    env: uat-11001-log\n#11001-catalina.out\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/11001/logs/catalina.out\n  fields:\n    env: uat-11001-catalina\n  include_lines: ['ERROR']\n#12001-log\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/12001/logs/mstore.log\n  fields:\n    env: uat-12001-log\n  include_lines: ['ERROR']\n#12001-catalina\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/12001/logs/catalina.out\n  fields:\n    env: uat-12001-catalina\n  include_lines: ['ERROR']\n#13001-log\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/13001/logs/pay-web-boss.log\n  fields:\n    env: uat-13001-log\n    include_lines: ['ERROR']\n#13001-catalina\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/13001/logs/catalina.out\n  fields:\n    env: uat-13001-catalina\n  include_lines: ['ERROR']\n#14001-log\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/14001/logs/pay-web-gateway.log\n  fields:\n    env: uat-14001-log\n  include_lines: ['ERROR']\n#14001-catalina\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/14001/logs/catalina.out\n  fields:\n    env: uat-14001-catalina\n  include_lines: ['ERROR']\n#15001-log\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/15001/logs/roncoo-pay-web-merchant.log\n  fields:\n    env: uat-15001-log\n  include_lines: ['ERROR']\n#15001-catalina\n- type: log\n  enable: true\n  paths:\n    - /mkt/tomcat/8.5.32/15001/logs/catalina.out\n  fields:\n    env: uat-15001-catalina\n  include_lines: ['ERROR']      每次创建索引会少uat-11001-log和uat-12001-log,filebeat读取了这个两个日志文件","title":"es创建索引失败","uid":"10557","views":"185","votes":"0"},"_type":"doc"}
{"_id":"6151","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542868275","category_id":"18","comments":"0","has_attach":"0","id":"6151","message":"1.node框架接入ELK实践总结\nhttp://t.cn/E21vqIJ\n2.携程机票日志追踪系统架构演进\nhttp://t.cn/EzisYHb\n3.手写ElasticSearch分词器\nhttp://t.cn/E21vLG3\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6151\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第456期 (2018-11-22)","uid":"668","views":"214","votes":"0"},"_type":"doc"}
{"_id":"6149","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542724401","category_id":"14","comments":"38","has_attach":"1","id":"6149","message":"活动规则很简单：\n \n活动创意来自于圣诞节倒计时，从12月1号开始到12月25日结束。\n \n每天固定一篇文章分享，内容长短都可。\n \n报名现在开始，留言报名即可，留言格式： Day[日期] -  你的分享标题。\n\n一共25篇，报满即止。\n \n虽然是西方的节日，不过目的是为了大家一起分享，重在参与嘛。\n \n往期活动可参考：https://elasticsearch.cn/topic/advent\n \n活动参与名单：\n[list]\n[*][url=https://elasticsearch.cn/article/6163]Day 1 - ELK 使用小技巧 - @rochy[/url][/*]\n[*][url=https://elasticsearch.cn/article/6166]Day 2 - ES 6.x拼音分词高亮爬坑记 - @abia[/url][/*]\n[*][url=https://elasticsearch.cn/article/6168]Day 3 - kibana二次开发tips - @vv[/url][/*]\n[*][url=https://elasticsearch.cn/article/6171]Day 4 - PB级规模数据的Elasticsearch分库分表实践 - @ouyangchucai[/url][/*]\n[*][url=https://elasticsearch.cn/article/6172]Day 5 - es存储设备全解析 - @cyberdak[/url][/*]\n[*][url=https://elasticsearch.cn/article/6176]Day 6 - 上手 Logstash Pipeline to Pipeline 特性 - @rockybean[/url][/*]\n[*][url=https://elasticsearch.cn/article/6178]Day 7 - Elasticsearch中数据是如何存储的 - @weizijun[/url][/*]\n[*][url=https://elasticsearch.cn/article/6179]Day 8 - 如何使用Spark快速将数据写入Elasticsearch - @Ricky Huo[/url][/*]\n[*][url=https://elasticsearch.cn/article/6182]Day 9 - 动手实现一个自定义beat - @Xinglong[/url][/*]\n[*][url=https://elasticsearch.cn/article/6184]Day 10 - Elasticsearch 分片恢复并发数过大引发的bug分析 - @howardhuang[/url][/*]\n[*][url=https://elasticsearch.cn/article/6186]Day 11 - Elasticsearch 5.x 6.x父子关系维护检索实战 - @yinbp[/url][/*]\n[*][url=https://elasticsearch.cn/article/6191]Day 12 - Elasticsearch日志场景最佳实践 - @ginger[/url][/*]\n[*][url=https://elasticsearch.cn/article/6194]Day 13 - Elasticsearch-Hadoop打通Elasticsearch和Hadoop - @Jasonbian[/url][/*]\n[*][url=https://elasticsearch.cn/article/6197]Day 14 - 订单中心基于elasticsearch 的解决方案 - @blogsit[/url][/*]\n[*][url=https://elasticsearch.cn/article/6199]Day 15 - 基于海量公司分词ES中文分词插件 - @novia[/url][/*]\n[*][url=https://elasticsearch.cn/article/6202]Day 16 - Elasticsearch性能调优 - @白衬衣[/url][/*]\n[*][url=https://elasticsearch.cn/article/6205]Day 17 - 关于日志型数据管理策略的思考 - @kennywu76[/url][/*]\n[*][url=https://elasticsearch.cn/article/6206]Day 18 - 记filebeat内存泄漏问题分析及调优 - @点火三周[/url][/*]\n[*][url=https://elasticsearch.cn/article/6208]Day 19 - 通过点击反馈优化es搜索结果排序 - @laigood[/url][/*]\n[*][url=https://elasticsearch.cn/article/6211]Day 20 - Elastic性能实战指南 - @laoyang360[/url][/*]\n[*][url=https://elasticsearch.cn/article/6213]Day 21 - ECE 版本升级扫雷实战 - @Ben_Wu[/url][/*]\n[*][url=https://elasticsearch.cn/article/6216]Day 22 - 熟练使用ES离做好搜索还差多远 - @nodexy[/url][/*]\n[*][url=https://elasticsearch.cn/article/6219]Day 23 - 基于 HanLP 的 ES 中文分词插件 - @rochy[/url][/*]\n[*][url=https://elasticsearch.cn/article/6215]Day 24 - predator捕捉病毒样本 - @swordsmanli[/url][/*]\n[*][url=https://elasticsearch.cn/article/6221]Day 25 - Elasticsearch Ingest节点数据管道处理器 - @bindiego[/url][/*]\n[/list]\n \n \n [size=16]如何发布？[/size]\n自己选择发布文章，按你的标题在12月你的这一天发布出来就好了。\n\n[attach]3197[/attach]\n\n ","title":"2018 年 Elastic Advent Calendar 分享活动已结束 ??","uid":"1","views":"3454","votes":"7"},"_type":"doc"}
{"_id":"6145","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542598260","category_id":"2","comments":"6","has_attach":"0","id":"6145","message":"海量分词是天津海量信息技术股份有限公司自主研发的中文分词核心，已于2018年7月将分词5.0版免费开放，欢迎试用。\n \n海量分词演示界面 http://bigdata.hylanda.com/smartCenter2018/index\n\n另外，海量提供免费API接口，文档详见http://bigdata.hylanda.com/smartCenter2018/doc，欢迎大家试用，如有疑问，请联系nlp@hylanda.com\n\nAnalyzer: hlseg_search , hlseg_large , hlseg_normal, Tokenizer: hlseg_search , hlseg_large , hlseg_normal\n \ngithub地址：https://github.com/HylandaOpen/elasticsearch-analysis-hlseg/blob/master/README.md","title":"海量科技股份有限公司ES中文插件","uid":"1609","views":"271","votes":"3"},"_type":"doc"}
{"_id":"6140","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542424555","category_id":"2","comments":"0","has_attach":"0","id":"6140","message":"*本文同步发布在腾讯云+社区Elasticsearch专栏中：https://cloud.tencent.com/developer/column/4008*    \n在“[当Elasticsearch遇见Kafka--Logstash kafka input插件](https://cloud.tencent.com/developer/article/1362320)”一文中，我对Logstash的Kafka input插件进行了简单的介绍，并通过实际操作的方式，为大家呈现了使用该方式实现Kafka与Elastisearch整合的基本过程。可以看出使用Logstash input插件的方式，具有配置简单，数据处理方便等优点。然而使用Logstash Kafka插件并不是Kafka与Elsticsearch整合的唯一方案，另一种比较常见的方案是使用Kafka的开源组件Kafka Connect。\n\n![Confluent实现Kafka与Elasticsearch的连接](https://main.qcloudimg.com/raw/ec1869b638c09556cd49bd0965a27ca3.png)\n\n### 1 Kafka Connect简介\n\nKafka Connect是Kafka的开源组件Confluent提供的功能，用于实现Kafka与外部系统的连接。Kafka Connect同时支持分布式模式和单机模式，另外提供了一套完整的REST接口，用于查看和管理Kafka Connectors，还具有offset自动管理，可扩展等优点。  \n\nKafka connect分为企业版和开源版，企业版在开源版的基础之上提供了监控，负载均衡，副本等功能，实际生产环境中建议使用企业版。(本测试使用开源版)  \n\nKafka connect workers有两种工作模式，单机模式和分布式模式。在开发和适合使用单机模式的场景下，可以使用standalone模式, 在实际生产环境下由于单个worker的数据压力会比较大，distributed模式对负载均和和扩展性方面会有很大帮助。（本测试使用standalone模式）  \n\n关于Kafka Connect的详细情况可以参考[[Kafka Connect](https://docs.confluent.io/current/connect/index.html)]\n\n### 2 使用Kafka Connect连接Kafka和Elasticsearch\n\n#### 2.1 测试环境准备\n\n本文与使用Logstash Kafka input插件环境一样[[传送门](https://cloud.tencent.com/developer/article/1362320)]，组件列表如下\n\n| 服务 | ip | port |\n|:----|:----|:----|\n| Elasticsearch service | 192.168.0.8 | 9200 |\n| Ckafka | 192.168.13.10 | 9092 |\n| CVM | 192.168.0.13 | - |\n\n\nkafka topic也复用原来了的**kafka\\_es\\_test**\n\n#### 2.2 Kafka Connect 安装\n\n[[Kafka Connec下载地址](https://www.confluent.io/download/)]  \n\n本文下载的为开源版本confluent-oss-5.0.1-2.11.tar.gz，下载后解压\n\n#### 2.3 Worker配置\n\n1) 配置参考   \n\n如前文所说,worker分为Standalone和Distributed两种模式，针对两种模式的配置，参考如下  \n\n[[通用配置](https://www.confluent.io/download/)]  \n\n[[Standalone Woker配置](https://www.confluent.io/download/)]  \n\n[[Distributed Worker配置](https://www.confluent.io/download/)]  \n\n此处需要注意的是Kafka Connect默认使用AvroConverter，使用该AvroConverter时需要注意必须启动Schema Registry服务\n\n2) 实际操作  \n\n本测试使用standalone模式，因此修改/root/confluent-5.0.1/etc/schema-registry/connect-avro-standalone.properties\n\n```\nbootstrap.servers=192.168.13.10:9092\n```\n\n#### 2.4 Elasticsearch Connector配置\n\n1) 配置参考  \n\n[[Connectors通用配置](https://docs.confluent.io/current/connect/managing/configuring.html#configuring-connectors)]  \n\n[[Elasticsearch Configuration Options](https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/configuration_options.html)]\n\n2) 实际操作  \n\n修改/root/confluent-5.0.1/etc/kafka-connect-elasticsearch/quickstart-elasticsearch.properties\n\n```\nname=elasticsearch-sink\nconnector.class=io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\ntasks.max=1\ntopics=kafka_es_test\nkey.ignore=true\nconnection.url=http://192.168.0.8:9200\ntype.name=kafka-connect\n```\n\n**注意:** 其中topics不仅对应Kafka的topic名称，同时也是Elasticsearch的索引名，当然也可以通过topic.index.map来设置从topic名到Elasticsearch索引名的映射\n\n#### 2.5 启动connector\n\n1 注意事项  \n\n1) 由于配置文件中jar包位置均采用的相对路径，因此建议在confluent根目录下执行命令和启动程序，以避免不必要的问题  \n\n 2) 如果前面没有修改converter，仍采用AvroConverter, 注意需要在启动connertor前启动Schema Registry服务\n\n2 启动Schema Registry服务  \n\n正如前文所说，由于在配置worker时指定使用了AvroConverter，因此需要启动Schema Registry服务。而该服务需要指定一个zookeeper地址或Kafka地址，以存储schema数据。由于CKafka不支持用户通过接口形式创建topic，因此需要在本机起一个kafka以创建名为\\_schema的topic。  \n\n1) 启动Zookeeper\n\n```\n./bin/zookeeper-server-start -daemon etc/kafka/zookeeper.properties\n```\n\n2) 启动kafka\n\n```\n./bin/kafka-server-start -daemon etc/kafka/server.properties\n```\n\n3) 启动schema Registry\n\n```\n./bin/schema-registry-start -daemon etc/schema-registry/schema-registry.properties\n```\n\n4) 使用netstat -natpl 查看各服务端口是否正常启动  \n\nzookeeper 2181  \n\nkafka 9092  \n\nschema registry 8081\n\n3 启动Connector\n\n```\n./bin/connect-standalone -daemon  etc/schema-registry/connect-avro-standalone.properties etc/kafka-connect-elasticsearch/quickstart-elasticsearch.properties\n```\n\nps：以上启动各服务均可在logs目录下找到对应日志\n\n#### 2.6 启动Kafka Producer\n\n由于我们采用的是AvroConverter，因此不能采用Kafka工具包中的producer。Kafka Connector bin目录下提供了Avro Producer\n\n1) 启动Producer\n\n```\n./bin/kafka-avro-console-producer --broker-list 192.168.13.10:9092 --topic kafka_es_test --property value.schema='{\u0026quot;type\u0026quot;:\u0026quot;record\u0026quot;,\u0026quot;name\u0026quot;:\u0026quot;person\u0026quot;,\u0026quot;fields\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;nickname\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;}]}'\n```\n\n2) 输入如下数据\n\n```\n{\u0026quot;nickname\u0026quot;:\u0026quot;michel\u0026quot;}\n{\u0026quot;nickname\u0026quot;:\u0026quot;mushao\u0026quot;}\n```\n\n#### 2.7 Kibana验证结果\n\n1) 查看索引  \n\n在kibana Dev Tools的Console中输入\n\n```\nGET _cat/indices\n```\n\n结果\n\n```\ngreen open kafka_es_test 36QtDP6vQOG7ubOa161wGQ 5 1 1 0 7.9kb 3.9kb\ngreen open .kibana       QUw45tN0SHqeHbF9-QVU6A 1 1 1 0 5.5kb 2.7kb\n```\n\n可以看到名为kafka\\_es\\_test的索引被成功创建\n\n2) 查看数据  \n\n```\n{\n  \u0026quot;took\u0026quot;: 0,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;skipped\u0026quot;: 0,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 2,\n    \u0026quot;max_score\u0026quot;: 1,\n    \u0026quot;hits\u0026quot;: [\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;kafka_es_test\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;kafka-connect\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;kafka_es_test+0+0\u0026quot;,\n        \u0026quot;_score\u0026quot;: 1,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;nickname\u0026quot;: \u0026quot;michel\u0026quot;\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot;: \u0026quot;kafka_es_test\u0026quot;,\n        \u0026quot;_type\u0026quot;: \u0026quot;kafka-connect\u0026quot;,\n        \u0026quot;_id\u0026quot;: \u0026quot;kafka_es_test+0+1\u0026quot;,\n        \u0026quot;_score\u0026quot;: 1,\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;nickname\u0026quot;: \u0026quot;mushao\u0026quot;\n        }\n      }\n    ]\n  }\n}\n```\n\n可以看到数据已经被成功写入\n\n### 3 Confluent CLI\n\n#### 3.1 简介\n\n查阅资料时发现很多文章都是使用Confluent CLI启动Kafka Connect，然而官方文档已经明确说明了该CLI只是适用于开发阶段，不能用于生产环境。  \n\n它可以一键启动包括zookeeper，kafka，schema registry, kafka rest, connect等在内的多个服务。但是这些服务对于Kafka Connect都不是必须的，如果不使用AvroConverter，则只需要启动Connect即可。即使使用了AvroConverter, 也只需要启动schema registry，将schema保存在远端的kafka中。Kafka Connect  REST API也只是为用户提供一个管理connector的接口，也不是必选的。  \n\n另外使用CLI启动默认配置为启动Distributed的Connector，需要通过环境变量来修改配置  \n\n#### 3.2 使用Confluent CLI\n\nconfluent CLI提供了丰富的命令，包括服务启动，服务停止，状态查询，日志查看等，详情参考如下简介视频 [[Introducing the Confluent CLI | Screencast](https://www.youtube.com/watch?v=ZKqBptBHZTg)]\n\n1) 启动\n\n```\n./bin/confluent start\n```\n\n2) 检查confluent运行状态\n\n```\n./bin/confluent status\n```\n\n当得到如下结果则说明confluent启动成功\n\n```\nksql-server is [UP]\nconnect is [UP]\nkafka-rest is [UP]\nschema-registry is [UP]\nkafka is [UP]\nzookeeper is [UP]\n```\n\n3) 问题定位\n\n如果第二步出现问题，可以使用log命令查看，如connect未启动成功则\n\n```\n./bin/confluent log connect\n```\n\n4) 加载Elasticsearch Connector\n\na) 查看connector\n\n```\n./bin/confluent list connectors\n```\n\n结果\n\n```\nBundled Predefined Connectors (edit configuration under etc/):\nelasticsearch-sink\nfile-source\nfile-sink\njdbc-source\njdbc-sink\nhdfs-sink\ns3-sink\n```\n\nb) 加载Elasticsearch connector\n\n```\n./bin/confluent load elasticsearch-sink\n```\n\n结果\n\n```\n{\n    \u0026quot;name\u0026quot;: \u0026quot;elasticsearch-sink\u0026quot;,\n    \u0026quot;config\u0026quot;: {\n        \u0026quot;connector.class\u0026quot;: \u0026quot;io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\u0026quot;,\n        \u0026quot;tasks.max\u0026quot;: \u0026quot;1\u0026quot;,\n        \u0026quot;topics\u0026quot;: \u0026quot;kafka_es_test\u0026quot;,\n        \u0026quot;key.ignore\u0026quot;: \u0026quot;true\u0026quot;,\n        \u0026quot;connection.url\u0026quot;: \u0026quot;http://192.168.0.8:9200\u0026quot;,\n        \u0026quot;type.name\u0026quot;: \u0026quot;kafka-connect\u0026quot;,\n        \u0026quot;name\u0026quot;: \u0026quot;elasticsearch-sink\u0026quot;\n    },\n    \u0026quot;tasks\u0026quot;: [],\n    \u0026quot;type\u0026quot;: null\n}\n```\n\n5) 使用producer生产数据，并使用kibana验证是否写入成功\n\n### 4 Kafka Connect Rest API\n\nKafka Connect提供了一套完成的管理Connector的接口，详情参考[[Kafka Connect REST Interface](https://docs.confluent.io/current/connect/references/restapi.html)]。该接口可以实现对Connector的创建，销毁，修改，查询等操作\n\n1) GET connectors 获取运行中的connector列表\n\n2) POST connectors 使用指定的名称和配置创建connector\n\n3) GET connectors/(string:name) 获取connector的详细信息\n\n4) GET connectors/(string:name)/config 获取connector的配置\n\n5) PUT connectors/(string:name)/config 设置connector的配置\n\n6) GET connectors/(string:name)/status 获取connector状态\n\n7) POST connectors/(stirng:name)/restart 重启connector\n\n8) PUT connectors/(string:name)/pause 暂停connector\n\n9) PUT connectors/(string:name)/resume 恢复connector\n\n10) DELETE connectors/(string:name)/ 删除connector\n\n11) GET connectors/(string:name)/tasks 获取connectors任务列表\n\n12) GET /connectors/(string: name)/tasks/(int: taskid)/status 获取任务状态\n\n13) POST /connectors/(string: name)/tasks/(int: taskid)/restart 重启任务\n\n14) GET /connector-plugins/ 获取已安装插件列表\n\n15) PUT /connector-plugins/(string: name)/config/validate 验证配置\n\n### 5 总结\n\nKafka Connect是Kafka一个功能强大的组件，为kafka提供了与外部系统连接的一套完整方案，包括数据传输，连接管理，监控，多副本等。相对于Logstash Kafka插件，功能更为全面，但配置也相对为复杂些。有文章提到其性能也优于Logstash Kafka Input插件，如果对写入性能比较敏感的场景，可以在实际压测的基础上进行选择。另外由于直接将数据从Kafka写入Elasticsearch, 如果需要对文档进行处理时，选择Logstash可能更为方便。","title":"当Elasticsearch遇见Kafka--Kafka Connect","uid":"8587","views":"365","votes":"1"},"_type":"doc"}
{"_id":"6137","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542278968","category_id":"18","comments":"0","has_attach":"0","id":"6137","message":"1.基于Lucene查询原理分析Elasticsearch的性能\nhttp://t.cn/EwZO5to\n2.一个让elastalert报警更简单的UI\nhttp://t.cn/EAgg8WQ\n3.Filebeat优化实践\nhttp://t.cn/EAge74i\n \n编辑：金桥\n归档：https://elasticsearch.cn/article/6137\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第449期 (2018-11-15)","uid":"668","views":"263","votes":"0"},"_type":"doc"}
{"_id":"6132","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542166752","category_id":"18","comments":"0","has_attach":"0","id":"6132","message":"1. 有赞搜索系统的搭建和演进\nhttp://t.cn/EAd7TEb\n2. 搜索引擎从0到1\nhttp://t.cn/EAVZqan\n3. CentOS7 上搭建多节点 Elasticsearch集群\nhttp://t.cn/EAdzxTP\n \n编辑：江水\n归档：https://elasticsearch.cn/article/6132\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第448期 (2018-11-14)","uid":"3828","views":"241","votes":"0"},"_type":"doc"}
{"_id":"6133","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542168027","category_id":"2","comments":"5","has_attach":"0","id":"6133","message":"2018 Elastic中国开发者大会前一天，我参加了Elastic认证工程师考试，隔天在大会的闪电演讲部分做了一个快速的分享。 昨天考试结果下来了，比较遗憾，没能通过。 不过这次参考心得颇多，值得专门写一篇文总结一下，帮助准备考认证的同学少走一点弯路。\n\n### 考试内容\n官方有一个考试要求达到的目标提纲[Objectives](https://training.elastic.co/exam/elastic-certified-engineer#objectives)， 其中涵盖的知识点还是比较广的，建议每个点都要根据文档操作演练一下。 我考前几天大致扫了一下提纲，感觉基本上都熟悉，没有仔细一一演练。 到了考试的时候，才发现有几个知识点只是浮于表面的了解，细节并不熟悉，临时去读文档时间又不够。\n\n### 考试环境\n用自己的电脑，登陆到考试网站，有一个远程桌面连接到考试虚拟机。虚拟机上原装了5个ES集群，结点数量各异。 桌面提供有一个浏览器，可以访问kibana和官方文档站点，还有一个终端，可以ssh到集群各个结点。 考试所有操作基本都是在kibana的sense和这个终端里完成， 期间只允许访问官方文档，不允许通过Google查找解决方案。 我们是现场考试，人工监考。 常规的考试是通过摄像头远程监考的，并且需要安装一个插件，检查后台进程。 按照规定，自己的机器只能开浏览器，不允许开evernotes等其他辅助工具。 \n远程桌面的速度不是很快，在浏览器里翻看文档会感觉有些卡顿，所以要求对文档非常熟悉，一查即准，否则来回翻页都会消耗不少时间。最好用鼠标，翻页会容易得多，我没带鼠标，用MAC的触摸板翻页，非常痛苦。 另外用Mac的同学，要适应一下拷贝粘贴快捷键，考试机器拷贝粘贴用的是ctrl-c / ctrl-v ，用惯了Mac的快捷键会有些不适应。\n\n### 考试时长\n3个小时，期间可以上厕所，但是建议考前少喝水，上好厕所，时间宝贵。\n\n### 考题形式\n12道考题全部是上机题，每道题描述一个场景，要求解决问题或者达到某个目标。 每道题都会涉及到考试提纲里2-3个知识点，所以对各个知识点细节的了解非常重要， 只要一个知识点理解的模糊，就容易卡住。 做题顺序可以自己控制，最好先把自己熟悉，马上能搞定的先做了，耗时超过10分钟还没把握的，先放一放最后再做把。这12道题我只完成了其中的9个，有3个在现场卡了比较长时间，因为时间不够放弃， 接下来的部分会做更细节的分析。\n\n\n\n### 亲历考题类型总结\n1. 给一个状态是red的集群，要求不损失数据的前提下，让集群变green。  \n该题我遇到3个要解决的问题:\n    * 有一个结点挂了，找到挂掉的结点，ssh上去，手动起来；\n    * 此时集群变成yellow，还是有shard不能分配，检查发现有一个索引的routings设置里，routing -\u0026gt;include里rack1写成了rakc1，故意写错的，修正好即可\n    * 集群依然还有shard是unassinged状态，继续检查发现有一个索引的routings里，include的rack数量不够，导致有些 replica分配不了。 更新一下routing，让他include更多的rack就解决了。集群状态变green。\n    \n    此题考查的知识点包括，如何查看集群状态，如果查看结点列表，如何使用allocation explain api， 如何通过索引的allocation routing控制shard的分布。因为平常工作中解决集群问题比较多，所以此题完成比较轻松。\n    \n\n2. 有一个文档，内容类似`dog \u0026amp; cat`， 要求索引这条文档，并且使用`match_phrase` query，查询`dog \u0026amp; cat`或者`dog and cat`都能match。\n\n    此题我现场没搞出来，当时第一反应是标准tokenizer已经将`\u0026amp;`剥离掉了，那么只要用stop words filter将`and`剥离掉，不就可以了吗？ 结果配置后，发现match不上。 仔细一想，match_phase需要匹配位置的，`\u0026amp;`是tokenize阶段剥离的， `and`是token filter阶段剥离的，这样位置就不对了。 用analyzer api分析一下，位置的确不对。然后想到应该用synonym token filter来处理，结果配置还是一直有问题。 这时候耗时已经太多，直接放弃了。回来后又演练了一下这道题，才发现用synonym token filter是没问题的，但是tokenizer应该改成whitespace，否则\u0026amp;被剥离了。 总结起来还是平常这块用得少，不熟练，所以考试的时候时间一紧，脑子没转过来。\n\n3. 有index_a包含一些文档， 要求创建索引index_b，通过reindex api将index_a的文档索引到index_b。 要求增加一个整形字段，value是index_a的field_x的字符长度； 再增加一个数组类型的字段，value是field_y的词集合。(field_y是空格分割的一组词，比方`\u0026quot;foo bar\u0026quot;`，索引到index_b后，要求变成`[\u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;]`。\n\n    此题没什么技巧，就是考察reindex api的使用+ painless script。 但是我平常不怎么用painless，虽然原理上知道需要对一个字段求size，一个需要做split，但具体的语法不熟悉，也是来不及翻看文档，直接放弃。\n    \n\n4. 按照要求创建一个index template，并且通过bulk api索引一些文档，达到自动创建索引的效果。 创建的索引的settings和mappings应该符合要求。\n    \n    此题比较简单，熟悉index template语法，常用的settings， mappings设置就OK了。\n\n\n5. 按要求写一个查询， 其中一个条件是某个关键词必须包含在4个字段中至少2个。  \n\n    此题也没什么技巧，考查bool query和minimum_should_match，熟悉就能写出来\n\n\n6. 按照要求写一个search template\n\n    熟悉search template的mustache模版语言即可轻松写出，但是很遗憾，平常没用过search template，虽然知道个大概，但是当时写的时候，不知道哪里语法有问题，PUT template总是不成功。猜想可能是哪个位置的字符没有转译产生非法json字符，或者哪一层嵌套有问题。 总之就是调试不成功，又浪费了很多时间。\n    \n\n7. 多层嵌套聚合，其中还包括bucket过滤\n\n    没技巧，熟悉聚合，聚合嵌套，buckets过滤即可。\n\n\n8. 给定一个json文档，要求创建一个索引，定义一个nested field，将json文档索引成嵌套类型，同时完成指定的嵌套查询和排序。\n\n    比较简单，熟悉nested type和nested query即可完成。\n    \n\n9. 给定两个集群，都包含有某个索引。 要求配置cross cluster search，能够从其中一个集群执行跨集群搜索，写出搜索的url和query body。\n\n    中间设置了一个陷阱，有一个集群有结点挂掉了，不能访问。 所以先要解决结点挂掉的问题，然后在要执行查询的集群配置cross cluster。 确认链接没问题以后，写出查询即可。\n\n10. 有一个3结点集群，还有一个kibana。 es集群没有安装x-pack，但是安装包已经放在了机器上，kibana有安装x-pack，并且启用了security，所以此时还连接不到集群。 要求给3个结点配置security，给内置的几个用户分别设定指定的密码。 之后添加指定的新用户，指定的role，并给用户赋予role a, role b。\n\n    此题熟悉x-pack security即可。 先分别ssh到3个结点，安装x-pack后启动结点。 等结点链接成功以后，用初始化内置用户密码的脚本，按要求分别设置密码。 之后就可以用elastic这个内置的管理员账号登陆kibana了。 然后通过kibana的用户和角色管理界面，分别添加对应的用户和角色。\n    \n\n还有2题是什么不太记得了，应该都是要求根据要求创建索引，reindex数据，然后执行某种类型的查询，或者聚合，比较简单吧。\n\n总结下来，本次考试就是考察的知识点比较多，虽然只有12道考题，但是每道考题都是对多个知识点的综合考察，对ES的理解只停留在理论上是不够的，要求比较强的实际动手能力。 能考过的同学，一定是有过比较丰富的实际操作经验，该认证的含金量我感觉还是非常非常的高！","title":"Elastic认证考试心得","uid":"81","views":"1227","votes":"17"},"_type":"doc"}
{"_id":"6127","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541734963","category_id":"2","comments":"1","has_attach":"1","id":"6127","message":"### Elasticsearch5.5冷热数据读写分离\n\n#### 前言\n\n\u0026gt; 冷数据索引：查询频率低，基本无写入，一般为当天或最近2天以前的数据索引\n\u0026gt;\n\u0026gt; 热数据索引：查询频率高，写入压力大，一般为当天数据索引\n\n当前系统日志每日写入量约为6T左右，日志数据供全线业务系统查询使用。\n\n查询问题：\n\n高峰时段写入及查询频率都较高，集群压力较大，查询ES时，常出现查询缓慢问题。\n\n写入问题：\n\n索引峰值写入量约为12w/s，且无副本。加上副本将导致索引写入速度减半、磁盘使用量加倍；不使用副本，若一个节点宕掉，整个集群无法写入，后果严重。\n\n#### 一、冷热数据分离\n\nES集群的索引写入及查询速度主要依赖于磁盘的IO速度，冷热数据分离的关键为使用SSD磁盘存储数据。\n\n若全部使用SSD，成本过高，且存放冷数据较为浪费，因而使用普通SATA磁盘与SSD磁盘混搭，可做到资源充分利用，性能大幅提升的目标。\n\n几个ES关键配置解读：\n\n- 节点属性（后续索引及集群路由分布策略均依据此属性）\n\n  ```\n  node.attr.box_type\n  node.attr.zone\n  ...\n  ```\n\n  elasticsearch.yml中可增加自定义配置，配置前缀为node.attr，后续属性及值可自定义，如：box_type、zone，即为当前es节点增加标签，亦可在启动命令时设置：bin/elasticsearch -d -Enode.attr.box_type=hot\n\n- 索引路由分布策略\n\n  ```\n  \u0026quot;index.routing.allocation.require.box_type\u0026quot;: \u0026quot;hot\u0026quot;\n  ```\n\n  可在索引模板setting中设置，也可通过rest api动态更新。意义为索引依据哪个属性标签，对分片、副本进行路由分布。\n\n  如我们对使用SSD作为存储介质的ES节点增加属性标签node.attr.box_type: hot，对其他SATA类ES节点增加属性标签node.attr.box_type: cool，将使当前索引的分片数据都落在SSD上。\n\n\n[attach]3102[/attach]\n\n  ​\n\n  后续对其索引配置更新为\n\n  ```\n  \u0026quot;index.routing.allocation.require.box_type\u0026quot;: \u0026quot;cool\u0026quot;\n  ```\n\n  将使索引分片从SSD磁盘上路由至SATA磁盘上，达到冷热数据分离的效果。\n\n\n[attach]3105[/attach]\n\n- 集群路由分布策略（此策略比索引级路由策略权重高）\n\n  目的：不将鸡蛋放进一个篮子中。\n\n  ```\n  \u0026quot;cluster.routing.allocation.awareness.attributes\u0026quot;: \u0026quot;box_type\u0026quot;\n  ```\n\n  如上配置，新建索引时，索引分片及副本只会分配到含有node.attr.box_type属性的节点上。（该值可以为多个，如\u0026quot;box_type,zone\u0026quot;）\n\n  若集群中的节点box_type值只有一个，如只有hot，索引分片及副本会落在hot标签的节点上；若box_type值包括hot、cool，则同一个分片与其副本将尽可能不在相同的box_type节点上。\n\n  此种场景使用于：同一个物理机含有多个ES节点，若这多个节点标签相同，使用此路由分布策略将尽可能保证相同物理机上不会存放同一个分片及其副本。\n\n  ```\n  \u0026quot;cluster.routing.allocation.awareness.force.box_type.values\u0026quot;: \u0026quot;hot,cool\u0026quot;\n  ```\n\n  **强制使分片与副本分离**。若只有hot标签的节点，索引只有分片可以写入，副本无法分配；若有hot、cool两种标签节点，相同分片与其副本绝不在相同标签节点上。\n\n\n[attach]3106[/attach]\n\n#### 二、数据读写分离\n\n几点结论：\n\n- 若使当天索引及副本都写在SSD磁盘上，SSD磁盘使用量需20T以上，代价可能过高。（读写效率最高，但由于SSD节点肯定较少，读写都在相同节点上，节点压力会非常大）\n- 现有的方式，只使用普通的SATA磁盘存储，代价最低。（读写效率最低，即为当前运行状况）\n- 使用集群路由分配策略，SSD与SATA各存放1份数据，SSD磁盘需分配10T以上。（读写效率折中，均有较大提升）\n\n若使用折中方案，另一个问题考虑：\n\nSSD节点即有读操作，也有写操作，节点较少，压力还是较大，怎么实现mysql的主从模式，达到读写分离的效果？\n\n**目标**：使主分片分配在SSD磁盘上，副本落在SATA磁盘上，读取时优先从副本中查询数据，SSD节点只负责写入数据。\n\n实现步骤：\n\n1. 修改集群路由分配策略配置\n\n   增加集群路由配置\n\n   ```\n   \u0026quot;allocation.awareness.attributes\u0026quot;: \u0026quot;box_type\u0026quot;,\n   \u0026quot;allocation.awareness.force.box_type.values\u0026quot;: \u0026quot;hot,cool\u0026quot;\n   ```\n\n2. 提前创建索引\n\n   提前创建下一天的索引，索引配置如下（可写入模板中）：\n\n   ```\n   PUT log4x_trace_2018_08_11\n   {\n       \u0026quot;settings\u0026quot;: {\n         \u0026quot;index.routing.allocation.require.box_type\u0026quot;: \u0026quot;hot\u0026quot;,\n         \u0026quot;number_of_replicas\u0026quot;: 0\n   \t}\n   }\n   ```\n\n   此操作可使索引所有分片都分配在SSD磁盘中。\n\n3. 修改索引路由分配策略配置\n\n   索引创建好后，动态修改索引配置\n\n   ```\n   PUT log4x_trace_2018_08_11/_settings\n   {\n     \u0026quot;index.routing.allocation.require.box_type\u0026quot;: null,\n     \u0026quot;number_of_replicas\u0026quot;: 1\n   }\n   ```\n\n\n[attach]3107[/attach]\n\n4. 转为冷数据\n\n   动态修改索引配置，并取消副本数\n\n   ```\n   PUT log4x_trace_2018_08_11/_settings\n   {\n     \u0026quot;index.routing.allocation.require.box_type\u0026quot;: \u0026quot;cool\u0026quot;,\n     \u0026quot;number_of_replicas\u0026quot;: 0\n   }\n   ```\n\n[attach]3104[/attach]\n","title":"elasticsearch冷热数据读写分离","uid":"3625","views":"1019","votes":"4"},"_type":"doc"}
{"_id":"3699","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541302017","category_id":"18","comments":"2","has_attach":"0","id":"3699","message":"1.使用Filebeat和Elasticsearch Ingest管道解析csv文件。\nhttp://t.cn/EwClFun\n2.(自备梯子)Netflix数据管道的演变。\nhttp://t.cn/EwCTGgw\n3.(自备梯子)在Docker容器中运行bash或任何命令。\nhttp://t.cn/EwCEbxU\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/3699\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第438期 (2018-11-04)","uid":"4460","views":"221","votes":"0"},"_type":"doc"}
{"_id":"6125","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541731650","category_id":"18","comments":"0","has_attach":"0","id":"6125","message":"1.Elasticsearch搜索词组，如何更准？\nhttp://t.cn/EZFBj2R\n2.基于日志实现数据同步和抽取方案\nhttp://t.cn/EAygWTO\n3.从es源码发现CPU热点线程\nhttp://t.cn/EAygE0k\n\n重磅活动：Elastic 中国开发者大会 2018明天开始啦！！！\nhttp://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6125\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第443期 (2018-11-09)","uid":"668","views":"272","votes":"0"},"_type":"doc"}
{"_id":"3680","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540961613","category_id":"18","comments":"0","has_attach":"0","id":"3680","message":"1. 日志采集中的关键技术分析\nhttp://t.cn/Ew2Wibs\n2. 日志汇集系统搭建\nhttp://t.cn/RDg9wU2\n3. Elasticsearch通过reroute api重新分配分片\nhttp://t.cn/Ew2lS08\n \n编辑：江水\n归档：https://elasticsearch.cn/article/3680\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第434期 (2018-10-31)","uid":"3828","views":"206","votes":"0"},"_type":"doc"}
{"_id":"127","_index":"forum-mysql","_score":1,"_source":{"addtime":"1484106306","category_id":"5","comments":"2","has_attach":"1","id":"127","message":"转载：[url]http://www.infoq.com/cn/news/2017/01/Rashid-buildYourOwnTool[/url]\n在 [url=http://conf.elasticsearch.cn/2016/beijing.html]Elastic 中国开发者大会 2016上[/url]，ELK 正式宣布更名为“Elastic Stack”，Elastic公司称其开源项目累计已经有8000万次下载。Elastic Stack 最新版本为5.0，从此，Elastic公司会对Elasticsearch、Kibana、Logstash、Beats、X-Pack进行统一规划以同版本号码发布。会上，Kibana 的原作者 Rashid Khan 进行了题为《Kibana 5.0: The Window into the Elastic Stack》。 PPT下载：[url]http://elasticsearch.cn/article/122[/url] \n\n[attach]389[/attach]\n\n早在2001年，Rashid 就接触了运维工作，他的第一份工作是在摩根大通集团做网络运维管理分析员。2012年，Rashid 在美国一家媒体公司担任架构工程师，并且研发了 Kibana 的初始版本，那时他的目的是专门设计界面以适配 Logstash，如今 Kibana 已经逐渐演变成了 Elasticsearch 的分析平台。运维出身的他是在怎样的情况下开始了 Kibana 开发，Kibana 走到今天经历了什么，将来 Kibana 的发展会是怎样的？InfoQ 对 Rashid 进行了采访，以下文章来自于采访稿件的整理。\n\n[b]作为运维人员，我亟须优化日志搜索[/b]\n\n开始的时候做运维工作遇到很多问题，on call待命，甚至在凌晨2点被叫醒；这种工作状态让我感到很厌烦。往往，在日志中可以发现问题所在，但是需要花费好久时间才能找到。\n\n于是，我寻找有哪些开源软件可以做基本的日志搜索，然后发现了Logstash和与之配合使用的Elasticsearch。经过测试，我发现Elasticsearch速度很快并且提供我所需要的功能；然后我就开始编写一套非常简单的interface作为补充展示，大概花费了我几天的时间。这就是第一版Kibana的诞生过程，当时是采用PHP编写的，功能是可以展示日志并配有搜索入口，目的是把这个工具可以交付给我的boss，使得他无需我的参与便可以使用这个interface。需要提一句的是，Elasticsearch 对于Web编程很友好，并且日志数据按照日期排列。\n\n在全职投入 Kibana 为 Elastic 公司工作之前，我一直从事运维工作并且我非常喜欢运维工作。因为这段实践经验帮助我体会到了运维人的问题和困难，这让我知道了需要创造一个什么样的工具。我依然认为运维是一个非常有挑战的工作，让所有的东西都正常地运转起来。\n\n[b]编程吧，动手创造自己的工具[/b]\n\n的确，我是运维人员，但是我还自己动手开发工具。这在美国越来越普遍了，因为大家意识到，如果你可以编写代码，你的工作会轻松很多，代码可以代替你进行重复工作。通过代码实现自动化是正确的途径，没有人愿意不停地做同样的事情。\n\n编写Kibana是因为我当时没有发现一个适合我的工具，于是我决定自己动手。第一版Kibana是用PHP写的，第二版是用Ruby，第三版之后是用JavaScript。我不害怕学习心得语言，因为学语言并不难，Ruby或者JavaScript的语言掌握仅仅是简单的熟悉语法，并没有接触到实际项目中复杂的事情。而重写Kibana的工作也并不复杂，因为其实Elasticsearch做的工作最重。\n\n“哪种编程语言最好？”说实话，其实这个问题的讨论对我而言并不重要。重要的是，为你的工作选择恰当的语言。PHP在我心中仍然有一席之地，我认为它依然是一个好的语言，可能很多人有异议，但是我认为它简单易上手、稳定变化慢，相关工具也很容易上手。Node.js相对来说，比较复杂；Node社区也意识到这个问题，并且正在改进。比如说，当时我选择了Ruby重写Kibana，是因为Logstash是用JRuby写的，Elasticsearch 使用Java写的（JRuby可以理解为Ruby可以跑在JVM里面）。当时想把 Kibana 的 Ruby那个版本是因为想放到Logstash中，但是没有成功。所以，接下来我们研发了Kibana 3 。\n\n在开发Kibana之前，我用过Graphite，但是为什么依然不满足呢？首先，Graphite很棒，所有关于数字、指标、时间序列的事情。但是那个时候，我需要的是一个可以做日志搜索的东西，需要有一个Dashboard可以给出一个图片。我非常希望从日志中获得信息并且把它们和预定的指标绑定在一起，实际上这些幕后工作都是Elasticsearch做的，并且速度真的快很多。此外需要考虑到扩展性，Graphite对于它适合的大小还算可以，即使超过了极限，更多的数据对应着更多的CPU消耗；但是想扩展很多的话，就很困难了，这一点上Graphite还有很多可以提升的空间，Elastic Stack就可以很轻松地实现。\n\n不过，我依然很喜欢Graphite，我也依然认为这是一个有需求的工具，并且它其实是可以和Elasticsearch、Kibana结合在一起使用的。Architecture dependent的问题困扰了很多人， 比如32bit和64bit两者之间，即便是传输一个文件也不能工作，这是一个非常可怕的事情。Graphite 解决了这个问题，并且界面很美，功能强大 。Kibana也解决了很多相似的问题， 尤其是加上了Elasticsearch的配合，解决了许多我在做运维工作时总是非常想做的工作。\n\n[b]从来没有犹豫过是否开源[/b]\n\n12岁的时候就开始接触开源项目了，所以在写Kibana的时候从来没有犹豫过要不要把它开源。\n\n开始的时候我们只是把需求写在纸上，然后一条条做。放到Github之后，看到下载量不断上升我们感到很吃惊。我们没有想到，原来这么多人都面临这同样的问题，没有想到大家对这样的一个开源项目如此需要。开源的目的就是为了能帮助人们，最初我也曾疑惑有可能根本没有人用；然后发现越来越多的人在讨论、使用它。现在Elastic Stack是一个开源整体，把个人的事业career放在服务其他人的开源项目上，并能收获到好的反馈，这让我们感到很开心、很欣慰。\n\n[b]当时的小愿望，现在的大公司[/b]\n\nKibana第一版存在仅仅几周。是因为我开始使用Ruby进行重写，这大概花费了两周的时间。因为Logstash使用Ruby写的（即便当时我并不会Ruby），而我的目的就是让Kibana适配Logstash和Elasticsearch，让三者在一起可以协作获得更多的信息。当时我的想法就是让三个工具可以无缝衔接起来好似一个工具一样，有趣的是，这仅仅是当时我自己的一个愿望，后来Elasticsearch的人联系我问要不要合并在成为同一家公司，我们才发现彼此的看法竟然不谋而合。\n\n[attach]392[/attach]\n\n我现在依然是on call的。在 Elastic 公司，我们有on call轮班制。其实这是与用户交流的机会，这是我们 Elastic 每一个开发者都非常珍视的机会。在对用户支持的过程中，我们可以更清晰地了解用户的需求和真实使用情况；还有一些其他方式，比如会议、沙龙、见面会等，任何可以帮助我们与社区连接的。在我看来，在用户发生问题时，你在他身边并且帮助修复问题：没有比这个更好的工作方式。所以，on call不是折磨，是机会。\n\n[b]Kibana的下一步：数据挖掘、角色报表[/b]\n\n1、数据挖掘，精益求精\n\n最开始在做日志分析的那个时候，坦率地讲，我并没有关联到了Data mining。因为那时只是想先把问题弄清楚。但是在把所有的问题都解决完（这些并不难，只是花时间而已），实现了最初我们想要的Kibana之后，运维的工作量就大大减少了。\n\n一切都运转得很顺利之后，我们开始思考怎样能把事情做得越来越好，尽量少地产生问题。我们可以获得数据，并且发现了一些问题发生的规律：问题的发生节点，比如说往往半夜三点、发布新版本之后；问题的发生频率，哪些问题非常热门，我们需要把对应的工作放在CDN上；问题的优化处理，发生问题之后如何最快地回滚。机器学习很强有力，而且对于运维人员而言，越少的红色提示越幸福。但是目前我的考虑是，能做到提前预警就已经很棒了。\n\n基于这些思考，我们认为需要开始进行数据挖掘的工作了，这样才把事情做得越来越好，才能更大程度地帮助公司用户。在五六年前，很少会有人想到运维团队可以给出商业业务的指导意见，但是现在这开始越来越普遍。\n\n2、接下来，Dashboard不会只有public一种\n\n此前Kibana的Dashboard是完全公开的，没有角色区分。我知道一些其他的工具提供了包边权限区分的功能。最初的时候，只是想保持事情的简单化，Kibana并没有考虑到把Dashboard做成基于角色的，我们考虑更多的是产品易用性、功能，而没有打算触及安全模块。对于我们自己而言，这并不是过去那些年优先级第一的事项。最开始Kibana的主要矛盾是怎样把内容展现出来，打造Elasticsearch的良好用户界面，所以那个时候是界面是对所有用户可见的。而权限的控制我们是在Elasticsearch上面实现的，搜索、索引、集群操作添加是在Elasticsearch，也就是说我们首先Elasticsearch中实现数据层的安全。\n\n接下来，我们考虑怎样把安全性延展到Kibana中，对不同角色进行区分化的搜索展示。（此前，有一个插件可以满足在Kibana中进行 Elasticsearch 用户的控制。代码是开源的，任何公司都可以编写自己的安全模块，并且我们也乐意帮助他们）在决定做一件事情之后我们就希望把一件事情做得非常好，而不是半途而废。\n\n[b]Kibana in Elastic Stack 5.0[/b]\n\n[attach]391[/attach]\n\n研发情况\n\n研发出新功能的第一版本通常很快，但是需要不断的测试确保所有运转正常。Elastic Stack5.0 的所有功能大概花费了9个月的研发时间。在决策哪些功能需要研发时，我们有几周的考虑时间，还会参考社区中的反馈。然后我们还会给开发者一些自主空间，我们试着避免总是给某些人下发某些任务。我们认为最好主意并不来自与管理层或者经理，而是来自于那些与用户交流频繁的软件工程师，花费很多时间做客户支持的同事。会面通常是远程的，因为我们是个分布式的公司，公司成员分布于30多个国家，一共470多人。Kibana部分的研发、测试和运营人员一共有20多人。\n\n如果有两个程序员所做的事情是一样的话，没有关系这不是重复劳动，反而可以让产品更加优化，两个人可以互相讨论加速功能研发；否则的话产品会被程序员打上过强的个人烙印，最终让产品交付给客户的是整个团队。\n\n[b]会一直并且只是配合Elasticsearch[/b]\n\n是的，我们没有其他 datasource 的计划，因为我们大部分的使用case是要有时间序列的。\n\n最开始融合在一起的是 Elasticsearch 和 Logstash，然后 Kibana 参与进来。在这个融合的过程中，遇到任何冲突或者改变，我们的评判标准都是怎样对用户而言更友好。举例说明，安全问题最佳的解决是在数据层，搜索非常占用内存，使用ES可以做很复杂的事情，在旧版本的 Kibana 中，可以使用 Elasticsearch 的 API，但是这拖缓了速度，并且用户可能会做一些危险的事情。在 Kibana 和 Elasticsearch 融合之后，我再也没有那样做了，对于一些重的内存需求工作不会在UI层（Kibana）而是会放到数据层（ES），用最少的内存，让尽可能多的计算脱离 JVM heap ，放入socket breaker，让我们管理更简洁干净并做到在UI可追踪。\n\n[b]Kibana的美学[/b]\n\nKibana最初的设计师只是我一个人，现在当然我们有了自己的很优秀的设计师，这是很被看重的部分，没有外包出去。因为我们需要和设计团队频繁地交流，不断地给予反馈，和工程团队。这是我们公司文化的一个重要部分。\n\n你想一想这是运维人员需要终日面对的工具，没有人愿意一直看着丑的东西；此外，也希望Kibana可以让运维人员的boss们感到惊艳，我们希望可以帮助使用者产生非常美的工作。\n\n[b]写在最后[/b]\n\n在采访结束时，InfoQ问Rashid是否可以给广大读者一些建议，Rashid想了想说：\n[quote]\n如果你有一个想法，把它code出来，build起来。不要等其他人的开源代码，有可能你会等到，但是有可能你永远等不到。在你写出来之后，你没准会收获惊喜。\n[/quote]\n [attach]388[/attach]\n ","title":"对话 Kibana 之父：如果需要，你应该自己动手编写工具","uid":"1","views":"3569","votes":"2"},"_type":"doc"}
{"_id":"136","_index":"forum-mysql","_score":1,"_source":{"addtime":"1488335857","category_id":"5","comments":"5","has_attach":"0","id":"136","message":"[b]Elasticsearch 5.2.2[/b]\n[list]\n[*]修复request熔断器没有正确处理当前运行请求数的bug，当请求返回前却被客户端关闭时没有对计数减一，会造成节点慢慢的不能处理任何请求，除非重启节点，所有的用户都应该升级 [url=https://github.com/elastic/elasticsearch/pull/23317]#23317[/url][/*]\n[*]修复cgroup正则解析的bug，造成节点的不能正常启动 [url=https://github.com/elastic/elasticsearch/pull/23219]#23219[/url][/*]\n[*]被shard锁暂缓执行的请求可能会别其他线程启动，并且该请求丢失了上下文，会造成该请求被当做非法请求而拒绝[/*]\n[*]恢复terms agg的include/exclude参数的支持[/*]\n[/list]\n \n下载：[url]https://www.elastic.co/downloads/elasticsearch[/url]\n完整的Release notes：[url]https://www.elastic.co/guide/en/elasticsearch/reference/5.2/release-notes-5.2.2.html[/url]\nXPack release notes：[url]https://www.elastic.co/guide/en/x-pack/current/xpack-release-notes.html#xpack-5.2.2[/url]\n \n[b]Logstash 5.2.2[/b]\n[list]\n[*]修复持久化队列在windows启用造成的崩溃[/*]\n[*]修复多实例公用相同的数据目录造成的数据损坏[/*]\n[*]修复JVM性能指标收集造成的吞吐影响[/*]\n[/list]\n \n下载：https://www.elastic.co/downloads/logstash\nRelease notes:https://www.elastic.co/guide/en/logstash/5.2/logstash-5-2-2.html\n \n[b]Kibana 5.2.2[/b]\n[list]\n[*] 之前的版本kibana的visualization依赖一个旧的Elasticsearch的include/exclude特性，但是该功能在Elasticsearch5.2.1被突然移除了，引起了kibana的visualization的错误，现在Kibana对新创建的visualization使用正确的结构，并且能在查询时自动转换遗留的旧结构到新的结构[/*]\n[*]从5.2.0开始，包含sub-bucket的垂直条形图（vertical bar）配置为分组没有合适的缩减y轴，造成相当小甚至某些情况下不可用，这次回归将再次对y轴进行必要的扩展而不管其条形图的模式[/*]\n[/list]\n \n下载：[url]https://www.elastic.co/downloads/kibana[/url]\n完整Release notes https://www.elastic.co/guide/en/kibana/current/release-notes-5.2.2.html\n \n[b]Beats 5.2.2[/b]\n[list]\n[*]Metricbeat修复当docker容器被kill掉造成的docker 模块挂起的bug[/*]\n[*]Metricbeat修复超时时间设置而不是默认值[/*]\n[/list]\n \nRelease notes：[url]https://www.elastic.co/guide/en/beats/libbeat/5.2/release-notes-5.2.2.html[/url]\n下载：https://www.elastic.co/downloads/beats/","title":"Elastic Stack 5.2.2 发布 ","uid":"1","views":"1588","votes":"2"},"_type":"doc"}
{"_id":"135","_index":"forum-mysql","_score":1,"_source":{"addtime":"1487820300","category_id":"5","comments":"1","has_attach":"1","id":"135","message":"问卷调查直达链接：[url]https://www.surveymonkey.com/r/elastic-china17[/url] \n \n同学们，乡亲们：\n    想要今年的Elastic线下活动来到您身边么，快参加我们的问卷调查吧，如果您的城市不在下拉列表，记得添加进去，问卷调查比较简单啦，大概只需要花费您几分钟时间，快来吧：https://www.surveymonkey.com/r/elastic-china17 。\n \n   另外Elastic也在寻找各个城市的演讲者、场地赞助、协办方、志愿者。如果您有项目用到了任何Elasticsearch、Kibana、Logstash或Beats，并且有兴趣分享您的经验故事（不管是5分钟还是50分钟）请让我们知道，我们非常愿意与我们的社区一起分享您的故事。不管是哪种参与方式都欢迎，请在问卷内留下联系方式或联系我：medcl123（添加注明来意）。\n[quote]\n我们感谢您参与本次问卷调查！问题集中在您想参加的线下活动类型，调查结果将被用来使组织者更好地安排活动计划。本调查预计需要花费2 - 5分钟才能完成。我们将与所有参与调查的人分享任何有趣的发现。所有收集的信息将保持匿名。为了鼓励大家花费这一天中的几分钟时间，将随机抽取五个人赢得 $50 美元的亚马逊礼品卡和十五个人将赢得 Elastic Stack 特别版T恤。为了进行抽奖活动，我们会在调查结束时要求您提供电子邮件，但只会用它来让您知道如果您中奖了。\n[/quote]\n \n除了这个问卷调查，我们在也同时更新了 Elastic 用户组的行为准则（Code of Conduct）。参加我们的活动意味着您同意我们的准则。完整的准则可以访问：https://www.elastic.co/community/codeofconduct。所有的细节可以这个链接页找到。如果您还要其他问题，也欢迎告知我们：） — 我们会一直在这里提供帮助!  :)\n [attach]420[/attach]","title":"欢迎参加Elastic的Meetup线下活动问卷调查","uid":"1","views":"1733","votes":"0"},"_type":"doc"}
{"_id":"146","_index":"forum-mysql","_score":1,"_source":{"addtime":"1490596451","category_id":"5","comments":"3","has_attach":"0","id":"146","message":"南京meetup筹备中，有意提供分享的同学请将\n1. 个人简介\n2. 主题简介\n3. 大概内容\n发送到 kenny_ye@trendmicro.com.cn\n \n征稿截止日期： 2017年5月7日\n \n欢迎踊跃投稿！","title":"Elastic南京meetup分享征集中","uid":"1264","views":"1880","votes":"5"},"_type":"doc"}
{"_id":"137","_index":"forum-mysql","_score":1,"_source":{"addtime":"1488352538","category_id":"3","comments":"8","has_attach":"1","id":"137","message":"\r\n写之前这里先打个广告，java版本的logstash已经开源。git地址：https://github.com/dtstack，下面进入正题。\r\n\r\n\r\n[b]jlogstash性能：[/b]\r\n\r\n当时袋鼠云的云日志系统的日志接收端是ruby版本的logstash，存储使用的是elasticsearch，前端的展示没有使用原生的kibana，而是自己写了一套前端。\r\n\r\n本人是负责日志接收端的logstash开发人员，主要负责基于ruby版本的logstash编写一些公司业务需要的插件。\r\n\r\n当时为了提升性能做了各种优化，比如用java重写了一些模块，再用ruby调用这些模块，比如ip的解析模块，但是最终优化的结果只是单机4core、4g的虚拟机每小时最多能处理800万的数据而已（我们的场景跟大部分人一样都是订阅kafka的消息，再经过一些filter(瓶颈主要是这里比较耗cpu)写入elasticsearch）。\r\n\r\n因为logstash的核心代码是用ruby语言开发，虽然运行在jruby上，但是由于中间涉及到数据结构的转化，性能跟原生的class运行在jvm上肯定是有所差距的。\r\n\r\n所以当时抱着尽可能最大程度上提升性能，更好地满足用户需求的目的，用java重写了logstash，并把需要用到的插件也进行了重写。在同样的4core、4g虚拟机环境下，每小时能处理4000万数据，性能有了近5倍的提升。\r\n\r\n\r\n下面是java logstash 和 ruby logstash（2.3.2版本）按照logstash官方测试方案做的性能对比：\r\n \r\n\r\n[attach]421[/attach]\r\n\r\n\r\ngit 地址（https://github.com/DTStack/jlogstash-performance-testing） \r\n\r\n\r\n\r\n以上三种场景的处理效率\r\n\r\njava版本logstash性能分别是ruby版本logstash的2.99倍、4.15倍、3.49倍。\r\n\r\n\r\n[b]jlogstash尽可能保证数据不丢失：[/b]\r\n\r\nruby 版本的logstash，对保证数据防丢失这块没做太多的设计。\r\n\r\n\r\n举个列子：数据从kafka消费再output到elasticsearch，一旦elasticsearch集群不可用，ruby logstash会自动重试几次，如果还不成功就会放弃继续消费kafka里的数据，而且重试的动作也是elasticsearch插件自身来完成的，logstash本身并没有对数据防丢失做设计。\r\n\r\n\r\n而java 版本logstash 的BaseOutput 这个抽象类里面有个failedMsgQueue队列，每个output实例维护一个，output 插件需要自身判断哪些数据失败了，再调用addFailedMsg方法把失败的数据写入到failedMsgQueue队列里。java logstash一旦发现failedMsgQueue里面有数据就会调用sendFailedMsg这个方法来消费这里的数据，直到数据消费完成才会去消费input里的数据。这个逻辑是可以通过consistency这个属性来控制的。该属性默认是关闭的。\r\n\r\n还有一点是input和output插件都提供了release方法，这个主要是为了jvm退出时要执行一些动作而设计的。\r\n\r\n因为大部分的input和output插件在获取和发送数据时都会先放在一个集合里面，再去慢慢消耗集合里面的数据。这样jvm退出时，插件就可以各自实现自己的逻辑，从而保证jvm退出前，集合里面的数据彻底消耗完。当然如果你强制杀死该进程（kill -9）那就没法保证了。\r\n\r\n现在我们的elasticsearch插件已经实现了数据防丢失逻辑，并且已经在我们的生产环境稳定的跑了很长时间了。\r\n\r\n\r\n[b]jlogstash可以是分布式应用，而不只是单机应用：[/b]\r\n\r\n我们这边开发了kafkadistributed插件，通过zookeeper把jlogstash变成分布式应用，因为从客户端采集上来的数据分发到kafka集群中数据是无序的，比如要分析jvm1.8 gc日志，cms的gc日志分成5个步骤，这5个步骤是一个整体，中间有可能夹杂着yonggc的日志，这样数据采集到kafka的时候就会乱序，后端又有多台jlogstash去订阅kafka，这样多台单机版本的jlogstash是没法保证一个完整的cms日志进入到同一个jvm上进行统一分析，所以我们通过zookeeper把jlogstash变成分布式应用，会把同一个文件的日志分发到同一个jlogstash上，这样就能保证cms数据的完整性。\r\n\r\n最后希望jlogstash能为一些开发者解决一些问题，也希望有更多的人参与到jlogstash的插件开发里来。\r\n\r\n注释：有人问jlogstash跟hangout有什么区别，这里就不做说明了，有兴趣的同学可以看看这两个的源码就知道区别了。\r\n\r\n\r\n\r\n\r\n\r\n\r\n ","title":"为什么用java重写logstash","uid":"2020","views":"6808","votes":"2"},"_type":"doc"}
{"_id":"142","_index":"forum-mysql","_score":1,"_source":{"addtime":"1489672363","category_id":"2","comments":"22","has_attach":"1","id":"142","message":"现代的搜索引擎，一般会具备\u0026quot;Suggest As You Type\u0026quot;功能，即在用户输入搜索的过程中，进行自动补全或者纠错。 通过协助用户输入更精准的关键词，提高后续全文搜索阶段文档匹配的程度。例如在Google上输入部分关键词，甚至输入拼写错误的关键词时，它依然能够提示出用户想要输入的内容:\n\n[attach]507[/attach]\n\n[attach]508[/attach]\n\n\n如果自己亲手去试一下，可以看到Google在用户刚开始输入的时候是自动补全的，而当输入到一定长度，如果因为单词拼写错误无法补全，就开始尝试提示相似的词。\n\n那么类似的功能在Elasticsearch里如何实现呢？ 答案就在Suggesters API。 Suggesters基本的运作原理是将输入的文本分解为token，然后在索引的字典里查找相似的term并返回。 根据使用场景的不同，Elasticsearch里设计了4种类别的Suggester，分别是:\n[list]\n[*]Term Suggester[/*]\n[*]Phrase Suggester[/*]\n[*]Completion Suggester[/*]\n[*]Context Suggester[/*]\n[/list]\n\n在官方的参考文档里，对这4种Suggester API都有比较详细的介绍，但苦于只有英文版，部分国内开发者看完文档后仍然难以理解其运作机制。 本文将在Elasticsearch 5.x上通过示例讲解Suggester的基础用法，希望能帮助部分国内开发者快速用于实际项目开发。限于篇幅，更为高级的Context Suggester会被略过。\n\n\n首先来看一个Term Suggester的示例:\n准备一个叫做blogs的索引，配置一个text字段。\n[quote]\nPUT /blogs/\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;tech\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;body\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n        }\n      }\n    }\n  }\n}\n[/quote]\n通过bulk api写入几条文档\n[quote]\nPOST _bulk/?refresh=true\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Lucene is cool\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elasticsearch builds on top of lucene\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elasticsearch rocks\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elastic is the company behind ELK stack\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;elk rocks\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{  \u0026quot;body\u0026quot;: \u0026quot;elasticsearch is rock solid\u0026quot;}\n[/quote]\n\n此时blogs索引里已经有一些文档了，可以进行下一步的探索。为帮助理解，我们先看看哪些term会存在于词典里。\n将输入的文本分析一下:\n[quote]\nPOST _analyze\n{\n  \u0026quot;text\u0026quot;: [\n    \u0026quot;Lucene is cool\u0026quot;,\n    \u0026quot;Elasticsearch builds on top of lucene\u0026quot;,\n    \u0026quot;Elasticsearch rocks\u0026quot;,\n    \u0026quot;Elastic is the company behind ELK stack\u0026quot;,\n    \u0026quot;elk rocks\u0026quot;,\n    \u0026quot;elasticsearch is rock solid\u0026quot;\n  ]\n}\n[/quote]\n\n(由于结果太长，此处略去)\n\n这些分出来的token都会成为词典里一个term，注意有些token会出现多次，因此在倒排索引里记录的词频会比较高，同时记录的还有这些token在原文档里的偏移量和相对位置信息。\n执行一次suggester搜索看看效果:\n[quote]\nPOST /blogs/_search\n{ \n  \u0026quot;suggest\u0026quot;: {\n    \u0026quot;my-suggestion\u0026quot;: {\n      \u0026quot;text\u0026quot;: \u0026quot;lucne rock\u0026quot;,\n      \u0026quot;term\u0026quot;: {\n        \u0026quot;suggest_mode\u0026quot;: \u0026quot;missing\u0026quot;,\n        \u0026quot;field\u0026quot;: \u0026quot;body\u0026quot;\n      }\n    }\n  }\n}\n[/quote]\n\nsuggest就是一种特殊类型的搜索，DSL内部的\u0026quot;text\u0026quot;指的是api调用方提供的文本，也就是通常用户界面上用户输入的内容。这里的lucne是错误的拼写，模拟用户输入错误。 \u0026quot;term\u0026quot;表示这是一个term suggester。 \u0026quot;field\u0026quot;指定suggester针对的字段，另外有一个可选的\u0026quot;suggest_mode\u0026quot;。 范例里的\u0026quot;missing\u0026quot;实际上就是缺省值，它是什么意思？有点挠头... 还是先看看返回结果吧:\n[quote]\n{\n  \u0026quot;took\u0026quot;: 1,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 1,\n    \u0026quot;successful\u0026quot;: 1,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 0,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;:\n  },\n  \u0026quot;suggest\u0026quot;: {\n    \u0026quot;my-suggestion\u0026quot;: [\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;lucne\u0026quot;,\n        \u0026quot;offset\u0026quot;: 0,\n        \u0026quot;length\u0026quot;: 5,\n        \u0026quot;options\u0026quot;: [\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;lucene\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.8,\n            \u0026quot;freq\u0026quot;: 2\n          }\n        ]\n      },\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;rock\u0026quot;,\n        \u0026quot;offset\u0026quot;: 6,\n        \u0026quot;length\u0026quot;: 4,\n        \u0026quot;options\u0026quot;:\n      }\n    ]\n  }\n}\n[/quote]\n\n在返回结果里\u0026quot;suggest\u0026quot; -\u0026gt; \u0026quot;my-suggestion\u0026quot;部分包含了一个数组，每个数组项对应从输入文本分解出来的token（存放在\u0026quot;text\u0026quot;这个key里）以及为该token提供的建议词项（存放在options数组里)。  示例里返回了\u0026quot;lucne\u0026quot;，\u0026quot;rock\u0026quot;这2个词的建议项(options)，其中\u0026quot;rock\u0026quot;的options是空的，表示没有可以建议的选项，为什么？ 上面提到了，我们为查询提供的suggest mode是\u0026quot;missing\u0026quot;,由于\u0026quot;rock\u0026quot;在索引的词典里已经存在了，够精准，就不建议啦。 只有词典里找不到词，才会为其提供相似的选项。\n\n如果将\u0026quot;suggest_mode\u0026quot;换成\u0026quot;popular\u0026quot;会是什么效果？\n尝试一下，重新执行查询，返回结果里\u0026quot;rock\u0026quot;这个词的option不再是空的，而是建议为rocks。\n[quote]\n \u0026quot;suggest\u0026quot;: {\n    \u0026quot;my-suggestion\u0026quot;: [\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;lucne\u0026quot;,\n        \u0026quot;offset\u0026quot;: 0,\n        \u0026quot;length\u0026quot;: 5,\n        \u0026quot;options\u0026quot;: [\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;lucene\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.8,\n            \u0026quot;freq\u0026quot;: 2\n          }\n        ]\n      },\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;rock\u0026quot;,\n        \u0026quot;offset\u0026quot;: 6,\n        \u0026quot;length\u0026quot;: 4,\n        \u0026quot;options\u0026quot;: [\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;rocks\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.75,\n            \u0026quot;freq\u0026quot;: 2\n          }\n        ]\n      }\n    ]\n  }\n[/quote]\n\n回想一下，rock和rocks在索引词典里都是有的。 不难看出即使用户输入的token在索引的词典里已经有了，但是因为存在一个词频更高的相似项，这个相似项可能是更合适的，就被挑选到options里了。 最后还有一个\u0026quot;always\u0026quot; mode，其含义是不管token是否存在于索引词典里都要给出相似项。\n\n有人可能会问，两个term的相似性是如何判断的？ ES使用了一种叫做Levenstein edit distance的算法，其核心思想就是一个词改动多少个字符就可以和另外一个词一致。 Term suggester还有其他很多可选参数来控制这个相似性的模糊程度，这里就不一一赘述了。\n\nTerm suggester正如其名，只基于analyze过的单个term去提供建议，并不会考虑多个term之间的关系。API调用方只需为每个token挑选options里的词，组合在一起返回给用户前端即可。 那么有无更直接办法，API直接给出和用户输入文本相似的内容？ 答案是有，这就要求助Phrase Suggester了。\n\nPhrase suggester在Term suggester的基础上，会考量多个term之间的关系，比如是否同时出现在索引的原文里，相邻程度，以及词频等等。看个范例就比较容易明白了:\n[quote]\nPOST /blogs/_search\n{\n  \u0026quot;suggest\u0026quot;: {\n    \u0026quot;my-suggestion\u0026quot;: {\n      \u0026quot;text\u0026quot;: \u0026quot;lucne and elasticsear rock\u0026quot;,\n      \u0026quot;phrase\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;body\u0026quot;,\n        \u0026quot;highlight\u0026quot;: {\n          \u0026quot;pre_tag\u0026quot;: \u0026quot;\u0026lt;em\u0026gt;\u0026quot;,\n          \u0026quot;post_tag\u0026quot;: \u0026quot;\u0026lt;/em\u0026gt;\u0026quot;\n        }\n      }\n    }\n  }\n}\n[/quote]\n\n返回结果:\n[quote]\n\u0026quot;suggest\u0026quot;: {\n    \u0026quot;my-suggestion\u0026quot;: [\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;lucne and elasticsear rock\u0026quot;,\n        \u0026quot;offset\u0026quot;: 0,\n        \u0026quot;length\u0026quot;: 26,\n        \u0026quot;options\u0026quot;: [\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;lucene and elasticsearch rock\u0026quot;,\n            \u0026quot;highlighted\u0026quot;: \u0026quot;\u0026lt;em\u0026gt;lucene\u0026lt;/em\u0026gt; and \u0026lt;em\u0026gt;elasticsearch\u0026lt;/em\u0026gt; rock\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.004993905\n          },\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;lucne and elasticsearch rock\u0026quot;,\n            \u0026quot;highlighted\u0026quot;: \u0026quot;lucne and \u0026lt;em\u0026gt;elasticsearch\u0026lt;/em\u0026gt; rock\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.0033391973\n          },\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;lucene and elasticsear rock\u0026quot;,\n            \u0026quot;highlighted\u0026quot;: \u0026quot;\u0026lt;em\u0026gt;lucene\u0026lt;/em\u0026gt; and elasticsear rock\u0026quot;,\n            \u0026quot;score\u0026quot;: 0.0029183894\n          }\n        ]\n      }\n    ]\n  }\n[/quote]\n\noptions直接返回一个phrase列表，由于加了highlight选项，被替换的term会被高亮。因为lucene和elasticsearch曾经在同一条原文里出现过，同时替换2个term的可信度更高，所以打分较高，排在第一位返回。Phrase suggester有相当多的参数用于控制匹配的模糊程度，需要根据实际应用情况去挑选和调试。\n\n\n最后来谈一下Completion Suggester，它主要针对的应用场景就是\u0026quot;Auto Completion\u0026quot;。 此场景下用户每输入一个字符的时候，就需要即时发送一次查询请求到后端查找匹配项，在用户输入速度较高的情况下对后端响应速度要求比较苛刻。因此实现上它和前面两个Suggester采用了不同的数据结构，索引并非通过倒排来完成，而是将analyze过的数据编码成FST和索引一起存放。对于一个open状态的索引，FST会被ES整个装载到内存里的，进行前缀查找速度极快。但是FST只能用于前缀查找，这也是Completion Suggester的局限所在。\n\n为了使用Completion Suggester，字段的类型需要专门定义如下:\n[quote]\nPUT /blogs_completion/\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;tech\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;body\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;completion\u0026quot;\n        }\n      }\n    }\n  }\n}\n[/quote]\n\n用bulk API索引点数据:\n[quote]\nPOST _bulk/?refresh=true\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Lucene is cool\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elasticsearch builds on top of lucene\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elasticsearch rocks\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;Elastic is the company behind ELK stack\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;the elk stack rocks\u0026quot;}\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;blogs_completion\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;tech\u0026quot; } }\n{ \u0026quot;body\u0026quot;: \u0026quot;elasticsearch is rock solid\u0026quot;}\n[/quote]\n\n\n查找:\n[quote]\nPOST blogs_completion/_search?pretty\n{ \u0026quot;size\u0026quot;: 0,\n  \u0026quot;suggest\u0026quot;: {\n    \u0026quot;blog-suggest\u0026quot;: {\n      \u0026quot;prefix\u0026quot;: \u0026quot;elastic i\u0026quot;,\n      \u0026quot;completion\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;body\u0026quot;\n      }\n    }\n  }\n}\n[/quote]\n\n结果:\n[quote]\n\u0026quot;suggest\u0026quot;: {\n    \u0026quot;blog-suggest\u0026quot;: [\n      {\n        \u0026quot;text\u0026quot;: \u0026quot;elastic i\u0026quot;,\n        \u0026quot;offset\u0026quot;: 0,\n        \u0026quot;length\u0026quot;: 9,\n        \u0026quot;options\u0026quot;: [\n          {\n            \u0026quot;text\u0026quot;: \u0026quot;Elastic is the company behind ELK stack\u0026quot;,\n            \u0026quot;_index\u0026quot;: \u0026quot;blogs_completion\u0026quot;,\n            \u0026quot;_type\u0026quot;: \u0026quot;tech\u0026quot;,\n            \u0026quot;_id\u0026quot;: \u0026quot;AVrXFyn-cpYmMpGqDdcd\u0026quot;,\n            \u0026quot;_score\u0026quot;: 1,\n            \u0026quot;_source\u0026quot;: {\n              \u0026quot;body\u0026quot;: \u0026quot;Elastic is the company behind ELK stack\u0026quot;\n            }\n          }\n        ]\n      }\n    ]\n  }\n[/quote]\n\n值得注意的一点是Completion Suggester在索引原始数据的时候也要经过analyze阶段，取决于选用的analyzer不同，某些词可能会被转换，某些词可能被去除，这些会影响FST编码结果，也会影响查找匹配的效果。\n\n比如我们删除上面的索引，重新设置索引的mapping，将analyzer更改为\u0026quot;english\u0026quot;:\n[quote]\nPUT /blogs_completion/\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;tech\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;body\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;completion\u0026quot;,\n          \u0026quot;analyzer\u0026quot;: \u0026quot;english\u0026quot;\n        }\n      }\n    }\n  }\n}\n[/quote]\n\nbulk api索引同样的数据后，执行下面的查询:\n[quote]\nPOST blogs_completion/_search?pretty\n{ \u0026quot;size\u0026quot;: 0,\n  \u0026quot;suggest\u0026quot;: {\n    \u0026quot;blog-suggest\u0026quot;: {\n      \u0026quot;prefix\u0026quot;: \u0026quot;elastic i\u0026quot;,\n      \u0026quot;completion\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;body\u0026quot;\n      }\n    }\n  }\n}\n[/quote]\n\n居然没有匹配结果了，多么费解！  原来我们用的english analyzer会剥离掉stop word，而is就是其中一个，被剥离掉了！\n用analyze api测试一下:\n[quote]\nPOST _analyze?analyzer=english\n{\n  \u0026quot;text\u0026quot;: \u0026quot;elasticsearch is rock solid\u0026quot;\n}\n\n会发现只有3个token:\n{\n  \u0026quot;tokens\u0026quot;: [\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;elasticsearch\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 0,\n      \u0026quot;end_offset\u0026quot;: 13,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 0\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;rock\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 17,\n      \u0026quot;end_offset\u0026quot;: 21,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 2\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;solid\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 22,\n      \u0026quot;end_offset\u0026quot;: 27,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 3\n    }\n  ]\n}\n[/quote]\n\nFST只编码了这3个token，并且默认的还会记录他们在文档中的位置和分隔符。 用户输入\u0026quot;elastic i\u0026quot;进行查找的时候，输入被分解成\u0026quot;elastic\u0026quot;和\u0026quot;i\u0026quot;，FST没有编码这个“i” , 匹配失败。\n\n好吧，如果你现在还足够清醒的话，试一下搜索\u0026quot;elastic is\u0026quot;，会发现又有结果，why?  因为这次输入的text经过english analyzer的时候is也被剥离了，只需在FST里查询\u0026quot;elastic\u0026quot;这个前缀，自然就可以匹配到了。\n\n其他能影响completion suggester结果的，还有诸如\u0026quot;preserve_separators\u0026quot;，\u0026quot;preserve_position_increments\u0026quot;等等mapping参数来控制匹配的模糊程度。以及搜索时可以选用Fuzzy Queries，使得上面例子里的\u0026quot;elastic i\u0026quot;在使用english analyzer的情况下依然可以匹配到结果。\n\n因此用好Completion Sugester并不是一件容易的事，实际应用开发过程中，需要根据数据特性和业务需要，灵活搭配analyzer和mapping参数，反复调试才可能获得理想的补全效果。\n\n回到篇首Google搜索框的补全/纠错功能，如果用ES怎么实现呢？我能想到的一个的实现方式:\n[list=1]\n[*]在用户刚开始输入的过程中，使用Completion Suggester进行关键词前缀匹配，刚开始匹配项会比较多，随着用户输入字符增多，匹配项越来越少。如果用户输入比较精准，可能Completion Suggester的结果已经够好，用户已经可以看到理想的备选项了。 [/*]\n[*]如果Completion Suggester已经到了零匹配，那么可以猜测是否用户有输入错误，这时候可以尝试一下Phrase Suggester。[/*]\n[*]如果Phrase Suggester没有找到任何option，开始尝试term Suggester。[/*]\n[/list]\n\n精准程度上(Precision)看： Completion \u0026gt;  Phrase \u0026gt; term， 而召回率上(Recall)则反之。从性能上看，Completion Suggester是最快的，如果能满足业务需求，只用Completion Suggester做前缀匹配是最理想的。 Phrase和Term由于是做倒排索引的搜索，相比较而言性能应该要低不少，应尽量控制suggester用到的索引的数据量，最理想的状况是经过一定时间预热后，索引可以全量map到内存。","title":"Elasticsearch Suggester详解","uid":"81","views":"24711","votes":"18"},"_type":"doc"}
{"_id":"160","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493979235","category_id":"2","comments":"3","has_attach":"0","id":"160","message":"我经过实际测试es5.2.2，发现_source/_all特性很好用：\n1. _source可用通过配置includes、excludes获取应用需要的field\n\u0026quot;_source\u0026quot;: {\n          \u0026quot;enabled\u0026quot;: true,\n          \u0026quot;includes\u0026quot;: [\n            \u0026quot;comId\u0026quot;,\n            \u0026quot;name\u0026quot;,\n            \u0026quot;userName\u0026quot;,\n            \u0026quot;equips.name\u0026quot;,\n            \u0026quot;equips.amount\u0026quot;\n          ],\n          \u0026quot;excludes\u0026quot;: [\n            \u0026quot;phone\u0026quot;,\n            \u0026quot;equips.code\u0026quot;\n          ]\n        },\n2.设置enabled=false关闭_source功能，关闭后，查询结果只返回doc的ID，而不会返回_source\n \u0026quot;_source\u0026quot;: {\n          \u0026quot;enabled\u0026quot;: false,\n3._all、include_in_all结合使用，是用户可用通过_all分词查询多个字段，而不需要写多个查询条件\n \u0026quot;mappings\u0026quot;: {\n      \u0026quot;testdoc03\u0026quot;: {\n        \u0026quot;_all\u0026quot;: {\n          \u0026quot;enabled\u0026quot;: true\n        },\n        \u0026quot;_source\u0026quot;: {\n          \u0026quot;enabled\u0026quot;: false,\n          \u0026quot;includes\u0026quot;: [\n            \u0026quot;comId\u0026quot;,\n            \u0026quot;name\u0026quot;,\n            \u0026quot;userName\u0026quot;,\n            \u0026quot;equips.name\u0026quot;,\n            \u0026quot;equips.amount\u0026quot;\n          ],\n          \u0026quot;excludes\u0026quot;: [\n            \u0026quot;phone\u0026quot;,\n            \u0026quot;equips.code\u0026quot;\n          ]\n        },\n        \u0026quot;properties\u0026quot;: {\n          \u0026quot;comId\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          },\n          \u0026quot;equips\u0026quot;: {\n            \u0026quot;properties\u0026quot;: {\n              \u0026quot;amount\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;double\u0026quot;,\n                \u0026quot;include_in_all\u0026quot;: true\n              },\n              \u0026quot;code\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n              },\n              \u0026quot;name\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n                \u0026quot;include_in_all\u0026quot;: true\n              }\n            }\n          },\n          \u0026quot;name\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;include_in_all\u0026quot;: true\n          },\n          \u0026quot;phone\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n          },\n          \u0026quot;userName\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;include_in_all\u0026quot;: true\n          }\n        }\n      }\n    }\n  }\n ","title":"_source/_all特性效果","uid":"2580","views":"2007","votes":"0"},"_type":"doc"}
{"_id":"164","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494223664","category_id":"16","comments":"12","has_attach":"1","id":"164","message":"1. 主办方\nElastic中文社区  趋势科技\n\n[attach]581[/attach]\n\n2. 时间地点\n 活动时间：2017年6月10日 13:30 - 18:00 \n 活动地点：雨花区软件大道48号苏豪国际广场B座 趋势科技中国研发中心（靠花神庙地铁站）\n\n3. 主题\n\n[b]分享一：The State of Elastic Stack[/b]\n演讲者简介：\n\n[attach]582[/attach]\n\n曾勇（Medcl） Elastic工程师与布道师\nElasticsearch爱好者，2015年加入Elastic，Elastic 中文社区的发起人，Elastic在中国的首位员工。\n\n主题简介：\nElastic Stack是Elastic公司的开源产品：Elasticsearch、Logstash、Kibana和Beats的统称，这些产品发布速度貌似有点快，在最近已经发布了的版本中有哪些值得关注的特性，然后Elastic的工程师手头上又在忙着码哪些新的特性呢?\n机器学习、AI目前非常火，Elastic在最近的5.0也发布了一个机器学习的模块，这次也会带来demo演示。\n\n[b]分享二： Elastic Stack的容器化使用与Alert[/b]\n\n演讲者简介：\n\n[attach]583[/attach]\n\n瞿盛熙 嘀哒物流科技有限公司运维组组长\n\n主题简介：\n介绍嘀哒物流在公有云上的Elastic Stack部署以及日志分析与监控\n1.目的和环境 \n2.部署：自动化，容器化下kubernetes与single mode的考量\n3.日志分析与alert\n4.监控：prometheus与docker\n\n[b]分享三：Elasticsearch辅助的智能客服机器人 [/b]\n\n演讲者简介：\n\n[attach]585[/attach]\n\n杨文俊 趋势科技个人消费者部机器学习工程师\n从2013年开始投入大数据处理与机器学习，目前依托Elasticsearch的搜索能力构建了一系列的智能服务。\n\n主题简介：\n1. 将原始的日文记录导入Elasticsearch之中\n2. 使用Elasticsearch对原始内容进行初次过滤\n3. 在过滤的基础之上，调用wmd + word2vec进行rerank，并综合进行判定\n\n[b]分享四： Elastic在华为电信软件运维中的应用简介[/b]\n\n演讲者简介：\n\n[attach]584[/attach]\n\n肖曙旭 华为电信软件业务云运维开发部软件工程师\n华为日志服务特性负责人。从2015年起开始接触Elasticsearch并使用至今。先后负责服务调用链和日志服务特性的设计和开发，依托Elasticsearch实现搜索相关能力。\n\n主题简介：\n1. 日志采集代理。提供按正则表达式匹配或者分隔符的逻辑行分割方式；支持逻辑行内按分隔符提取字段，或者按正则表达式提取字段；支持一些简易算子对字段进行处理。\n2. 日志汇聚。不同的日志类型通过不同的Topic区分\n3. 流式处理。日志数据二次处理，或者一些实时分析的逻辑处理。\n4. 参考kibana开发搜索和可视化能力，同时支持关键词告警，环比告警等告警能力，以及整个日志服务通道的自身监控能力。\n\n[b]分享五：基于ES的SQL报警引擎[/b]\n\n演讲者简介：\n\n[attach]586[/attach]\n\n张立丹 南京云利来软件科技有限公司\n2010年参加工作，工作内容包括：Windows音频驱动及声卡固件；Linux高并发服务器；数据采集及分析。自2015年开始接触Elasticsearch，在工作中使用ES进行网络数据（TCP/HTTP/DNS等）的安全分析。\n\n主题简介：\n1. SQL：将ES的DSL抽象成 SQL\n2. RDL：规则描述语言\n3. 报警规则","title":"【线下活动】2017-06-10南京Elastic Meetup日程安排","uid":"1264","views":"3012","votes":"2"},"_type":"doc"}
{"_id":"191","_index":"forum-mysql","_score":1,"_source":{"addtime":"1498649118","category_id":"12","comments":"0","has_attach":"0","id":"191","message":"职位描述【工作职责】：\n1、负责搜索系统分布式架构设计、搭建、维护和优化；\n2、负责分词，索引和查询的算法优化，提高查全率和搜索性能；\n3、负责搜索服务端的开发工作，融合大数据平台实现个性化搜索，完成各种垂直搜索应用的开发；\n4、负责内容的数据挖掘，分析与挖掘各种潜在关联，分析特征，建议模型，优化现有的排序结果；\n5、搜索服务的线上部署和维护，监控搜索服务的运行状态；\n\n【岗位要求】：\n1. 熟悉搜索引擎原理和机制，熟练撑握搜索引擎技术，有丰富的搜索引擎相关的研发经验，对算法设计、数据结构有深刻的理解；\n2. 熟悉Solr、Elasticsearch等开源搜索技术及mysql、redis等数据库，能够胜任搜索引擎应用技术的研究与开发、设计与架构能力；\n3. 熟悉LINUX操作命令及Python、SHELL脚本编写；\n4、对数据敏感，具备优秀的逻辑思维，对解决挑战性问题充满热情，善于独立解决问题和分析问题；\n5. 在用户行为挖掘上有相关研究和专业积累；有较好的创新能力；\n6. 良好的团队合作精神，较强的沟通能力；\n7. 实践过自然语言处理、数据挖掘、机器学习者优先；\n8. 有信息提取和大型搜索索引建立、排序算法、query优化经验者优先；\n \n有意者请发简历至 yuezhitao@patsnap.com\n\n【加入我们，你可以得到什么？】\n你可以得到国际化的视野，可以和国外的同事和客户进行交流沟通\n你可以跟随公司快速成长，从“前台”到“总裁”的华丽变身不再是梦想\n你可以学习和应用最新最酷的技术，我们鼓励学习创新，而不是重复使用过时效率差的技术\n你不需要定时打卡，不用担心迟到扣钱，因为我们是弹性工作制\n你不需要担心五险一金，因为我们完全按照规定缴纳，员工还可以享受年假、病假、婚假、丧假、产假等带薪休假，另外我们还有补充商业保险\n\n【为什么选择我们？】\n1. 公司前景：整个大环境对知识产权的重视，除了现有业务增长迅猛，还在新兴业务上积极布局\n2. 办公地点：坐落于上海静安区黄金地段，CBD中的CBD\n3. 交通方便：地铁五线环绕（1，3，4，12，13），步行10分钟之内可到，数十多路公交车近在咫尺\n4. 工作环境：开放，明亮。无限量供应的饮料和零食，可以让你迅速成为胖纸！ Mac Pro, Surface Pro, 大屏显示器各种标配。\n\n【我们是谁？】\n或许现在你对专利市场还感到陌生，或许你还并不了解知识产权的重要性，但互联网时代，“IP”这个热词你一定有所听说，且耳熟能详。看看身边高精尖的技术产品，被百姓津津乐道的新能源汽车，到酷炫的无人驾驶，还有风靡持久的日本电饭煲……无不持续着、保护着、更迭着他们的IP技术。\n\n崛起的IP界应证着这样一句话： \n21世纪一定是知识经济的时代，科技创新更是知识经济时代的灵魂——\n而PatSnap智慧芽，正立旨于为科技创新指路。\n\nPatSnap是全球领先的专利分析与管理平台，公司致力于让全球更多组织机构了解并使用专利。PatSnap通过提供强大又易用的专利工具，帮助客户从专利中获取有价值的资讯，从而促进客户的商业化过程，加速研发进度，确定重要技术发展方向，最终提高客户在行业内的核心竞争力。\n\nPatSnap通过位于新加坡，中国苏州，英国伦敦的三家分公司，业务辐射全球上千家企业，客户中不乏 IBM ，美国国立卫生研究院，美国国防部，MIT（麻省理工学院）以及新加坡国立大学等知名企业及团体。\n\n目前我们已经获得C轮融资，在近期的在德勤亚太区高科技高成长500强企业中获得第44位的优质排名。德勤高科技高成长500强是亚太区内享负盛名的高科技企业评选活动。本次评选基于过去三年企业的收入增长百分比而定，智慧芽在这段时期内增长了1078%！\n \n有意者请发简历至 yuezhitao@patsnap.com","title":"智慧芽诚聘高级搜索工程师20-30K（C轮互联网Saas）","uid":"3206","views":"1070","votes":"0"},"_type":"doc"}
{"_id":"200","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501143626","category_id":"12","comments":"3","has_attach":"1","id":"200","message":"[attach]830[/attach]\n想不想去最棒的开源软件公司工作？\n想不想不用朝9晚5浪费大量时间在路上，在家就能办公？\n想不想让您的代码运行在成千上万台服务器上面，拯救世界？\n想不想工作与生活的完美结合，做自己感兴趣的事情？\n... ...\n那考虑来Elastic吧，与全球顶尖工程师一起合作，福利待遇从优，一年至少2次出国机会。\n\n基本要求：\n[list]\n[*]英语流利沟通[/*]\n[*]掌握现代开发技术[/*]\n[*]贡献过Elastic相关开源项目者优先[/*]\n[/list]\n \n  下面是热招职位，位置不限，We are Distributed! \n[list]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1272161?t=iup1q61]社区技术布道师[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1180712?t=iup1q61]技术支持工程师[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/997867?t=iup1q61]技术顾问[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1056032?t=iup1q61]业务架构师[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1284660?t=iup1q61]Elasticsearch - Java Engineer - Search[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1212494?t=iup1q61]Elasticsearch - Java Engineer - Securit[/url]y[/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1441074?t=iup1q61]Elasticsearch - Java Performance Engineer[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1331730?t=iup1q61]Elasticsearch - Senior Java Engineer (Core Team)[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/978673?t=iup1q61]Beats - Golang Engineer[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1378744?t=iup1q61]Logstash - Ruby Engineer[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1292795?t=iup1q61]Kibana - Platform JavaScript Engineer (Node.js) [/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1143849?t=iup1q61]Kibana - Senior JavaScript Engineer[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1418186?t=iup1q61]Kibana - Visualisations \u0026amp; Vega Engineer [/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1273539?t=iup1q61]UI Engineer - Design [/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1424933?t=iup1q61]SecOps - JavaScript Engineer[/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1314470?t=iup1q61]SRE- Infrastructure - Site Reliability Engineer [/url][/*]\n[*][url=https://boards.greenhouse.io/elastic/jobs/1453838?t=iup1q61]InfoSec - Sr. Security Engineer[/url][/*]\n[/list]\n\n除了上面这些，还有很多其他市场商务类职务，\n查看 Elastic 全部在招职位信息，点击[url=http://grnh.se/iup1q61]这里[/url]！\n\n[b]关于 Elastic[/b]\n[i]Elastic 致力于构建大规模实时数据处理软件，场景主要涵盖搜索、日志、安全与数据分析等领域。公司成立于 2012 年，旗下拥有产品：开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、 X-Pack （商业特性）和 Elastic Cloud （一个 SaaS 服务）。迄今为止，这些产品的累积下载次数已超过 3.5 亿。[/i]\n[i]成千上万的企业包括思科、易趣、高盛、美国宇航局、微软、梅约诊所、纽约时报、维基百科以及微讯通信等都在使用 Elastic 来助力其关键业务应用。 [/i]\n[i]Elastic 由 Benchmark Capital、Index Ventures 及 NEA 投资，投资额超过 1 亿美金。Elastic 拥有超过 1000 位员工，分布于世界上 30 多个国家和地区。了解更多请访问： elastic.co 。[/i]","title":"[招聘] ?Elastic 邀您一起共创开源事业 ❄️","uid":"1","views":"5453","votes":"17"},"_type":"doc"}
{"_id":"303","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506673226","category_id":"2","comments":"1","has_attach":"0","id":"303","message":"百度Fscrawler或ambar","title":"文件（txt,html,pdf,word...）导入到Elasticsearch实现全文检索","uid":"5616","views":"2391","votes":"0"},"_type":"doc"}
{"_id":"309","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507771738","category_id":"18","comments":"0","has_attach":"0","id":"309","message":"1.awesome elasticstack\nhttp://t.cn/RO2qZJx\n2.用filebeat处理mysql日志到es\nhttp://t.cn/ROiWg0k\n3.使用filebeat的注意事项\nhttp://t.cn/ROiWFsE\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/309\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第67期 (2017-10-12)","uid":"668","views":"447","votes":"0"},"_type":"doc"}
{"_id":"311","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507876466","category_id":"12","comments":"2","has_attach":"0","id":"311","message":"岗位职责：\n\n围绕Elasticsearch、Lucene进行优化开发，满足业务系统要求；\n\n优化搜索引擎的性能。\n\n\n任职要求：\n\n本科以上学历，两年以上开发经验；\n\n熟悉Solr，Elasticsearch等至少一个基于Lucene的开源搜索引擎，研究过Lucene源码优先；\n\n具备处理海量数据的经验者优先；\n\n遇到难题能够持续保持积极，乐观的态度，并最终解决问题；\n\n具有良好的沟通能力和团队合作能力；\n\n有很好的求知欲和创新能力。\n \n简历请发送至：  liaoying@szsandstone.com","title":"【杉岩招聘】 ES研发工程师招聘","uid":"5545","views":"911","votes":"1"},"_type":"doc"}
{"_id":"317","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508121104","category_id":"17","comments":"3","has_attach":"1","id":"317","message":"[attach]1141[/attach]\n[list]\n[*]简化_cat使用，可以直接输入 cat 命令 ，可以滚动查看历史结果[/*]\n[*]支持字体放大缩小[/*]\n[*]支持命令历史记录（通过上下方向键来切换 ）[/*]\n[*]支持鼠标划取的复制粘贴（暂不复制到剪贴板）[/*]\n[*]安装后在 [url]http://127.0.0.1:9200/_console[/url]  使用，也可本地使用：直接访问html文件[/*]\n[/list]\n \n[url=https://github.com/psfu/es-sp-console]GIT 地址[/url]\n \n欢迎加 576037940 这个群讨论哈\n ","title":"一个仿Linux 控制台的ES的_cat的插件","uid":"5889","views":"666","votes":"3"},"_type":"doc"}
{"_id":"324","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508451689","category_id":"18","comments":"0","has_attach":"0","id":"324","message":"1、spring boot 整合 elasticsearch 5.x实现\n[url]http://t.cn/ROdYijN[/url] \n2、基于Elasticsearch搜索平台设计及踩坑教训\n[url]http://t.cn/ROdYCun[/url] \n3、深度剖析倒排索引原理\n[url]http://t.cn/RyUOW4X[/url] \n\n编辑：laoyang360\n归档：https://elasticsearch.cn/publish/article/324\n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":" Elastic日报 第75期 (2017-10-20)","uid":"1341","views":"474","votes":"0"},"_type":"doc"}
{"_id":"331","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508924725","category_id":"18","comments":"6","has_attach":"0","id":"331","message":"[b][size=18]日报征稿内容要求：[/size][/b]\n[list=1]\n[*]elastic主题相关的文章；[/*]\n[*]鼓励原创文章；[/*]\n[*]同一篇文章请勿重复投稿；[/*]\n[/list]\n\n[b][size=18]日报征稿形式要求：[/size][/b]\n[list=1]\n[*]简要概述投稿文章内容；[/*]\n[*]提供文章对应的链接；[/*]\n[*]中英文不限；[/*]\n[/list]\n","title":"日报征稿","uid":"3851","views":"431","votes":"2"},"_type":"doc"}
{"_id":"339","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509023169","category_id":"2","comments":"1","has_attach":"1","id":"339","message":"[b]一，何为优雅：[/b]\r\n    在此需要感谢@Medcl,开发了ik,mmseg等为elasticsearch的分词插件，使我们能够比较容易的上手并应用elasticsearch。\r\n   但是我们如果要对插件进行二次定制，或者重新开发一个插件呢。按照官网教程，每次都得打包、替换、重启，这是一个很不方便的过程，固然可以通过testCase来做debug，但是所见即所得的编码习惯，直接上手debug，才是最高效的方式。\r\n   介绍插件开发的博客何其多，个人私以为都没有get到G点，其实深入研究下elasticsearch源码，fix 这个问题并不难，下面希望通过这篇文章帮助到大家。\r\n[b]二，elasticsearch插件的加载机制[/b]\r\n①：Node节点启动过程，Elasticsearch.java会调用Bootstrap.java中的init函数。\r\n[code]static void init(...)  {\r\n        ...\r\n        INSTANCE = new Bootstrap();\r\n        INSTANCE.setup(true, environment);\r\n        ...\r\n        INSTANCE.start();\r\n}[/code]②：Node节点通过setup方法进行实例化。\r\n[code] private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException {\r\n         \r\n    node = new Node(environment) {\r\n \r\n     ...\r\n}[/code]③：Node.java类中会包含各类的service服务，其中包括PluginsService服务。在实例化PluginsService服务时会传参\r\nenvironment.pluginsFile(),classpathPlugins等参数。而pluginsFile()即是elasticsearch所指定的plugin目录，elasticsearch会扫描该路径下所有的插件，并加载进来。\r\n[code]public Node(Environment environment) {\r\n    this(environment, Collections.emptyList());\r\n}\r\n \r\nprotected Node(final Environment environment, Collection\u0026lt;Class\u0026lt;? extends Plugin\u0026gt;\u0026gt; classpathPlugins) {\r\n    ...\r\n    this.pluginsService = new PluginsService(tmpSettings, environment.modulesFile(), environment.pluginsFile(), classpathPlugins);\r\n    ...\r\n}[/code]④classpathPlugins参数介绍：\r\n[code]public Node(Environment environment) {\r\n        this(environment, Collections.emptyList());\r\n    }[/code]在elasticsearch源码中，这个参数Collection\u0026lt;Class\u0026lt;? extends Plugin\u0026gt;\u0026gt; classpathPlugins一直都是空集合。\r\n没有任何地方注入修改该参数。elasticsearch不但会扫描插件所在路径中的插件，同样也会加载classpathPlugins中所指定的插件，只不过问题是elasticsearch没有给我们提供相应的参数！！！！\r\n[b]三，如何更优雅的开发开发插件[/b]\r\n    接上一段小节④，我们只要利用classpathPlugins该参数，就可以在elasticsearch源码环境中进行debug了！！！\r\n    我的实现思路如下，通过继承Node.java，并重写Node类的构造方法，然后在bootstrap中直接实例化该子类，便可以通过elasticsearch直接bug 插件源码了。\r\n   下面贴出我的实现代码，供大家参考：\r\n[code]/**\r\n * Created by jiangtao on 2017/07/30.\r\n */\r\n\r\nimport org.elasticsearch.Version;\r\nimport org.elasticsearch.env.Environment;\r\nimport org.elasticsearch.node.Node;\r\nimport org.elasticsearch.plugins.Plugin;\r\n\r\nimport java.util.Collection;\r\n\r\npublic class EmbeddedNode extends Node {\r\n\r\n  private Version version;\r\n  private Collection\u0026lt;Class\u0026lt;? extends Plugin\u0026gt;\u0026gt; plugins;\r\n\r\n  public EmbeddedNode(Environment environment, Version version, Collection\u0026lt;Class\u0026lt;? extends Plugin\u0026gt;\u0026gt; classpathPlugins) {\r\n    super(environment,  classpathPlugins);\r\n    this.version = version;\r\n    this.plugins = classpathPlugins;\r\n  }\r\n\r\n  public Collection\u0026lt;Class\u0026lt;? extends Plugin\u0026gt;\u0026gt; getPlugins() {\r\n    return plugins;\r\n  }\r\n\r\n  public Version getVersion() {\r\n    return version;\r\n  }\r\n}[/code][code]    private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException {\r\n      .....\r\n       //注释Node初始化源码\r\n       /* node = new Node(environment) {\r\n            @Override\r\n            protected void validateNodeBeforeAcceptingRequests(\r\n                final Settings settings,\r\n                final BoundTransportAddress boundTransportAddress, List\u0026lt;BootstrapCheck\u0026gt; checks) throws NodeValidationException {\r\n                BootstrapChecks.check(settings, boundTransportAddress, checks);\r\n            }\r\n        };*/\r\n\r\n        Collection plugins = new ArrayList\u0026lt;\u0026gt;();\r\n        Collections.addAll(plugins,   AnalysisIkPlugin.class, HelloPlugin.class, AnalysisMMsegPlugin.class);//, ,AnalysisMMsegPlugin.class\r\n        node = new EmbeddedNode(environment, Version.CURRENT, plugins) {\r\n            @Override\r\n            protected void validateNodeBeforeAcceptingRequests(final Settings settings, final BoundTransportAddress boundTransportAddress, List\u0026lt;BootstrapCheck\u0026gt; checks) throws NodeValidationException {\r\n                BootstrapChecks.check(settings, boundTransportAddress, checks);\r\n            }\r\n        };\r\n    }[/code]\r\n \r\n四，部署插件相关的注意事项：\r\n     有关插件开发的详细配置，es插件的种类，在此不再赘述，具体可参考官方文档，更权威，更直接。\r\n下面贴个图，本人在elasticsearch中同时整合了多个插件，以供学习研究时用，直接debug，个人感觉十分不错。\r\n\r\n[attach]1180[/attach]\r\n ","title":"如何更优雅的定制开发elasicsearch插件","uid":"6245","views":"1628","votes":"6"},"_type":"doc"}
{"_id":"344","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509343107","category_id":"16","comments":"0","has_attach":"1","id":"344","message":" \r\n[attach]1190[/attach]\r\n\r\nElastic Meetup 线下交流活动首次来到江城武汉，武汉是湖北省省会、中部六省唯一的副省级市和特大城市、中国中部地区的中心城市，全国重要的工业基地、科教基地和综合交通枢纽。\r\n \r\n\r\n[b]主办：[/b]\r\n本次活动由 [b]Elastic[/b] 与 [b]猫友会[/b] 联合举办。\r\n \r\n媒体：\r\n本次活动由 [b]IT大咖说[/b] 独家提供现场直播。\r\n \r\n[b]时间：[/b]\r\n2017.11.4​  下午2:00-5:00（1点半开始签到）\r\n \r\n[b]地点：[/b]\r\n氪空间（武汉市武昌区湖北省科技创业大厦A栋3楼客空间）\r\n \r\n[b]主题：[/b]\r\nElastic - Medcl - Elastic Stack 6.0 新功能介绍\r\n尚德机构 - 白凡 - 高吞吐状况下斗鱼搜索引擎优化之路\r\n基于爬虫和 Elasticsearch 快速构建站内搜索引擎\r\n闪电分享（5-10分钟，可现场报名） \r\n\r\n[b]参会报名：[/b]\r\nhttp://elasticsearch.mikecrm.com/O6o0yq3\r\n \r\n[b]现场直播[/b]\r\n\r\n[attach]1220[/attach]\r\n\r\n\r\n[b]现场交流微信群[/b]\r\n（❗️⚠️请注意：限武汉本地同学，外地毋加，微信人数限制，仅供现场参会人员沟通使用，谢谢合作???）\r\n\r\n[attach]1195[/attach]\r\n\r\n \r\n广州、深圳也在筹备中：https://elasticsearch.cn/article/261\r\n \r\n \r\n[b]关于 Elastic Meetup[/b]\r\n\r\nElastic Meetup 由 Elastic 中文社区定期举办的线下交流活动，主要围绕 Elastic 的开源产品（Elasticsearch、Logstash、Kibana 和 Beats）及周边技术，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。\r\n\r\n \r\n[b]关于 Elastic[/b]\r\n\r\n[attach]1192[/attach]\r\n\r\nElastic 通过构建软件，让用户能够实时地、大规模地将数据用于搜索、日志和分析场景。Elastic 创立于 2012 年，相继开发了开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、X-Pack（商业功能）和 Elastic Cloud（托管服务）。截至目前，累计下载量超过 1.5 亿。Benchmark Capital、Index Ventures 和 NEA 为 Elastic 提供了超过 1 亿美元资金作为支持，Elastic 共有 600 多名员工，分布在 30 个国家/地区。有关更多信息，请访问 [url]http://elastic.co/cn[/url] 。\r\n \r\n[b]关于猫友会[/b]\r\n\r\n[attach]1191[/attach]\r\n\r\n猫友会介绍：猫友会通过“人才回流，知识回流，创业回流”，来改变武汉互联网的行业环境。目前是影响力最大的湖北籍互联网社群，聚集了世界各地的5000余名湖北籍的互联网工程师。猫友会社区http://bbs.maoyouhui.cc.  光谷猫友会公众号：mtydev。\r\n\r\n[b]关于IT大咖说[/b]\r\n\r\n[attach]1193[/attach]\r\n \r\nIT大咖说，IT垂直领域的大咖知识分享平台，践行“开源是一种态度”，通过线上线下开放模式分享行业TOP大咖干货，技术大会在线直播点播，在线活动直播平台。[url]http://www.itdks.com[/url] 。\r\n \r\n再次感谢猫友会和IT大咖说的大力支持!","title":"Elastic Meetup 武汉交流会","uid":"1","views":"1466","votes":"1"},"_type":"doc"}
{"_id":"350","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509645050","category_id":"2","comments":"2","has_attach":"0","id":"350","message":"主要讲解如何通过Search guard 为Elasticsearch 进行安全加固。\nhttp://rickywag.com/archives/618","title":"Elasticsearch 安全 （希望日报能给我发下。）","uid":"2363","views":"750","votes":"2"},"_type":"doc"}
{"_id":"357","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510019520","category_id":"18","comments":"0","has_attach":"0","id":"357","message":"1.使用ELK监控HTTP服务的一套完整解决方案。\n[url]http://t.cn/RloiI8o[/url] \n2.用elastic stack来分析下你的redis slowlog\n[url]http://t.cn/Rlo6dQu[/url] \n3.ES分片recovery 流程分析与速度优化\n[url]http://t.cn/RloJr8Q[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/357[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]  \n ","title":" Elastic日报 第93期 (2017-11-07)","uid":"3788","views":"407","votes":"0"},"_type":"doc"}
{"_id":"361","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510138492","category_id":"2","comments":"12","has_attach":"1","id":"361","message":"```2018年8月24日更新:  今天放出的6.4版修复了这个问题。```\n\n\n原文链接: http://www.jianshu.com/p/d4f7a6d58008\n\n前天公司度假部门一个线上ElasticSearch集群发出报警，有Data Node的Heap使用量持续超过80%警戒线。 收到报警邮件后，不敢怠慢，立即登陆监控系统查看集群状态。还好，所有的结点都在正常服务，只是有2个结点的Heap使用率非常高。此时，Old GC一直在持续的触发，却无法回收内存。\n\n\n[attach]1768[/attach]\n\n\n\n---\n#初步排查\n问题结点的Heap分配了30GB，80%的使用率约等于24GB。 但集群的数据总量并不大，5个结点所有索引文件加起来占用的磁盘空间还不到10GB。\n```\nGET /_cat/allocation?v\u0026amp;h=shards,disk.indices,disk.used,disk.avail\n\nshards disk.indices disk.used disk.avail\n     3        1.9gb    38.3gb     89.7gb\n     4        2.2gb    13.4gb    114.6gb\n     4        2.5gb    20.3gb    107.7gb\n     4        2.3gb    33.9gb     94.1gb\n     3        1.7gb    12.8gb    115.2gb\n```\n\n查看各结点的segment memory和cache占用量也都非常小，是MB级别的。\n```\nGET /_cat/nodes?v\u0026amp;h=id,port,v,m,fdp,mc,mcs,sc,sm,qcm,fm,im,siwm,svmm\n\nid   port v     m fdp mc     mcs sc     sm     qcm      fm siwm svmm\ne1LV 9300 5.3.2 -   1  0      0b 68   69mb   1.5mb   1.9mb   0b 499b\n5VnU 9300 5.3.2 -   1  0      0b 75   79mb   1.5mb   1.9mb   0b 622b\n_Iob 9300 5.3.2 -   1  0      0b 56 55.7mb   1.3mb 914.1kb   0b 499b\n4Kyl 9300 5.3.2 *   1  1 330.1mb 81 84.4mb   1.2mb   1.9mb   0b 622b\nXEP_ 9300 5.3.2 -   1  0      0b 45 50.4mb 748.5kb     1mb   0b 622b\n```\n集群的QPS只有30上下，CPU消耗10%都不到，各类thread pool的活动线程数量也都非常低。\n\n[attach]1769[/attach]\n\n\n非常费解是什么东西占着20多GB的内存不释放？\n\n出现问题的集群ES版本是`5.3.2`，而这个版本的稳定性在公司内部已经经过长时间的考验，做为稳定版本在线上进行了大规模部署。 其他一些读写负载非常高的集群也未曾出现过类似的状况，看来是遇到新问题了。\n\n查看问题结点ES的日志，除了看到一些Bulk异常以外，未见特别明显的其他和资源相关的错误:\n```\n[2017-11-06T16:33:15,668][DEBUG][o.e.a.b.TransportShardBulkAction] [] [suggest-3][0] failed to execute bulk item (update) BulkShardRequest [[suggest-3][0]] containing [44204\n] requests\norg.elasticsearch.index.engine.DocumentMissingException: [type][Á∫≥Ê†ºÂ∞îÊûúÂæ∑_1198]: document missing\n        at org.elasticsearch.action.update.UpdateHelper.prepare(UpdateHelper.java:92) ~[elasticsearch-5.3.2.jar:5.3.2]\n        at org.elasticsearch.action.update.UpdateHelper.prepare(UpdateHelper.java:81) ~[elasticsearch-5.3.2.jar:5.3.2]\n```\n\n和用户确认这些异常的原因，是因为写入程序会从数据源拿到数据后，根据`doc_id`对ES里的数据做update。会有部分`doc_id`在ES里不存在的情况，但并不影响业务逻辑，因而ES记录的`document missing`异常应该可以忽略。\n\n至此别无他法，只能对JVM做Dump分析了。\n\n---\n# Heap Dump分析\n用的工具是[Eclipse MAT](http://wiki.eclipse.org/MemoryAnalyzer)，从这里下载的Mac版:[Downloads](https://www.eclipse.org/mat/downloads.php) 。 使用这个工具需要经过以下2个步骤:\n- 获取二进制的head dump文件  ` jmap -dump:format=b,file=/tmp/es_heap.bin \u0026lt;pid\u0026gt; ` 其中pid是ES JAVA进程的进程号。\n- 将生成的dump文件下载到本地开发机器，启动MAT，从其GUI打开文件。\n\n要注意，MAT本身也是JAVA应用，需要有JDK运行环境的支持。\n\nMAT第一次打dump文件的时候，需要对其解析，生成多个索引。这个过程比较消耗CPU和内存，但一旦完成，之后再打开dump文件就很快，消耗很低。 对于这种20多GB的大文件，第一次解析的过程会非常缓慢，并且很可能因为开发机内存的较少而内存溢出。因此，我找了台大内存的服务器来做第一次的解析工作:\n- 将linux版的MAT拷贝上去，解压缩后，修改配置文件MemoryAnalyzer.ini，将内存设置为20GB左右:\n  ```\n   $ cat MemoryAnalyzer.ini \n\n      -startup\n      plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar\n      --launcher.library\n      plugins/org.eclipse.equinox.launcher.gtk.linux.x86_64_1.1.300.v20150602-1417\n      -vmargs\n      -Xmx20240m\n  ```\n  这样能保证解析的过程中不会内存溢出。\n- 将dump文件拷贝上去，执行下面几个命令生成索引及3个分析报告:\n  - `mat/ParseHeapDump.sh es_heap.bin org.eclipse.mat.api:suspects`\n  - `mat/ParseHeapDump.sh es_heap.bin org.eclipse.mat.api:overview`\n  - `mat/ParseHeapDump.sh es_heap.bin org.eclipse.mat.api:top_components`\n\n分析成功以后，会生成如下一堆索引文件(.index)和分析报告(.zip)\n```\n-rw-r--r--@ 1 xgwu  staff    62M Nov  6 16:18 es_heap.a2s.index\n-rw-r--r--@ 1 xgwu  staff    25G Nov  6 14:59 es_heap.bin\n-rw-r--r--@ 1 xgwu  staff    90M Nov  6 16:21 es_heap.domIn.index\n-rw-r--r--@ 1 xgwu  staff   271M Nov  6 16:21 es_heap.domOut.index\n-rw-r--r--  1 xgwu  staff   144K Nov  7 18:38 es_heap.i2sv2.index\n-rw-r--r--@ 1 xgwu  staff   220M Nov  6 16:18 es_heap.idx.index\n-rw-r--r--@ 1 xgwu  staff   356M Nov  6 16:20 es_heap.inbound.index\n-rw-r--r--@ 1 xgwu  staff   6.8M Nov  6 16:20 es_heap.index\n-rw-r--r--@ 1 xgwu  staff    76M Nov  6 16:18 es_heap.o2c.index\n-rw-r--r--@ 1 xgwu  staff   231M Nov  6 16:20 es_heap.o2hprof.index\n-rw-r--r--@ 1 xgwu  staff   206M Nov  6 16:21 es_heap.o2ret.index\n-rw-r--r--@ 1 xgwu  staff   353M Nov  6 16:20 es_heap.outbound.index\n-rw-r--r--@ 1 xgwu  staff   399K Nov  6 16:16 es_heap.threads\n-rw-r--r--@ 1 xgwu  staff    89K Nov  7 17:40 es_heap_Leak_Suspects.zip\n-rw-r--r--@ 1 xgwu  staff    78K Nov  6 19:22 es_heap_System_Overview.zip\n-rw-r--r--@ 1 xgwu  staff   205K Nov  6 19:22 es_heap_Top_Components.zip\ndrwxr-xr-x@ 3 xgwu  staff    96B Nov  6 16:15 workspace\n```\n将这些文件打包下载到本地机器上，用MAT GUI打开就可以分析了。\n\n在MAT里打开dump文件的时候，可以选择打开已经生成好的报告，比如Leak suspects:\n![选择打开leak Suspects报告](http://upload-images.jianshu.io/upload_images/7952780-f644b0e562da1da5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n通过Leak Suspects，一眼看到这20多GB内存主要是被一堆bulk线程实例占用了，每个实例则占用了接近1.5GB的内存。\n![Leak Suspects](http://upload-images.jianshu.io/upload_images/7952780-d75f5d03dc229ba2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n进入\u0026quot;dominator_tree\u0026quot;面板，按照\u0026quot;Retained Heap\u0026quot;排序，可以看到多个bulk线程的内存占用都非常高。\n![Dominator Tree](http://upload-images.jianshu.io/upload_images/7952780-3b85c241476e2e1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n将其中一个thread的引用链条展开，看看这些线程是如何Retain这么多内存的，特别注意红圈部分:\n![对象引用链](http://upload-images.jianshu.io/upload_images/7952780-89fc083aacd575ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n这个引用关系解读如下:\n1. 这个bulk线程的thread local map里保存了一个log4j的`MultableLogEvent`对象。\n2. `MutablelogEvent`对象引用了log4j的`ParameterizedMessage`对象。\n3. `ParameterizedMessage`引用了`bulkShardRequest`对象。\n4. `bulkShardRequest`引用了4万多个`BulkitemRequest`对象。\n\n这样看下来，似乎是log4j的logevent对一个大的bulk请求对象有强引用而导致其无法被垃圾回收掉，产生内存泄漏。\n\n联想到ES日志里，有记录一些`document missing`的bulk异常，猜测是否在记录这些异常的时候产生的泄漏。\n\n---\n#问题复现\n为了验证猜测，我在本地开发机上，启动了一个单结点的`5.3.2`测试集群，用bulk api做批量的update，并且有意为其中1个update请求设置不存在的doc_id。为了便于测试，我在ES的配置文件`elasticsearch.yml`里添加了配置项` processors: 1 `。 这个配置项影响集群thread_pool的配置，bulk thread pool的大小将减少为1个，这样可以更快速和便捷的做各类验证。\n\n启动集群，发送完bulk请求后，立即做一个dump，重复之前的分析过程，问题得到了复现。 这时候想，是否其他bulk异常也会引起同样的问题，比如写入的数据和mapping不匹配？  测试了一下，问题果然还是会产生。再用不同的bulk size进行测试，发现无法回收的这段内存大小，取决于最后一次抛过异常的bulk size大小。至此，基本可以确定内存泄漏与log4j记录异常消息的逻辑有关系。\n\n为了搞清楚这个问题是否`5.3.2`独有，后续版本是否有修复，在最新的`5.6.3`上做了同样的测试，问题依旧，因此这应该是一个还未发现的深层Bug.\n\n---\n#读源码查根源\n大致搞清楚问题查找的方向了，但根源还未找到，也就不知道如何修复和避免，只有去扒源码了。\n在` TransportShardBulkAction` 第209行，找到了ES日志里抛异常的代码片段。\n```java\n if (isConflictException(failure)) {\n     logger.trace((Supplier\u0026lt;?\u0026gt;) () -\u0026gt; new ParameterizedMessage(\u0026quot;{} failed to execute bulk item ({}) {}\u0026quot;,\n             request.shardId(), docWriteRequest.opType().getLowercase(), request), failure);\n } else {\n     logger.debug((Supplier\u0026lt;?\u0026gt;) () -\u0026gt; new ParameterizedMessage(\u0026quot;{} failed to execute bulk item ({}) {}\u0026quot;,\n             request.shardId(), docWriteRequest.opType().getLowercase(), request), failure);\n }\n```\n这里看到了`ParameterizedMessage`实例化过程中，`request`做为一个参数传入了。这里的`request`是一个`BulkShardRequest`对象，保存的是要写入到一个shard的一批bulk item request。  这样以来，一个批次写入的请求数量越多，这个对象retain的内存就越多。 可问题是，为什么logger.debug（）调用完毕以后，这个引用不会被释放？\n\n通过和之前MAT上的dominator tree仔细对比，可以看到`ParameterizedMessage`之所以无法释放，是因为被一个`MutableLogEvent`在引用，而这个`MutableLogEvent`被做为一个thread local存放起来了。 由于ES的Bulk thread pool是fix size的，也就是预先创建好，不会销毁和再创建。 那么这些`MutableLogEvent`对象由于是thread local的，只要线程没有销毁，就会对该线程实例一直全局存在，并且其还会一直引用最后一次处理过的`ParameterizedMessage`。 所以在ES记录bulk exception这种比较大的请求情况下， 整个request对象会被thread local变量一直强引用无法释放，产生大量的内存泄漏。\n\n再继续挖一下log4j的源码，发现`MutableLogEvent`是在`org.apache.logging.log4j.core.impl.ReusableLogEventFactory`里做为thread local创建的。\n```java\npublic class ReusableLogEventFactory implements LogEventFactory {\n    private static final ThreadNameCachingStrategy THREAD_NAME_CACHING_STRATEGY = ThreadNameCachingStrategy.create();\n    private static final Clock CLOCK = ClockFactory.getClock();\n\n    private static ThreadLocal\u0026lt;MutableLogEvent\u0026gt; mutableLogEventThreadLocal = new ThreadLocal\u0026lt;\u0026gt;();\n```\n而`org.apache.logging.log4j.core.config.LoggerConfig`则根据一个常数`ENABLE_THREADLOCALS`的值来决定用哪个LogEventFactory。\n```java\n        if (LOG_EVENT_FACTORY == null) {\n            LOG_EVENT_FACTORY = Constants.ENABLE_THREADLOCALS\n                    ? new ReusableLogEventFactory()\n                    : new DefaultLogEventFactory();\n        }\n```\n\n继续深挖，在`org.apache.logging.log4j.util.Constants`里看到，log4j会根据运行环境判断是否是WEB应用，如果不是，就从系统参数`log4j2.enable.threadlocals`读取这个常量，如果没有设置，则默认值是`true`。\n```java\npublic static final boolean ENABLE_THREADLOCALS = !IS_WEB_APP \u0026amp;\u0026amp; PropertiesUtil.getProperties().getBooleanProperty(\n            \u0026quot;log4j2.enable.threadlocals\u0026quot;, true);\n```\n\n由于ES不是一个web应用，导致log4j选择使用了`ReusableLogEventFactory`，因而使用了thread_local来创建`MutableLogEvent`对象，最终在ES记录bulk exception这个特殊场景下产生非常显著的内存泄漏。\n\n再问一个问题，为何log4j要将logevent做为thread local创建？ 跑到log4j的官网去扒了一下文档，在这里 [Garbage-free Steady State Logging](https://logging.apache.org/log4j/2.x/manual/garbagefree.html) 找到了合理的解释。 原来为了减少记录日志过程中的反复创建的对象数量，减轻GC压力从而提高性能，log4j有很多地方使用了thread_local来重用变量。 但使用thread local字段装载非JDK类，可能会产生内存泄漏问题，特别是对于web应用。 因此才会在启动的时候判断运行环境，对于web应用会禁用thread local类型的变量。\n\u0026gt;ThreadLocal fields holding non-JDK classes can cause memory leaks in web applications when the application server's thread pool continues to reference these fields after the web application is undeployed. To avoid causing memory leaks, Log4j will not use these ThreadLocals when it detects that it is used in a web application (when the javax.servlet.Servlet class is in the classpath, or when system property log4j2.is.webapp is set to \u0026quot;true\u0026quot;).\n\n参考上面的文档后，也为ES找到了规避这个问题的措施： 在ES的JVM配置文件`jvm.options`里，添加一个log4j的系统变量` -Dlog4j2.enable.threadlocals=false`，禁用掉thread local即可。  经过测试，该选项可以有效避开这个内存泄漏问题。\n\n这个问题Github上也提交了Issue，对应的链接是:  [Memory leak upon partial TransportShardBulkAction failure](https://github.com/elastic/elasticsearch/issues/27300)\n\n---\n#写在最后\nES的确是非常复杂的一个系统，包含非常多的模块和第三方组件，可以支持很多想象不到的用例场景，但一些边缘场景可能会引发一些难以排查的问题。完备的监控体系和一个经验丰富的支撑团队对于提升业务开发人员使用ES开发的效率、提升业务的稳定性是非常重要的！\n ","title":"Bulk异常引发的Elasticsearch内存泄漏","uid":"81","views":"3281","votes":"18"},"_type":"doc"}
{"_id":"362","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510151446","category_id":"2","comments":"1","has_attach":"1","id":"362","message":"[attach]1229[/attach]\n [Elasticsearch 5.6 Java API 中文手册]\n\n本手册由 全科 翻译，并且整理成电子书，支持PDF,ePub,Mobi格式，方便大家下载阅读。\n\n不只是官方文档的翻译，还包含使用实例，包含我们使用踩过的坑\n\n阅读地址：https://es.quanke.name\n\n下载地址：https://www.gitbook.com/book/quanke/elasticsearch-java\n\ngithub地址：https://github.com/quanke/elasticsearch-java\n\n编辑：http://quanke.name\n\n编辑整理辛苦，还望大神们点一下star ，抚平我虚荣的心\n\n[全科的公众号]\n\n[attach]1230[/attach]\n ","title":"Elasticsearch 5.6 Java API 中文手册","uid":"6646","views":"8253","votes":"19"},"_type":"doc"}
{"_id":"363","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510191487","category_id":"18","comments":"0","has_attach":"0","id":"363","message":"1.Bulk异常引发的Elasticsearch内存泄漏\nhttp://t.cn/RlY7tMh\n2.Spring Boot 中使用 Java API 调用 Elasticsearch\nhttp://t.cn/RljQNFJ\n3.一个实时查看，搜索尾部日志事件的kibana插件\nhttp://t.cn/RcXglR2\n招聘：京东北京招聘ES高级工程师\nhttps://elasticsearch.cn/article/358\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/363\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第95期 (2017-11-09)","uid":"668","views":"416","votes":"1"},"_type":"doc"}
{"_id":"367","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510326972","category_id":"12","comments":"6","has_attach":"1","id":"367","message":"[attach]1252[/attach]\n\n\n[立即申请](https://www.elastic.co/about/careers/support/jobs/923231) \n\n## Support Engineer - Mandarin Speaking\n\n### Location: Beijing, China\n\n###  Department: Support\n\n### Responsibilities \n- Ensuring customer issues are resolved within our committed service level agreements.\n- Maintain strong relationships with our customers for the delivery of support.\n- Have a mindset of continuous improvement, in terms of efficiency of support processes and customer satisfaction.\n\n### Experience \n- Demonstrable experience in of support in technology businesses\n- Experience working across multi-cultural and geographically distributed teams\n\n### Key Skills\n\n- Strong verbal and written communication skills in both Mandarin and English.\n- Customer orientated focus.\n- Team player, ability to work in a fast pace environment with a positive and adaptable approach.\n- Knowledge of databases or search technologies a plus.\n- Demonstrated strong technical understanding of software products.\n\n### Additional Information\n\n- Competitive pay and benefits\n- Stock options\n- Catered lunches, snacks, and beverages in most offices\n- An environment in which you can balance great work with a great life\n- Passionate people building great products\n- Employees with a wide variety of interests\n- Distributed-first company with employees in over 30 countries, spread across 18 time zones, and speaking over 30 languages!\n\n[立即申请](https://www.elastic.co/about/careers/support/jobs/923231) \n\nElastic is an Equal Employment employer committed to the principles of equal employment opportunity and affirmative action for all applicants and employees. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status or any other basis protected by federal, state or local law, ordinance or regulation. Elastic also makes reasonable accommodations for disabled employees consistent with applicable law.\n\n### About Elastic\nElastic is the world's leading software provider for making structured and unstructured data usable in real time for search, logging, security, and analytics use cases. Founded in 2012 by the people behind the Elasticsearch, Kibana, Beats, and Logstash open source projects, Elastic's global community has more than 80,000 members across 45 countries, and since its initial release. Elastic's products have achieved more than 100 million cumulative downloads. Today thousands of organizations, including Cisco, eBay, Dell, Goldman Sachs, Groupon, HP, Microsoft, Netflix, The New York Times, Uber, Verizon, Yelp, and Wikipedia, use the Elastic Stack, X-Pack, and Elastic Cloud to power mission-critical systems that drive new revenue opportunities and massive cost savings. Elastic is backed by more than $104 million in funding from Benchmark Capital, Index Ventures, and NEA; has headquarters in Amsterdam, the Netherlands, and Mountain View, California; and has over 500 employees in more than 30 countries around the world.\n\n### Our Philosophy\n\nWe’re always on the search for amazing people, people who have deep passion for technology and are masters at their craft. We build highly sophisticated distributed systems and we don’t take our technology lightly. In Elasticsearch, you’ll have the opportunity to work in a vibrant young company next to some of the smartest and highly skilled technologists the industry has to offer. We’re looking for great team players, yet we also promote independence and ownership. We’re hackers… but of the good kind. The kind that innovates and creates cutting edge products that eventually translates to a lot of happy, smiling faces.\n\n### LifeAtElastic\n\n\n[attach]1253[/attach]\n\n[attach]1255[/attach]\n\n[attach]1254[/attach]\n\n[attach]1258[/attach]\n\n[attach]1261[/attach]\n\n[attach]1259[/attach]\n\n[attach]1257[/attach]\n\n[attach]1256[/attach]\n\n[attach]1260[/attach]\n\n\n[有兴趣加入我们么？点击申请](https://www.elastic.co/about/careers/support/jobs/923231) \n","title":"Elastic 招聘技术支持工程师，坐标北京","uid":"1","views":"2125","votes":"3"},"_type":"doc"}
{"_id":"368","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510364240","category_id":"18","comments":"0","has_attach":"0","id":"368","message":"1. sense为什么不能用了，看看ES官方怎么说？\n   http://t.cn/RlB3B62\n\n2. 使用allocation API快速定位分片分配问题\n   http://t.cn/RlrzTsD\n\n3. ES6.0有关防止硬盘被填满的改进\n   http://t.cn/RlrU3Nr\n\n4. 喜大普奔，ES社区支持Markdown编辑器了\n   https://elasticsearch.cn/article/366\n\n5. Elastic 收购网站搜索 SaaS 服务领导者 Swiftype\n   http://t.cn/Rl3a4P2\n\n6. 只等你来 | Elastic Meetup 广州交流会\n   https://elasticsearch.cn/article/364 \n\n- 编辑：bsll\n- 归档：https://elasticsearch.cn/article/368\n- 订阅：https://tinyletter.com/elastic-daily\n","title":" Elastic日报 第97期 (2017-11-11)","uid":"1874","views":"451","votes":"0"},"_type":"doc"}
{"_id":"580","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524102450","category_id":"18","comments":"0","has_attach":"0","id":"580","message":"1. 6.x 复制片恢复引起flush操作死循环的BUG。\n[https://elasticsearch.cn/article/573](https://elasticsearch.cn/article/573) \n\n2. Elasticsearch内核剖析。\n[http://t.cn/Rm8UGij](http://t.cn/Rm8UGij) \n\n3. 将数据从Postgres索引到Elasticsearch的CLI。\n[http://t.cn/Rm135eK](http://t.cn/Rm135eK) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/580\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第246期 (2018-04-19)","uid":"668","views":"412","votes":"0"},"_type":"doc"}
{"_id":"59","_index":"forum-mysql","_score":1,"_source":{"addtime":"1456804777","category_id":"5","comments":"1","has_attach":"0","id":"59","message":"视频：[url]https://www.elastic.co/elasticon/conf/2016/sf[/url]\nPPT: [url]https://speakerdeck.com/elastic[/url]\n ","title":"Elastic{ON}16的资料已经放出","uid":"1","views":"2372","votes":"2"},"_type":"doc"}
{"_id":"62","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459163575","category_id":"2","comments":"4","has_attach":"0","id":"62","message":"我是最近从lucene过渡Elasticsearch的，直接用的最新的2.2.0版本的。发现离线安装插件的方式和以前不一样了，一些配置也有改变，最大的问题是java client api 连接报了如下的异常，我是参照官方api测试的，地址：[url]https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/transport-client.html[/url]\n[code]org.elasticsearch.transport.RemoteTransportException: Failed to deserialize exception response from stream[/code]谷歌都说是服务和客户端的jvm不一致，我是本机环境测试的，所以，现在这个问题都还没解决，有遇到过的么，还是和版本有关系啊","title":"大家聊一聊使用的什么版本的Elasticsearch，看看Elasticsearch版本变化","uid":"1032","views":"3199","votes":"0"},"_type":"doc"}
{"_id":"65","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459307342","category_id":"1","comments":"5","has_attach":"1","id":"65","message":"Shanghai Elastic Meetup\n\n时间：2016年5月7日 13:30\n\n地点：上海市徐汇区广元西路55号浩然科技大厦1808（交通大学内）\n\n报名链接：\n\n[Meetup](http://www.meetup.com/Shanghai-Elastic-Meetup/events/229807915/)\n\n[微信](https://jinshuju.net/f/Ed5I5o)\n\n## 《ES用于时间序列存储 - Hickwall监控报警平台简介》\n\n唐锐华  携程旅行网软件技术专家\n\n简介：\n  \n  \n  随着携程业务的扩张，新应用不断涌现，基础监控和应用监控的需求迅猛增长，zabbix已经不堪负重。在调研了很多开源的解决方案之后发觉或多或少都存在不太满意的地方。\n  所以在借鉴多种方案的基础上重新设计开发了一套监控告警系统。其中对比过多种现有存储方案之后我们选择了ES。这里和大家分享一下这个系统和ES用在在我们场景中的优缺点。\n\n提纲：\n\n* 为什么会有这个项目\n* 现有开源项目的调研\n* 项目的整体设计与其特点\n* ES在使用过程中碰到的问题\n\n## 《ES在日志分析产品中的实践》\n\n简介：\n\n主要介绍如何在JAVA开发产品中使用ES，以及常用的ES JAVA接口，以及JAVA代码阅读的简单说明\n\n2010年进入深圳天源迪科从事运营商业务系统相关的开发工作，期间做过软件开发，需求分析师，架构师等职务，后面2006年进入江苏保旺达从事安全产品相关的研发。从毕业到工作十几年的时间大部分都在做和技术相关的工作，本人非常热爱技术，热爱开发，现任赛克蓝德公司技术总监，从事数据分析领域相关产品的研发，现在主要研发日志分析产品(SeciLog)。\n\n## 《Hangout: 一个logstash indexer的替代方案》\n讲师简介:\n\n刘佳  携程旅行网软件技术专家\n\n简介:\n\nlogstash以其丰富的插件功能，成为ELK技术栈中不可或缺的一个组件。 但目前版本的logstash主要由jruby实现，在处理日志的吞吐量方面不尽如人意。 hangout是一个类logsatsh的java实现，提供了logstash里常用的filter功能。 这里分享一下hangout的特性，实际生产环境的吞吐量以及多实例的管理方式。\n\n提纲:\n\n* 为何开发hangout   \n* 支持的filter\n* 与logsatsh性能对比\n* 影响吞吐量的主要参数及其含\n* 用mesos+marathon管理hangout\n    ","title":"Shanghai Elastic Meetup启动啦！","uid":"1045","views":"3876","votes":"3"},"_type":"doc"}
{"_id":"70","_index":"forum-mysql","_score":1,"_source":{"addtime":"1460950887","category_id":"11","comments":"0","has_attach":"0","id":"70","message":"\r\n[attach]156[/attach]\r\n我试试怎么用","title":"ES中文社区logo","uid":"1103","views":"2062","votes":"0"},"_type":"doc"}
{"_id":"78","_index":"forum-mysql","_score":1,"_source":{"addtime":"1463994548","category_id":"2","comments":"108","has_attach":"0","id":"78","message":"[url]https://github.com/medcl/elasticsearch-migration[/url]\n支持多个版本间的数据迁移，使用scroll+bulk\n1.版本支持1.x,2.x.5.0 (0.x未测试)\n2.支持http basic auth 认证的es集群\n3.支持导入覆盖索引名称（目前只支持单个索引导入的情况下可指定）\n4.支持index setting和mapping的同步（相关es大版本，2.x和5.0之间不支持）\n5.支持dump到本地文件\n6.支持从dump文件加载导入到指定索引\n \n欢迎测试！\n \n[code]#copy index index_name from 192.168.1.x to 192.168.1.y:9200\n./bin/esm  -s http://192.168.1.x:9200   -d http://192.168.1.y:9200 -x index_name  -w=5 -b=10 -c 10000\n\n#copy index src_index from 192.168.1.x to 192.168.1.y:9200 and save with dest_index\n./bin/esm -s http://localhost:9200 -d http://localhost:9200 -x src_index -y dest_index -w=5 -b=100\n\n#support Basic-Auth\n./bin/esm -s http://localhost:9200/ -x \u0026quot;src_index\u0026quot; -y \u0026quot;dest_index\u0026quot;  -d http://localhost:9201 -n admin:111111\n\n#copy settings and override shard size\n./bin/esm -s http://localhost:9200/ -x \u0026quot;src_index\u0026quot; -y \u0026quot;dest_index\u0026quot;  -d http://localhost:9201 -m admin:111111 -c 10000 --shards=50  --copy_settings \n\n#copy settings and mapping, recreate target index, add query to source fetch, refresh after migration\n./bin/esm -s http://localhost:9200/ -x \u0026quot;src_index\u0026quot; -q=query:phone -y \u0026quot;dest_index\u0026quot;  -d http://localhost:9201  -c 10000 --shards=5  --copy_settings --copy_mapping --force  --refresh\n\n#dump elasticsearch documents into local file\n./bin/esm -s http://localhost:9200 -x \u0026quot;src_index\u0026quot;  -m admin:111111 -c 5000 -b -q=query:mixer  --refresh -o=dump.bin \n\n#loading data from dump files, bulk insert to another es instance\n./bin/esm -d http://localhost:9200 -y \u0026quot;dest_index\u0026quot;   -n admin:111111 -c 5000 -b 5 --refresh -i=dump.bin[/code]\n ","title":"发布个es迁移工具：elasticsearch-migration","uid":"1","views":"13295","votes":"3"},"_type":"doc"}
{"_id":"82","_index":"forum-mysql","_score":1,"_source":{"addtime":"1465369235","category_id":"2","comments":"0","has_attach":"0","id":"82","message":"    BoolQueryBuilder bool=QueryBuilders.boolQuery();\n        SearchResponse searchResponse = esClient.prepareSearch(\u0026quot;index\u0026quot;)\n                .setTypes(\u0026quot;type\u0026quot;)\n            .setSize(10000)\n            //这个游标维持多长时间\n            .setScroll(TimeValue.timeValueMinutes(8))\n            .execute().actionGet();\n         System.out.println(searchResponse.getHits().getTotalHits());\n        while(true){\n             for (SearchHit hit : searchResponse.getHits()) {\n                   System.out.println(hit.getSourceAsString()));         \n                }\n            searchResponse = esClient.prepareSearchScroll(searchResponse.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(8))\n                .execute().actionGet();\n            if (searchResponse.getHits().getHits().length == 0) {\n                break;\n            }\n        }","title":"elasticsearch遍历所有数据集","uid":"1121","views":"4788","votes":"1"},"_type":"doc"}
{"_id":"94","_index":"forum-mysql","_score":1,"_source":{"addtime":"1467731791","category_id":"13","comments":"1","has_attach":"0","id":"94","message":"论坛有多少人在用Cassandra的啊？弄了一个Cassandra的协议，有在用的Cassandra么？帮忙测试一下，看看有没有bug，\n欢迎反馈。\n \n[url]https://github.com/elastic/beats/pull/1959[/url]\n ","title":"Packetbeat的Cassandra协议扩展","uid":"1","views":"2706","votes":"0"},"_type":"doc"}
{"_id":"87","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738068","category_id":"15","comments":"0","has_attach":"0","id":"87","message":"[code]前言\n\nLuke是一个用于Lucene搜索引擎的，方便开发和诊断的第三方工具，它可以访问现有Lucene的索引，并允许您显示和修改。如果我们把Lucene的索引比作数据库数据的话，那么Luke就是一个管理数据的客户端（DBMS）。我们开发Lucene的时候可以借助这个工具来提高我们的开发效率\n\n准备工作\n\nLuke是一个开源的i项目，项目托管在GitHub上，地址https://github.com/DmitryKey/luke，选好我们的Luke分支下载下来\n\nps:Lucene更新迭代的很快，每个版本的变化也比较大，所以我们在选Luke版本的时候也要选择对应的分支下对应的版本，不然就gg了，笔者这里的Lucene是最新的5.X版本，当然Luke也是选的最新的\n\nLuke是一个maven项目，下载好后，install下，会打成一个jar包，直接双击jar就可以运行\n\nps：最新的Luke的使用的是jdk1.8，其他版本的不清楚，可以去pom.xml文件看下\n\n运行后的界面如下，我这里已选则好索引目录了\n\n\n\n图解\n\n1处信息可以看出这个Document有几个Field，以及每个Field的分词个数，百分占比，编码\n\n2.处信息是一个统计区，列出了有几个Document，Document有几个FIeld，总共多少个分词\n\n3.处可以重新打开索引（当索引变化时），提交更改\n\n4.处是索引的详细信息，可以看出每个分词出现的频次，以及对于的Field\n\n使用Luke\n\n上图可以看到第一个选项卡OverView的功能，接下来就看看其他的选项卡的功能\n\ndocuments选项卡是用来进行文档的操作和查看的，比如文件的删除、添加。下面一个大listview就可以用来查看文档的详细信息了，是不是和DBMS的查看表数据非常的像呢？上面有两个查找文档的方法，根据文档编号来查找和根据词来查找了，其实这个就是搜索了，详情如下图\n\nsearch选项卡是我认为最有用的一个界面了，其中我们可以在这里进行索引的搜索测试，可以编写最的lucene搜索语句，然后可以看到语句解析后的query树，这样就可以知道为什么我们有些查询会查询不到我们想要的信息了，然后还可以选择进行搜索的分词器、默认字段和重复搜索次数的(可以通过多次搜索来获取平均一个搜索过程的耗时长短，这个对查询的性能测试时非常有用的)，然后下面的listview中就会列出一个搜索的的文档的所有保存的（store）字段的值，下面可以看到查询花费的时间。详情如下图\n\n\nCommits选项卡就是用来查看每个索引相关文件的一些属性的界面，具体的话，可以通过这个界面分析下索引文件的多少大小，是否需要优化或者合并等等。详情如下图\n\n最后一个plugins选项卡，就是可以看到luke提供的各种插件，我认为比较有用的还是那个分词工具，提供一个分词的类，然后下面文本框输入一段文本，然后就可以让这个工具帮你分词，你可以看到详细的分词信息。详情如下图\n\n\n原文地址：[url]http://www.kailing.pub/article/index/arcid/74.html[/url]\n[/code]","title":"Lucene5.5入门第四篇——Lucene索引查看工具Luke","uid":"1032","views":"3490","votes":"0"},"_type":"doc"}
{"_id":"88","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738147","category_id":"15","comments":"0","has_attach":"0","id":"88","message":"[code]前言\n\n从入门的demo，到了解原理到了解结构，继而学习工具，现在我们可以用Lucene来做简单的数据增删改查操作了\n\n直接上代码\n\nps：代码注释比较全，鉴于作者的水平，有些东西可能未理解到位。推荐使用Luke来配合测试，了解Luke可参考我的上一篇博文：http://www.kailing.pub/article/index/arcid/74.html\n\npackage com.kl.Lucene;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.*;\nimport org.apache.lucene.queryparser.classic.QueryParser;\nimport org.apache.lucene.search.*;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.FSDirectory;\nimport org.junit.Test;\nimport java.nio.file.Paths;\n/**\n * @author kl by 2016/3/14\n * @boke www.kailing.pub\n */\npublic class IndexerCURD {\n    //测试数据，模拟数据库表结构\n    private static String ids={\u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot;}; //用户ID\n    private static String  names={\u0026quot;kl\u0026quot;,\u0026quot;wn\u0026quot;,\u0026quot;sb\u0026quot;};\n    private static String  describes={\u0026quot;shi yi ge mei nan zi\u0026quot;,\u0026quot;Don't know\u0026quot;,\u0026quot;Is an idiot\\n\u0026quot;};\n    //索引存储地址\n    private static String indexDir=\u0026quot;E:\\\\javaEEworkspace\\\\LuceneDemo\\\\LuceneIndex\u0026quot;;\n    /**\n     * 获取操作索引实体,并添加测试数据\n     * @param indexDir 索引存储位置\n     * @return\n     * @throws Exception\n     */\n    public static IndexWriter getIndexWriter(String indexDir)throws Exception{\n        IndexWriterConfig writerConfig=new IndexWriterConfig(getAnalyzer());\n        IndexWriter indexWriter=new IndexWriter(getDirectory(indexDir),writerConfig);\n        Document document=new Document();\n        //Field.Store.YES或者NO(存储域选项)\n        //设置为YES表示或把这个域中的内容完全存储到文件中，方便进行文本的还原\n        //设置为NO表示把这个域的内容不存储到文件中，但是可以被索引，此时内容无法完全还原(doc.get)\n        for(int i=0;i\u0026lt;ids.length;i++){\n            document.add(new StringField(\u0026quot;ids\u0026quot;,ids[i], Field.Store.YES));\n            document.add(new StringField(\u0026quot;names\u0026quot;,names[i], Field.Store.YES));\n            document.add(new TextField(\u0026quot;describes\u0026quot;,describes[i], Field.Store.YES));\n            indexWriter.addDocument(document);\n        }\n        return indexWriter;\n    }\n    /**\n     * 得到默认分词器\n     * @return\n     */\n    public static Analyzer getAnalyzer(){\n        return  new StandardAnalyzer();\n    }\n    /**\n     * 得到索引磁盘存储器\n     * @param indexDir 存储位置\n     * @return\n     */\n    public static Directory getDirectory(String indexDir){\n        Directory directory=null;\n        try {\n             directory= FSDirectory.open(Paths.get(indexDir));\n        }catch (Exception e){\n            e.printStackTrace();\n        }\n        return  directory;\n    }\n    /**\n     * 获取读索引实体，并打印读到的索引信息\n     * @return\n     */\n    public  static IndexReader getIndexReader(){\n        IndexReader reader=null;\n        try {\n            reader= DirectoryReader.open(getDirectory(indexDir));\n            //通过reader可以有效的获取到文档的数量\n            System.out.println(\u0026quot;当前存储的文档数：:\u0026quot;+reader.numDocs());\n            System.out.println(\u0026quot;当前存储的文档数，包含回收站的文档：:\u0026quot;+reader.maxDoc());\n            System.out.println(\u0026quot;回收站的文档数:\u0026quot;+reader.numDeletedDocs());\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return reader;\n    }\n\n    /**\n     * 写索引测试，借助Luke观察结果\n     * @throws Exception\n     */\n    @Test\n    public void Testinsert() throws  Exception{\n        IndexWriter writer=getIndexWriter(indexDir);\n        writer.close();\n        getIndexReader();\n    }\n    /**\n     * 删除索引测试，借助Luke观察结果\n     * @throws Exception\n     */\n    @Test\n    public void TestDelete()throws Exception{\n        //测试删除前我们先把上次的索引文件删掉，或者换个目录\n        IndexWriter writer=getIndexWriter(indexDir);\n        QueryParser parser=new QueryParser(\u0026quot;ids\u0026quot;, getAnalyzer());//指定Document的某个属性\n        Query query=parser.parse(\u0026quot;2\u0026quot;);//指定索引内容，对应某个分词\n        Term term=new Term(\u0026quot;names\u0026quot;,\u0026quot;kl\u0026quot;);\n        //参数是一个选项，可以是一个query，也可以是一个term，term是一个精确查找的值\n        writer.deleteDocuments(query);//此时删除的文档并不会被完全删除，而是存储在一个回收站中的，可以恢复\n         writer.forceMergeDeletes();//强制合并删除的索引信息，索引量大的时候不推荐使用，真正的删除\n       // writer.commit(); //更改索引要提交，和提交数据库事务一个概念，真正的删除\n        writer.close();\n        getIndexReader();\n    }\n    /**\n     * 更新操作测试，借助Luke观察结果\n     * @throws Exception\n     */\n    @Test\n    public void TestUpdate()throws Exception{\n       // Lucene并没有提供更新，这里的更新操作相当于新增，他并不会去掉原来的信息\n        IndexWriter writer = getIndexWriter(indexDir);\n        try {\n            Document doc = new Document();\n            doc.add(new StringField(\u0026quot;id\u0026quot;,\u0026quot;1\u0026quot;,Field.Store.YES));\n            doc.add(new StringField(\u0026quot;names\u0026quot;,\u0026quot;ckl\u0026quot;,Field.Store.YES));\n            doc.add(new StringField(\u0026quot;describes\u0026quot;,\u0026quot;chenkailing\u0026quot;,Field.Store.NO));\n            writer.updateDocument(new Term(\u0026quot;id\u0026quot;,\u0026quot;1\u0026quot;), doc);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n                if(writer!=null) writer.close();\n        }\n    }\n    /**\n     * 查询测试\n     */\n    @Test\n    public void TestSearchaer(){\n        try {\n            IndexReader reader = getIndexReader();\n            IndexSearcher searcher = new IndexSearcher(reader);\n            QueryParser parser=new QueryParser(\u0026quot;names\u0026quot;, getAnalyzer());//指定Document的某个属性\n            Query query=parser.parse(\u0026quot;kl\u0026quot;);//指定索引内容，对应某个分词\n            Term term=new Term(\u0026quot;names\u0026quot;,\u0026quot;kl\u0026quot;);\n            //参数是一个选项，可以是一个query，也可以是一个term，term是一个精确查找的值\n            TopDocs hits = searcher.search(query, 10);\n            for(ScoreDoc sd:hits.scoreDocs) {\n                Document doc = searcher.doc(sd.doc);\n                System.out.println(\n                        doc.get(\u0026quot;names\u0026quot;)+\u0026quot;[\u0026quot;+doc.get(\u0026quot;describes\u0026quot;)+\u0026quot;]--\u0026gt;\u0026quot;+doc.get(\u0026quot;ids\u0026quot;));\n            }\n            reader.close();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}[/i][/i][/i][/code][code][i][i][i]原文地址：[url]http://www.kailing.pub/article/index/arcid/75.html[/url]\n[/i][/i][/i][/code]","title":"Lucene5.5入门第五篇——Lucene索引的【增删改查】","uid":"1032","views":"4031","votes":"0"},"_type":"doc"}
{"_id":"96","_index":"forum-mysql","_score":1,"_source":{"addtime":"1468712230","category_id":"2","comments":"1","has_attach":"0","id":"96","message":"[url]http://laravel.fuxiben.com/elastic[/url]  测试地址 \n[url]https://github.com/zhuowenji/Laravel5.2-Demo[/url]   github地址 \n \n \n搞了一晚上，头疼，高亮，分页，高级搜索还没搞。大家有建议或者 demo的一起分享下！","title":"laravel5.2 \u0026amp; es2.3.4 Demo","uid":"1445","views":"2490","votes":"1"},"_type":"doc"}
{"_id":"100","_index":"forum-mysql","_score":1,"_source":{"addtime":"1472624799","category_id":"2","comments":"1","has_attach":"0","id":"100","message":"比如，由logstash打到es中的数据，除了其中一个字段比如message，其余字段都想设置为not analyzed,这种情况如何设置？貌似目前es只支持设置那些具体的字段为not analyzed，而不能反过来设置啊？","title":"如何反向设置es mapping template","uid":"1553","views":"2826","votes":"0"},"_type":"doc"}
{"_id":"101","_index":"forum-mysql","_score":1,"_source":{"addtime":"1474190163","category_id":"2","comments":"1","has_attach":"1","id":"101","message":"[b]Elastic中文社区技术沙龙【成都站】即将开始咯！[/b]\n    Elastic 中文社区联手成都卡莱博尔信息技术股份有限公司共同举办线下技术分享会，欢迎对elastic、搜索引擎、大数据等相关技术感兴趣的朋友来参加。\n[b]   卡莱博尔是一家以“大数据、移动智能和认知计算”技术为核心的高新技术企业，公司坐落于成都市高新区天府五街，致力于成为中国高端装备产业大数据应用产品和服务提供商，主要为“国防军工、民用航空、先进船舶、轨道交通、电力能源”等装备行业，提供基于装备运行全生命周期故障预测与健康管理相关的大数据技术支撑和运营服务。[/b]\n    ElasticSearch（下文简称ES）是当前流行的企业级搜索引擎，它提供了一个分布式多用户能力的全文搜索引擎。大数据时代ES能够提供简单易用的方式帮助企业从大型数据库中快速提取有效信息进行分析。\n主办方：elastic中文社区        http://elasticsearch.cn/article/101\n协办方：成都卡莱博尔信息技术股份有限公司  http://www.cdcalabar.com\n \n[attach]286[/attach]\n\n[b]活动信息：[/b]\n活动时间：[b]2016年10月29日 下午13:00-17:30（本周六）[/b]\n活动地点：[b]成都市高新区天府软件园E区1栋10楼 [/b] 成都卡莱博尔信息技术股份有限公司 多功能会议厅\n           （活动地点如有变化，会提前通知）\n场地容量：60人\n活动费用：免费 \n交通信息：地铁1号线  天府五街站下车  E区1栋10楼\n\n[b]分享主题:[/b]\n（1）[b]ES 在多维分析中的使用​  [/b]—— [b]李峰@ logicmonitor    logicmonitor数据平台高级工程师 [/b]\n                                                     专注于hadoop生态系统相关实数数据的存储计算\n（2）[b]ElasticStack V5 新特性与变化 [/b]  —— [b]Medcl@elastic  Elastic中文社区创始人和布道师[/b]\nElasticStack包括Elasticsearch、Logstash、Kibana和Beats，ElasticStack将在过段时间发布一个V5.0全新版本，这次的分享将给大家介绍一下5.0版里面各个产品的一些新的特性和改进。曾勇是Elasticsearch国内首批用户，自2010年起就开始接触Elasticsearch并投入到生产环境中使用，并编写过一系列的中文处理相关的插件，是Elasticsearch中文社区发起人，筹办了一系列线上线下的Elasticsearch技术分享与交流活动，出于对Elasticsearch的喜爱，目前已全职加入Elasticsearch项目背后的Elastic公司。\n（3）[b]探究ES的内部存储结构[/b]  —— [b]林添@ logicmonitor    logicmonitor后端高级工程师  [/b]\n                                   \nPPT资料链接：[url=https://github.com/rudyLi/es-chengdu-meetup-share]https://github.com/rudyLi/es-chengdu-meetup-share​[/url] \n\n[b]报名方式：[/b]\n （1）报名连接：http://www.jsform.com/web/formview/57df49d90cf2176714afc6a6\n （2）扫描下面微信二维码加入成都Elastic微信群，无法扫描的同学加我微信(xcx_2013)，我来拉你进群。电话：15008467351\n\n真诚邀请对elastic技术、搜索引擎技术、大数据存储索引可视化、大数据分析、日志分析等技术感兴趣的朋友前来交流和分享。\n ","title":"成都地区Elastic中文社区线下活动通知公告！！！","uid":"1327","views":"4912","votes":"1"},"_type":"doc"}
{"_id":"103","_index":"forum-mysql","_score":1,"_source":{"addtime":"1474381393","category_id":"5","comments":"8","has_attach":"0","id":"103","message":"[b]大会网站：[url]https://info.elastic.co/elasticon-dev-china.html[/url] [/b]\n[b]大会网站：​[url=http://conf.elasticsearch.cn]http://conf.elasticsearch.cn​[/url] [/b]\n[b]大会介绍：[/b]\nElastic 中国开发者大会 2016（Elastic{ON} Dev China 2016）是由 Elastic 官方在中国举办的第一次开发者大会，前身 ESCC (Elasticsearch China Conference) 是由 Elastic 中文社区每年定期举办的线下交流活动，主要围绕 Elastic 的开源产品: Elasticsearch、Logstash、Kibana 和 Beats，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。 \n\n[b]大会时间：[/b]\n2016-12-10 08:00 至 2016-12-10 18:00 周六\n \n[b]如何参与：[/b]\n提供赞助：[url]http://elasticsearch.mikecrm.com/nECSP4[/url]\n提交演讲：[url]http://elasticsearch.mikecrm.com/x0y56G[/url]\n当志愿者：[url]http://elasticsearch.mikecrm.com/n5BVwP[/url]\n购买门票：[url]http://event.3188.la/460820612/[/url]\n \n大会具体场地和日程不断更新中，敬请关注！","title":"Elastic{ON} Dev China 2016 开始报名了！","uid":"1","views":"2923","votes":"2"},"_type":"doc"}
{"_id":"113","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480774797","category_id":"14","comments":"0","has_attach":"1","id":"113","message":"Elastic Advent 第三篇, 手头上事情实在太多，这两天正在进行权威指南翻译的冲刺阶段，临时填下坑，翻译官网的一篇文章吧(原文:[url]https://www.elastic.co/blog/build-your-own-beat[/url])，Advent 规则很自由的，没说不能翻译文章啊，嘿嘿嘿，另外号召大家踊跃报名，大家一起玩才有意思。\n \n活动地址：[url]http://elasticsearch.cn/article/107[/url]\n \n言归正传！\n Beat 是一个开源的用来构建轻量级数据汇集的平台，可用于将各种类型的数据发送至Elasticsearch 与 Logstash。我们有 Packetbeat 用于监控局域网内服务器之间的网络流量信息，有 Filebeat 收集服务器上的日志信息，还有新推出的 Metricbeat 可以定期获取外部系统的监控指标信息，除此以外，你还可以非常方便的基于 libbeat 框架来构建你属于自己的专属 Beat，目前 beas 社区已经有超过25个 Community Beats 了。\n\nElastic 还提供一个 Beat generator（Beat 生成器）来帮你快速构建属于你自己的 Beat。通过这篇博客你将会看到如何通过 Beat 生成器来快速创建一个你自己的 Beat。今天我们创建的是一个叫做 lsbeat 的 Beat，lsbeat 非常类似 Unix 系统下的命令行 ls，我们用 lsbeat 来索引目录和文件信息。本篇文章环境基于 Unix 系统，如果你是 Windows 或是其它系统，相关操作可能需要根据实际情况进行调整。\n\n第一步 – 配置 Golang 环境\n\nBeats 是用 Golang写的，显然，要创建和开发一个 beat，Golang 环境必不可少，关于这方面的文章很多，建议查看这篇 Golang 的安装向导： install Golang。当前 Beats 需要的最低版本是 Golang 1.6。另外请确保正确设置了你的 $GOPATH 环境变量。\n\n另外 Golang Glide 被用来进行包的依赖管理，所以也需要确保正确安装，最低版本是 Glide 0.10.0，安装说明点这里。\n\n让我们先来看看 lsbeat 将会用到的一段代码吧，这是一个简单的 golang 程序，通过命令行接收一个目录参数，然后列出该目录下的文件和子目录信息。[code]package main\n \nimport (\n    \u0026quot;fmt\u0026quot;\n    \u0026quot;io/ioutil\u0026quot;\n    \u0026quot;os\u0026quot;\n)\n \nfunc main() {\n    //apply run path \u0026quot;.\u0026quot; without argument.\n    if len(os.Args) == 1 {\n        listDir(\u0026quot;.\u0026quot;)\n    } else {\n        listDir(os.Args[1])\n    }\n}\n \nfunc listDir(dirFile string) {\n    files, _ := ioutil.ReadDir(dirFile)\n    for _, f := range files {\n        t := f.ModTime()\n        fmt.Println(f.Name(), dirFile+\u0026quot;/\u0026quot;+f.Name(), f.IsDir(), t, f.Size())\n \n        if f.IsDir() {\n            listDir(dirFile + \u0026quot;/\u0026quot; + f.Name())\n        }\n    }\n}[/code]\n后面我们将使用到这段代码和 listDir 函数。\n\n第二步 – 生成项目\n\n要生成一个你自己的 Beat，就要用到 beat-generator 了，首先你必须安装 cookiecutter。安装的详细说明看这里。安装好 cookiecutter 之后，我们要给自己的 Beat 起一个好听的名字，最好是小写的英文字母，我们今天这个例子就叫 lsbeat 吧。\n\n生成项目模板之前，我们需要下载 Beats generator 包文件，就在 beats 仓库。安装好 GoLang 之后，你就可以很方便的使用 go get 命令来下载 Beats generator 包文件了。 当你执行下面的这个命令后，所有的源码文件都会下载到 $GOPATH/src 目录。[code]$ go get github.com/elastic/beats[/code]\n在 GOPATH 下创建一个以你自己github账号名称命名的目录，并切换过去，然后执行 cookiecutter 命令并指向 Beat Generator 源码路径。[code]$ cd $GOPATH/src/github.com/{user}\n$ cookiecutter $GOPATH/src/github.com/elastic/beats/generate/beat[/code]\nCookiecutter 接下来会问你几个问题，比如项目名称，我们输入：lsbeat；你的 github 用户名，输入你自己的 github 账户；还有两个关于beat和beat_path应该会自动识别，默认回车就好；最后的问题，你可以输入你的姓和名。[code]project_name [Examplebeat]: lsbeat\ngithub_name [your-github-name]: {username}\nbeat [lsbeat]:\nbeat_path [github.com/{github id}]:\nfull_name [Firstname Lastname]: {Full Name}[/code]\n\n现在应该已经创建好了一个名为 lsbeat 的目录，并且里面应该会生成一些文件，让我们一起来看一下吧，结构如下：[code]$ cd lsbeat\n$ tree\n.\n├── CONTRIBUTING.md\n├── LICENSE\n├── Makefile\n├── README.md\n├── beater\n│   └── lsbeat.go\n├── config\n│   ├── config.go\n│   └── config_test.go\n├── dev-tools\n│   └── packer\n│       ├── Makefile\n│       ├── beats\n│       │   └── lsbeat.yml\n│       └── version.yml\n├── docs\n│   └── index.asciidoc\n├── etc\n│   ├── beat.yml\n│   └── fields.yml\n├── glide.yaml\n├── lsbeat.template.json\n├── main.go\n├── main_test.go\n└── tests\n    └── system\n        ├── config\n        │   └── lsbeat.yml.j2\n        ├── lsbeat.py\n        ├── requirements.txt\n        └── test_base.py[/code]\n\n我们刚刚已经生成好了一个原始的 Beat 模板了，但是你还需要获取相关的依赖和设置好 git 仓库。\n\n首先，你需要拉取依赖的相关包信息，我们的这个例子是 lsbeat，我们先做一些的基本的配置，回头再看看详细看看其它的模板和配置文件，只需要执行 make setup 就可以自动获取依赖。[code]$ make setup[/code]\n\n当你创建好了自己的 Beat 之后，记得上传到 github 仓库，并和社区进行分享哦，如下：\n\n\n[attach]347[/attach]\n\n\n要 push lsbeat 到你的 git 仓库，只需要执行如下命令:[code]$ git remote add origin git@github.com:{username}/lsbeat.git\n$ git push -u origin master[/code]\n\n恭喜你，现在你已经完成了一个 Beat ，并且发布了第一个版本到了 Github，不过里面还没有什么具体内容，现在让我们进一步看看里面的代码吧。\n\n第四步 – 配置\n\n执行过上面一系列命令之后，项目里将会自动创建名为 lsbeat.yml 和 lsbeat.template.json 的配置文件。所有的基本配置项都已经生成在了里面。[code]lsbeat.yml\nlsbeat:\n# Defines how often an event is sent to the output\nperiod: 1s[/code]\n\nPeriod 参数包含在每一个生成的 Beats 里面，它表示 lsbeat 将会每隔 1 秒钟轮询一次，这里我们修改 period 时间间隔为 10 秒。还可以在修改 etc/ 目录下面的 beat.yml 文件，这里新增一个 path 参数表示我们具体要监听哪个目录。[code]lsbeat:\n# Defines how often an event is sent to the output\nperiod: 10s\npath: \u0026quot;.\u0026quot;[/code]\n\n参数添加好了之后，我们只需要运行 make update 命令就能让这些修改应用到配置文件lsbeat.yml。[code]$ make update\n$ cat lsbeat.yml\n \n################### Lsbeat Configuration Example #########################\n \n############################# Lsbeat ######################################\n \nlsbeat:\n  # Defines how often an event is sent to the output\n  period: 10s\n  path: \u0026quot;.\u0026quot;\n###############################################################################[/code]\n\n修改完 yml 文件，记得修改 config/config.go文件，添加一个path 参数。[code]package config\n \nimport \u0026quot;time\u0026quot;\n \ntype Config struct {\nPeriod time.Duration `config:\u0026quot;period\u0026quot;`\nPath   string        `config:\u0026quot;path\u0026quot;`\n}\n \nvar DefaultConfig = Config{\nPeriod: 10 * time.Second,\nPath:   \u0026quot;.\u0026quot;,\n}[/code]\n\n同时我们修改 period 默认时间间隔为 10 秒，默认监听的是当前目录 (.) 。.\n\n第五步 – 添加代码\n\n每一个 Beat 需要实现 Beater 接口，里面定义了 Run() 和 Stop() 函数。. \n\n我们可以定义一个名为 Lsbeat 的结构体，然后用这个对象实现 Beater 接口。然后添加字段 lastIndexTime 来保存最后运行的时间戳信息。[code]type Lsbeat struct {\ndone   chan struct{}\nconfig config.Config\nclient publisher.Client\n \nlastIndexTime time.Time\n...\n}[/code]\n\n另外，每个 Beat 还需要实现 New() 方法来接收 Beat 配置信息和返回 Lsbeat 的具体实例。[code]func New(b *beat.Beat, cfg *common.Config) (beat.Beater, error) {\nconfig := config.DefaultConfig\nif err := cfg.Unpack(\u0026amp;config); err != nil {\nreturn nil, fmt.Errorf(\u0026quot;Error reading config file: %v\u0026quot;, err)\n}\n \nls := \u0026amp;Lsbeat{\ndone:   make(chan struct{}),\nconfig: config,\n}\nreturn ls, nil\n}[/code]\n\n在我们的 lsbeat 例子中，我们要做的就是扩展默认的 Run() 函数来导出指定目录的文件和子目录信息。\n\n在修改 Run() 函数之前，我们先在 lsbeat.go 增加 listDir() 函数，就是我们前面最开始测试的那段代码，用于收集目录和文件信息的简单例子稍微修改一下。另外我们还要生成以下字段信息：[code]\u0026quot;@timestamp\u0026quot;: common.Time(time.Now()),\n\u0026quot;type\u0026quot;: beatname,\n\u0026quot;modtime\u0026quot;: common.Time(t),\n\u0026quot;filename\u0026quot;: f.Name(),\n\u0026quot;path\u0026quot;: dirFile + \u0026quot;/\u0026quot; + f.Name(),\n\u0026quot;directory\u0026quot;: f.IsDir(),\n\u0026quot;filesize\u0026quot;: f.Size(),[/code]\n\n第一次运行的时候我们将索引所有的文件和目录信息，然后我们再定期检查是否有新文件被创建或者修改，再索引这些新创建的文件和目录。每次定期检查的时间戳都会保存在 lasIndexTime 变量，完整代码如下：[code]func (bt *Lsbeat) listDir(dirFile string, beatname string, init bool) {\nfiles, _ := ioutil.ReadDir(dirFile)\nfor _, f := range files {\nt := f.ModTime()\n \nevent := common.MapStr{\n\u0026quot;@timestamp\u0026quot;: common.Time(time.Now()),\n\u0026quot;type\u0026quot;:       beatname,\n\u0026quot;modtime\u0026quot;:    common.Time(t),\n\u0026quot;filename\u0026quot;:   f.Name(),\n\u0026quot;path\u0026quot;:       dirFile + \u0026quot;/\u0026quot; + f.Name(),\n\u0026quot;directory\u0026quot;:  f.IsDir(),\n\u0026quot;filesize\u0026quot;:   f.Size(),\n}\nif init {\n// index all files and directories on init\nbt.client.PublishEvent(event)\n} else {\n// Index only changed files since last run.\nif t.After(bt.lastIndexTime) {\nbt.client.PublishEvent(event)\n}\n}\n \nif f.IsDir() {\nbt.listDir(dirFile+\u0026quot;/\u0026quot;+f.Name(), beatname, init)\n}\n}\n}[/code]\n\n记住在最开始需要导入 “io/ioutil” 包。[code]import (\n\u0026quot;fmt\u0026quot;\n\u0026quot;io/ioutil\u0026quot;\n\u0026quot;time\u0026quot;\n)[/code]\n\n现在，让我们看看如何在 Run() 函数里面调用 listDir() 函数，并且保存时间戳到 lasIndexTime 变量。[code]func (bt *Lsbeat) Run(b *beat.Beat) error {\nlogp.Info(\u0026quot;lsbeat is running! Hit CTRL-C to stop it.\u0026quot;)\n \nbt.client = b.Publisher.Connect()\nticker := time.NewTicker(bt.config.Period)\ncounter := 1\nfor {\n \nselect {\ncase \u0026lt;-bt.done:\nreturn nil\ncase \u0026lt;-ticker.C:\n}\n \nbt.listDir(bt.config.Path, b.Name, true)   // call lsDir\nbt.lastIndexTime = time.Now()               // mark Timestamp\n \nlogp.Info(\u0026quot;Event sent\u0026quot;)\ncounter++\n}\n \n}[/code]\n\n函数 Stop() 用来中断 run 的循环执行，保持默认生成的就行。[code]func (bt *Lsbeat) Stop() {\nbt.client.Close()\nclose(bt.done)\n}[/code]\n\n到这里，编码部分基本就完成了。我们接下来添加新字段到 mapping 中，修改文件 etc/fields.yml。.[code]- key: lsbeat\n  title: LS Beat\n  description:\n  fields:\n    - name: counter\n      type: integer\n      required: true\n      description: \u0026gt;\n        PLEASE UPDATE DOCUMENTATION\n    #new fiels added lsbeat\n    - name: modtime\n      type: date\n    - name: filename\n      type: text\n    - name: path\n    - name: directory\n      type: boolean\n    - name: filesize\n      type: long\n\n[/code]\n重新应用新的配置。\n\n$ make update\n\n字段 file_name 将使用 nGram 分词，我们还需要在文件 lsbeat.template.json 的 “settings” 节点添加一个自定义的 analyzer。[code]{\n  \u0026quot;mappings\u0026quot;: {\n        ...\n  },\n  \u0026quot;order\u0026quot;: 0,\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;index.refresh_interval\u0026quot;: \u0026quot;5s\u0026quot;,\n    \u0026quot;analysis\u0026quot;: {\n      \u0026quot;analyzer\u0026quot;: {\n        \u0026quot;ls_ngram_analyzer\u0026quot;: {\n          \u0026quot;tokenizer\u0026quot;: \u0026quot;ls_ngram_tokenizer\u0026quot;\n        }\n      },\n      \u0026quot;tokenizer\u0026quot;: {\n        \u0026quot;ls_ngram_tokenizer\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;ngram\u0026quot;,\n          \u0026quot;min_gram\u0026quot;: \u0026quot;2\u0026quot;,\n          \u0026quot;token_chars\u0026quot;: [\n            \u0026quot;letter\u0026quot;,\n            \u0026quot;digit\u0026quot;\n          ]\n        }\n      }\n    }\n  },\n  \u0026quot;template\u0026quot;: \u0026quot;lsbeat-*\u0026quot;\n}\n\n[/code]\n第六步 – 编译和运行\n\n现在我们可以编译和运行了，只需要执行 make 命令就可以编译出可执行文件 lsbeat (lsbeat.exe on windows) 。\n\n$ make\n\n修改 lsbeat.yml 文件，设置需要监听的目录，如： “/Users/ec2-user/go”，记住是全路径。[code]lsbeat:\n  # Defines how often an event is sent to the output\n  period: 10s\n  path: \u0026quot;/Users/ec2-user/go\u0026quot;[/code]\n同时确保你的 elasticsearch 和 kibana 正常运行。现在运行一下 lsbeat 命令看看会发生什么事情吧。\n\n$ ./lsbeat\n\n打开Kibana，通过调用 _cat 接口我们看看的索引是不是创建了。\n\n[attach]346[/attach]\n\n可以看到创建了一个名为 lsbeat-2016.06.03 的索引，并且看到已经有了一些文档了。现在对 filename 字段查询一下，由于使用的是 nGram 分词，支持模糊匹配，我们使用 lsbe 关键字搜一下。\n\n[attach]348[/attach]\n\n大功告成! 恭喜你，你已经完成了第一个属于你自己的 beat。","title":"Day3: 《创建一个你自己的 Beat》","uid":"1","views":"4296","votes":"3"},"_type":"doc"}
{"_id":"117","_index":"forum-mysql","_score":1,"_source":{"addtime":"1481010070","category_id":"4","comments":"0","has_attach":"0","id":"117","message":"kibana到5.0后可以直接在kibana.yml上面使用tilemap.url进行配置，\n但是之前使用的url貌似都不行，有伙伴能提供个K5能用的url吗？","title":"求一个Kibana5能用的高德URL","uid":"2041","views":"2755","votes":"0"},"_type":"doc"}
{"_id":"519","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520226170","category_id":"8","comments":"0","has_attach":"1","id":"519","message":"[size=16]北京时间周四凌晨1点15分，知名代码托管网站GitHub遭遇了有史以来最严重的DDoS网络攻击，峰值流量达到了1.35Tbps。尽管此类攻击的特点就是利用如潮水般的流量同时涌入网站，不过本次攻击不同之处在于采用了更先进的放大技术，目的是针对主机服务器产生更严重的影响。[/size]\n\n[size=16][attach]1841[/attach][/size]\n\n[size=16]报道称，拥有超过900万开发者用户的GitHub，是全球最知名的开源代码库之一。美国东部时间周三下午，为用户提供海量开源代码的GitHub透露，其可能遭受了有史最强的DDoS攻击，专家称攻击者采用了放大攻击的新方法，可能会在未来发生更大规模的分布式拒绝服务（DDoS）攻击。[/size]\n\n[size=16][attach]1844[/attach][/size]\n\n[size=16]据悉，对GitHub平台的第一次峰值流量攻击达到了1.35Tbps，随后又出现了另外一次400Gbps的峰值，这可能也将成为目前记录在案的最强DDoS攻击。对GitHub的攻击甚至超过了2016年对Dyn的大规模DDoS攻击，峰值流量达1.2Tbps，当时关闭了美国的互联网服务。[/size]\n\n\n[size=16]然而，对GitHub的攻击几乎毫发无损，只经历了几分钟的零星停机时间。按照GitHub方面的说法，从当地时间2月28日起，GitHub.com经历了两次间歇性不可访问，但其强调开发者数据依然安全。此外，GitHub在攻击发生10分钟后便向CDN服务商Akamai请求协助，访问GitHub的流量目前已由AkamaiProlexic接管。Prolexic接管了中间人路由所有进出GitHub的流量，并通过其清理中心发送数据来清除和阻止恶意数据包。八分钟后，攻击者松了口气，袭击事件下降了。[/size]\n\n\n[size=16]近年来随着互联网病毒的广泛传播，大规模的DDoS攻击愈发增多。而GitHub也并非第一次遭到DDoS攻击，2015年，Github曾遭到当时最大规模的攻击。[/size]","title":"GitHub疑遭有史以来最强的DDoS 攻击 峰值流量高达1.35Tbps！","uid":"7849","views":"429","votes":"0"},"_type":"doc"}
{"_id":"524","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520474398","category_id":"18","comments":"0","has_attach":"0","id":"524","message":"1. 知乎Live全文搜索之使用Elasticsearch全文搜索。\n[http://t.cn/RxAz6g1](http://t.cn/RxAz6g1) \n\n2. 简单尝试Kibana Canvas插件。\n[http://t.cn/RE8osJJ](http://t.cn/RE8osJJ) \n\n3. 用ansible管理你的es集群。\n[http://t.cn/RE8KPZR](http://t.cn/RE8KPZR) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/524 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第204期 (2018-03-08)","uid":"668","views":"380","votes":"0"},"_type":"doc"}
{"_id":"523","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520403074","category_id":"11","comments":"0","has_attach":"0","id":"523","message":"Docker 社区版从 17.12 版本开始已经提供了对 Kubernetes 的支持。但是由于其安装过程依赖的镜像服务在国内访问很不稳定，很多朋友都无法配置成功。阿里提供了一个简单的工具帮助大家开启 Docker 社区版的Kubernetes 功能\n\n开启 Kubernetes 从 Docker 官方站点下载并安装 Docker for Mac 或 Docker for Windows\n\n在 Docker -\u0026gt; Preferences ... 中，配置 registry mirror 为 https://registry.docker-cn.com\n\n具体步骤参考： [url]https://github.com/wellpeng/k8s-for-docker-desktop[/url]\n ","title":"Docker 社区版中 Kubernetes 开启","uid":"1160","views":"651","votes":"0"},"_type":"doc"}
{"_id":"522","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520386529","category_id":"18","comments":"0","has_attach":"0","id":"522","message":"1. 中小规模搜索引擎（ElasticSearch）典型应用场景及性能优化系列文章（一共四篇）\n[url]http://t.cn/RlDYuI7[/url] \n[url]http://t.cn/RlDeubP[/url] \n[url]http://t.cn/Rjwyqwm[/url] \n[url]http://t.cn/REQIHEp[/url] \n2. ElasticSearch tips\n[url]http://t.cn/REQIe3k[/url] \n[url]http://t.cn/REQIsmF[/url] \n3. 多数据源索引同步设计\n[url]http://t.cn/RjCAaus[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/522[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第203期 (2018-03-07)","uid":"3828","views":"334","votes":"0"},"_type":"doc"}
{"_id":"534","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521013819","category_id":"16","comments":"0","has_attach":"0","id":"534","message":"## 一、活动介绍\n互联网业务井喷，给运维带来了越来越多的挑战。在运维领域，也产生了很多新的实践和方法论，自动化运维、DevOps、敏捷运维等，运维已然成为驱动各大公司研发运维流程和理念变革的关键角色。本次活动，又拍云联合日志易，并邀请华数传媒、二维火，在强调一线落地实践的同时，为你提供来自业界最前沿的智能运维思路。\n\n又拍云 Open Talk 是由又拍云发起的系列主题分享沙龙，秉承又拍云帮助企业提升发展速度的初衷，从 2015 年开启以来，Open Talk 至今已成功举办 39 期，辐射线上线下近 70,000 技术人群。不管是从某个“主题”出发，并从横向拓展技术干货分享，还是以某个“品牌企业”为主，从纵深丰富演讲内容，活动都场场爆满。 \n\n截止目前，又拍云 Open Talk 已经举办 39 期活动，分别在北京、上海、广州、深圳、杭州等12 座城市举办，覆盖美拍、唱吧、美联集团、唯品会、哔哩哔哩、华为等诸多知名企业，往期的活动的讲稿及视频详见：https://opentalk.upyun.com\n\n## 二、报名地址\n\nhttp://www.huodongxing.com/event/5431062720800\n\n## 三、活动时间\n2018 年 03 月 31 日（ 周六 ）14:00-17:30 \n\n## 四、活动地点\n\n浙江省杭州市西湖区黄姑山路 29 号颐高创业大厦 4 楼楼友会咖啡厅\n\n## 五、活动议程\n\n13:00-14:00  签到\n\n14:00-14:40  宣云辉 二维火运维总监 - 《二维火的自动化运维探索》\n\n14:40-15:20  邵海杨  又拍云运维总监 -《第三代又拍云数据中心架构改造》\n\n15:20-15:30  茶歇\n\n15:30-16:10  唐文俊 日志易技术总监 -《智能运维与海量日志分析》\n\n16:10-16:50  姚建兵 华数传媒 P8 解决方案专家、高级项目经理 -《华数互联网 CDN 架构应用及运维实践》\n\n16:50-17:30  自由交流\n\n## 六、嘉宾介绍\n\n![alt 文本](http://musee20160425.b0.upaiyun.com/fileimage/ot40qixi.jpg)\n\n**分享嘉宾一：宣云辉 二维火运维总监**\n\n花名七喜，二维火运维总监，Redhat 认证架构师，专注于运维新技术实践和中国传统文化在运维工作中的探索。\n\n分享主题：《二维火的自动化运维探索》\n本次分享主要介绍二维火在多地容灾，海外数据中心建设中对自动化运维的探索和实践。\n\n![alt 文本](http://musee20160425.b0.upaiyun.com/fileimage/ot40haiyang.jpg)\n\n**分享嘉宾二：邵海杨 又拍云运维总监**\n\n资深系统运维架构师。来自杭州 Linux 用户组。业余撰稿人，QCon 讲师及出品人，致力于开源软件及前沿科技的研究和探索。\n\n分享主题：《第三代又拍云数据中心架构改造》\n又拍云在经历了由小变大的过程中，数据中心也由简单变复杂，伴随着传统运维向自动化运维的转型，以此来更好地迎接未来的挑战，拥抱智能运维的到来。本次分享，将会介绍又拍云如何打造一个集松耦合，弹性可扩容，无状态微服务，可用资源池化的新一代数据中心架构。\n\n![alt 文本](http://musee20160425.b0.upaiyun.com/fileimage/ot40tang.jpg)\n\n**分享嘉宾三：唐文俊 日志易技术总监**\n\n先后在互联网、电商、信息安全等领域深耕多年，从事IT安全运维、日志分析等方面工作，项目实战经验丰富，拥有Redhat 、Cisco、Vmware、 EMC、Splunk、ITIL等等诸多专家认证资质，对智能运维、信息安全、大数据分析等领域有独到见解。\n\n分享主题：《智能运维与海量日志分析》\n大数据分析正在被广泛应用，大数据里 90% 都是非结构化数据。日志是重要的非结构化数据，日志无处不在，所以能够从日志里面挖掘的价值非常高，可用于运维监控、安全审计、用户以及业务数据分析。那么，如何最大限度发挥日志的价值成为业内人士研究思考最多的问题之一。本次分享将为大家分享当前海量日志分析的相关应用场景、技术难点以及趋势发展等。\n\n![alt 文本](http://musee20160425.b0.upaiyun.com/fileimage/ot40yao.jpg)\n\n**分享嘉宾四：姚建兵 华数传媒 P8 解决方案专家、高级项目经理**\n\n华数传媒互联网技术专家，高级项目经理，致力于 OTT 后台架构的研究，新产品、新方案的探索和实施，解决日常运营、运维中遇到的重大问题并给出改造的解决方案。\n\n分享主题：《华数互联网 CDN 架构应用及运维实践》\n华数传媒在互联网电视、 OTT 行业深耕，积累了丰富的经验。本次分享首先会介绍华数传媒的后台架构及 CDN 架构，结合统一调度、统一云存储、统一编排库等如何智能化解决问题，并大幅降低运维的工作量，介绍一些日常遇到的问题及解决方案。\n\n## 七、现场礼品\n\n![alt 文本](http://musee20160425.b0.upaiyun.com/fileimage/ot40lipin.jpg)\n","title":"[杭州活动][3月31日] 智能运维探索与实践丨又拍云 Open Talk NO.40","uid":"2840","views":"598","votes":"0"},"_type":"doc"}
{"_id":"539","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521335310","category_id":"18","comments":"0","has_attach":"0","id":"539","message":"1.用于API开发的不同搜索引擎。\nhttp://t.cn/RnUot3a\n2.搜索引擎与关系数据库。\nhttp://t.cn/RnUSobB\n3.(自备梯子)每个人都应该了解技术的12件事。\nhttp://t.cn/RnUVuOY\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/539\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第214期 (2018-03-18)","uid":"4460","views":"499","votes":"0"},"_type":"doc"}
{"_id":"545","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521757181","category_id":"18","comments":"0","has_attach":"0","id":"545","message":"1、Elasticsearch 集群部署注意事项\nhttp://t.cn/Rnih4Md\n2、php的操作类库| DSL的sql实现\nhttps://elasticsearch.cn/article/543\n3、Postgresql同步Elasticsearch实现\n[url]http://t.cn/RnihfAU[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/545\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第219期 (2018-03-23)","uid":"1341","views":"643","votes":"0"},"_type":"doc"}
{"_id":"552","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522294002","category_id":"18","comments":"0","has_attach":"0","id":"552","message":"1. filebeat5.3.1结合rancher和data-volume实现横向扩展。\n[http://t.cn/RHHKOEf](http://t.cn/RHHKOEf) \n\n2. 基于filebeat二次开发Kubernetes日志采集。\n[http://t.cn/RnRxR6m](http://t.cn/RnRxR6m) \n\n3. 将systemd/journald数据发送到到Logstash/Elasticsearch的shipper。\n[http://t.cn/Rj56r0y](http://t.cn/Rj56r0y) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/552\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第225期 (2018-03-29)","uid":"668","views":"309","votes":"0"},"_type":"doc"}
{"_id":"554","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522458521","category_id":"18","comments":"0","has_attach":"0","id":"554","message":"1. 利用Kibana的vega绘制桑基图\n[http://t.cn/Rn3IA5I](http://t.cn/Rn3IA5I) \n\n2. 可视化基础篇：利用kibana绘图。\n[http://t.cn/Rn3INrW](http://t.cn/Rn3INrW) \n\n3.  lucene索引原理介绍。\n[http://t.cn/Rn3JgFv](http://t.cn/Rn3JgFv) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/554 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第227期 (2018-03-31)","uid":"1874","views":"337","votes":"0"},"_type":"doc"}
{"_id":"558","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522767493","category_id":"8","comments":"2","has_attach":"1","id":"558","message":"大家好，经过近半年的辛勤努力，我在慕课网推出了[url=https://coding.imooc.com/class/chapter/181.html#Anchor]《Elastic Stack 从入门到实践》[/url]的课程（https://coding.imooc.com/class/chapter/181.html），其中包含了 elasticsearch 教程、beats 和 logstash 教程、kibana 教程，简单看下课程的内容：\n[quote]\n第1章 课程概述\n对课程整体进行介绍给出相关学习说明和建议\n\n第2章 Elasticsearch 篇之 入门\n本章会对 Elasticsearch 篇进行一个总体的介绍，让大家对该篇每一章要讲解的内容有初步的了解。然后会讲解 Elasticsearch 中常见的术语、api，然后运行 Elasticsearch 并实际感受 api 的调用方式，为接下来的课程做好准备。\n\n第3章 Elasticsearch 篇之倒排索引与分词\n本章会讲解搜索引擎的基础倒排索引，让大家对倒排索引有一个直观的认识，掌握它的组成。然后为大家讲解分词的相关知识，介绍 es 内置的分词器，还会介绍中文分词的常见解决方案。\n\n第4章 Elasticsearch 篇之Mapping 设置\n本章会讲解 Elasticsearch 中数据建模的基础--Mapping，即如何定义数据字段和类型。让大家熟悉 mapping 中常见的配置项，也会讲解 dynamic mapping 和 template 的相关知识。\n\n第5章 Elasticsearch 篇之Search API 介绍\n本章会讲解搜索特性，详细讲解 Search API 的组成和分类，带领大家逐个了解、掌握 API 的使用方法和技巧。\n\n第6章 Elasticsearch 篇之分布式特性介绍\n本章会讲解 Elasticsearch 集群是如何一步步搭建起来的，让大家了解不同节点类型的作用，shard 设计的意义以及文档是如何存储到 shard 上的，也会给大家介绍脑裂等问题。\n\n第7章 Elasticsearch 篇之深入了解 Search 的运行机制\n本章会深入讲解 Search 的运行机制，比如 Query 和 Fetch 阶段具体哪些工作，分片为相关性算分带来了哪些问题。另外还会讲解排序、分页与遍历的解决方案和相关问题。\n\n第8章 Elasticsearch 篇之聚合分析入门\n本章会介绍 Elasticsearch 聚合分析的功能，让大家了解其分类、组成，带领大家逐个了解、掌握每一个聚合 API 的使用方法和技巧，为后续 Kibana 使用打好基础。\n\n第9章 Elasticsearch 篇之数据建模\n本章会介绍使用 Elasticsearch 中要注意的数据建模常见问题以及优化思路和方案，让大家可以根据自己的业务场景设置最合理的模型。\n\n第10章 Elasticsearch 篇之集群调优建议\n本章会介绍 Elasticsearch 集群在搭建、配置上的注意事项，也会讲解读写性能优化的方案和调优的方式。\n\n第11章 Logstash 篇之入门与运行机制\n本章会介绍 Logstash 的作用、使用方法，让大家了解其组成和运行机制，带领大家实际操作 Logstash 来收集1个日志文件。\n\n第12章 Logstash 篇之插件详解\n本章会详细介绍 Input、Filter、Ouput 以及 Codec 插件 的作用和相关配置，让大家了解常见相关插件的使用场景和效果，以及如何合理选择各个插件来实现自己的业务需求。\n\n第13章 Logstash 篇之实例分析\n本章会以实例的形式为大家演示如何使用 Logstash 收集各种类型的数据，比如日志文件、数据库、tcp/udp 等。\n\n第14章 Beats 篇之Filebeat\n本章会介绍 Beats 的作用和组成，然后为大家详细介绍 Filebeat 的功能和常见配置，同时会详细讲解如何使用 Module 模块来快速完成日志的收集到分析工作。\n\n第15章 Beats 篇之Metricbeat\n本章会介绍 Metricbeat 的功能和使用技巧，让大家对 Metricbeat 的使用有一个直观的感受。\n\n第16章 Beats 篇之Packetbeat\n本章会介绍 Packetbeat 的功能和使用技巧，带领大家用 Packetbeat 来收集网络数据并进行分析，让大家对 Packetbeat 有一个直观的感受。\n\n第17章 Beats 篇之其他 beat\n本章会介绍其他众多beat的作用和应用场景，带领大家去发现社区提供的多种多样的beat,以满足日常业务开发的需求。\n\n第18章 Kibana 篇之 入门与管理\n本章会介绍 Kibana 的入门知识，让大家对 Kibana 有一个整体的了解，另外还会详细介绍Management 的功能，熟悉 Kibana 的配置。\n\n第19章 Kibana 篇之 数据探索 Discovery\n本章会介绍 Kibana 的数据探索功能，让大家了解 Discovery 的功能和使用技巧。\n\n第20章 Kibana 篇之 可视化分析\n本章会介绍Kibana 的可视化分析功能，首先会带领大家逐个操作 Kibana 提供的每一个图表，并会介绍时序分析工具 Timelion，然后会介绍如何使用 Dashboard功能来整合图表后讲故事或者做报表，也会讲解 Dashboard 使用中要注意的问题和使用技巧。 ...\n\n第21章 实践篇 之搜索项目\n本章会讲解一个搜索引擎相关的实践项目，带领大家通过编写少量的代码，快速基于 Elastic Stack 来构建一个具备常见搜索功能的系统，比如类似 Airbnb 的搜房系统、豆瓣电影等。\n\n第22章 实践篇 之日志分析项目\n本章会根据慕课网的日志为大家展示如何使用 Elastic Stack 来快速分析日志数据，带领大家一步步完成数据收集、处理、存储到可视化分析的步骤，最终打造属于自己的 Dashboard。\n\n第23章 实践篇 之数据分析项目\n本章会为大家展示如何使用 Elastic Stack 来分析身边的数据，比如空气质量分析、订单数据分析等等，让大家通过本章的学习可以快速将 Elastic Stack 应用到实际生活中。\n \n[/quote]\n \n实践方面我从搜索项目、日志分析和数据分析三个维度介绍了 Elastic Stack 的功能，可以看下最终的效果截图：\n \n\n[attach]1949[/attach]\n \n\n[attach]1950[/attach]\n \n \n\n[attach]1951[/attach]\n\n[attach]1952[/attach]\n \n那么剩下的就看你们了！\n \n \n \n \n \n \n \n ","title":"《Elastic Stack 从入门到实践》的课程已在慕课网上线，一次搞定 es logstash beats kibana","uid":"86","views":"1946","votes":"7"},"_type":"doc"}
{"_id":"565","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523146117","category_id":"18","comments":"0","has_attach":"0","id":"565","message":"1.使用Logz.io和ELK进行AWS成本和使用情况报告分析 - 第2部分。\nhttp://t.cn/RmGDHbc\n2.(自备梯子)Logstash是否使用X-PACK。\nhttp://t.cn/RmGezqS\n3.(自备梯子)Facebook，告诉我该怎么做！\nhttp://t.cn/RmGkTOQ\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/565\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第235期 (2018-04-08)","uid":"4460","views":"334","votes":"0"},"_type":"doc"}
{"_id":"566","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523240338","category_id":"18","comments":"0","has_attach":"0","id":"566","message":"1.(自备梯子)如何做到每秒一百万写入的es集群基准测试。\nhttp://t.cn/Rm5uw5E\n\n2.elasticsearch5.3.0 bulk index 性能调优实践\nhttp://t.cn/Rm5uEYw\n\n3.kibana 雷达图插件\nhttp://t.cn/Rm5BvcW\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/566\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第236期 (2018-04-09)","uid":"4063","views":"335","votes":"0"},"_type":"doc"}
{"_id":"568","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523324444","category_id":"18","comments":"0","has_attach":"0","id":"568","message":"1.Elasticsearch分布式一致性原理剖析-节点篇。\n[url]http://t.cn/RmIN5RX[/url] \n2.ELK 系统在中小企业从0到1的落地实践。\n[url]http://t.cn/RmIN4C8[/url] \n3.ES查询流程剖析。\n[url]http://t.cn/RmIN2Pt[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/568[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第237期 (2018-04-10)","uid":"3788","views":"333","votes":"0"},"_type":"doc"}
{"_id":"574","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523620951","category_id":"2","comments":"3","has_attach":"1","id":"574","message":"如图\r\n[attach]2024[/attach]\r\n\r\n[attach]2025[/attach]\r\n ","title":"es搜索head工具和kibana的dev tools结果不一样","uid":"8187","views":"973","votes":"0"},"_type":"doc"}
{"_id":"576","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523747952","category_id":"18","comments":"0","has_attach":"0","id":"576","message":"1.Elasticsearch配置和性能调节。\nhttp://t.cn/RmOXAb3\n2.(自备梯子)AWS ElasticSearch索引快照。\nhttp://t.cn/RmOa9o0\n3.(自备梯子)是的，你应该删除Facebook。\nhttp://t.cn/RmOa4DH\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/576\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第242期 (2018-04-15)","uid":"4460","views":"361","votes":"0"},"_type":"doc"}
{"_id":"589","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524537202","category_id":"2","comments":"0","has_attach":"0","id":"589","message":"使用_validate/query?explain API得到的结果如下，Synonym是什么意思啊？同义词吗？求解释{\n  \u0026quot;valid\u0026quot;: true,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 1,\n    \u0026quot;successful\u0026quot;: 1,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;explanations\u0026quot;: [\n    {\n      \u0026quot;index\u0026quot;: \u0026quot;country\u0026quot;,\n      \u0026quot;valid\u0026quot;: true,\n      \u0026quot;explanation\u0026quot;: \u0026quot;name:z Synonym(name:g name:zg)\u0026quot;\n    }\n  ]\n}","title":"_validate/query?explain解释","uid":"8168","views":"320","votes":"0"},"_type":"doc"}
{"_id":"596","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524961217","category_id":"18","comments":"0","has_attach":"0","id":"596","message":"1.高效地在Elasticsearch中搜索和获取大数据集。\nhttp://t.cn/RuSvIsp\n2.安全永不眠 - ElasticSearch恶意软件和量子通信。\nhttp://t.cn/Ruas2gO\n3.(自备梯子)更好的表单设计是这样的。\nhttp://t.cn/RuodFMf\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/596\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第256期 (2018-04-29)","uid":"4460","views":"409","votes":"0"},"_type":"doc"}
{"_id":"600","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525319915","category_id":"18","comments":"0","has_attach":"0","id":"600","message":"1. 构建流式计算卖家日志系统架构的应用实践。\n[http://t.cn/Ru8CDaU](http://t.cn/Ru8CDaU) \n\n2. 测试下载速度的beat：Fastcombeat。\n[http://t.cn/Ru8CsN6](http://t.cn/Ru8CsN6) \n\n3. Elasticsearch实战。\n[http://t.cn/Ru8NhZs](http://t.cn/Ru8NhZs) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/600\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第260期 (2018-05-03)","uid":"668","views":"479","votes":"0"},"_type":"doc"}
{"_id":"601","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525333298","category_id":"11","comments":"0","has_attach":"0","id":"601","message":"随着 7.0 版本的即将发布，`type`  的移除也是越来越近了，在 6.0 的时候，已经默认只能支持一个索引一个 type 了，7.0 版本新增了一个参数  `include_type_name` ，即让所有的 API 是 type 相关的，这个参数在 7.0 默认是 `true`，不过在 8.0 的时候，会默认改成 `false`，也就是不包含 type 信息了，这个是 type 用于移除的一个开关。\n\n让我们看看最新的使用姿势吧，当 `include_type_name` 参数设置成 `false` 后：\n\n- 索引操作：PUT {index}/{type}/{id}` 需要修改成  `PUT {index}/_doc/{id}\n- Mapping 操作：`PUT  {index}/{type}/_mapping` 则变成 `PUT  {index}/_mapping`\n- 所有增删改查搜索操作返回结果里面的关键字 `_type` 都将被移除\n- 父子关系使用 `join` 字段来构建\n\n\n```\n#创建索引\nPUT twitter\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;_doc\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;type\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \n        \u0026quot;name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; },\n        \u0026quot;user_name\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; },\n        \u0026quot;email\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; },\n        \u0026quot;content\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; },\n        \u0026quot;tweeted_at\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; }\n      }\n    }\n  }\n}\n\n#修改索引\nPUT twitter/_doc/user-kimchy\n{\n  \u0026quot;type\u0026quot;: \u0026quot;user\u0026quot;, \n  \u0026quot;name\u0026quot;: \u0026quot;Shay Banon\u0026quot;,\n  \u0026quot;user_name\u0026quot;: \u0026quot;kimchy\u0026quot;,\n  \u0026quot;email\u0026quot;: \u0026quot;shay@kimchy.com\u0026quot;\n}\n\n#搜索\nGET twitter/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;bool\u0026quot;: {\n      \u0026quot;must\u0026quot;: {\n        \u0026quot;match\u0026quot;: {\n          \u0026quot;user_name\u0026quot;: \u0026quot;kimchy\u0026quot;\n        }\n      },\n      \u0026quot;filter\u0026quot;: {\n        \u0026quot;match\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;tweet\u0026quot; \n        }\n      }\n    }\n  }\n}\n\n#重建索引\nPOST _reindex\n{\n  \u0026quot;source\u0026quot;: {\n    \u0026quot;index\u0026quot;: \u0026quot;twitter\u0026quot;\n  },\n  \u0026quot;dest\u0026quot;: {\n    \u0026quot;index\u0026quot;: \u0026quot;new_twitter\u0026quot;\n  }\n}\n```\n\n相关链接：\n- [removal-of-types](https://www.elastic.co/guide/en/elasticsearch/reference/master/removal-of-types.html#_use_literal_include_type_name_false_literal_to_prepare_for_upgrade_to_8_0)\n- [#15613](https://github.com/elastic/elasticsearch/issues/15613#issuecomment-239435920)\n- [join filed](https://www.elastic.co/guide/en/elasticsearch/reference/master/parent-join.html)","title":"Elasticsearch 移除 type 之后的新姿势","uid":"1","views":"2270","votes":"3"},"_type":"doc"}
{"_id":"605","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525568235","category_id":"18","comments":"0","has_attach":"0","id":"605","message":"1.捕捉动态数据。\nhttp://t.cn/RuBl5Ef\n2.如何用Grafana监控Elasticsearch。\nhttp://t.cn/RHcsJYJ\n3.(自备梯子)为什么未来属于拥有多领域能力的人。\nhttp://t.cn/RuB9Ko7\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/605\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第263期 (2018-05-06)","uid":"4460","views":"401","votes":"0"},"_type":"doc"}
{"_id":"611","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525991081","category_id":"18","comments":"0","has_attach":"0","id":"611","message":"1、号外！Elastic 技能的官方认证来了！\nhttp://t.cn/Ruuvok6\n2、公开 | Elasticsearch 团队的开发章程\nhttp://t.cn/RueX0MI\n3、新特性 | Elasticsearch正在实现逻辑删除功能\nhttp://t.cn/Rus9JBR\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/611\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第268期 (2018-05-11)","uid":"1341","views":"389","votes":"0"},"_type":"doc"}
{"_id":"683","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529915530","category_id":"16","comments":"1","has_attach":"1","id":"683","message":"[attach]2528[/attach]\r\n 活动简介：\r\n\r\n互联网时代，创新、高效、速度是企业保持核心竞争力的必要条件。DevOps被描述为“开发团队与运营团队之间更具协作性、更高效的关系”。本次活动邀请到阿里云Docker团队，ES团队、袋鼠云日志团队的同学从各个方面向大家介绍Devops的实践经验，帮助企业更敏捷、更自动化、更高效地实现持续交付。\r\n \r\n主办方：袋鼠云\r\n\r\n特别支持：养码场、高效运维社区、DBAPLUS、Elastic中文社区、阿里云、跨星、杭州创业大街\r\n\r\n报名平台：活动行\r\n\r\n直播支持：IT大咖说\r\n\r\n活动时间：2018年6月30日13：00-17：00\r\n\r\n活动地点：杭州市滨江区阡陌路459号聚光中心内 杭州创业大街C1-105室跨星空间\r\n \r\n分享嘉宾：\r\n\r\n[attach]2529[/attach]\r\n\r\n赵汉青 阿里巴巴集团搜索事业部 高级工程师\r\n\r\nElasticsearch运维实践分享\r\n\r\n简介：2014年硕士毕业于中国科学技术大学 曾就职于思科系统(中国)研发有限公司云服务部，本次主题针对Elasticsearch集群运维：监控，诊断，优化，升级进行详细的介绍，并向大家分享阿里云Elasticsearch服务。\r\n\r\n[attach]2527[/attach]\r\n南方   袋鼠云日志产品经理\r\n\r\n企业日志中心建设思路\r\n \r\n简介：企业日志中心建设是一个整体和复杂的过程，本次主题向大家分享袋鼠云日志产品在迭代过程踩过的坑，并通过什么样的方案去解决这些问题，同时向大家分享我们在天弘基金、新网银行中建设企业日志中心中的几个实践案例。\r\n\r\n[attach]2530[/attach]\r\n\r\n朱延生   阿里云Docker团队专家\r\n\r\n​Kubernetes日志实践\r\n\r\n简介：从第一代PaaS平台cloudfoundry到现在的kubernetes容器编排平台，一直从事关于容器云平台研发及解决方案相关工作。容器时代越来越多的传统应用将会逐渐容器化，那么如何在应用容器化过程中方便快捷地自动发现和采集应用日志、如何与日志存储系统协同来高效存储和搜索应用日志将会是关键；本次分享主要介绍容器原生日志输出到容器日志的自动发现与采集，以及高性能容器日志采集部署架构及性能测试。\r\n\r\n[attach]2532[/attach]\r\n\r\n直播报名\r\n\r\n[attach]2533[/attach]\r\n\r\n​线下报名\r\n\r\n欢迎关注“袋鼠云技术团队”微信公众号，获取最新线下及线上活动信息。\r\n\r\n[attach]2534[/attach]\r\n\r\n\r\n[attach]2531[/attach]\r\n\r\n\r\n​","title":"【线下活动】【袋鼠云技术团队】2018-06-30-杭州-Devops运维沙龙","uid":"7597","views":"321","votes":"0"},"_type":"doc"}
{"_id":"624","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526524051","category_id":"18","comments":"0","has_attach":"0","id":"624","message":"1. 基于elk和zipkin的分布式追踪系统。\n[http://t.cn/R3CO5BM](http://t.cn/R3CO5BM) \n\n2. Elasticsearch的选举机制。\n[http://t.cn/R3COV8R](http://t.cn/R3COV8R) \n\n3. 各大厂分布式链路跟踪系统架构对比。\n[http://t.cn/R3COiRs](http://t.cn/R3COiRs) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/624\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第274期 (2018-05-17)","uid":"668","views":"334","votes":"0"},"_type":"doc"}
{"_id":"631","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526873055","category_id":"2","comments":"1","has_attach":"0","id":"631","message":"https://forum.huaweicloud.com/thread-8494-1-1.html","title":"【分享】想用ELK做日志分析的TX们可以参考啦~~~","uid":"8616","views":"807","votes":"0"},"_type":"doc"}
{"_id":"633","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526952554","category_id":"18","comments":"0","has_attach":"0","id":"633","message":"1.使用 Elasticsearch 和 Spring data 实现一个简单标签设计模式。\n[url]http://t.cn/R33Mt28[/url] \n2.Elasticsearch 查询构造器转换小工具。\n[url]http://t.cn/R33MfPM[/url] \n3.Elasticsearch DSL Python 文档，值得收藏。\n[url]http://t.cn/R8xuJC1[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/633[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第279期 (2018-05-22)","uid":"3788","views":"303","votes":"0"},"_type":"doc"}
{"_id":"5","_index":"forum-mysql","_score":1,"_source":{"addtime":"1446377875","category_id":"8","comments":"3","has_attach":"1","id":"5","message":"Elastic 社区： [url]http://elasticsearch.cn[/url] \n \n[b]社区活动：[/b]\n \nElastic 中国开发者大会：[url]http://conf.elasticsearch.cn[/url] \n线下 Meetup【旧】: [url]http://www.meetup.com/Elasticsearch-China-Users/[/url] \nMeetup 发布： [url]https://meetup.elasticsearch.cn[/url] \n社区电台：[url]https://radio.elasticsearch.cn[/url] \nIT 大咖说社区分享视频：[url]http://www.itdks.com/member/organizer/93[/url]\nApple iTunes: https://itunes.apple.com/cn/podcast/elastic-社区电台\n喜马拉雅：[url]https://www.ximalaya.com/zhubo/111156131/[/url]\n蜻蜓 FM：[url]https://www.qingting.fm/channels/244978/[/url]\nSlack 讨论组：[url=https://join.slack.com/t/elastic-cn/shared_invite/enQtNDIzMzY5OTQ0MTY0LTc2NTU2M2E0NmRhYmVkM2YzZGNjNjI2ZTdmZmIxOWIxMjMzMDgwOWRlODg3MGE1NmFlYjBjZWI4MjVmMzk3YWI​ ]https://join.slack.com/t/elastic-cn[/url]\nTelegram 讨论组：http://t.cn/RksTb6I\n\n\n[b]Elastic 日报：[/b]\n \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n归档：https://elasticsearch.cn/explore/category-18\n\n[b]社区微信公众号[/b]\n\n[attach]387[/attach]\n\n[b]交流QQ群：[/b]\n\nElastic中文社区1 （190605846） \nElastic中文社区2（211682609） \nElastic中文社区3（258143901）\nElastic中文社区4  (456336484)\nElastic中文社区5  (223764502)\nELKstack交流1群（315428175）\n\n[b]官方资源：[/b]\n\nElastic 官方网站：[url]http://elastic.co[/url]\nElastic 用户大会： [url]http://elasticon.com[/url] \nElastic 源代码：[url]http://github.com/elastic[/url] \nElastic 案例大全： [url]https://github.com/elastic/examples/[/url] \nElastic@Speakdeck: [url]https://speakerdeck.com/elastic[/url] \nElastic@Vimeo: [url]https://vimeo.com/elasticsearch[/url] \nElastic@Youtube: [url]https://www.youtube.com/user/elasticsearch[/url]\nElastic@Facebook: [url]http://www.facebook.com/elastic.co[/url]\nElastic@Twitter: [url]https://www.twitter.com/elastic[/url]\nElastic@Linkedin: [url]https://www.linkedin.com/company/elastic-co[/url]\nElastic@Xing: [url]https://www.xing.com/companies/elastic.co[/url]\n \n\n[b]相关书籍[/b]\n\n[官方] Elasticsearch 权威指南: https://www.elastic.co/guide/cn/index.html\nELKStack中文指南:  http://elkguide.elasticsearch.cn/\nKibana 中文指南：http://chenryn.gitbooks.io/kibana-guide-cn/\nExploring elasticsearch: [url]http://exploringelasticsearch.com/[/url]\n\n[b]其他资源[/b]\n\nElasticsearch Stackshare: [url]https://stackshare.io/elasticsearch[/url] \n \n工具\nGrok Debugger（国内镜像）：[url]http://grok.elasticsearch.cn[/url] \nGrokdebug：[url]http://grokdebug.herokuapp.com[/url] \nElastic情报局：[url]https://index.elasticsearch.cn[/url]\n\n欢迎补充完善!!","title":"常用链接及资源索引","uid":"1","views":"4566","votes":"2"},"_type":"doc"}
{"_id":"8","_index":"forum-mysql","_score":1,"_source":{"addtime":"1448524347","category_id":"2","comments":"10","has_attach":"0","id":"8","message":"才开始研究ElasticSearch不到两个月时间，准备把公司现在的基于hubble.net的搜索解决方案换成基于ElasticSearch的。本来用的1.7.2版本，刚进入到测试阶段，现在2.0发布了，就尝试直接升级到2.0吧。\n \n我把在Windows平台上的ElasticSearch2.0安装，1.7.2升级的全过程的[b]步骤、经验、教训[/b]记录下来，如文档([url]http://pan.baidu.com/s/1qWOTpz2[/url])。\n操作过程和记录的内容或许有很多地方不合理不恰当，和我一样的新手可以一起交流，请大神多给予指导。","title":"ElasticSearch2.0安装 \u0026amp; 1.7.2升级-新手日志","uid":"596","views":"7042","votes":"3"},"_type":"doc"}
{"_id":"9","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449037227","category_id":"8","comments":"0","has_attach":"0","id":"9","message":"","title":"ELK ","uid":"618","views":"2544","votes":"0"},"_type":"doc"}
{"_id":"10","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449038400","category_id":"8","comments":"1","has_attach":"0","id":"10","message":"ELK系列文章推荐 [url]http://www.ttlsa.com/log-system/elk/[/url]    写的还不错。","title":"elasticsearch logstash kibana beats 资料分享","uid":"619","views":"5276","votes":"3"},"_type":"doc"}
{"_id":"12","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449288042","category_id":"14","comments":"0","has_attach":"0","id":"12","message":"Elasticsearch 中有些高级特性，可能不太常用，但是在恰当场景下，又非常有效果。今天，我们来说说 nested object。\n\n我们都知道，Elasticsearch 宣传中是 schemaless 的。但实际使用中，并不是完全的随意。比如过多的 kv 切割，会导致 mapping 大小暴涨，对集群稳定性是个不小的挑战。\n\n以 urlparams 为例，下面这段 urlparams 直接通过 logstash-filter-kv 切割得到的结果，需要在 mapping 中占用 4 个字段的定义。[code]\u0026quot;urlparams\u0026quot; : {\n    \u0026quot;uid\u0026quot; : \u0026quot;1234567890\u0026quot;,\n    \u0026quot;action\u0026quot; : \u0026quot;payload\u0026quot;,\n    \u0026quot;t\u0026quot; : \u0026quot;1449053032000\u0026quot;,\n    \u0026quot;pageid\u0026quot; : \u0026quot;v6\u0026quot;\n}[/code]如果哪个开发一时想不开(我真的碰到过)，把 urlparams 写成 [i]uid=123456789\u0026amp;action=payload\u0026amp;[b]1449053032000=t[/b]\u0026amp;pageid=v6[/i]，那基本上整个 ES 集群就会被过于频繁的 mapping 更新搞挂了。\n\n这时候，我们修改一下 mapping 定义：[code]{\n  \u0026quot;accesslog\u0026quot; : {\n    \u0026quot;properties\u0026quot; : {\n      \u0026quot;urlparams\u0026quot; : {\n        \u0026quot;type\u0026quot; : \u0026quot;nested\u0026quot;,\n        \u0026quot;properties\u0026quot; : {\n            \u0026quot;key\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;, \u0026quot;doc_values\u0026quot; : true },\n            \u0026quot;value\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;, \u0026quot;doc_values\u0026quot; : true }\n        }\n      }\n    }\n  } \n}[/code]同时在 Logstash 的 filter 配置中添加一段：[code]if [urlargs] {\n    ruby {\n        init =\u0026gt; \u0026quot;@kname = ['key','value']\u0026quot;\n        code =\u0026gt; \u0026quot;event['urlparams'] = event['urlargs'].split('\u0026amp;').collect {|i| Hash[@kname.zip(i.split('='))]}\u0026quot;\n        remove_field =\u0026gt; [ \u0026quot;urlargs\u0026quot;,\u0026quot;uri\u0026quot;,\u0026quot;request\u0026quot; ]\n    }\n}[/code]生成的 JSON 数据变成这个样子：[code]\u0026quot;urlargs\u0026quot;: [\n    { \u0026quot;key\u0026quot;: \u0026quot;uid\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;1234567890\u0026quot; },\n    { \u0026quot;key\u0026quot;: \u0026quot;action\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;payload\u0026quot; },\n    { \u0026quot;key\u0026quot;: \u0026quot;1449053032000\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;t\u0026quot; },\n    { \u0026quot;key\u0026quot;: \u0026quot;pageid\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;v6\u0026quot; }\n][/code]这样，再错乱的 urlparams，也不会发生 mapping 变更，导致集群故障了！\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day2: 利用nested object缩减mapping大小","uid":"7","views":"3103","votes":"6"},"_type":"doc"}
{"_id":"21","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449681197","category_id":"14","comments":"2","has_attach":"0","id":"21","message":"ELK Stack 在入门学习过程中，必然会碰到自己修改定制索引映射(mapping)乃至模板(template)的问题。\n这时候，不少比较认真看 Logstash 文档的新用户会通过下面这段配置来制定自己的模板策略：[code]output {\n    elasticsearch {\n        host =\u0026gt; \u0026quot;127.0.0.1\u0026quot;\n        manage_template =\u0026gt; true\n        template =\u0026gt; \u0026quot;/path/to/mytemplate\u0026quot;\n        template_name =\u0026gt; \u0026quot;myname\u0026quot;\n    }\n}[/code]\n然而随后就发现，自己辛辛苦苦修改出来的模板，通过 curl -XGET 'http://127.0.0.1:9200/_template/myname' 看也确实上传成功了，但实际新数据索引创建出来，就是没生效！\n\n这个原因是：Logstash 默认会上传一个名叫 logstash 的模板到 ES 里。如果你在使用上面这个配置之前，曾经运行过 Logstash（一般来说都会），那么 ES 里就已经存在这么一个模板了。你可以curl -XGET 'http://127.0.0.1:9200/_template/logstash' 验证。\n\n这个时候，ES 里就变成有两个模板，logstash 和 myname，都匹配 logstash-* 索引名，要求设置一定的映射规则了。\n\nES 会按照一定的规则来尝试自动 merge 多个都匹配上了的模板规则，最终运用到索引上:https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html#multiple-templates\n\n其中要点就是：template 是可以设置 order 参数的！而不写这个参数，默认的 order 值就是 0。order 值越大，在 merge 规则的时候优先级越高。\n\n所以，解决这个问题的办法很简单：在你自定义的 template 里，加一行，变成这样：\n[code]{\n    \u0026quot;template\u0026quot; : \u0026quot;logstash-*\u0026quot;,\n    \u0026quot;order\u0026quot; : 1,\n    \u0026quot;settings\u0026quot; : { ... },\n    \u0026quot;mappings\u0026quot; : { ... }\n}[/code]当然，其实如果只从 Logstash 配置角度出发，其实更简单的办法是：直接修改原来默认的 logstash 模板，然后模板名称也不要改，就好了：\n[code]output {\n    elasticsearch {\n        host =\u0026gt; \u0026quot;127.0.0.1\u0026quot;\n        manage_template =\u0026gt; true\n        template_overwrite =\u0026gt; true\n    }\n}[/code]想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day9: Elasticsearch template的order","uid":"7","views":"5461","votes":"3"},"_type":"doc"}
{"_id":"30","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450529592","category_id":"14","comments":"0","has_attach":"0","id":"30","message":"代@childe 发文。\n\n除了应用在日志系统外, 越来越多的业务数据也接入ES, 利用它天生强大的搜索性能和分布式可扩展, 可以为业务的精确快速灵活的搜索提供极大便利, 我觉得这是未来一个很好的方向.\n但是, 对它ES各种各样的搜索方式, 你了解了吗?\n我们来看几个”奇怪”的搜索.\n## 奇怪的打分\n### 奇怪的打分1\n我们有个数据结构是\n[code]{\n “first_name”:”string”,\n “last_name”:”string”\n}\n[/code]\n插入了几条数据, 有诸葛亮 诸葛明 诸葛暗 诸葛黑, 还有个人名字很奇怪, 叫司马诸葛.\n然后我们要搜索诸葛瑾, 虽然索引里面没有一个人叫这个名字, 但搜索出来诸葛亮也不错, 他们名字这么像, 说不定是亲兄弟, 可以顺藤摸瓜, 找到我们需要的信息呢.\n[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;multi_match\u0026quot;: {\n            \u0026quot;query\u0026quot;:       \u0026quot;诸葛瑜\u0026quot;,\n            \u0026quot;type\u0026quot;:        \u0026quot;most_fields\u0026quot;,\n            \u0026quot;fields\u0026quot;:      [ “*_name” ]\n        }\n    }\n}\n[/code]\n但实际上呢, 司马诸葛这个人居然稳居搜索榜首位, 他是搞竞价排名了吧? 你知道其中的打分原理吗?\n### 奇怪的打分2\n我们有两条数据:[code]PUT /my_index/my_type/1\n{\n    \u0026quot;title\u0026quot;: \u0026quot;Quick brown rabbits\u0026quot;,\n    \u0026quot;body\u0026quot;:  \u0026quot;Brown rabbits are commonly seen.\u0026quot;\n}\nPUT /my_index/my_type/2\n{\n    \u0026quot;title\u0026quot;: \u0026quot;Keeping pets healthy\u0026quot;,\n    \u0026quot;body\u0026quot;:  \u0026quot;My quick brown fox eats rabbits on a regular basis.\u0026quot;\n}\n[/code]要搜索[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;bool\u0026quot;: {\n            \u0026quot;should\u0026quot;: [\n                { \u0026quot;match\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;Brown fox\u0026quot; }},\n                { \u0026quot;match\u0026quot;: { \u0026quot;body\u0026quot;:  \u0026quot;Brown fox\u0026quot; }}\n            ]\n        }\n    }\n}\n[/code]第二条文档里面明确含有”brown fox”这个词组, 但是它的搜索得分比较低, 你知道为啥吗?\n## and用在哪[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;multi_match\u0026quot;: {\n            \u0026quot;query\u0026quot;:       \u0026quot;peter smith\u0026quot;,\n            \u0026quot;type\u0026quot;:        \u0026quot;most_fields\u0026quot;,\n            \u0026quot;operator\u0026quot;:    \u0026quot;and\u0026quot;,\n            \u0026quot;fields\u0026quot;:      [ \u0026quot;first_name\u0026quot;, \u0026quot;last_name\u0026quot; ]\n        }\n    }\n}\n[/code]你知道这个and代表什么吗?\n是说\nA: 姓和名里面都要含有\u0026quot;peter smith”,\n还是说\nB: 姓或者名里面要包含peter以及smith ?\n还有, 怎么才能获得另外一个效果呢?\n# 列表中的元素\n我们有一条数据如下(按汉语分词)[code]{\n “时代”:”三国”,\n “姓名”: [“大司马”，“诸葛亮”]\n}\n[/code]我以词组的方式搜索:[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;match_phrase\u0026quot;: {\n            \u0026quot;姓名\u0026quot;: \u0026quot;司马诸葛\u0026quot;\n        }\n    }\n}\n[/code]能搜索到吗?\n上面这些其实都是[elasticsearch Definitive Guide](https://www.elastic.co/guide)里面的几个小例子, 欢迎大家继续去那里寻找答案和其他各种小技巧.\n ","title":"Day17: \u0026quot;奇怪\u0026quot;的搜索","uid":"7","views":"2622","votes":"0"},"_type":"doc"}
{"_id":"32","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450781512","category_id":"14","comments":"52","has_attach":"1","id":"32","message":"【携程旅行网  吴晓刚】\n \n[b]注： 本文主要针对ES 2.x。[/b]\n\n “该给ES分配多少内存？” \n“JVM参数如何优化?“\n“为何我的Heap占用这么高？”\n“为何经常有某个field的数据量超出内存限制的异常？“\n“为何感觉上没多少数据，也会经常Out Of Memory？”\n\n以上问题，显然没有一个统一的数学公式能够给出答案。 和数据库类似，ES对于内存的消耗，和很多因素相关，诸如数据总量、mapping设置、查询方式、查询频度等等。默认的设置虽开箱即用，但不能适用每一种使用场景。作为ES的开发、运维人员，如果不了解ES对内存使用的一些基本原理，就很难针对特有的应用场景，有效的测试、规划和管理集群，从而踩到各种坑，被各种问题挫败。\n\n要理解ES如何使用内存，先要理解下面两个基本事实:\n1.  ES是JAVA应用\n2.  底层存储引擎是基于Lucene的\n\n看似很普通是吗？但其实没多少人真正理解这意味着什么。 \n\n首先，作为一个JAVA应用，就脱离不开JVM和GC。很多人上手ES的时候，对GC一点概念都没有就去网上抄各种JVM“优化”参数，却仍然被heap不够用，内存溢出这样的问题搞得焦头烂额。了解JVM GC的概念和基本工作机制是很有必要的，本文不在此做过多探讨，读者可以自行Google相关资料进行学习。如何知道ES heap是否真的有压力了？ 推荐阅读这篇博客：[url=https://www.elastic.co/blog/found-understanding-memory-pressure-indicator ]Understanding Memory Pressure Indicator[/url]。 即使对于JVM GC机制不够熟悉，头脑里还是需要有这么一个基本概念: 应用层面生成大量长生命周期的对象，是给heap造成压力的主要原因，例如读取一大片数据在内存中进行排序，或者在heap内部建cache缓存大量数据。如果GC释放的空间有限，而应用层面持续大量申请新对象，GC频度就开始上升，同时会消耗掉很多CPU时间。严重时可能恶性循环，导致整个集群停工。因此在使用ES的过程中，要知道哪些设置和操作容易造成以上问题，有针对性的予以规避。\n\n其次，Lucene的倒排索引(Inverted Index)是先在内存里生成，然后定期以段文件(segment file)的形式刷到磁盘的。每个段实际就是一个完整的倒排索引，并且一旦写到磁盘上就不会做修改。 API层面的文档更新和删除实际上是增量写入的一种特殊文档，会保存在新的段里。不变的段文件易于被操作系统cache，热数据几乎等效于内存访问。 \n\n基于以上2个基本事实，我们不难理解，为何官方建议的heap size不要超过系统可用内存的一半。heap以外的内存并不会被浪费，操作系统会很开心的利用他们来cache被用读取过的段文件。\n\nHeap分配多少合适？遵从官方建议就没错。 不要超过系统可用内存的一半，并且不要超过32GB。JVM参数呢？对于初级用户来说，并不需要做特别调整，仍然遵从官方的建议，将xms和xmx设置成和heap一样大小，避免动态分配heap size就好了。虽然有针对性的调整JVM参数可以带来些许GC效率的提升，当有一些“坏”用例的时候，这些调整并不会有什么魔法效果帮你减轻heap压力，甚至可能让问题更糟糕。\n\n那么，ES的heap是如何被瓜分掉的? 说几个我知道的内存消耗大户并分别做解读:\n1.  segment memory\n2.  filter cache\n3.  field data cache\n4.  bulk queue\n5.  indexing buffer\n6.  state buffer\n7.  超大搜索聚合结果集的fetch\n8. 对高cardinality字段做terms aggregation\n\n\n[b]Segment Memory[/b]\nSegment不是file吗？segment memory又是什么？前面提到过，一个segment是一个完备的lucene倒排索引，而倒排索引是通过词典 (Term Dictionary)到文档列表(Postings List)的映射关系，快速做查询的。 由于词典的size会很大，全部装载到heap里不现实，因此Lucene为词典做了一层前缀索引(Term Index)，这个索引在Lucene4.0以后采用的数据结构是FST (Finite State Transducer)。 这种数据结构占用空间很小，Lucene打开索引的时候将其全量装载到内存中，加快磁盘上词典查询速度的同时减少随机磁盘访问次数。\n\n下面是词典索引和词典主存储之间的一个对应关系图:\n\n[attach]56[/attach]\n\nLucene  file的完整数据结构参见[url=https://lucene.apache.org/core/5_3_0/core/org/apache/lucene/codecs/lucene53/package-summary.html#package_description]Apache Lucene - Index File Formats[/url]\n\n说了这么多，要传达的一个意思就是，ES的data node存储数据并非只是耗费磁盘空间的，为了加速数据的访问，每个segment都有会一些索引数据驻留在heap里。因此segment越多，瓜分掉的heap也越多，并且这部分heap是无法被GC掉的！ 理解这点对于监控和管理集群容量很重要，当一个node的segment memory占用过多的时候，就需要考虑删除、归档数据，或者扩容了。\n\n怎么知道segment memory占用情况呢?  CAT API可以给出答案。\n1.  查看一个索引所有segment的memory占用情况:\n\n[attach]57[/attach]\n\n2.  查看一个node上所有segment占用的memory总和:\n\n[attach]58[/attach]\n\n\n那么有哪些途径减少data node上的segment memory占用呢？ 总结起来有三种方法:\n1.  删除不用的索引\n2.  关闭索引 （文件仍然存在于磁盘，只是释放掉内存）。需要的时候可以重新打开。\n3.  定期对不再更新的索引做optimize (ES2.0以后更改为force merge api)。这Optimze的实质是对segment file强制做合并，可以节省大量的segment memory。\n\n[b]Filter Cache (5.x里叫做Request cache)[/b]\nFilter cache是用来缓存使用过的filter的结果集的，需要注意的是这个缓存也是常驻heap，在被evict掉之前，是无法被GC的。我的经验是默认的10% heap设置工作得够好了，如果实际使用中heap没什么压力的情况下，才考虑加大这个设置。\n\n\n[b]Field Data cache[/b]\n在有大量排序、数据聚合的应用场景，可以说field data cache是性能和稳定性的杀手。 对搜索结果做排序或者聚合操作，需要将倒排索引里的数据进行解析，按列构造成docid-\u0026gt;value的形式才能够做后续快速计算。 对于数据量很大的索引，这个构造过程会非常耗费时间，因此ES 2.0以前的版本会将构造好的数据缓存起来，提升性能。但是由于heap空间有限，当遇到用户对海量数据做计算的时候，就很容易导致heap吃紧，集群频繁GC，根本无法完成计算过程。 ES2.0以后，正式默认启用Doc Values特性(1.x需要手动更改mapping开启)，将field data在indexing time构建在磁盘上，经过一系列优化，可以达到比之前采用field data cache机制更好的性能。因此需要限制对field data cache的使用，最好是完全不用，可以极大释放heap压力。 需要注意的是，很多同学已经升级到ES2.0，或者1.0里已经设置mapping启用了doc values，在kibana里仍然会遇到问题。 这里一个陷阱就在于kibana的table panel可以对所有字段排序。 设想如果有一个字段是analyzed过的，而用户去点击对应字段的排序表头是什么后果？ 一来排序的结果并不是用户想要的，排序的对象实际是词典； 二来analyzed过的字段无法利用doc values，需要装载到field data cache，数据量很大的情况下可能集群就在忙着GC或者根本出不来结果。\n\n\n[b]Bulk Queue[/b]\n一般来说，Bulk queue不会消耗很多的heap，但是见过一些用户为了提高bulk的速度，客户端设置了很大的并发量，并且将bulk Queue设置到不可思议的大，比如好几千。 Bulk Queue是做什么用的？当所有的bulk thread都在忙，无法响应新的bulk request的时候，将request在内存里排列起来，然后慢慢清掉。 这在应对短暂的请求爆发的时候有用，但是如果集群本身索引速度一直跟不上，设置的好几千的queue都满了会是什么状况呢？ 取决于一个bulk的数据量大小，乘上queue的大小，heap很有可能就不够用，内存溢出了。一般来说官方默认的thread pool设置已经能很好的工作了，建议不要随意去“调优”相关的设置，很多时候都是适得其反的效果。\n\n\n[b]Indexing Buffer[/b]\nIndexing Buffer是用来缓存新数据，当其满了或者refresh/flush interval到了，就会以segment file的形式写入到磁盘。 这个参数的默认值是10% heap size。根据经验，这个默认值也能够很好的工作，应对很大的索引吞吐量。 但有些用户认为这个buffer越大吞吐量越高，因此见过有用户将其设置为40%的。到了极端的情况，写入速度很高的时候，40%都被占用，导致OOM。\n\n\n[b]Cluster State Buffer[/b]\nES被设计成每个node都可以响应用户的api请求，因此每个node的内存里都包含有一份集群状态的拷贝。这个cluster state包含诸如集群有多少个node，多少个index，每个index的mapping是什么？有少shard，每个shard的分配情况等等 (ES有各类stats api获取这类数据)。 在一个规模很大的集群，这个状态信息可能会非常大的，耗用的内存空间就不可忽视了。并且在ES2.0之前的版本，state的更新是由master node做完以后全量散播到其他结点的。 频繁的状态更新就可以给heap带来很大的压力。 在超大规模集群的情况下，可以考虑分集群并通过tribe node连接做到对用户api的透明，这样可以保证每个集群里的state信息不会膨胀得过大。\n\n\n[b]超大搜索聚合结果集的fetch[/b]\nES是分布式搜索引擎，搜索和聚合计算除了在各个data node并行计算以外，还需要将结果返回给汇总节点进行汇总和排序后再返回。无论是搜索，还是聚合，如果返回结果的size设置过大，都会给heap造成很大的压力，特别是数据汇聚节点。超大的size多数情况下都是用户用例不对，比如本来是想计算cardinality，却用了terms aggregation + size:0这样的方式; 对大结果集做深度分页；一次性拉取全量数据等等。\n \n[b]对高cardinality字段做terms aggregation[/b]\n所谓高cardinality，就是该字段的唯一值比较多。 比如client ip，可能存在上千万甚至上亿的不同值。 对这种类型的字段做terms aggregation时，需要在内存里生成海量的分桶，内存需求会非常高。如果内部再嵌套有其他聚合，情况会更糟糕。  在做日志聚合分析时，一个典型的可以引起性能问题的场景，就是对带有参数的url字段做terms aggregation。 对于访问量大的网站，带有参数的url字段cardinality可能会到数亿，做一次terms aggregation内存开销巨大，然而对带有参数的url字段做聚合通常没有什么意义。 对于这类问题，可以额外索引一个url_stem字段，这个字段索引剥离掉参数部分的url。可以极大降低内存消耗，提高聚合速度。\n\n\n[b]小结：[/b]\n[list=1]\n[*]倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。[/*]\n[*]各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小，并且要应该根据最坏的情况来看heap是否够用，也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？避免采用clear cache等“自欺欺人”的方式来释放内存。[/*]\n[*]避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan \u0026amp; scroll api来实现。[/*]\n[*]cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。[/*]\n[*]想知道heap够不够，必须结合实际应用场景，并对集群的heap使用情况做持续的监控。[/*]\n[*]根据监控数据理解内存需求，合理配置各类circuit breaker，将内存溢出风险降低到最低。[/*]\n[/list]\n","title":"Day19 ES内存那点事","uid":"81","views":"27914","votes":"52"},"_type":"doc"}
{"_id":"33","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450884412","category_id":"14","comments":"0","has_attach":"0","id":"33","message":"事情是这样滴,  我们在很多linux机器上部署了logstash采集日志, topic_id用的是 test-%{type}, 但非常不幸的是,  有些机器的某些日志, 没有带上type字段. \n \n因为在topic名字里面不能含有%字符, 所以kafka server的日志里面大量报错. Logstash每发一次数据, kafka就会生成下面一大段错误\n [code][2015-12-23 23:20:47,749] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 48; ClientId: ; Topics: test-%{type} (kafka.server.KafkaApis)\nkafka.common.InvalidTopicException: topic name test-%{type} is illegal, contains a character other than ASCII alphanumerics, '.', '_' and '-'\n        at kafka.common.Topic$.validate(Topic.scala:42)\n        at kafka.admin.AdminUtils$.createOrUpdateTopicPartitionAssignmentPathInZK(AdminUtils.scala:181)\n        at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:172)\n        at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:520)\n        at kafka.server.KafkaApis$$anonfun$19.apply(KafkaApis.scala:503)\n        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n        at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)\n        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n        at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)\n        at scala.collection.SetLike$class.map(SetLike.scala:93)\n        at scala.collection.AbstractSet.map(Set.scala:47)\n        at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:503)\n        at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:542)\n        at kafka.server.KafkaApis.handle(KafkaApis.scala:62)\n        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)\n        at java.lang.Thread.run(Thread.java:744)[/code]\n把可用的信息瞬间淹没.  \n \n更不幸的是, 错误日志里面并没有客户来源的信息, 根本不知道是哪些机器还有问题.\n \n我想做的, 就是把有问题的logstash机器找出来.\n \n我就先事后诸葛亮一把, 用下面这个命令就可以把配置错误的机器找出来(也可以没有任何结果, 原因后面说)[code]tcpdump -nn 'dst port 9092 and tcp[37]==3 and tcp[57]==37'[/code]\ndst port 9092就不说了, 这是kafka的默认端口, 后面的tcp[37]==3 and tcp[57]==37是啥意思呢, 我们慢慢说.\n \n先要说一下: client要生产数据到kafka, 在发送消息之前, 首先得向kafka\u0026quot;询问\u0026quot;这个topic的metadata信息, 包括有几个partiton, 每个parttion在哪个服务器上面等信息, 拿到这些信息之后, 才能把消息发到正确的kafka服务器上.\n \n重点来了!  向kafka\u0026quot;询问\u0026quot;topic的metadata, 其实就是发送一个tcp包过去, 我们需要知道的是这个tcp包的格式. 我已经帮你找到了, 就在这里 [url]https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-TopicMetadataRequest[/url]\n \n看完文档之后(半小时或者更长时间过去了), 你就会知道, tcp body(除去tcp head)里面的第6个字节是03, 代表这是一个TopicMetadataRequest请求.  topicname里面的%字符出现在tcp body的第26个字节, %的ascii码是37\n \ntcp头一般是20个字符, 所以加上这20个字节, 然后下标从0算起, 就是tcp[20+5]==3 and tcp[20+25]==37, 也就是tcp[25]==3 and tcp[45]==37.\n \n咦, 为啥和开始写的那个过滤条件不一样呢, 因为tcp头\u0026quot;一般\u0026quot;是20字节, 但是如果其中还包含了tcp选项的话, 就可能比20多了. 反正我这里看到的的tcp头都是32个字节, 所以不能加20, 要加32, 也就是最开始写的 tcp[37]==3 and tcp[57]==37 \n最后呢, 再提2点结束.\n \n1. 终极大杀器, 不过tcp头的长度是多少, 20也好, 32也好, 或者其他也好, 下面这样都能搞定[code]tcpdump -nn 'dst port 9092 and tcp[(tcp[12]\u0026gt;\u0026gt;2)+5]==3 and tcp[(tcp[12]\u0026gt;\u0026gt;2)+25]==37'[/code]\n2.  不要一上来就这么高端, 其实我最开始是这样先确定问题的[code]tcpdump -vv -nn -X -s 0 dst port 9092 | grep -C 5 \u0026quot;test-\u0026quot;[/code]你问我为啥不把test-t{type}写完整? 不是为了省事, 其实是因为很不幸, test-%{t 到这里的时候, 正好换行了.","title":"Day20 利用tcpdump和kafka协议定位不合法topic的来源","uid":"666","views":"3836","votes":"4"},"_type":"doc"}
{"_id":"34","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450928752","category_id":"5","comments":"4","has_attach":"0","id":"34","message":"版本1.5.0 支持es2.0.0\n \n项目地址：[url]https://github.com/medcl/elasticsearch-analysis-stconvert[/url] \n \nmvn 编译打包，拷贝release下面的zip并解压到你的es plugins目录即可，需要重启es\n\n这个插件帮你处理简繁体，简繁体全部统一成简体或繁体，不管输入的简体还是繁体，都能得到搜索结果\n \n比如：\n不管输入的是『北京国际电视台』的还是『北京國際電視臺』都能命中。\n \n详细配置和使用请参照上面的地址。\n ","title":"简繁体转换插件更新：elasticsearch-analysis-stconvert 升级支持2.0","uid":"1","views":"5703","votes":"0"},"_type":"doc"}
{"_id":"220","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502328457","category_id":"18","comments":"0","has_attach":"0","id":"220","message":"1.elasticsearch中的机器学习集群规模设计\nhttp://t.cn/R9QP6II\nelastic stack 5之后推出了机器学习的功能，越来越多的公司开始使用elastic的机器学习功能来进行安全分析，操作分析，那么在elastic stack中机器学习应该怎么分配资源呢？\n\n2.日志聚合和APM，不一样的事情\nhttp://t.cn/R9QzkKE\n在这篇文章中，我们将看一下日志聚合与APM，以及这两个数据累积/分析域之间的关系，以及为什么重要的是使用一整套适合的工具来解决这两个问题，而不是一个单一工具。\n\n3.用heartbeat监控服务的运行情况\nhttp://t.cn/R9QZvYJ\n如何使用elastic stack中的Heartbeat的监控服务，并结合elasticsearch，kibana一起使用。\n\n4.elastic stack 6.0 beta了，参加官方的先锋计划\nhttp://t.cn/R9QZz9J\n参与官方6.0试用，赢Elastic{ON}参会机票。\n\n编辑：金桥\n\n归档：https://elasticsearch.cn/article/220\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第12期 (2017-08-10)","uid":"668","views":"736","votes":"0"},"_type":"doc"}
{"_id":"221","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502415567","category_id":"18","comments":"0","has_attach":"0","id":"221","message":"1.有赞订单管理的三生三世与“十面埋伏”  http://t.cn/R6rEbC1\n\n\n订单系统是电商交易的核心，如何实现海量订单数据的管理呢？来看看有赞的解决方案以及 es 在其中发挥的作用吧！\n\n2.高可用日志探险——基于 Kubernetes 中的 ELK http://t.cn/R9nL7kg\n\n来看看 Parsec 工程师基于 Kubernetes 使用 ELK 的经验分享！\n\n3.Building a Better Search Experience in Kibana http://t.cn/R9RLj5f\n\n在 Kibana 6.0.0-Beta1 中新增了 Kuery 查询语言，相比之前 Lucene 的查询语言使用体验更好，快来体验下吧！\n\n4.Github UseCase http://t.cn/R9RZb04\n\n天天上 Github 的你可知道它背后大量使用了 elastic 的产品吗？来看看 Github 是如何用的吧!\n\n\n\n\n编辑：rockybean\n\n归档：https://elasticsearch.cn/article/221\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第13期 (2017-08-11)","uid":"86","views":"919","votes":"0"},"_type":"doc"}
{"_id":"223","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502589806","category_id":"18","comments":"1","has_attach":"0","id":"223","message":"1. Elastic :heart: Windows (aka Windows MSI Installer release)  http://t.cn/R9rIrc0\n\n   你知道es发布了windows MSI版本吗？\n\n2. High-quality-recommendation-systems-with-elastic \n\n   part1:http://t.cn/Rcp2m5J\n\n   part2:http://t.cn/Rcp2m5i    \n\n3. 你知道最受欢迎的数据库排行吗？ http://t.cn/R9rIVOB\n\n   周末放松一下，看一下目前排名前十的数据库吧,es也在其列哦！\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/223\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第15期 (2017-08-13)","uid":"1874","views":"647","votes":"0"},"_type":"doc"}
{"_id":"224","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502672191","category_id":"18","comments":"1","has_attach":"0","id":"224","message":"1.Kafka Elasticsearch Connect: From 9,071 to 1 Line of Code http://t.cn/R9eL0zT\n使用 一句 shell 脚本将 Kafka 的数据存入 es，你可以做到吗？\n\n2.Timelion Tutorial – From Zero to Hero http://t.cn/R9eyjfe\n如果你想学习 Kibana 中的 Timelion 功能，那么不要错过这篇文章哦！\n\n3.Elasticsearch cheetsheet http://t.cn/R9eGZFc\n送你一份 Elasticsearch 的 cheetsheet，再也不用为记不住语法发愁了！\n\n编辑：rockybean\n\n归档：https://elasticsearch.cn/article/224\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第16期 (2017-08-14)","uid":"86","views":"752","votes":"2"},"_type":"doc"}
{"_id":"226","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502765717","category_id":"12","comments":"2","has_attach":"0","id":"226","message":"工作职责：\n1、负责ElasticSearch集群的配置优化；\n2、提升系统和集群性能，优化代码和数据结构。\n\n技能及资质要求：\n1、本科及以上学历，计算机专业背景，有独立分析问题和解决问题的能力；\n2、熟练掌握ElasticSearch，熟悉其原理、常用算法和源代码；\n3、熟悉hadoop、saprk技术体系者优先\n\n有意向者，请将简历发送至：594940831@qq，或者直接加QQ联系，QQ：594940831\n ","title":"【腾讯.深圳.急聘】ES开发工程师","uid":"4279","views":"1162","votes":"3"},"_type":"doc"}
{"_id":"233","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503313817","category_id":"12","comments":"0","has_attach":"0","id":"233","message":"北京去哪儿招聘搜索开发工程师，急招岗位职责：\n1、负责搜索排序的系统设计和可发，并与业务相结合；\n2、技术和业务架构设计优化、梳理和解决系统关键问题和难题。\n职位要求：\n1、本科以上学历，1-4年经验，可接受16年毕业优秀工程师；\n2、具有良好的数据结构/算法、忘了、操作系统等计算机基础知识；\n3、精通Java，熟悉各种中间件技术，熟悉各种常见数据库，熟悉网络编程，多线程编程；\n4、熟悉kafka，elasticsearch等系统，并且基于相关集群做过开发工作；\n5、有搜索或者推荐系统相关算法经验者优先。\n工作地点：北京西小口东升科技园\n简历请投递：chuoying.huang@qunar.com","title":"【北京 去哪儿】搜索开发工程师","uid":"4520","views":"1055","votes":"0"},"_type":"doc"}
{"_id":"236","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503365069","category_id":"2","comments":"0","has_attach":"0","id":"236","message":"岗位职责：\n1. 参与/负责地图的个性化的推荐排序 \n2. 参与/负责亿级别的用户画像，位置画像及知识库建设 \n任职资格：\n1. 对数据有敏感的分析能力，能设计合理的效果评价指标，并制定相应的规划 \n2. 熟悉常见的分类，聚类，LTR，深度学习等机器学习算法，有推荐领域相关经验\n3. 熟练使用C、C++ /Python \n4. 熟悉Linux/Unix 环境开发经验，有hadoop/spark等大数据平台工作经验 \n5. 有LBS和搜索相关工作经验优先 \n6. 有用户画像，知识库建设相关工作经验者优先","title":"【北京 阿里巴巴】 推荐算法资深工程师","uid":"4535","views":"521","votes":"0"},"_type":"doc"}
{"_id":"238","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503537978","category_id":"18","comments":"6","has_attach":"0","id":"238","message":"1.即将在elasticsearch 6.0中发布索引排序使用场景及注意事项：http://t.cn/RCCPeZU\n\n2.再来一篇elasticsearch业务场景的性能调优指南：http://t.cn/RCChPYU\n\n3.Elasticsearch 5.x 源码分析 -用plugin来拦截Request、Response 的可行性调研：http://t.cn/R99MMAM\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/238\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第26期 (2017-08-24)","uid":"668","views":"770","votes":"0"},"_type":"doc"}
{"_id":"243","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503643156","category_id":"2","comments":"3","has_attach":"0","id":"243","message":"一个关于模糊查询的问题，比如我的每条日志都有几个标签：namespace , app , service ,pod等等，要在按照这几个标签查出来的日志中进行模糊匹配（即关键字搜索），该怎么写查询语句？下面这个查询语句无法达到预期，就是不能满足在规定了namespace和application之后，再进行的模糊查询，而结果能匹配我所需要的。实际情况却是，只能查出来namespace=default和app=test下面的所有日志，而不能进一步的匹配包含“goose migrate start”这句话的日志\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;bool\u0026quot;: {\n      \u0026quot;must\u0026quot;: [\n        {\n          \u0026quot;term\u0026quot;: {\n            \u0026quot;kubernetes.namespace\u0026quot;: \u0026quot;default\u0026quot;\n          }\n        },\n        {\n          \u0026quot;term\u0026quot;: {\n            \u0026quot;kubernetes.labels.application\u0026quot;: \u0026quot;test\u0026quot;\n          }\n        }\n      ],\n      \u0026quot;should\u0026quot;: [\n        {\n          \u0026quot;match_phrase\u0026quot;: {\n            \u0026quot;log\u0026quot;: {\n              \u0026quot;query\u0026quot;: \u0026quot;goose migrate start\u0026quot;,\n              \u0026quot;slop\u0026quot;:  50\n            }\n          }\n        }\n      ]\n    }\n  }","title":"一个关于模糊查询的问题","uid":"4120","views":"733","votes":"0"},"_type":"doc"}
{"_id":"244","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503722937","category_id":"18","comments":"0","has_attach":"0","id":"244","message":"1. 几种验证es与源数据是否同步的简单方法\n\nhttp://t.cn/RCTARnH\n\n2. 对于英语除了设置Standard分析器,你还可以利用官方提供的tokenizer和filter选项构建更适合自己的分析器\n\nhttp://t.cn/RCTbs2d\n\n3. 有关es数据的备份和恢复，留着以备不时之需。\n\nhttp://t.cn/RCQaeOJ\n\n编辑：bsll\n\n\n\n\n归档：https://www.elasticsearch.cn/article/244\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第28期 (2017-08-26)","uid":"1874","views":"647","votes":"0"},"_type":"doc"}
{"_id":"248","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504054290","category_id":"18","comments":"0","has_attach":"0","id":"248","message":"1.改造 Filebeat，让你的 Filebeat 支持更多功能并且性能至少提升三倍\n[url]http://t.cn/RNZUcJq[/url] \n\n2.基于 ELKB 架构的欢乐逛大数据平台\n[url]http://t.cn/RCj62cL[/url] \n\n3. Streaming SQL on Kafka\n[url]http://t.cn/RNhatJX[/url] \n \n4. 腾讯招聘ES研发工程师\n[url]https://elasticsearch.cn/article/239[/url]\n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/248[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第32期 (2017-08-30)","uid":"3828","views":"642","votes":"1"},"_type":"doc"}
{"_id":"262","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504851757","category_id":"13","comments":"3","has_attach":"0","id":"262","message":"各位朋友大家好:\n \n進行配置「Filebeat」證書加密 出現錯誤如下，有哪位朋友遇過此問題可以幫幫忙!\n \nERR Failed to publish events caused by: read tcp 192.168.1.57:56182-\u0026gt;192.168.1.249:5043: wsarecv: An existing connection was forcibly closed by the remote host.\n \n使用過「telnet IP Port」測試「ELK」服務器，確認通訊協議 OK !\n \nFilebeat 配置如檔如下:  (Windows 環境)[code]filebeat.prospectors:\n- input_type: log                      #輸入 type「log」\n  paths:\n    - D:\\Wireshark_Log\\*               #指定推送日誌「Log」文件\n    \noutput.logstash:\n  hosts: [\u0026quot;192.168.1.249:5043\u0026quot;]         #指定接收Logstash\n  tls:\n      certificate_authorities:\n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\logstash\\192.168.1.249.crt\n      ssl.certificate:\n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\filebeat\\192.168.1.57.crt\n      ssl.certificate:\n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\filebeat\\192.168.1.57.key[/code]\n以下是「FileBeat」錯誤 日誌[code]2017-09-08T14:14:57+08:00 ERR Failed to publish events caused by: read tcp 192.168.1.57:56202-\u0026gt;192.168.1.249:5043: wsarecv: An existing connection was forcibly closed by the remote host.\n2017-09-08T14:14:57+08:00 INFO Error publishing events (retrying): read tcp 192.168.1.57:56202-\u0026gt;192.168.1.249:5043: wsarecv: An existing connection was forcibly closed by the remote host.\n2017-09-08T14:15:19+08:00 INFO Non-zero metrics in the last 30s: filebeat.harvester.closed=1 filebeat.harvester.open_files=-1 filebeat.harvester.running=-1 libbeat.logstash.call_count.PublishEvents=1 libbeat.logstash.publish.read_errors=1 libbeat.logstash.publish.write_bytes=323 libbeat.logstash.published_but_not_acked_events=5\n2017-09-08T14:15:49+08:00 INFO No non-zero metrics in the last 30s[/code]\n 2017.09.08 感謝 medcl 兄弟幫忙，再次修改如下:[code]filebeat.prospectors:\n- input_type: log                      #輸入 type「log」\n  paths:\n    - D:\\Wireshark_Log\\*               #指定推送日誌「Log」文件\n    \noutput.logstash:\n  hosts: [\u0026quot;192.168.1.249:5043\u0026quot;]         #指定接收Logstash\n  ssl:     # \u0026lt;=== 新版本貌似要改成「SSL」\n      certificate_authorities:\n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\logstash\\192.168.1.249.crt\n      ssl.certificate:\n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\filebeat\\192.168.1.57.crt\n      ssl.key: # \u0026lt;===  修正為「ssl.key」      \n      - C:\\filebeat-5.5.0-windows-x86_64\\ssl\\filebeat\\192.168.1.57.key[/code]\n以下是「FileBeat」錯誤 日誌[code]2017-09-08T15:40:23+08:00 INFO Non-zero metrics in the last 30s: filebeat.harvester.open_files=1 filebeat.harvester.running=1 filebeat.harvester.started=1 libbeat.logstash.publish.read_bytes=5120 libbeat.logstash.publish.write_bytes=660 libbeat.publisher.published_events=20\n2017-09-08T15:40:29+08:00 ERR Connecting error publishing events (retrying): x509: certificate is valid for 192.168.1.57, not 192.168.1.249\n2017-09-08T15:40:53+08:00 INFO Non-zero metrics in the last 30s: libbeat.logstash.publish.read_bytes=1024 libbeat.logstash.publish.write_bytes=132\n2017-09-08T15:41:01+08:00 ERR Connecting error publishing events (retrying): x509: certificate is valid for 192.168.1.57, not 192.168.1.249\n2017-09-08T15:41:23+08:00 INFO Non-zero metrics in the last 30s: libbeat.logstash.publish.read_bytes=1024 libbeat.logstash.publish.write_bytes=132\n2017-09-08T15:41:53+08:00 INFO No non-zero metrics in the last 30s[/code]意思是說 \n证书对 192.168.1.57 有效，而不是192.168.1.249 。 這裡有些不明白...","title":"Filebeat 配置「SSL」證書加密 出現錯誤 ... ERR Failed to publish events","uid":"3022","views":"5332","votes":"0"},"_type":"doc"}
{"_id":"273","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505293815","category_id":"2","comments":"15","has_attach":"0","id":"273","message":"【携程旅行网  吴晓刚】\n\n\n\u0026gt;  更新 @2018/07/20:  ES 6.3解决了这个问题，对应的pull request: [#29264](https://github.com/elastic/elasticsearch/pull/29264)\n\n\u0026gt;本文是针对社区问题[question#2352](https://elasticsearch.cn/question/2352)的分析和总结\n\n现在很多公司（包括我们自己）将ES用作数据库数据的索引，将多个数据库的数据同步到ES是非常常见的应用场景。所以感觉这个问题可能会困扰不止一个用户，而官方的文档也没有对update的底层机制及局限做特别说明，特将该问题的讨论和结论整理成文，供社区用户参考。\n\n---\n#问题描述\n\n在ES5.x里通过bulk update将数据从数据库同步到ES，如果短时间更新的一批数据里存在相同的文档ID，例如一个bulk update里大量写入下面类型的数据:\n```\n {id:1,name:aaa} \n {id:1,name:bbb}\n {id:1,name:ccc}\n {id:2,name:aaa}\n {id:2,name:bbb}\n {id:2,name:ccc}\n .......\n```\n则更新的速度非常慢。  而在ES 1.x和2.x里同样的操作快得多\n\n---\n#根源追溯\n\nupdate操作是分为两个步骤进行，即先根据文档ID做一次GET，得到最新版本的文档，然后在内存里做好更新后，再写回去。问题就出在这个GET操作上面。\n\n在`core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java` 这个类里面，get函数会根据一个`realtime`参数（默认是`true`)，决定如何获取原始文档。 \n```\npublic GetResult get(Get get, Function\u0026lt;String, Searcher\u0026gt; searcherFactory, LongConsumer onRefresh) throws EngineException {\n        assert Objects.equals(get.uid().field(), uidField) : get.uid().field();\n        try (ReleasableLock lock = readLock.acquire()) {\n            ensureOpen();\n            if (get.realtime()) {\n                VersionValue versionValue = versionMap.getUnderLock(get.uid());\n                if (versionValue != null) {\n                    if (versionValue.isDelete()) {\n                        return GetResult.NOT_EXISTS;\n                    }\n                    if (get.versionType().isVersionConflictForReads(versionValue.getVersion(), get.version())) {\n                        throw new VersionConflictEngineException(shardId, get.type(), get.id(),\n                            get.versionType().explainConflictForReads(versionValue.getVersion(), get.version()));\n                    }\n                    long time = System.nanoTime();\n                    refresh(\u0026quot;realtime_get\u0026quot;);\n                    onRefresh.accept(System.nanoTime() - time);\n                }\n            }\n\n            // no version, get the version from the index, we know that we refresh on flush\n            return getFromSearcher(get, searcherFactory);\n        }\n```\n\n可以看到`realtime`参数决定了是否以实时的方式获取数据。 如果设置为`false`，意味着不关心实时性，此时直接从`searcher`对象里面拿数据。因为`searcher`只能访问refresh过的数据，那些刚写入到indexing writter buffer里，还未经历过refresh的数据不会被访问到，故而该读取方式是***准实时(Near Real Time)***。 而这个`realtime`参数默认设置是`true`，说明需要以实时的方式访问数据，也就是说writter buffer里未经refresh的数据也要能被检索到，如何保证这块数据也能被实时访问呢？ \n\n从代码里可以看到，其中存在一个`refresh(\u0026quot;realtime_get\u0026quot;)` 的函数调用。这个函数调用会检查，GET的doc id是否都是可以被搜索到。 如果已经写入了但无法搜索到，也就是刚刚写入到writter buffer里还未refresh这种情况，就会强制执行一次refresh操作，让数据对searcher可见，保证`getFromSearcher`调用拿的是完全实时的数据。\n\n实际上测试下来，正是这样的结果： 在关闭索引的自动刷新的情况下(设置`refresh_interval: -1`，只写入一条文档，然后对该文档ID执行一个GET操作，就会看到有一个新的segment生成。 说明GET的过程触发了refresh。\n\n查了下文档，如果仅仅是做GET API调用，这个实时性可以人为控制，只需要在url里带可选参数`realtime=[true/|false]`。 参考: [reference/5.6/docs-get.html#realtime](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-get.html#realtime)。\n\n然而，不幸的是，update API的文档和源码都没有提供一个**禁用**实时性的参数。 update对GET的调用，传入的realtime参数是在代码里写死为true的，意味着update的时候，必须强制执行一次realtime GET.\n\n为什么是这样的代码逻辑，仔细想一下就也就了然了。因为update允许对文档做部分字段更新，如果有2个请求分别更新了同一个文档的不同字段， 可能先更新的数据还在writter buffer里，没来得及refresh，因而对searcher不可见。如果后续更新不做一次refresh，前面的更新可能就丢失了。 \n\n另外一个问题，为啥5.x之前的版本没有这个性能问题？  看了下2.4的GET方法源码，其的确没有采用refresh的方式来保障数据的实时性，而是通过访问translog来达到同样的目的。官方在这个变更里[pull#20102](https://github.com/elastic/elasticsearch/pull/20102)将机制从访问translog改为了refresh。理由是之前ES里有很多地方利用translog来维护数据的位置，使得很多操作变得很慢，去掉对translog的依赖可以全面提高性能。\n\n很遗憾，这个更改对于短时间反复大量更新相同doc id的操作，会因为过于频繁的强制refresh，短时间生成很多小segment，继而不断触发segment合并，产生显著的性能损耗。 从上面链接里的讨论看，官方认为，在提升大多数应用场景性能的前提下，对于这种较少见的场景下的性能损失是值得付出的。所以，建议从应用层面去解决。\n\n因此，如果实际应用场景里遇到类似的数据更新问题， 只能是优化应用数据架构，在应用层面合并相同doc id的数据更新后再写入ES，或者只能使用ES 2.x这样的老版本了。","title":"ES 5.x Bulk update重复的文档id性能低下","uid":"81","views":"3523","votes":"12"},"_type":"doc"}
{"_id":"274","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505354061","category_id":"18","comments":"0","has_attach":"0","id":"274","message":"1.喜大普奔，elasticsearch的java高层级rest client发布了！\nhttp://t.cn/RpWnkWI\n2.干货：携程wood叔告诉你，ES 5.x Bulk update重复的文档id为什么性能低下。\nhttps://elasticsearch.cn/article/273\n3.详解elasticsearch中的乐观并发控制。\nhttp://t.cn/RpWnrDX\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/274\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第47期 (2017-09-14)","uid":"668","views":"565","votes":"0"},"_type":"doc"}
{"_id":"276","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505428676","category_id":"18","comments":"0","has_attach":"0","id":"276","message":"1.基于时间轴的可视化方案选型：kibana or grafana?\n[url]http://t.cn/RpOCVsz[/url] \n2.twitter数据导入Elasticsearch的三种方式。\n[url]http://t.cn/RpOC6An[/url] \n3.CSV数据导入Elasticsearch及可视化方案。\n[url]http://t.cn/RCGeeJK[/url] \n\n编辑：laoyang360\n归档：[url]https://www.elasticsearch.cn/article/276[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第48期 (2017-09-15)","uid":"1341","views":"658","votes":"0"},"_type":"doc"}
{"_id":"278","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505447782","category_id":"2","comments":"3","has_attach":"0","id":"278","message":"\n举例：content字段是一篇正文，很长。我这边只需要前300个字节。\n我可以通过_source控制输出content，\n有没有办法控制content，只返回前300个字节的内容。\n\n返回完再裁剪，我知道通过程序处理。\n想知道有没有参数控制，直接返回给定长度的串内容？","title":"ES中可否控制字段输出的长度，只返回前300个字节的内容？","uid":"1341","views":"1155","votes":"0"},"_type":"doc"}
{"_id":"281","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505697246","category_id":"18","comments":"0","has_attach":"0","id":"281","message":"1.针对不同大小数据的index优化设置 index 分区（需梯子）。\n\nhttp://t.cn/RpBZ8d7\n\n2. 来看看国外最流行的协作工具slack是如何运用elk来做安全分析的。\n\nhttp://t.cn/RpB26BH\n\n3. 在 Kibana 中使用脚本字段（需梯子）。\n\n[url]http://t.cn/RpBLhDb[/url] \n\n编辑：cyberdak\n归档：https://www.elasticsearch.cn/article/281\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第51期 (2017-09-18)","uid":"4063","views":"523","votes":"0"},"_type":"doc"}
{"_id":"282","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505779578","category_id":"2","comments":"0","has_attach":"0","id":"282","message":"http://mp.weixin.qq.com/s/qOYg4wOK-ShIPYEHXcQK0Q\nElasticsearch大文件检索性能提升20倍实践（干货）\n\n感谢群内各位大神的帮助！现将遇到问题、问题排查、问题定位、优化处理分享给大家。\n欢迎拍砖！","title":"Elasticsearch大文件检索性能提升20倍实践（干货）","uid":"1341","views":"1042","votes":"5"},"_type":"doc"}
{"_id":"283","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505783941","category_id":"18","comments":"0","has_attach":"0","id":"283","message":"1.ES中关于并发问题的解决方法。[url]http://t.cn/RprZpbi[/url] \n2.看Logz如何构建一个完美的Kibana可视化系统。[url]http://t.cn/Rpr21iH[/url] \n3.易宝支付日志中心平台从0到1的搭建，值得借鉴。[url]http://t.cn/Rpgse8D[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/283[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n \n\n ","title":"Elastic日报 第52期 (2017-09-19)","uid":"3788","views":"513","votes":"0"},"_type":"doc"}
{"_id":"378","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510715637","category_id":"12","comments":"0","has_attach":"1","id":"378","message":"[attach]1276[/attach]\n \n 招聘职位：Elastic技术支持工程师\n\n[b]工作地点[/b]：上海\n\n[b]薪资待遇[/b]：18k ~ 25k\n\n[b]公司介绍[/b]：上海普翔是 elastic 目前在中国的合作伙伴，负责 X-Pack、ECE 产品销售以及技术咨询等 elastic相关的业务，详情可以查看 http://elastictech.cn 。\n\n[b]工作内容：[/b]\n\n1、与 Elastic 公司一起挖掘国内的付费用户，拜访客户并介绍 X-Pack 、ECE 等产品。\n\n2、参与国内付费用户的 elastic 产品实践，帮助他们解决实际中遇到的问题。\n\n3、参与国内 elastic 产品的推广工作，比如录制教学视频、直播等。\n\n[b]职位要求：[/b]\n\n1、本科以上学历，3年以上工作经验。\n\n2、熟悉 Elastic 产品（如 Elasticsearch、Kibana、Logstash、Beats ）的使用方法，了解常见优化方案，可以解决社区和客户中用户遇到的问题。\n\n3、需要极强的学习和研究能力，面对一个新产品或者特性时，可以在极短的时间内掌握并通过自己的语言给客户讲解和演示。\n\n4、有良好的沟通和表达能力，擅长倾听客户的问题并快速定位解决问题的关键点。\n\n我们是 elastic 的官方合作伙伴，所以会有很多最新的信息与资料，对 elastic 在中国的发展有信心的同学不要错过机会哦！\n\n欢迎投递简历至：[b]weibinway@elastictech.cn[/b]\n\n\n \n ","title":"上海普翔招聘 Elastic技术支持工程师","uid":"86","views":"1096","votes":"1"},"_type":"doc"}
{"_id":"396","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511696696","category_id":"2","comments":"0","has_attach":"1","id":"396","message":"bboss elasticsearch是一套基于query dsl语法操作和访问分布式搜索引擎elasticsearch的o/r mapping高性能开发库，底层基于es restful api。基于bboss elasticsearch，可以快速编写出访问和操作elasticsearch的程序代码，简单、高效、可靠、安全。\r\n\r\n    bboss elasticsearch以类似于mybatis的方式,使用xml文件管理elasticsearch的query dsl脚本，在query dsl脚本中可以使用变量、foreach循环、逻辑判断；配置文件支持在线修改、自动热加载，开发和调试非常方便。\r\n\r\nbboss-elastic特色：\r\n\r\n采用类似于mybatis的方式配置语法配置和管理访问es的qsl脚本，简洁而直观，支持配置文件热加载功能；提供丰富的逻辑判断语法；支持qsl脚本片段和片段引用功能\r\n\r\n提供创建和查询索引表配置模板api；提供创建和查询索引表api；提供索引文档创建、修改、删除、获取基本功能;提供索引文档批量创建、批量修改、批量删除api\r\n\r\n支持获取索引文档字段元数据\r\n\r\n提供简洁易用的全文检索api，聚合检索和统计api；支持o/mapping功能，支持检索和聚合查询结果快速转换为java对象或者java对象列表；支持分页检索功能和关键词高亮显示；支持多索引表查询；提供检索和聚合查询结果的回调处理接口，可以自定义结果封装处理逻辑。\r\n\r\n支持关键字自动联想和自动纠错的api\r\n\r\n提供客户端的es rest集群负载均衡和容灾恢复机制，高效可靠\r\n\r\n支持基于X-Pack的客户端安全认证机制\r\n\r\n除了提供高价的o/r mapping API，还提供了简单易用的原生restful api和基于tcp的Transport api，可以根据实际需要使用合适的API  \r\n\r\nClientUtil组件可以指定elasticsearch服务器，支持在指定的elasticsearch服务器集群进行操作\r\n\r\nDemo应用：[url]https://gitee.com/bboss/elasticsearchdemo[/url]\r\n\r\nbboss elasticsearch开发库使用文档：\r\n\r\n[url]https://my.oschina.net/bboss/blog/1556866[/url]\r\n\r\nbboss与es官方客户端的对比：[url]https://my.oschina.net/bboss/blog/1574927[/url]\r\n\r\nbboss elasticsearch技术交流群：166471282\r\n\r\nbboss elasticsearch微信公众号：bbossgroups\r\n\r\n[attach]1326[/attach]\r\n\r\n ","title":"搜索引擎的 ORM 库 bboss-elastic","uid":"3989","views":"583","votes":"2"},"_type":"doc"}
{"_id":"402","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512080685","category_id":"18","comments":"0","has_attach":"0","id":"402","message":"1、wood叔深入解读scroll分页\nhttps://elasticsearch.cn/m/question/2935\n2、Elasticsearch6.0的重大变化清单\nhttp://t.cn/RYSpqMZ\n3、more_like_this相似度推荐的实现原理\nhttp://t.cn/RYaRIJm\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/publish/article/402\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第117期 (2017-12-1)","uid":"1341","views":"382","votes":"0"},"_type":"doc"}
{"_id":"405","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512350549","category_id":"18","comments":"0","has_attach":"0","id":"405","message":"1.ES搜索性能优化手段。\nhttp://t.cn/RYWPkhA\n\n2.完全掌握x-pack graph插件。\nhttp://t.cn/RYW7IRa\n\n3.advent-calendar系列文章：es入门指南\n[url]http://t.cn/RYODglV[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/405\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第120期 (2017-12-04)","uid":"4063","views":"377","votes":"0"},"_type":"doc"}
{"_id":"406","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512352788","category_id":"16","comments":"13","has_attach":"1","id":"406","message":"Elastic Meetup 线下交流活动再次来到鹏城深圳，此次活动是社区在深圳的第二次线下聚会了，深圳的小伙伴们，快快报名吧！\n\n回顾去年的线下活动，可以点击这里：https://elasticsearch.cn/article/99\n \n[attach]1376[/attach]\n\n\n## 主办：\n本次活动由 `Elastic` 与 `腾讯基础架构部` 联合举办。\n \n## 媒体：\n本次活动由 `IT大咖说` 独家提供现场直播。\n \n## 时间：\n2017.12.16​  下午2:00-5:00（1点半开始签到）\n \n## 地点：\n广东省深圳市南山区高新南一道飞亚达科技大厦506多功能厅\n\n \n## 主题：\n\n1. 腾讯 - 姜国强 - 基于ES的时序数据库服务\n1. 中投证券 - 尉晋洪 - ELK在证券行业业务监控中的应用\n1. vivo 手机 - 杨振涛 - Elasticsearch在vivo互联网的最佳实践\n1. 中信银行信用卡中心 - 陈刚 - ES的容器化之路\n1. Elastic - 曾勇 - 基于爬虫和 Elasticsearch 快速构建站内搜索引擎\n1. 闪电分享（5-10分钟，可现场报名） \n\n\n## 参会报名：\nhttp://elasticsearch.mikecrm.com/O6o0yq3\n \n## 现场直播：\n\n直播连接：\n[http://itdks.com/eventlist/detail/1826](http://itdks.com/eventlist/detail/1826)\n\n\n\n## 主题介绍：\n\n### Elasticsearch在vivo互联网的最佳实践\n\n#### 内容介绍：\n\n- 主要介绍vivo的搜索需求，方案的选型，搜索团队的发展，Elasticsearch从入门到普及，以及实践中遇到的典型功能和性能问题及解决方案；\n\n- 同时会简单分享个人对数据的存储、索引、检索及可视化的想法和经验积累；\n\n- 最后介绍下与AI相关的LTR和NLP应用现状及未来方向。\n\n#### 分享嘉宾：\n[attach]1377[/attach]\n\n杨振涛，vivo互联网搜索团队负责人 。\n \n\n### 基于ES的时序数据库服务\n\n#### 内容介绍：\n \n主要介绍腾讯在时序数据库产品方面的技术实践，包含读写性能优化、高级功能特性、应用现状等方面，以及相比开源时序数据库产品的优势。\n\n#### 分享嘉宾：\n\n[attach]1401[/attach]\n\n姜国强，腾讯高级工程师，2012年毕业加入百度，从事大数据OLAP相关研发工作；目前在腾讯TEG基础架构部，负责腾讯时序数据库（CTSDB）研发相关工作。\n \n### ELK在证券行业业务监控中的应用\n\n#### 内容介绍：\n\n介绍最近一年间，使用ELK做业务监控的一些案例分享。\n\n#### 分享嘉宾：\n\n[attach]1408[/attach]\n\n尉晋洪，就职于中国中投证券信息技术部，负责券商周边系统的运维。\n \n\n### ES的容器化之路\n\n#### 内容介绍：\n\n现在应用的趋势是docker化，容器化，ES如何实现容器化，性能又如何呢。\n\n\n#### 分享嘉宾：\n\n[attach]1394[/attach]\n\n陈刚 ，男，华南师大硕士，职场新人，搜索应用开发猿。接触ES时间不久，但对其技术拥有极厚的兴趣，希望能和各位大牛交流学习如何玩转ES，不断优化查询，一切为了搜索~\n \n\n### 基于爬虫和 Elasticsearch 快速构建站内搜索引擎\n#### 内容介绍\n\n介绍如何基于开源的 Elasticsearch 和开源的爬虫 GOPA 来快速构建自己的搜索引擎。\n\n#### 分享嘉宾\n\n[attach]1410[/attach]\n\n曾勇，Elastic 技术布道师。\n\n-----\n  \n\n---\n\n## 关于 Elastic Meetup\n\nElastic Meetup 由 Elastic 中文社区定期举办的线下交流活动，主要围绕 Elastic 的开源产品（Elasticsearch、Logstash、Kibana 和 Beats）及周边技术，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。\n\n \n## 关于 Elastic\n\n[attach]1378[/attach]\n\nElastic 通过构建软件，让用户能够实时地、大规模地将数据用于搜索、日志和分析场景。Elastic 创立于 2012 年，相继开发了开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、X-Pack（商业功能）和 Elastic Cloud（托管服务）。截至目前，累计下载量超过 1.5 亿。Benchmark Capital、Index Ventures 和 NEA 为 Elastic 提供了超过 1 亿美元资金作为支持，Elastic 共有 600 多名员工，分布在 30 个国家/地区。有关更多信息，请访问 http://elastic.co/cn 。\n \n## 关于腾讯基础架构部\n\n[attach]1381[/attach]\n\n基础架构部（Cloud Foundation Department）作为腾讯TEG重要的技术支持部门，拥有业界领先的云平台技术，为数以万计的业务提供云数据库、云存储、云接入的专业服务，是腾讯公司“互联网+”战略的践行者，为公司互联网支付、金融类业务提供有力的支撑。部门拥有的产品包括CDB、CMongo、CTSDB、CRS、CMem、CBS、CNAS、TGW、CMQ、CKafka等。\n\n## 关于IT大咖说\n\n [attach]1380[/attach]\n\nIT大咖说，IT垂直领域的大咖知识分享平台，践行“开源是一种态度”，通过线上线下开放模式分享行业TOP大咖干货，技术大会在线直播点播，在线活动直播平台。http://www.itdks.com 。\n \n \n_ 再次感谢腾讯基础架构部和IT大咖说的大力支持! _\n\n\n","title":"Elastic Meetup 深圳交流会","uid":"1","views":"2997","votes":"5"},"_type":"doc"}
{"_id":"413","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512873397","category_id":"18","comments":"0","has_attach":"0","id":"413","message":"1.监控Logstash Pipelines。\nhttp://t.cn/RT7WHKH\n2.如何使用Kibana检索字段的唯一计数。\nhttp://t.cn/RT7Pi88\n3.(自备梯子)如何使用神经网络找到Wally。\nhttp://t.cn/RT7PKZI\n4.(英文)Elastic Advent Calendar, Day 9:  竞技优势\nhttp://t.cn/RT7PYJ1\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/413\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第126期 (2017-12-10)","uid":"4460","views":"374","votes":"0"},"_type":"doc"}
{"_id":"427","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513821271","category_id":"18","comments":"0","has_attach":"0","id":"427","message":"1.如何将CSV文件导入Elasticsearch并使用Hive运行SQL查询\nhttp://t.cn/RTBFA3B\n2.关于elastic stack 6，你必须知道的事情\nhttp://t.cn/RTBgYrd\n3.elasticsearch relevance scoring 检索相关性计算\nhttp://t.cn/RTr7PNT\n4.Elastic Advent Calendar Day 20, 使用Elasticsearch和Gopa快速构建属于自己的Google \nhttp://t.cn/RTmW1XF\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/427\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第137期 (2017-12-21)","uid":"668","views":"429","votes":"1"},"_type":"doc"}
{"_id":"432","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514080351","category_id":"18","comments":"0","has_attach":"0","id":"432","message":"1.宣布Kibana比赛的胜者。\nhttp://t.cn/RHhL7ss\n2.(自备梯子)用Zipkin和Kibana跟踪微服务。\nhttp://t.cn/RHPkfsi\n3.(自备梯子)Apache Kafka的区块链实验。\nhttp://t.cn/RHPsx09\n4.(英语)Elastic Advent Calendar, Day 23:  新用户的Kibana小贴士\nhttp://t.cn/RHhAlGm\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/432\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第140期 (2017-12-24)","uid":"4460","views":"419","votes":"0"},"_type":"doc"}
{"_id":"438","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514528506","category_id":"18","comments":"0","has_attach":"0","id":"438","message":"1.提高Elasticsearch性能的建议\nhttp://t.cn/RHJRhik\n2.中国民生银行大数据团队的Flume实践\nhttp://t.cn/RYOh7Lc\n3.Filebeat简单压测\nhttp://t.cn/RHJRJfQ\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/438\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第145期 (2017-12-29)","uid":"668","views":"417","votes":"0"},"_type":"doc"}
{"_id":"445","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515374062","category_id":"18","comments":"0","has_attach":"0","id":"445","message":"1、es以及lunece的2017年年终总结\nhttp://t.cn/RHeXPeb\n\n2、logstash特性更新：新的pipeline视图，更直观地监控logstash event\nhttp://t.cn/RHea79O\n\n3、社区讨论：多数据中心ELK Stack部署方案\n[url]http://t.cn/RHeaOsM[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/445\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第152期 (2018-01-08)","uid":"4063","views":"357","votes":"0"},"_type":"doc"}
{"_id":"451","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515634719","category_id":"18","comments":"0","has_attach":"0","id":"451","message":"1.小米的Elasticsearch 服务化实践\nhttp://t.cn/RQZjbhL\n2.wood出品：number?keyword?傻傻分不清楚\nhttps://elasticsearch.cn/article/446\n3.ebay的elasticsearch性能调优实践\nhttp://t.cn/RQhzDiP\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/451\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第155期 (2018-01-11)","uid":"668","views":"388","votes":"0"},"_type":"doc"}
{"_id":"453","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515805442","category_id":"18","comments":"0","has_attach":"0","id":"453","message":"1. ES6.1新特性：利用机器学习进行按需预测\n[http://t.cn/RQ4GZll](http://t.cn/RQ4GZll) \n\n2. 利用ES为推荐的产品定制评分（需翻墙）\n[http://t.cn/RQ45Wva](http://t.cn/RQ45Wva) \n\n3. 一周热点：冲顶大会等答题类游戏的辅助决策开源代码，各位道友可以试试\n[http://t.cn/RQAxiCr](http://t.cn/RQAxiCr) \n\n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/453\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第157期 (2018-01-13)","uid":"1874","views":"354","votes":"0"},"_type":"doc"}
{"_id":"463","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516496879","category_id":"18","comments":"0","has_attach":"0","id":"463","message":"1. Elasticsearch的最佳分片管理策略。\n[http://t.cn/RQp1VMF](http://t.cn/RQp1VMF) \n\n2. Elasticsearch映射：关于如何创建，编辑，删除的例子。\n[http://t.cn/RQObLTG](http://t.cn/RQObLTG) \n\n3. (自备梯子)想象一个更好的互联网环境。\n[http://t.cn/RQO589h](http://t.cn/RQO589h) \n\n\n* 编辑：至尊宝\n\n* 归档：https://elasticsearch.cn/article/463\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第165期 (2018-01-21)","uid":"4460","views":"352","votes":"0"},"_type":"doc"}
{"_id":"471","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516918543","category_id":"18","comments":"0","has_attach":"0","id":"471","message":"1、Elasticsearch性能监控指北\nhttp://t.cn/RQkbVhv\n2、ElasticSearch Aggregations 进行统计分析实战\nhttp://t.cn/RQD5n3F\n3、注意，这6种方式能搞死Elasticsearch！\nhttp://t.cn/RQxkfQH\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/471\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第170期 (2018-01-26)","uid":"1341","views":"413","votes":"0"},"_type":"doc"}
{"_id":"480","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517526220","category_id":"18","comments":"0","has_attach":"0","id":"480","message":"1、Elasticsearch打分策略详解与explain手把手计算\nhttp://t.cn/R8i2ws4\n2、Elasticsearch聚合性能优化实战\nhttp://t.cn/R8xdCra\n3、Python福音|Elasticsearch 6.1 DSL 核心知识点（可下载）\n[url]http://t.cn/R8xuJC1[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/publish/article/480\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第177期 (2018-02-02)","uid":"1341","views":"365","votes":"0"},"_type":"doc"}
{"_id":"482","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517685869","category_id":"18","comments":"1","has_attach":"0","id":"482","message":"1.kafka 基础知识梳理。\nhttp://t.cn/R8KkCkj\n2.如何记录日志：应用程序日志记录最佳实践。\nhttp://t.cn/R8aW8ug\n3.(自备梯子)使用Pandas和Seaborn了解我的浏览模式。\nhttp://t.cn/R8aO7S1\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/482\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第179期 (2018-02-04)","uid":"4460","views":"339","votes":"0"},"_type":"doc"}
{"_id":"483","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517796625","category_id":"18","comments":"0","has_attach":"0","id":"483","message":"1.Elastic Search 6.0 .NET 客户端正式发布。\nhttp://t.cn/R8OKXzT\n\n2.kibana 插件开发指南\nhttp://t.cn/R8ONWsN\n\n3.kibana 汉化项目：一秒钟让你kibana焕然一新。\n[url]http://t.cn/R8Opez4[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/483\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第180期 (2018-02-05)","uid":"4063","views":"306","votes":"0"},"_type":"doc"}
{"_id":"490","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518083696","category_id":"5","comments":"0","has_attach":"1","id":"490","message":"[attach]1767[/attach]\n\nhttps://elasticsearch.cn/slides/\n \n对不起，来晚了！\n应该是期待已久的功能！\n社区年年都有很多的精彩的分享（感谢所有参与社区分享的同学，赞），以前的资料都丢在百度网盘里面，大家还能凑合着用，谁知道前段时间，网盘居然把所有的链接都弄失效了，分享出去没多久就自动失效了。\n国外的 slides share、speakerdeck，统统不能用，哎。国内的幻灯片分享平台实在没有找到合适的。\n经常有同学私下问我要 PPT，什么时候分享啊，什么的。\n看个幻灯片，太麻烦啊。\n这次终于忍不了了。\n自己动手、丰衣足食。\n于是抽空几天为社区开发了幻灯片分享功能。\n使用 PDF.js 做前端展现，pdf 传上去就能直接查看，目前只在 chrome 和 Firefox 下测试是 OK 的，抱歉了，IE 我已放弃。\n封面使用 ImageMagick 做一个 pdf 到 png 的转换即可，上传完 PDF 同步就开始转，咱这个功能社区自己用，没什么压力。\n目前还没给所有人开放上传分享的功能（主要现在还没有做修改和删除的功能，[捂脸]）。\n \n已上传完本社区的历史分享的小 100 个 PPT，重复的分享没有传，也可能存在漏掉和遗忘的，大家可以帮忙查漏补缺。\n \n今年线下交流活动继续走起，欢迎大家踊跃报名分享，\n分享提交链接：http://elasticsearch.mikecrm.com/A6QbFvU。\n\n农历新年马上到了，祝大家新年愉快，工作顺利！\n \n \n ","title":"社区新增幻灯片分享功能","uid":"1","views":"489","votes":"3"},"_type":"doc"}
{"_id":"489","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518054340","category_id":"18","comments":"0","has_attach":"0","id":"489","message":"1. 假如我来设计scroll-Elasticsearch的遍历操作分析。\n[http://t.cn/RYGZyUD](http://t.cn/RYGZyUD) \n\n2. 剖析Lucene底层原理及基于他开发搜索引擎网站。\n[http://t.cn/R8rHNZY](http://t.cn/R8rHNZY) \n\n3. elasticsearch shard split 分析--系列文章。\n[http://t.cn/R8rHOjJ](http://t.cn/R8rHOjJ) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/489\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第183期 (2018-02-08)","uid":"668","views":"334","votes":"0"},"_type":"doc"}
{"_id":"494","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518166574","category_id":"4","comments":"7","has_attach":"1","id":"494","message":"[attach]1770[/attach]\n\n上图是我们最终的地图效果。\n## 总体步骤：\n一、使用logstash geoip插件解析IP字段；\n\n二、配置geoip.location字段为geo_point类型。\n\n三、使用kibana的Coordinate map作图。\n\n## 具体步骤：\n### 一、解析IP字段\n使用logstash的geoip插件 logstash-filter-geoip 解析IP字段，需要在logstash的配置文件中配置geoip的解析配置，配置如下：\n```\ngeoip {\n       source =\u0026gt; \u0026quot;ip\u0026quot; //需要解析的IP地址\n      }\n```\n解析出的效果如下：\n```\n\u0026quot;geoip\u0026quot;: {\n      \u0026quot;city_name\u0026quot;: \u0026quot;Wuhan\u0026quot;,\n      \u0026quot;timezone\u0026quot;: \u0026quot;Asia/Shanghai\u0026quot;,\n      \u0026quot;ip\u0026quot;: \u0026quot;117.136.52.200\u0026quot;,\n      \u0026quot;latitude\u0026quot;: 30.5801,\n      \u0026quot;country_name\u0026quot;: \u0026quot;China\u0026quot;,\n      \u0026quot;country_code2\u0026quot;: \u0026quot;CN\u0026quot;,\n      \u0026quot;continent_code\u0026quot;: \u0026quot;AS\u0026quot;,\n      \u0026quot;country_code3\u0026quot;: \u0026quot;CN\u0026quot;,\n      \u0026quot;region_name\u0026quot;: \u0026quot;Hubei\u0026quot;,\n      \u0026quot;location\u0026quot;: {\n        \u0026quot;lon\u0026quot;: 114.2734,\n        \u0026quot;lat\u0026quot;: 30.5801\n      },\n      \u0026quot;region_code\u0026quot;: \u0026quot;42\u0026quot;,\n      \u0026quot;longitude\u0026quot;: 114.2734\n    }\n\n```\n\u0026gt;**备注：**这个只是geoip的配置，解析日志的时候需要先解析出ip字段\n\n### 二、配置geoip字段类型\nIP经过logstash解析后就可以使用IP的所有解析信息了，但是如果想要在kibana中作图，就必须把geoip里面的相应信息配置成相应的字段类型，才能够被kibana识别，然后经过聚合作图。\n需要配置的字段：geoip.location\n需要配置的类型：geo_point\n在mapping中的配置为：\n```\n\u0026quot;geoip\u0026quot; : {\n          \u0026quot;properties\u0026quot; : {\n            \u0026quot;location\u0026quot; : {\n              \u0026quot;type\u0026quot; : \u0026quot;geo_point\u0026quot;,\n              \u0026quot;ignore_malformed\u0026quot;: \u0026quot;true\u0026quot;  \n            }\n          }\n        }\n```\n\u0026gt;**备注1：**\nignore_malformed 如果true，格式错误的地理位置被忽略。如果false（默认），格式错误的地理位置引发异常并拒绝整个文档。\n此字段需要配置成true，以防地理格式错误导致文档被拒绝。\n也可以在所以级别进行设置：\n\u0026quot;settings\u0026quot;: {\n  \u0026quot;index.mapping.ignore_malformed\u0026quot;: true \n  }\n\n\u0026gt;**备注2：**需要先设置mapping，再导入数据mapping才会生效，如果先导入数据，再设置mapping，则第二天八点后才会生效(北京时间)。\n\n### 三、kibana作图\n1、在kibana中打开visualize-\u0026gt;coordinate map \n\n[attach]1771[/attach]\n\n2、选择相应的索引进行画图\n\n[attach]1772[/attach]\n\n3、选择geoip.location作为聚合字段，然后设置Options，调整地图效果即可。\n\n[attach]1773[/attach]\n\n","title":"kibana使用geoip插件展示地图热力图","uid":"3221","views":"6148","votes":"2"},"_type":"doc"}
{"_id":"528","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520819023","category_id":"18","comments":"0","has_attach":"0","id":"528","message":"1. Elasticsrach-dump : 数据导入导出工具\nhttp://t.cn/8kmCqB2\n\n2. 多个ElasticSearch Cluster的一致性问题\nhttp://t.cn/RIwrbul\n\n3. searchkit:一款方便的搜索UI，帮你快速构建一套搜索系统。\n[url]http://t.cn/Rqv3jow[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/528\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第208期 (2018-03-12)","uid":"4063","views":"592","votes":"0"},"_type":"doc"}
{"_id":"507","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519520545","category_id":"18","comments":"0","has_attach":"0","id":"507","message":"1.Beats教程：入门。\nhttp://t.cn/RELwX6X\n2.使用ELK堆栈监视Lambda度量 - 第2部分。\nhttp://t.cn/RELZNSA\n3.(自备梯子)通过Spark部署Python模型（更高效）。\nhttp://t.cn/REL7or8\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/507\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第193期 (2018-02-25)","uid":"4460","views":"496","votes":"0"},"_type":"doc"}
{"_id":"508","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519609166","category_id":"18","comments":"0","has_attach":"0","id":"508","message":"1.6.0的新index api : split,更好的调整和优化索引分片。\nhttp://t.cn/REbCTvG\n\n2.使用新的vega套件来展示散点图\nhttp://t.cn/REbjv9d\n\n3.启用SAML来实现kibana以及es的认证功能\n[url]http://t.cn/REbpuYp[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/508\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第194期 (2018-02-26)","uid":"4063","views":"322","votes":"0"},"_type":"doc"}
{"_id":"514","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519871933","category_id":"18","comments":"0","has_attach":"0","id":"514","message":"1. elasticsearch 集群启动流程。\n[http://t.cn/REiU69N](http://t.cn/REiU69N) \n\n2. 23种非常有用的ElasticSearch查询例子。\n[http://t.cn/REiUajR](http://t.cn/REiUajR) \n\n3. elastalert基于比例报警。\n[http://t.cn/REiUoyy](http://t.cn/REiUoyy) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/514\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第197期 (2018-03-01)","uid":"668","views":"325","votes":"0"},"_type":"doc"}
{"_id":"209","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501748328","category_id":"12","comments":"0","has_attach":"0","id":"209","message":"岗位描述：\n1. 负责阿里云上搜索云产品的设计和研发工作，确保项目质量和进度 \n2. 能深入理解产品和业务，推动技术不断升级，解决客户和平台问题。\n岗位要求：\n1. 编程基本功扎实，熟悉常用数据结构和算法，擅长Java编程语言，熟悉JVM机制，熟悉shell、python等脚本语言； \n2. 学习能力较强，有较好的逻辑思维能力，较强的抽象、概括和总结能力，有较好的沟通交流能力，善于主动思考，对技术有强烈激情； \n3. 熟悉ElasticSearch/Lucene开源系统\n4. 熟悉分布式系统，例如hadoop、spark、flink，有云计算相关开发经验者优先 \n5. 具有敏捷开发经验者优先，具有完整产品生命周期开发者优先\n \n阿里云近期会推出ES云产品，正在组建ES专家小组，工作地点北京、杭州，薪资待遇优厚，简历请发送至ruijie.guo@alibaba-inc.com","title":"【阿里巴巴】【急聘】高级搜索研发专家","uid":"3904","views":"2089","votes":"4"},"_type":"doc"}
{"_id":"214","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501915248","category_id":"2","comments":"0","has_attach":"1","id":"214","message":"1：需要传入安装路径这个参数\n2：默认是安装5.2.2，可以在脚本中修改\n[b]注意：[/b]\n因为不能上传.sh结尾的，我把后缀名改为.doc 使用的时候再改回.sh即可\n \n有不完善的地方，还望大家指正[b](:[/b]\n [code]installDir=$1\ncurl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.2.2.tar.gz\n\nmkdir $installDir\necho \u0026quot;安装的位置$installDir\u0026quot;\ntar -xvf elasticsearch-5.2.2.tar.gz -C $installDir\n\nmv $installDir/elasticsearch-5.2.2 $installDir/elasticsearch\necho \u0026quot;添加es用户 esuser 组 esuser\u0026quot;\ngroupadd esuser\nuseradd esuser -g esuser -p esuser\n\necho \u0026quot;输入es用户密码\u0026quot;\npasswd esuser\n\ncd $installDir\nchown -R esuser:esuser $installDir/elasticsearch\n###sh +x $installDir/elasticsearch/bin/elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name\n\nfunction install_mvn(){\nwget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo\nyum -y install apache-maven\n\n}\nfunction getik(){\nver=\u0026quot;v5.2.2\u0026quot;\nyum -y install git\ngit clone https://github.com/medcl/elasticsearch-analysis-ik\ncd elasticsearch-analysis-ik\ngit checkout tags/$ver\nmvn clean\nmvn compile\nmvn package\ncd -\n\n}\ninstall_mvn\nversion=5.2.2\ngetik\nmkdir $installDir/elasticsearch/plugins/ik\nunzip elasticsearch-analysis-ik/target/releases/elasticsearch-analysis-ik-$version.zip -d $installDir/elasticsearch/plugins/ik\n\n[/code]","title":"elasticsearch 安装脚本","uid":"3600","views":"952","votes":"3"},"_type":"doc"}
{"_id":"640","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527389232","category_id":"18","comments":"0","has_attach":"0","id":"640","message":"1.ElasticSearch的地理编码对象。\nhttp://t.cn/R12Q3zm\n2.开源X / MIT许可的用于光栅和矢量地理空间数据格式的转换器库。\nhttp://t.cn/R128rZU\n3.(自备梯子)关于数据。\nhttp://t.cn/R12ETtD\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/640\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第284期 (2018-05-27)","uid":"4460","views":"332","votes":"0"},"_type":"doc"}
{"_id":"643","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527557880","category_id":"3","comments":"0","has_attach":"0","id":"643","message":"不同版本的logstash集成的插件不一样，在5.6版本就未集成logstash-filter-elasticsearch插件，所以需要自己安装。\n\n官方提供的方法因为需要联网，并且需要调整插件管理源，比较麻烦，针对logstash-filter-elasticsearch插件，使用下面这种方式安装。\n\nlogstash-filter-elasticsearch插件安装\n\n1、在git上下载logstash-filter-elasticsearch压缩包，logstash-filter-elasticsearch.zip，\n\n2、在logstash的目录下新建plugins目录，解压logstash-filter-elasticsearch.zip到此目录下。\n\n3、在logstash目录下的Gemfile中添加一行：[code]gem \u0026quot;logstash-filter-elasticsearch\u0026quot;, :path =\u0026gt; \u0026quot;./plugins/logstash-filter-elasticsearch\u0026quot;[/code]\n4、重启logstash即可。\n \n此方法适用logstash-filter-elasticsearch，但不适用全部logstash插件。","title":"logstash-filter-elasticsearch的简易安装","uid":"3221","views":"456","votes":"1"},"_type":"doc"}
{"_id":"657","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528335914","category_id":"18","comments":"0","has_attach":"0","id":"657","message":"1. Elasticsearch性能调优。\n[http://t.cn/R1dGOZB](http://t.cn/R1dGOZB) \n\n2. Kibana之Scripted Fields。\n[http://t.cn/R1dGH53](http://t.cn/R1dGH53) \n\n3. 记录一次线上迁库后对ES的数据全量同步。\n[http://t.cn/R1dGRcf](http://t.cn/R1dGRcf) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/657\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第295期 (2018-06-07)","uid":"668","views":"399","votes":"0"},"_type":"doc"}
{"_id":"659","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528410718","category_id":"18","comments":"0","has_attach":"0","id":"659","message":"1、Elasticsearch用户视角精确的QPS是什么？\nhttp://t.cn/R1eMNXe\n2、Elasticsearch5.3.0 bulk index 性能调优实践\nhttp://t.cn/Rm5uEYw\n3、Elasticsearch常用命令备忘录\n[url]http://t.cn/R1eJL2Q[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/659\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第296期 (2018-06-08)","uid":"1341","views":"304","votes":"0"},"_type":"doc"}
{"_id":"694","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530494819","category_id":"18","comments":"1","has_attach":"0","id":"694","message":"1. es merge 功能导致linux宕机原因调查\nhttp://t.cn/RrBADX9\n\n2.使用ElasticSearch搭建动态排序引擎\nhttp://t.cn/RVchTMI\n\n3.elasticsearch以及lucene本周发展进展\n[url]http://t.cn/RrB2HPd[/url] \n\n活动预告\n\n1. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：cyberdak\n归档：[url=https://elasticsearch.cn/article/{}]https://elasticsearch.cn/article/[/url]694\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第320期 (2018-07-02)","uid":"4063","views":"267","votes":"0"},"_type":"doc"}
{"_id":"697","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530683403","category_id":"18","comments":"0","has_attach":"0","id":"697","message":"1.es与solr的15个不同点； \nhttp://t.cn/RdwtPxy \n2.ES熔断器了解一下； \nhttp://t.cn/Rd7tMFJ \n3.如何取消一个ES检索； \nhttp://t.cn/Rd7cdBi \n \n活动预告 \n1. 7月21日上海meetup演讲申请中 \nhttps://elasticsearch.cn/m/article/655 \n \n编辑：wt \n归档：https://elasticsearch.cn/article/697\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第322期 (2018-07-04) ","uid":"3851","views":"264","votes":"0"},"_type":"doc"}
{"_id":"702","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530769211","category_id":"18","comments":"0","has_attach":"0","id":"702","message":"1.使用python操作ES \nhttp://t.cn/RBzKP6H \n2.使用Beats模块将日志和指标导入ES \nhttp://t.cn/RdLtJJp \n3.如何在生产环境中重启Elasticsearch集群 \nhttp://t.cn/RdL4oxk \n\n活动预告 \n1. 7月21日上海meetup演讲申请中 \nhttps://elasticsearch.cn/m/article/655 \n\n编辑：sterne vencel \n归档：https://elasticsearch.cn/article/702\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第323期 (2018-07-05)","uid":"3851","views":"263","votes":"0"},"_type":"doc"}
{"_id":"703","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530830049","category_id":"18","comments":"0","has_attach":"0","id":"703","message":"1、Kibana 里程碑插件的使用\nhttps://elasticsearch.cn/article/696\n2、Filebeat中文开发指南\nhttp://t.cn/RmQsOJx\n3、Logstash 五种替代方案\n[url]http://t.cn/RdGstKP[/url] \n\n活动预告：\n7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/703\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第324期 (2018-07-06)","uid":"1341","views":"249","votes":"0"},"_type":"doc"}
{"_id":"704","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530929456","category_id":"18","comments":"0","has_attach":"0","id":"704","message":"1. dockers添加es license教程(需翻墙)。\n[http://t.cn/RdfZFBP](http://t.cn/RdfZFBP) \n\n2. C#调用ES例子。\n[http://t.cn/RdfwISy](http://t.cn/RdfwISy) \n\n3. 一周热点：《我不是药神》观看指南。\n[http://t.cn/RdL0cdI](http://t.cn/RdL0cdI) \n\n活动预告\n1. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/704\n\n订阅：https://tinyletter.com/elastic-daily \n","title":"Elastic日报 第325期 (2018-07-07)","uid":"1874","views":"309","votes":"0"},"_type":"doc"}
{"_id":"710","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531380191","category_id":"18","comments":"0","has_attach":"0","id":"710","message":"1.携程酒店订单Elastic Search实战\nhttp://t.cn/Rdumu4V\n2.如何使用Kafka Streams构建广告消耗预测系统\nhttp://t.cn/RlDKqWa\n3.请自查！这些优秀日志实践准则，你做到了几点？\nhttp://t.cn/Rldk5Ku\n\n活动预告\n1. 7月21日上海meetup倒计时\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/710\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第330期 (2018-07-12)","uid":"668","views":"268","votes":"0"},"_type":"doc"}
{"_id":"722","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532087152","category_id":"8","comments":"2","has_attach":"0","id":"722","message":" \n去年做了3期 ElasticTalk 的直播节目，预计下周开始恢复。现在放出相关的视频内容，希望对大家有所帮助。\n \n第1期的课程内容为用 ElasticStack 快速收集分析 Nginx 日志，其中详细讲解了如何使用 filebeat 的 module 功能。\n \n \n视频地址如下：\nhttps://www.bilibili.com/video/av27123368/","title":"ElasticTalk #1 用 ElasticStack 快速收集和分析 Nginx 日志","uid":"86","views":"328","votes":"0"},"_type":"doc"}
{"_id":"729","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532313089","category_id":"18","comments":"1","has_attach":"0","id":"729","message":"1. Lucene 查询原理\nhttp://t.cn/Rg1Ihw1\n\n2. es 在磁盘故障时的故障表现以及排查方式\nhttp://t.cn/Rg1ILik\n\n3.大规模 Elasticsearch 集群性能的最佳实践\n[url]http://t.cn/RfEWPgM[/url] \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/publish/article/729\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第341期 (2018-07-23)","uid":"4063","views":"348","votes":"0"},"_type":"doc"}
{"_id":"730","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532411820","category_id":"18","comments":"0","has_attach":"0","id":"730","message":"1.Elasticsearch使用NFS进行数据备份。\nhttp://t.cn/RgDxJj3\n2.使用Elasticsearch、Kibana、Zookeeper、Kafka 和 Rsyslog 构造一个集群。\nhttp://t.cn/RgeunEb\n3.如何在Cloudways上的WordPress上配置Elasticsearch。\n[url]http://t.cn/RgeuBrh[/url] \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/730\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第342期 (2018-07-24)","uid":"3788","views":"277","votes":"0"},"_type":"doc"}
{"_id":"738","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533002701","category_id":"18","comments":"0","has_attach":"0","id":"738","message":"1.使用Curator删除Elasticsearch中的旧索引。\nhttp://t.cn/RepwwlM\n2.了解如何在Elasticsearch中执行负载测试。\nhttp://t.cn/RepZ7Aa\n3.Logstash中如何处理到ElasticSearch的数据映射。\nhttp://t.cn/RepzFAk\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/738\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第349期 (2018-07-31)","uid":"3788","views":"304","votes":"0"},"_type":"doc"}
{"_id":"735","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532744949","category_id":"18","comments":"0","has_attach":"0","id":"735","message":"1. 怎样使用es和rails构建搜索应用？\n[http://t.cn/Ref4Xp4](http://t.cn/Ref4Xp4) \n\n2.适用于ES5.0以上的mysql与es同步工具。\n[http://t.cn/RC44piW](http://t.cn/RC44piW) \n\n3. 一周热点：长春长生疫苗的流向以及各省二类疫苗采购公示数据。\n[http://t.cn/Rgdq2su](http://t.cn/Rgdq2su) \n[http://t.cn/Ref4Xpb](http://t.cn/Ref4Xpb) \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/735\n\n* 订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第346期 (2018-07-28)","uid":"1874","views":"310","votes":"0"},"_type":"doc"}
{"_id":"739","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533103186","category_id":"18","comments":"0","has_attach":"0","id":"739","message":"1. 使用ELK Stack建设SIEM\nhttp://t.cn/ReQQwtq\n2. 360数据处理平台的架构演进及优化实践\nhttp://t.cn/RdruDtn\n3. Filebeat合并多行日志示例\nhttp://t.cn/ReQ8LOG\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/739[/url] \n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第350期 (2018-08-01)","uid":"3828","views":"282","votes":"0"},"_type":"doc"}
{"_id":"751","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533969765","category_id":"18","comments":"0","has_attach":"0","id":"751","message":"1. 如何根据自己的日志记录来选择ES集群结构？\n[http://t.cn/RDpOkya](http://t.cn/RDpOkya) \n\n2. 一款计算向量相似度的插件。\n[http://t.cn/R6Nt4X3](http://t.cn/R6Nt4X3) \n\n3. 让 Kibana 支持 Nested document的插件。\n[http://t.cn/RDIeIbq](http://t.cn/RDIeIbq) \n\n活动预告\n1. 活动预告：Elastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/751\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第360期 (2018-08-11)","uid":"1874","views":"247","votes":"0"},"_type":"doc"}
{"_id":"763","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534644560","category_id":"18","comments":"0","has_attach":"0","id":"763","message":"1.如何使用Nginx作为CentOS 7上的反向代理来保护Kibana。\nhttp://t.cn/RDes1PI\n2.如何使用ELK stack管理Nginx日志。\nhttp://t.cn/RkUKe2L\n3.(自备梯子)数据科学项目最重要的部分是写博客文章。\nhttp://t.cn/RkU9jJW\n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会预热票今天发售！\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/763\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第368期 (2018-08-19)","uid":"4460","views":"262","votes":"0"},"_type":"doc"}
{"_id":"764","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534728718","category_id":"18","comments":"1","has_attach":"0","id":"764","message":"1、探索Elasitc Cloud的弹性伸缩部署架构\nhttp://t.cn/Rk2LTeO\n2、更方便的基于kibana的多数据源导入插件\nhttp://t.cn/REOhwGT\n3、马上到来的kibana 6.4 api变更\n[url]http://t.cn/RkcPT9Y[/url] \n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n\n编辑：cyberdak\n归档：\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第369期 (2018-08-20)","uid":"4063","views":"279","votes":"0"},"_type":"doc"}
{"_id":"775","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535431412","category_id":"2","comments":"1","has_attach":"0","id":"775","message":"在 Elasticsearch 中处理字符串类型的数据时，如果我们想把整个字符串作为一个完整的 term 存储，我们通常会将其类型 `type` 设定为 `keyword`。但有时这种设定又会给我们带来麻烦，比如同一个数据再写入时由于没有做好清洗，导致大小写不一致，比如 `apple`、`Apple`两个实际都是 `apple`，但当我们去搜索 `apple`时却无法返回 `Apple`的文档。要解决这个问题，就需要 `Normalizer`出场了。废话不多说，直接上手看！\n\n\n# 1. 上手\n\n我们先来重现一下开篇的问题\n\n```json\nPUT test_normalizer\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;doc\u0026quot;:{\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;type\u0026quot;:{\n          \u0026quot;type\u0026quot;:\u0026quot;keyword\u0026quot;\n        }\n      }\n    }\n  }\n}\n\nPUT test_normalizer/doc/1\n{\n  \u0026quot;type\u0026quot;:\u0026quot;apple\u0026quot;\n}\n\nPUT test_normalizer/doc/2\n{\n  \u0026quot;type\u0026quot;:\u0026quot;Apple\u0026quot;\n}\n\n\n# 查询一 \nGET test_normalizer/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;:{\n      \u0026quot;type\u0026quot;:\u0026quot;apple\u0026quot;\n    }\n  }\n}\n\n\n# 查询二\nGET test_normalizer/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;:{\n      \u0026quot;type\u0026quot;:\u0026quot;aPple\u0026quot;\n    }\n  }\n}\n```\n\n大家执行后会发现 `查询一`返回了文档1，而 `查询二`没有文档返回，原因如下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180828115330.png)\n\n\n\n1. `Docs`写入 `Elasticsearch`时由于 `type`是 `keyword`,分词结果为原始字符串\n2. 查询 Query 时分词默认是采用和字段写时相同的配置，因此这里也是 `keyword`，因此分词结果也是原始字符\n3. 两边的分词进行匹对，便得出了我们上面的结果\n\n\n\n# 2. Normalizer\n\n`normalizer`是 `keyword`的一个属性，可以对 `keyword`生成的单一 `Term`再做进一步的处理，比如 `lowercase`，即做小写变换。使用方法和自定义分词器有些类似，需要自定义，如下所示：\n\n```json\nDELETE test_normalizer\n# 自定义 normalizer\nPUT test_normalizer\n{\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;analysis\u0026quot;: {\n      \u0026quot;normalizer\u0026quot;: {\n        \u0026quot;lowercase\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\n          \u0026quot;filter\u0026quot;: [\n            \u0026quot;lowercase\u0026quot;\n          ]\n        }\n      }\n    }\n  },\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;doc\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;type\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n        },\n        \u0026quot;type_normalizer\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n          \u0026quot;normalizer\u0026quot;: \u0026quot;lowercase\u0026quot;\n        }\n      }\n    }\n  }\n}\n\n\nPUT test_normalizer/doc/1\n{\n  \u0026quot;type\u0026quot;: \u0026quot;apple\u0026quot;,\n  \u0026quot;type_normalizer\u0026quot;: \u0026quot;apple\u0026quot;\n}\n\n\nPUT test_normalizer/doc/2\n{\n  \u0026quot;type\u0026quot;: \u0026quot;Apple\u0026quot;,\n  \u0026quot;type_normalizer\u0026quot;: \u0026quot;Apple\u0026quot;\n}\n# 查询三\nGET test_normalizer/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;term\u0026quot;:{\n      \u0026quot;type\u0026quot;:\u0026quot;aPple\u0026quot;\n    }\n  }\n}\n\n# 查询四\nGET test_normalizer/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;term\u0026quot;:{\n      \u0026quot;type_normalizer\u0026quot;:\u0026quot;aPple\u0026quot;\n    }\n  }\n}\n```\n\n我们第一步是自定义了名为 `lowercase`的 normalizer，其中`filter` 类似自定义分词器中的 `filter` ，但是可用的种类很少，详情大家可以查看官方文档。然后通过 `normalizer`属性设定到字段`type_normalizer`中，然后插入相同的2条文档。执行发现，`查询三`无结果返回，`查询四`返回2条文档。\n\n问题解决了！我们来看下是如何解决的\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180828121900.png)\n\n1. 文档写入时由于加入了 `normalizer`,所有的 `term`都会被做小写处理\n2. 查询时搜索词同样采用有 `normalizer`的配置，因此处理后的 `term`也是小写的\n3. 两边分词匹对，就得到了我们上面的结果\n\n\n# 3. 总结\n\n本文通过一个实例来给大家讲解了 `Normalizer`的实际使用场景，希望对大家有所帮助！\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)\n\n\n\n\n\n\n\n\n","title":"听说你还没掌握 Normalizer 的使用方法？","uid":"86","views":"375","votes":"3"},"_type":"doc"}
{"_id":"776","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535449954","category_id":"16","comments":"0","has_attach":"1","id":"776","message":"10月5日，Elastic 正式在纽交所上市了，股票代码 ESTC，当日股票涨幅超过100%，超越14年阿里巴巴，开盘价创有史以来新高。\n\n[attach]2983[/attach]\n\nElastic这么受欢迎，说明大家手里的 Elastic 技术更值钱了，那么在国内的年度开发者交流大会更是不能错过啦，并且现在福利来了，大会门票抢购中，[https://www.bagevent.com/event/1654662?discountCode=50OFF](https://www.bagevent.com/event/1654662?discountCode=50OFF) 手快有，手慢无啊！\n\n\u0026gt;知道 ELK 么？知道 Elasticsearch 么？目前最流行的开源数据库及分析类软件，目前已新晋级到数据库兵器谱排名第七位，搜索引擎排行榜长期霸占第一位，想要了解更多他的本事，快来了解一下他的官方用户大会：Elastic 中国开发者大会，时间2018年11月10日周六，地点深圳金茂 JW 万豪酒店。届时，将有来自 Elastic、eBay、暴雪、Grab、华为、阿里巴巴、顺丰等公司的25位各领域的专家大拿为你带来围绕 Elastic 开源技术的各自精彩干货分享。\n\n[attach]2940[/attach]\n\nElastic Stack 作为目前全球最流行的数据搜索与实时分析引擎套件，其产品累计下载次数已超过三亿五千万次，各行各业从一线互联网公司到传统的行业都能找到使用 Elasticsearch 的身影。Elastic 的开源技术正越来越受到众多开发者的青睐，已然成为大数据领域分析工具的最佳选择。  \n\n[attach]2937[/attach]\n\n[来自 db-engines.com的最新综合排名]\n\nElastic 中国开发者大会 2018（Elastic Developers China 2018）是由 Elastic 官方在中国举办的第二次开发者大会，主要围绕 Elastic 的开源产品: Elasticsearch、Logstash、Kibana 和 Beats，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。 \n\n举办 Elastic 开发者大会的目的是为中国广大的 Elastic 开发者提供一个技术交流和学习切磋的地方，汇集业界众多的成功案例，集思广益，发散思维，促进社区和行业的进步。\n\n不管您是 Elasticsearch 的初学者还是资深的用户，您都应该参加！\n\n# 大会亮点\n\n## 01 部分精彩议题\n\n1. Beats 创始人 Monica Sarbu 带来的运维分析的三连击\n\n2. 新产品 Codesearch（原 Insight.io） 的初次亮相\n\n3. Elastic 内部是如何使用 Elastic 产品的案例\n\n4. 暴雪中国借助 ELK 运营游戏的经验分享\n\n5. 东南亚打车软件 Grab 的 POI 搜索平台迁移史\n\n6. 东半球对 Kibana 二次开发最多团队带来的经验分享\n\n7. 千亿数据规模下的 Elasticsearch 深度应用\n\n8. Elasticsearch 和 AI 的深度结合与用户画像系统\n\n更多在互联网、证券、快递、新零售、安全等领域的分享，点击[这里](https://www.bagevent.com/event/1654662?discountCode=50OFF)了解更多\n\n\n## 02 部分嘉宾阵容\n\n[attach]2935[/attach]\n\n[attach]2939[/attach]\n\n\n## 03 Elastic AMA 展台\n\n[attach]2941[/attach]\n\nAMA 即 Ask Me Anything，意思是尽管随便问，您可以在大会当天，尽情的在现场咨询 Elastic 官方工作人员任意的问题，可以是技术的咨询，可以是特性的讲解，可以是最佳实践，可以是商务合作。AMA 展台，您一定不要错过。\n\n\n## 04 Elastic Demo 展台\n\n[attach]2936[/attach]\n\n如果您对 Elastic 能够帮您做哪些事情比较感兴趣，最直观的方式就是来到 Elastic 的 Demo 展台，现场有 Elastic 技术专家为您讲解各种酷炫的 Demo 以及具体的如何使用 Elastic Stack 来完成特定的任务。 Demo 展台有趣又好玩，记得打卡。\n\n\n## 05 闪电演讲\n\n[attach]2938[/attach]\n\n您也来讲讲，大会的最后一个环节名叫闪电演讲，参会者可以现场报名，每位分享者可以有5分钟的时间来进行分享，可以是任何相关的话题，可以是 Demo 演示，可以是技术脱口秀，或是您的一个开源的项目，名额有限，先报先得。\n\n最后，赶紧报名吧！\n[https://www.bagevent.com/event/1654662?discountCode=50OFF](https://www.bagevent.com/event/1654662?discountCode=50OFF)\n","title":"Elastic 中国开发者大会 2018 疯狂来袭！","uid":"1","views":"1509","votes":"2"},"_type":"doc"}
{"_id":"781","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535780502","category_id":"18","comments":"0","has_attach":"0","id":"781","message":"1. Elasticsearch 5.x 字段折叠的使用。\n[http://t.cn/RFodkB2](http://t.cn/RFodkB2) \n\n2. 一例Query Cache引起的性能问题分析。\n[http://t.cn/RnOejt6](http://t.cn/RnOejt6) \n\n3.  ES性能优化。\n[http://t.cn/RFoFaRM](http://t.cn/RFoFaRM) \n\n活动预告\n\n1、Elastic 中国开发者大会最后一波早鸟票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\nhttps://elasticsearch.cn/article/759\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/781\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第381期 (2018-09-01)","uid":"1874","views":"624","votes":"0"},"_type":"doc"}
{"_id":"800","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536994108","category_id":"18","comments":"0","has_attach":"0","id":"800","message":"1、容器化日志收集方案-EFK \nhttp://t.cn/EvUKuIX \n2、painless获取doc字段的方式 \nhttp://t.cn/EvqCbBD \n3、基于spark和es的简单推荐系统 \nhttp://t.cn/Evqplv5 \n \n活动预告 \n1、Elastic 中国开发者大会门票发售中 \nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑: bsll \n归档：https://elasticsearch.cn/article/800\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第395期 (2018-09-15） ","uid":"3851","views":"197","votes":"0"},"_type":"doc"}
{"_id":"810","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537489565","category_id":"18","comments":"0","has_attach":"0","id":"810","message":"1、Elasticsearch profile使用解读（需梯子）\nhttp://t.cn/Evg55aC\n2、ElasticSearch底层原理浅析\nhttp://t.cn/EvBndhG\n3、用antd和webview打造一款大数据客户端程序（支持ES）\nhttp://t.cn/EvBmv9Z\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/810\n订阅：https://tinyletter.com/elastic-daily","title":"​ Elastic日报 第401期 (2018-09-21)","uid":"1341","views":"247","votes":"0"},"_type":"doc"}
{"_id":"818","_index":"forum-mysql","_score":1,"_source":{"addtime":"1538029018","category_id":"18","comments":"0","has_attach":"0","id":"818","message":"1.SkyWalking 分布式追踪系统\nhttp://t.cn/EP9fCEK\n2.相对于OLTP，列式存储到底好用在哪里？\nhttp://t.cn/EP9fTDB\n3.ES的heap是如何被瓜分掉的\nhttp://t.cn/R3zA5Tw\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：金桥\n归档：https://elasticsearch.cn/article/818\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第407期 (2018-09-27)","uid":"668","views":"278","votes":"0"},"_type":"doc"}
{"_id":"819","_index":"forum-mysql","_score":1,"_source":{"addtime":"1538110721","category_id":"2","comments":"3","has_attach":"0","id":"819","message":"1、基于FTRL和个性化推荐的搜索排序优化优化\nhttp://t.cn/EPjzCa2\n2、Elasticsearch实现仿美团搜索排序功能\n3、性能监控之JMeter分布式压测轻量日志解决方案\nhttp://t.cn/EPjzM1s\n \n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/819\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第408期 (2018-09-28)","uid":"1341","views":"220","votes":"0"},"_type":"doc"}
{"_id":"820","_index":"forum-mysql","_score":1,"_source":{"addtime":"1538183546","category_id":"18","comments":"0","has_attach":"0","id":"820","message":"1. 利用react和Elastic App Search搭建搜索应用。\n[http://t.cn/EPEySqd](http://t.cn/EPEySqd) \n\n2. 使用机器学习构建自定义搜索路由器。\n[http://t.cn/EPEVEiC](http://t.cn/EPEVEiC) \n\n3. 搜索引擎算法体系简介——排序和意图篇。\n[http://t.cn/EPExV5U](http://t.cn/EPExV5U) \n\n\n活动预告\n\n1、Elastic 中国开发者大会门票发售中\n\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/820 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第409期 (2018-09-29）","uid":"1874","views":"276","votes":"0"},"_type":"doc"}
{"_id":"825","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539181487","category_id":"18","comments":"0","has_attach":"0","id":"825","message":"1、抓取、代码、检索构建站点搜索和垂直应用搜索引擎。\nhttp://t.cn/E74iLIP\n2.Beats家族6.4支持kafka2.0啦！！\nhttp://t.cn/E74iaku\n3. 有赞搜索系统的架构演进 \nhttp://t.cn/E74QkWx\n\n\n活动预告\n1、Elastic 中国开发者大会门票发售中,庆祝上市，抢半价门票\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：wt\n归档：https://elasticsearch.cn/article/825\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第413期 (2018-10-10)","uid":"3851","views":"215","votes":"0"},"_type":"doc"}
{"_id":"822","_index":"forum-mysql","_score":1,"_source":{"addtime":"1538967501","category_id":"18","comments":"0","has_attach":"0","id":"822","message":"1.ECE 2.0：主机标记、ML、冷热节点架构，不一而足\nhttp://t.cn/Ehm0ymw\n\n2.来了解 Elastic Search开源项目是如何处理 Pull Request\nhttp://t.cn/EhmHl3W\n\n3.搜索软件Elastic上市：市值近50亿美元 是开源项目商业化范本\nhttp://t.cn/EhHzhBv\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中,庆祝上市，抢半价门票\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：cyberdak\n归档：https://elasticsearch.cn/article/822\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第411期 (2018-10-08)","uid":"4063","views":"240","votes":"0"},"_type":"doc"}
{"_id":"826","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539219229","category_id":"18","comments":"0","has_attach":"0","id":"826","message":"1.（自备梯子）QuickBook  的搜索平台发展介绍\nhttp://t.cn/E7Gd9Iv\n2.如果你对文本相似度感兴趣，可以看看这篇文章\nhttp://t.cn/E7GdOSC\n3.（自备梯子）在医药分析领域推荐 ELK 技术栈\nhttp://t.cn/E7GdHwf\n\n活动预告\n1、Elastic 中国开发者大会门票发售中,庆祝上市，抢半价门票\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/826\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第414期 (2018-10-11)","uid":"86","views":"222","votes":"0"},"_type":"doc"}
{"_id":"832","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539668770","category_id":"18","comments":"0","has_attach":"0","id":"832","message":"1.为什么Elasticsearch查询变慢了\nhttp://t.cn/E73NIrD\n2.Elasticsearch技术分享--基于5.1.1\nhttp://t.cn/E73N9xX\n3.ubuntu下EFK(elasticsearch+fluentd+kibana)的搭建和使用\nhttp://t.cn/E73NHkW\n\n活动预告：\n1、Elastic 官方开发者认证现场考试+ Elastic 开发者大会 VIP 门票\nhttps://elasticsearch.cn/article/827\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/832\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第419期 (2018-10-16)","uid":"3788","views":"190","votes":"0"},"_type":"doc"}
{"_id":"991","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539783067","category_id":"18","comments":"0","has_attach":"0","id":"991","message":"1. ElasticSearch源码解析之启动流程\ni、http://t.cn/EzUc7ox\nii、http://t.cn/EzUcOoL\n2. Elasticsearch聚合优化 | 聚合速度提升5倍\nhttp://t.cn/EzUx0rX\n3. Elastic 社区电台 第五期，嘉宾：李啸、张振风@趋势科技\nhttps://elasticsearch.cn/article/990\n\n编辑：wt\n归档：https://elasticsearch.cn/article/991\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第420期 (2018-10-17)","uid":"3851","views":"194","votes":"0"},"_type":"doc"}
{"_id":"996","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540054106","category_id":"18","comments":"0","has_attach":"0","id":"996","message":"1.Logstash和Elasticsearch 集成。\nhttp://t.cn/EzYLgoO\n2.如何在Logstash中设置Elasticsearch输出模板。\nhttp://t.cn/EzYLx6u\n3.(自备梯子)怎样真正成为高级开发人员。\nhttp://t.cn/EzYyl2E\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/996\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第424期 (2018-10-21)","uid":"4460","views":"182","votes":"0"},"_type":"doc"}
{"_id":"998","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540183663","category_id":"18","comments":"0","has_attach":"0","id":"998","message":"1. 了解elasticsearch开源代码开发流程\nhttp://t.cn/EzEHZcs\n\n2. 如何高效率在grafana中使用elasticsearch 数据源以及避免一些常见的陷阱\nhttp://t.cn/EzERBsL\n\n3. 全球权威数据库排名网站，帮助你了解各种db，es目前排在第八位，前十中唯一的搜索引擎\nhttp://t.cn/RSbV39S\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/998\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第425期 (2018-10-22)","uid":"4063","views":"201","votes":"0"},"_type":"doc"}
{"_id":"999","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540260504","category_id":"18","comments":"0","has_attach":"0","id":"999","message":"1.使用Elasticsearch和Neo4j进行知识图搜索\nhttp://t.cn/EzrbU56\n2、Elasticsearch关于data那些事。\nhttp://t.cn/EzrG7Ue\n3.手把手教你搭建一个 Elasticsearch 集群\nhttp://t.cn/EzrbPYA\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/999\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第426期 (2018-10-23)","uid":"3788","views":"228","votes":"0"},"_type":"doc"}
{"_id":"1008","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540778418","category_id":"18","comments":"0","has_attach":"0","id":"1008","message":"1.kibana 6.5 中的插件api相关更新\nhttp://t.cn/EZECcbY\n\n2.elastalert的kibana插件，从此可以在kibana中方便配置报警规则\nhttp://t.cn/EZmaw65\n\n3.nginx 与 elasticsearch 结合使用\nhttp://t.cn/RwF1kqE\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/1008\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第432期 (2018-10-29)","uid":"4063","views":"218","votes":"0"},"_type":"doc"}
{"_id":"6331","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547518902","category_id":"18","comments":"0","has_attach":"0","id":"6331","message":"1、几个常用的Elasticsearch Management GUI推荐。\nhttp://t.cn/Eql0exu\n2、(自备梯子)Dejavu 3.0: 一个你需要的Elasticsearch Web UI。\n​http://t.cn/EqlOPrD\n3、从Lucene到Elasticsearch:全文检索实战。\nhttp://t.cn/EqlOLdL\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6331\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第510期 (2019-01-15)","uid":"3788","views":"191","votes":"0"},"_type":"doc"}
{"_id":"6318","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546707338","category_id":"2","comments":"4","has_attach":"0","id":"6318","message":"本文将详细介绍利用 ES-Hadoop 将 Spark 处理的数据写入到 ES 中。\n\n## 一、开发环境\n### 1、组件版本\n- CDH 集群版本：6.0.1\n- Spark 版本：2.2.0\n- Kafka 版本：1.0.1\n- ES 版本：6.5.1\n\n### 2、Maven 依赖\n```xml\n\u0026lt;!-- scala --\u0026gt;\n\u0026lt;dependency\u0026gt;\n  \u0026lt;groupId\u0026gt;org.scala-lang\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;scala-library\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;2.11.8\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- spark 基础依赖 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n  \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;spark-core_2.11\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- spark-streaming 相关依赖 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n  \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;spark-streaming_2.11\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- spark-streaming-kafka 相关依赖 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n  \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;spark-streaming-kafka-0-10_2.11\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- zookeeper 相关依赖 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n  \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;3.4.5-cdh6.0.1\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- Spark-ES 相关依赖 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n    \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt;\n    \u0026lt;artifactId\u0026gt;elasticsearch-spark-20_2.11\u0026lt;/artifactId\u0026gt;\n    \u0026lt;version\u0026gt;6.5.4\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n\n\u0026lt;!-- Spark-ES 依赖的 HTTP 传输组件 --\u0026gt;\n\u0026lt;dependency\u0026gt;\n    \u0026lt;groupId\u0026gt;commons-httpclient\u0026lt;/groupId\u0026gt;\n    \u0026lt;artifactId\u0026gt;commons-httpclient\u0026lt;/artifactId\u0026gt;\n    \u0026lt;version\u0026gt;3.1\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\u0026gt;\n```\n\n### 3、注意事项\n如果使用 CDH 版本的 Spark，则在调试及实际部署运行的时候会出现下面的错误：\n```\njava.lang.ClassNotFoundException: org.apache.commons.httpclient.protocol.Protocol\n```\n\n很显然是缺少 httpclient 相关依赖造成的，对比开源版本与 CDH 版本的 Spark，发现开源版本多出了 `commons-httpclient-3.1.jar`，因此上述 Maven 的 pom 文件添加上对其依赖即可。\n\n## 二、ES-Hadoop\n### 1、简介\nES-Hadoop 实现了 Hadoop 生态（Hive、Spark、Pig、Storm 等）与 ElasticSearch 之间的数据交互，借助该组件可以将 Hadoop 生态的数据写入到 ES 中，然后借助 ES 对数据快速进行搜索、过滤、聚合等分析，进一步可以通过 Kibana 来实现数据的可视化。\n\n同时，也可以借助 ES 作为数据存储层（类似数仓的 Stage 层或者 ODS 层），然后借助 Hadoop 生态的数据处理工具（Hive、MR、Spark 等）将处理后的数据写入到 HDFS 中。\n\n\u0026gt; 使用 ES 做为原始数据的存储层，可以很好的进行数据去重、数据质量分析，还可以提供一些即时的数据服务，例如趋势展示、汇总分析等。\n\n![对 Hadoop 数据进行交互分析](http://img.luooqi.com/FvvdyhdXXZxgU1fwqLDWrZHvK6ZB)\n\n### 2、组成\nES-Hadoop 是一个整合性质的组件，它封装了 Hadoop 生态的多种组件与 ES 交互的 API，如果你只需要部分功能，可以使用细分的组件：\n- elasticsearch-hadoop-mr\n- elasticsearch-hadoop-hive\n- elasticsearch-hadoop-pig\n- elasticsearch-spark-20_2.10\n- elasticsearch-hadoop-cascading\n- elasticsearch-storm\n\n## 三、elasticsearch-spark\n### 1、配置\nes-hadoop 核心是通过 es 提供的 restful 接口来进行数据交互，下面是几个重要配置项，更多配置信息请参阅[官方说明](https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html)：\n- `es.nodes`：需要连接的 es 节点（不需要配置全部节点，默认会自动发现其他可用节点）；\n- `es.port`：节点 http 通讯端口；\n- `es.nodes.discovery`：默认为 true，表示自动发现集群可用节点；\n- `es.nodes.wan.only`：默认为 false，设置为 true 之后，会关闭节点的自动 discovery，只使用 `es.nodes` 声明的节点进行数据读写操作；如果你需要**通过域名**进行数据访问，则设置该选项为 true，否则请务必设置为 false；\n- `es.index.auto.create`：是否自动创建不存在的索引，默认为 true；\n- `es.net.http.auth.user`：Basic 认证的用户名；\n- `es.net.http.auth.pass`：Basic 认证的密码。\n\n```scala\nval conf = new SparkConf().setIfMissing(\u0026quot;spark.app.name\u0026quot;,\u0026quot;rt-data-loader\u0026quot;).setIfMissing(\u0026quot;spark.master\u0026quot;, \u0026quot;local[5]\u0026quot;)\nconf.set(ConfigurationOptions.ES_NODES, esNodes)\nconf.set(ConfigurationOptions.ES_PORT, esPort)\nconf.set(ConfigurationOptions.ES_NODES_WAN_ONLY, \u0026quot;true\u0026quot;)\nconf.set(ConfigurationOptions.ES_INDEX_AUTO_CREATE, \u0026quot;true\u0026quot;)\nconf.set(ConfigurationOptions.ES_NODES_DISCOVERY, \u0026quot;false\u0026quot;)\nconf.set(ConfigurationOptions.ES_NET_HTTP_AUTH_USER, esUser)\nconf.set(ConfigurationOptions.ES_NET_HTTP_AUTH_PASS, esPwd)\nconf.set(\u0026quot;es.write.rest.error.handlers\u0026quot;, \u0026quot;ignoreConflict\u0026quot;)\nconf.set(\u0026quot;es.write.rest.error.handler.ignoreConflict\u0026quot;, \u0026quot;com.jointsky.bigdata.handler.IgnoreConflictsHandler\u0026quot;)\n```\n\n特别需要注意的配置项为 `es.nodes.wan.only`，由于在云服务器环境中，配置文件使用的一般为内网地址，而本地调试的时候一般使用外网地址，这样将 `es.nodes` 配置为外网地址后，最后会出现节点找不到的问题（由于会使用节点配置的内网地址去进行连接）：\n```\norg.elasticsearch.hadoop.EsHadoopIllegalArgumentException: No data nodes with HTTP-enabled available; \nnode discovery is disabled and none of nodes specified fit the criterion [xxx.xx.x.xx:9200]\n```\n\n此时将 `es.nodes.wan.only` 设置为 true 即可。**推荐开发测试时使用域名，集群部署的时候将该选项置为 false**。\n\n### 2、屏蔽写入冲突\n如果数据存在重复，写入 ES 时往往会出现数据写入冲突的错误，此时有两种解决方法。\n\n方法一：设置 `es.write.operation` 为 upsert，这样达到的效果为如果存在则更新，不存在则进行插入，该配置项默认值为 index。\n\n方法二：自定义冲突处理类，类似上述配置中设置了自定义的 `error.handlers`，通过自定义类来处理相关错误，例如忽略冲突等：\n```java\npublic class IgnoreConflictsHandler extends BulkWriteErrorHandler {\n    public HandlerResult onError(BulkWriteFailure entry, DelayableErrorCollector\u0026lt;byte[]\u0026gt; collector) throws Exception {\n        if (entry.getResponseCode() == 409) {\n            StaticLog.warn(\u0026quot;Encountered conflict response. Ignoring old data.\u0026quot;);\n            return HandlerResult.HANDLED;\n        }\n        return collector.pass(\u0026quot;Not a conflict response code.\u0026quot;);\n    }\n}\n```\n\n\u0026gt; 方法二可以屏蔽写入版本比预期的小之类的版本冲突问题。\n\n### 3、RDD 写入 ES\nEsSpark 提供了两种主要方法来实现数据写入：\n- `saveToEs` ：RDD 内容为 `Seq[Map]`，即一个 Map 对象集合，每个 Map 对应一个文档；\n- `saveJsonToEs`：RDD 内容为 `Seq[String]`，即一个 String 集合，每个 String 是一个 JSON 字符串，代表一条记录（对应 ES 的 _source）。\n\n数据写入可以指定很多配置信息，例如：\n- `es.resource`：设置写入的索引和类型，索引和类型名均**支持动态变量**；\n- `es.mapping.id`：设置文档 _id 对应的字段名；\n- `es.mapping.exclude`：设置写入时忽略的字段，支持通配符。\n\n```scala\nval itemRdd = rdd.flatMap(line =\u0026gt; {\n    val topic = line.topic()\n    println(\u0026quot;正在处理：\u0026quot; + topic + \u0026quot; - \u0026quot; + line.partition() + \u0026quot; : \u0026quot; + line.offset())\n    val jsonArray = JSON.parseArray(line.value()).toJavaList(classOf[JSONObject]).asScala\n    val resultMap = jsonArray.map(jsonObj =\u0026gt;{\n      var tmpId = \u0026quot;xxx\u0026quot;\n      var tmpIndex = \u0026quot;xxxxxx\u0026quot;\n      jsonObj.put(\u0026quot;myTmpId\u0026quot;, tmpId)\n      jsonObj.put(\u0026quot;myTmpIndex\u0026quot;, tmpIndex)\n      jsonObj.getInnerMap\n    })\n    resultMap\n})\nval mapConf = Map(\n    (\u0026quot;es.resource\u0026quot; , \u0026quot;{myTmpIndex}/doc\u0026quot;),\n    (\u0026quot;es.write.operation\u0026quot; , \u0026quot;upsert\u0026quot;),\n    (\u0026quot;es.mapping.id\u0026quot; , \u0026quot;myTmpId\u0026quot;),\n    (\u0026quot;es.mapping.exclude\u0026quot; , \u0026quot;myTmp*\u0026quot;)\n)\nEsSpark.saveToEs(itemRdd, mapConf)\n```\n\u0026gt; `es.mapping.exclude` 只支持 RDD 为 Map 集合（saveToEs），当为 Json 字符串集合时（saveJsonToEs）会提示不支持的错误信息；这个配置项非常有用，例如 myTmpId 作为文档 id，因此没有必要重复存储到 _source 里面了，可以配置到这个配置项，将其从 _source 中排除。\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](https://user-gold-cdn.xitu.io/2018/10/14/16672d99876e4363?w=258\u0026amp;h=258\u0026amp;f=png\u0026amp;s=45449)","title":"使用 ES-Hadoop 将 Spark Streaming 流数据写入 ES","uid":"8031","views":"228","votes":"2"},"_type":"doc"}
{"_id":"6314","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546400407","category_id":"18","comments":"0","has_attach":"0","id":"6314","message":"1. 快手万亿级实时OLAP平台的建设与实践\nhttp://t.cn/E4439oI\n \n2. 引入ELK前需要知道的“坑”(上)\nhttp://t.cn/EbggZrv\n\n3.公司 Elasticsearch 升级带来的坑怎么填\nhttp://t.cn/EbguZUx\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/6314[/url]\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第497期 (2019-01-02)","uid":"3828","views":"219","votes":"0"},"_type":"doc"}
{"_id":"6307","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545879576","category_id":"4","comments":"0","has_attach":"1","id":"6307","message":" Elastic stack不停的迭代中狂奔。在最新的V6.5版本发布后，我们可以发现，其路线图已经越来越倾向于成为一个全栈的，全链路的，从下至上，从底层硬件资源数据一直到上层用户数据，从资源监控，到性能监控，直至安全审计的智能化运维系统了。这其中解决的一个痛点是：企业中存在各种各样的业务系统，每个系统又存在不同的数据源和存储数据的数据库；同时在运维管理层面上，又各种不同的监控系统（资源监控，性能监控，安全和审计）以及上层的可视化系统。这样，导致运维人员需要面对繁多的系统、入口和数据维度，在处理问题时，需要登录不同的平台，并且无法对数据进行有效的关联分析，因此，是迫切需要一个强大的平台，能够快速便捷的处理这些问题的。\n 我们可以看到，从不停发布的beats，以及beats里面不停添加的modules：\n\n[attach]3376[/attach]\n\n以及支持的各种数据指标模版：\n\n[attach]3379[/attach]\n\nelastic stack在加速将越来越多的数据需要汇聚到一起，并且提供一个统一的接口进入，这就是Kibana。这里，我不打算深入的比较Kibana和Grafana，简单说一句，就是grafana的主要场景只是dashboard，并不适合将其用作一个将所有数据集中到一起，需要做各种维度的查询，分析，安全检查等功能的portal。所以，这里我们讨论的是Kibana上如何展示其他数据源的数据。\n\n### 为什么是prometheus而不是beats\n\n在这个人人上云的时代，无论是open stack还是K8S，最流行的资源监控软件我看到的是prometheus，特别是以node_exporter为基础的一系列metric采集工具，为prometheus提供了各种维度的监控数据。而对应的，elastic stack也提供了类似filebeat, metricbeat, packatbeat等一系列工具和对应的数据template。\n\n我没有深入使用过prometheus，但作为一个beats的资深用户，我还是感觉到beats还存在诸多的问题，特别是filebeat上幽灵般存在的内存占用过多的问题，导致大规模在所有的节点上安装beats成为一种风险。并且，最主要的一个点，我觉得是beats采集的数据，是依赖于整个elastic stack进行展示的，而作为云的运维人员，其关心的重点是每个虚拟机，容器的资源监控情况，metric和alart是其重心，而非query，search，security等功能。并且安装一个prometheus，比安装整个elastic stack简便得多，消耗的资源也小的多。所以，普遍的，从主机运维人员的角度，肯定首选安装prometheus的exporter来作资源的监控，而非安装beats。\n\n### 为什么Kibana上需要集成prometheus的数据\n\n正因为之前所讲的，我们试图使用elastic stack作为一个多维度的统一的数据入口和展示工具，要求我们必须能在Kibana看到硬件资源监控级别的指标，而elastic stack提供的beats等工具，却并不为云运维人员所待见（因为他们更喜欢prometheus，而非elastic stack，原因见以上）。因此，如果我们需要将elastic stack打造为一套全栈的智能运维系统，大多数情况下，prometheus成为必须跨越的一个槛。\n\n### 将prometheus上的数据转移到elasticsearch\n\n这是我想到的第一个解决方案。可惜logstash上没有prometheus的input plugins。所以，我们还是需要beats。注意，在metricbeat上有一个prometheus的module，号称可以 **fetch metric from prometheus exporter**，但实际上只是一个乌龙，这个module的并不能从成千上万的云主机或者容器中拉取数据，它能做的只是获取prometheus服务器节点prometheus这个进程的基本数据，然并卵。\n这里给大家介绍的是两个社区提供prometheus相关的beats：\n\n但建议大家还是自己写一个beat吧，代码可以参考prombeat。\n不过如果你仔细观看prometheus里面的数据，都是num type的，将其转存到elasticsearch绝对不是一个经济的选择：\n\n[attach]3377[/attach]\n\n### 将grafana集成到kibana中\n\n这是为什么我在一开始提到了grafana，虽然它不适合做portal，但是极其适合做dashboard，而kibana又是如此的开放，随便做个插件，可以轻松的跳转到grafana的dashboard上。而grafana与prometheus又是如此的登对，看看grafana上的各种专业而美丽的prometheus的dashboard吧：\n\n[attach]3378[/attach]\n\n我们要做的是做一个kibana的插件，然后将关键参数传递给grafana，并跳转：\n\n[attach]3380[/attach]\n\n虽然kibana和grafana是两个不同的工具，但并不妨碍我们将它们放在一起工作。而Kibana的开放性和基于插件的独立开发模式，让我们可以更方便的将各种好用的开源工具集成到一起，这里展示的Kibana与grafana和promethues的集成，希望能给到你一些微光。\n\n\n\n\n\n\n\n","title":"为何要通过Kibana展示promethues的数据以及如何去做","uid":"5649","views":"336","votes":"4"},"_type":"doc"}
{"_id":"6223","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545702942","category_id":"18","comments":"0","has_attach":"0","id":"6223","message":"1、用ElasticSearch搭建自己的搜索和分析引擎\nhttp://t.cn/E4n6of8\n2、Elasticsearch 集群性能的最佳实践\nhttp://t.cn/E4n6M3v\n3、海量数据下Elasticsearch搜索引擎分析与搭建\nhttp://t.cn/R3bde2J\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6223\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第489期 (2018-12-25)","uid":"3788","views":"213","votes":"0"},"_type":"doc"}
{"_id":"6218","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545530606","category_id":"18","comments":"0","has_attach":"0","id":"6218","message":"1.使用Elasticsearch进行简单标记。\nhttp://t.cn/E4pK0fk\n2.Java中的Elasticsearch指南。\nhttp://t.cn/E4pXPl4\n3.(自备梯子)智能家居技术仍然不够智能。\nhttp://t.cn/E4CNtpJ\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6218\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第487期 (2018-12-23)","uid":"4460","views":"177","votes":"0"},"_type":"doc"}
{"_id":"6219","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545537090","category_id":"14","comments":"0","has_attach":"0","id":"6219","message":"## 一、分词插件\n### 1、分词器概念\n在 ES 中，分词器的作用是从文本中提取出若干词元（token）来支持索引的存储和搜索，分词器（Analyzer）由**一个分解器**（Tokenizer）、**零个或多个词元过滤器**（TokenFilter）组成。\n\n分解器用于将字符串分解成一系列词元，词元过滤器的作用是对分词器提取出来的词元做进一步处理，比如转成小写，增加同义词等。处理后的结果称为索引词（Term），引擎会建立 Term 和原文档的倒排索引（Inverted Index），这样就能根据 Term 很快到找到源文档了。\n\n![文本分词并索引的过程](http://img.luooqi.com/FsIejZLnwcQiiTYNlLl-a8sLUepg)\n\n### 2、选择分词器\n目前 ES 分词插件的选择性还是很多的，分词插件的核心就是提供各种分词器（Analyzer）、分解器（Tokenizer）、词元过滤器（TokenFilter）；根据依赖的核心分词包（分词算法）的不同显现出不同的差异性，除了分词算法之外，是否支持用户自定义词典，是否支持词典热更新等其他附加功能也是选择分词插件时需要参考的。\n\n下面列出选择分词插件需要考虑的因素（仅供参考）：\n- 分词准确性：大家都希望分词结果能够尽可能准确，与分词准确性直接相关的就是用户词典了，此外才是分词算法；\n- 分词算法：个人认为无需纠结于分词算法，大多数分词包提供的分词算法都比较类似，选择时不需要过于纠结；\n- 分词速度：这个与分词算法直接相关，基于词典的分词算法一般比基于模型的分词算法要快；基于词典如果考虑词频、命名实体识别、词性标注则会慢一些；\n- 启动速度：当词典较大时，初始化词典会比较慢，某些分词器会对词典进行缓存，第二次启动会非常速度；\n- 内存占用：与分词算法、词典大小、模型大小均有关系，设计精巧的算法对内存占用较小；\n- 易用性：分词器是否开箱即用，是否可以直接使用在线链接或者压缩包进行安装，是否需要复杂的配置；\n- 扩展性：是否支持用户自定义词典、是否支持自定义分词算法、是否支持热更新等；\n- 是否开源：开源的分词器在遇到问题的时候可以自己进行深度调试，甚至可以进行二次开发；\n- 社区活跃度：这个看一下 github 的 star 数或者依赖的分词包的 star 数和 issue 数目即可判定；\n- 更新频率：是否能够与最新版的 ES 同步更新。\n\n## 二、HanLP 简介\nHanLP 是一系列模型与算法组成的 NLP 工具包，具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点,详情可参考 github 介绍：[https://github.com/hankcs/HanLP](https://github.com/hankcs/HanLP)。\n\n选择 HanLP 作为核心的分词包开发 ES 分词插件，主要考虑以下因素：\n- HanLP 是 Java 分词包中最为流行的；\n- HanLP 提供了多种分词器，既可以基于词典也可以基于模型（在一亿字的大型综合语料库上训练的分词模型）；\n- HanLP 坚持使用明文词典，这样可以借助社区的力量对词典不断进行完善；\n- 完善的开发文档和代码样例，较为活跃的用户群体；\n- 个人参与了部分功能的开发，对代码结构较为熟悉。\n\n## 三、开发分词插件\n### 1、代码结构\n- `conf`：插件的配置文件、HanLP 的配置文件、Java 安全策略文件；\n- `scr.main.java.assemby`：插件打包（maven-assembly-plugin）配置文件；\n- `org.elasticsearch.plugin.hanlp.analysis`：分词插件核心构建器；\n- `org.elasticsearch.plugin.hanlp.conf`：管理插件配置、分词器配置以及 HanLP 配置；\n- `org.elasticsearch.plugin.hanlp.lucene`：HanLP 中文分词 Lucene 插件，对 Lucune 分词进行实现；\n- `scr.main.resources`：插件属性文件所在目录\n\n![插件代码结构](http://img.luooqi.com/FnyoQBBEjOGfmv7sEQHQToqqba0r)\n\n### 2、TokenStream\nAnalyzer 类是一个抽象类，是所有分词器的基类，它通过 TokenStream 类将文本转换为词汇单元流；TokenStream 有两种实现 Tokenizer（输入为 Reader） 和 TokenFilter（输入为另一个 TokenStream）。\n\n![文本分词流程](http://img.luooqi.com/FmvVcPk8KM-Ujd-lqh6qmToXL18C)\n\nTokenStream 基本使用流程：\n1. 实例化 TokenStream，向 AttributeSource 添加/获取属性（词汇单元文本、位置增量、偏移量、词汇类型等）；\n2. 调用 `reset()` 方法，将流（stream）重置到原始（clean）状态；\n3. 循环调用 `incrementToken()` 方法，并处理 Attribute 属性信息，直到它返回 false 表示流处理结束；\n4. 调用 `end()` 方法，确保流结束（end-of-stream）的操作可以被执行；\n5. 调用 `close()` 方法释放资源。\n\n```\n// 实例化 TokenStream\nTokenStream tokenStream = new IKAnalyzer().tokenStream(\u0026quot;keywords\u0026quot;,new StringReader(\u0026quot;思想者\u0026quot;));\n// 向 AttributeSource 添加/获取属性\nCharTermAttribute attribute = tokenStream.addAttribute(CharTermAttribute.class);\n// 将流（stream）重置到原始（clean）状态\ntokenStream.reset();\n// 判断是否还有下一个 Token\nwhile(tokenStream.incrementToken()) {\n  System.out.println(attribute);\n}\ntokenStream.end();\ntokenStream.close();\n```\n\n\u0026gt; 综上，开发 Tokenizer 或者 TokenFilter 时，需要重点关注 `reset、incrementToken、end、close` 四个方法的实现。\n\n### 3、开发中的小技巧\n#### 获取插件目录或文件目录\n```\n//获取插件根目录\nprivate static Path getPluginPath() {\n    return env.pluginsFile().resolve(\u0026quot;analysis-hanlp\u0026quot;);\n}\n//获取插件目录下的文件\nprivate static Path getDefDicConfigPath() {\n    return env.pluginsFile().resolve(\u0026quot;analysis-hanlp/hanlp.properties\u0026quot;).toAbsolutePath();\n}\n```\n\n#### 插件属性文件\n如果希望插件属性文件（`plugin-descriptor.properties`）能够自动根据 `pom.xml` 中的属性进行赋值，则需要将文件防止到 resources 文件夹下。\n\n#### 插件版本兼容性\n从实际测试来看：\n- ES5.X 及其以上的代码是完全复用的，也就是说代码逻辑不需要调整；\n- ES5.X 到 ES6.2.X 的插件是可以通用的，其特征是打包的时候需要将插件的文件全部打包到 `elasticsearch` 文件夹下；\n- ES6.3.X 以上的插件是可以通用的，打包的时候插件的文件全部打包到根目录即可。\n\n\u0026gt; 也就是说，如果你升级了新版本 ES，对于插件升级，大多数情况只需要修改下 `plugin-descriptor.properties` 文件中 ES 的版本号即可。\n\n### 4、安全策略文件\n在插件开发中经常会使用到文件读取、属性读取、网络链接等功能，如果不提前注册安全策略，在调用这些功能的时候会报以下错误`java.security.AccessControlException: access denied`。\n\n官方给出的解决方案就是新建一个 `plugin-security.policy` 文件，然后在文件中声明需要的权限信息，最后在**打包的时候将文件放置到插件的根目录**，这样在使用 zip 包进行安装的时候，ES 会提示用户插件所需的权限信息，需要用户确认后插件才能正常安装。\n```\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@     WARNING: plugin requires additional permissions     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n* java.io.FilePermission \u0026lt;\u0026lt;ALL FILES\u0026gt;\u0026gt; read,write,delete\n* java.lang.RuntimePermission createClassLoader\n* java.lang.RuntimePermission getClassLoader\n* java.lang.RuntimePermission setContextClassLoader\n* java.net.SocketPermission * connect,resolve\n* java.util.PropertyPermission * read,write\nSee http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html\nfor descriptions of what these permissions allow and the associated risks.\n\nContinue with installation? [y/N]y\n-\u0026gt; Installed analysis-hanlp\n```\n\n### 5、安全策略的坑\n最开始认为只需要添加了 policy 文件，且打包到正确的位置即可解决插件的权限问题，因为在插件安装的时候 ES 已经提示了所需权限，但是代码在实际执行的时候依旧报 `AccessControlException` 的错误。\n\n参考了多个 HanLP 的 ES 分词插件，都没有获得较好的方法，后来考虑到 IK 分词器远程加载词典时，需要网络连接权限，就去看了下其远程词典加载的代码，最终找到了正确的使用方法。\n```\n// 需要特殊权限的代码\nAccessController.doPrivileged((PrivilegedAction\u0026lt;Segment\u0026gt;) () -\u0026gt; {\n    Segment segment;\n    if (config.getAlgorithm().equals(\u0026quot;extend\u0026quot;)) {\n        segment = new ViterbiSegment();\n    } else {\n        segment = HanLP.newSegment(config.getAlgorithm());\n    }\n    // 在此处显示调用一下分词，使得加载词典、缓存词典的操作可以正确执行\n    System.out.println( segment.seg(\u0026quot;HanLP中文分词工具包！\u0026quot;));\n    return segment;\n});\n```\n\n## 四、插件特色\n简单介绍一下插件的特点：\n- 内置多种分词模式，适合不同场景；\n- 内置词典，无需额外配置即可使用；\n- 支持外置词典，用户可自定义分词算法，基于词典或是模型；\n- 支持分词器级别的自定义词典，便于用于多租户场景；\n- 支持远程词典热更新（待开发）；\n- 拼音过滤器、繁简体过滤器（待开发）；\n- 基于词语或单字的 ngram 切分分词（待开发）。\n\n\u0026gt; Github 地址：[https://github.com/AnyListen/elasticsearch-analysis-hanlp](https://github.com/AnyListen/elasticsearch-analysis-hanlp)\n","title":"Day 23 - 基于 HanLP 的 ES 中文分词插件","uid":"8031","views":"551","votes":"5"},"_type":"doc"}
{"_id":"6213","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545360655","category_id":"2","comments":"1","has_attach":"1","id":"6213","message":"Elastic Cloud Enterprise 出来也有一年多的时间了。对于这类的开源软件企业版本，基本都是在可管理性和稳定性上面下功夫。但是新产品免不了需要经历一下bug的打磨才会变得成熟。\n\n下面分享的这个案例是当我们在把集群从5.4.1 升级到5.6.12 的过程中，遇到节点关闭受阻，升级不完整等情景。以及对应的处理方法。\n首先在ECE中，版本是通过stack的方式管理\n \n[attach]3343[/attach]\nRef : https://www.elastic.co/guide/en/cloud-enterprise/current/ece-manage-elastic-stack.html\n\n这些版本都是以docker images的形式存储\n\n[attach]3344[/attach]\n因此，ECE根据不同的版本,然后选择对应的docker image就可以创建一个节点了. 那么升级的过程就可以简单分成几个步骤\n\n1.exclude准备升级的节点。\n\n2.停止节点ES进程，更换container 版本。\n\n3.重新启动节点，加入集群。\n\n4.在其他节点上重复以上流程。\n\n在这个过程中, 实际使用的时候发现有一些需要注意的雷区.\n扫雷一：使用UI触发升级，必须保证集群没有自定义插件和bundles\n\nECE 里面的集群操作是通过plan来控制的\n\n[attach]3345[/attach]\n任何的集群操作最终都会生成一个plan的diff。如上图，把集群从5.4.1 升级到 5.6.12 会产生以上diff.\n\n正常情况下是没有问题的.\n\n如果集群配置了自定义bundles, 比如LDAP bundles, ref:https://www.elastic.co/guide/en/cloud-enterprise/current/ece-securing-clusters-LDAP.html\n\n那么在集群的plan里面就会存在这么一段配置\n\n[attach]3346[/attach]\n那么当我们在按下升级按钮的时候\n\n[attach]3347[/attach]\nECE 只在plan中修改了集群大版本的配置, 但是并没有修改自定义bundles中的版本号(仍然是5.4.1).\n\n在这种情况下去执行升级,会直接产生报错.\n\n[attach]3348[/attach]\n界面上没有显示原因, 但是这是因为plan里面大版本和bundle中的版本不一致,然后会导致新增的节点无法启动. 于是ECE 就认为集群升级失败了.\n解决方法是手动编辑plan,把自定义bundles中的版本号改成和集群版本一致\n\n[attach]3349[/attach]\n然后使用ECE 提供的一种手动使用plan进行集群升级的方式进行升级.\n\n扫雷二：节点无法关闭\n\nECE 控制container 是通过一个叫做 constructor的服务。constructor 通过接收集群的更改需求，制定具体的更改计划与步骤，指导allocator对container进行操作。同时也负责保证集群高可靠性，通过Availability Zone的数量在不同的AZ上面部署节点。\n\n当Allocator接受到关闭container命令的时候，会尝试去关闭container，如果container处于一个阻塞状态无法响应, 那么关闭命令无法执行成功。这个时候constructor会等待节点关闭，但是allocator又认为节点已经接受到关闭命令了。又或者constructor发送给allocator的过程中网络丢包, 这个时候allocator 没有正确接受关闭container的命令. 整个升级进程就卡住了。 这种情况十分罕见,通常发现一个container如果处于”正在关闭”时间太久了, 那么通常就是中间的通信出现问题了.\n\n[attach]3350[/attach]\n解决办法是可以通过手动停止container, 在对应的allocator上面找到container，使用\n\ndocker stop \u0026lt;container_name\u0026gt;\n\n停止container，这样可以出发allocator更新container的健康状态,上报这个container已经关闭了, 从而打通流程并执行下一步。\n扫雷三: 多版本并存\n\n如果使用上面的方式强行关闭docker container, 虽然可以让升级进程继续进行下去. 但是被手动关闭的节点会保留原来的版本。于是在升级后查看各个节点的版本，会发现部分节点是5.4.1， 部分是5.6.12.\n\n因为节点是强制关闭的, ECE直接认为节点已经完成升级,并重新启动这个container. 而在这个处理中,跳过了升级docker image的一步.\n\n为什么不是生成一个新的container呢? 因为从plan里面可以看到\n\n[attach]3351[/attach]\n在默认情况下, ECE 处理版本升级是使用rolling 策略 Ref: https://www.elastic.co/guide/en/cloud-enterprise/current/PlanStrategy.html\n\n在这个策略下，ECE会停止当前container并直接修改重启。\n\n如果ECE集群容量允许, 可以改成grow_and_shrink 策略, 这样ECE 会创建新的container并且销毁旧的container, 避免集群出现多版本.\n如果出现了多版本的集群,可以通过更改集群任意一个配置来触发 grow_and_shrink 同样可以使到版本回归一致.\n总结来说ECE 在版本升级方面还是有很多需要改进的地方. 对于ECE用户再说在使用ECE的版本升级功能的时候主要有以下建议\n\n1. 自己学会手动修改plan. 这也是每一个ECE support engineer 都会干的事情.\n\n2.如果集群容量允许,尽量使用 grow_and_shrink的策略来进行集群操作.\n ","title":"Day 21 - ECE 版本升级扫雷实战","uid":"10534","views":"223","votes":"4"},"_type":"doc"}
{"_id":"6147","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542615823","category_id":"12","comments":"0","has_attach":"0","id":"6147","message":"\nElasticsearch相关产品的新功能设计、开发、运营和维护工作；\n 跟进研究业界前沿技术，推动产品技术升级。\n岗位要求：\n编程能力扎实，熟悉Java/C++中的一种，具有良好的数据结构、算法、操作系统等计算机基本知识；\n 熟悉ElasticSearch/Lucene开源系统，有实际开发经验者优先；\n 熟悉Hadoop、HBase、InfluxDB等开源系统，有云计算相关开发经验者优先；\n 具有敏捷开发、完整产品生命周期开发者优先；\n 学习能力强，善于独立思考，思维活跃，对技术有强烈激情。\n \n请发简历至：360608805@qq.com\n ","title":"腾讯云Elasticsearch团队招聘高级后台开发工程师 base深圳","uid":"10474","views":"420","votes":"0"},"_type":"doc"}
{"_id":"6142","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542450982","category_id":"2","comments":"1","has_attach":"0","id":"6142","message":"\u0026gt; ELK Tips 主要介绍一些 ELK 使用过程中的小技巧，内容主要来源为 Elastic 中文社区。\n\n## 一、Logstash\n### 1、Filebeat ：Non-zero metrics in the last 30s\n- 问题表现：Filebeat 无法向 Elasticsearch 发送日志数据；\n- 错误信息：`INFO [monitoring] 1og/log.go:124 Non-zero metrics in the last 30s`；\n- 社区反馈：在 input 和 output 下面添加属性 enabled：true。\n\n```\nfilebeat.inputs:\n- type: log\n  enabled: true\n  paths:\n    - /var/log/*.log\n\noutput.elasticsearch:\n  hosts: [\u0026quot;https://localhost:9200\u0026quot;]\n  username: \u0026quot;filebeat_internal\u0026quot;\n  password: \u0026quot;YOUR_PASSWORD\u0026quot;\n  enabled: true\n```\n\n\u0026gt; input 和 output 下 enabled 属性默认值为 true，因此怀疑另有其因。\n\n### 2、Logstash 按月生成索引\n```\noutput {\n\tif [type] == \u0026quot;typeA\u0026quot;{\n\t\telasticsearch {\n\t\t\thosts  =\u0026gt; \u0026quot;127.0.0.1:9200\u0026quot;\n\t\t\tindex =\u0026gt; \u0026quot;log_%{+YYYY_MM}\u0026quot;\n\t\t}\n\t}\n}\n```\n\n\u0026gt; 按照日的原理类似：%{+YYYY.MM.dd}\n\n### 3、Filebeat 通过配置删除特定字段\nFilebeat 实现了类似 Logstash 中 filter 的功能，叫做处理器（processors），processors 种类不多，尽可能在保持 Filebeat 轻量化的基础上提供更多常用的功能。\n\n下面列几种常用的 processors：\n- `add_cloud_metadata`：添加云服务器的 meta 信息；\n- `add_locale`：添加本地时区；\n- `decode_json_fields`：解析并处理包含 Json 字符串的字段；\n- `drop_event`：丢弃符合条件的消息事件；\n- `drop_fields`：删除符合条件的字段；\n- `include_fields`：选择符合条件的字段；\n- `rename`：字段重命名；\n- `add_kubernetes_metadata`：添加 k8s 的 meta 信息；\n- `add_docker_metadata`：添加容器的 meta 信息；\n- `add_host_metadata`：添加操作系统的 meta 信息；\n- `dissect`：类似与 gork 的正则匹配字段的功能；\n- `dns`：配置 filebeat 独立的 dns 解析方式；\n- `add_process_metadata`：添加进程的元信息。\n\nprocessors 的使用方式：\n```\n- type: \u0026lt;input_type\u0026gt;\n  processors:\n  - \u0026lt;processor_name\u0026gt;:\n      when:\n        \u0026lt;condition\u0026gt;\n      \u0026lt;parameters\u0026gt;\n...\n```\n\n### 4、LogStash 采集 FTP 日志文件\n```\nexec {\n    codec =\u0026gt; plain { }\n    command =\u0026gt; \u0026quot;curl ftp://server/logs.log\u0026quot;\n    interval =\u0026gt; 3000}\n}\n```\n\n### 5、Logstash docker-compose 启动失败（Permission denied）\n在 docker-compose 中使用 user 选项设置使用 root 用户启动 docker，能解决权限问题。\n```\n$ cat docker-compose.yml\n\nversion: '2'\nservices:\n  logstash:\n    image: docker.elastic.co/logstash/logstash:6.4.2\n    user: root\n    command: id\n```\n\n### 6、Metricize filter plugin\n\u0026gt; 将一条消息拆分为多条消息。\n\n```\n# 原始信息\n{\n    type =\u0026gt; \u0026quot;type A\u0026quot;\n    metric1 =\u0026gt; \u0026quot;value1\u0026quot;\n    metric2 =\u0026gt; \u0026quot;value2\u0026quot;\n}\n\n# 配置信息\nfilter {\n  metricize {\n    metrics =\u0026gt; [ \u0026quot;metric1\u0026quot;, \u0026quot;metric2\u0026quot; ]\n  }\n}\n\n# 最终输出\n{                               {\n    type =\u0026gt; \u0026quot;type A\u0026quot;                type =\u0026gt; \u0026quot;type A\u0026quot;\n    metric =\u0026gt; \u0026quot;metric1\u0026quot;             metric =\u0026gt; \u0026quot;metric2\u0026quot;\n    value =\u0026gt; \u0026quot;value1\u0026quot;               value =\u0026gt; \u0026quot;value2\u0026quot;\n}                               }\n```\n\n## 二、Elasticsearch\n### 1、ES 倒排索引内部结构\nLucene 的倒排索引都是按照字段（field）来存储对应的文档信息的，如果 docName 和 docContent 中有“苹果”这个 term，就会有这两个索引链，如下所示：\n```\ndocName：\n\u0026quot;苹果\u0026quot; -\u0026gt; \u0026quot;doc1, doc2, doc3...\u0026quot;\n\ndocContent：\n\u0026quot;苹果\u0026quot; -\u0026gt; \u0026quot;doc2, doc4, doc6...\u0026quot;\n```\n\n### 2、Jest 和 RestHighLevelClient 哪个好用点\nRestHighLevelClient 是官方组件，会一直得到官方的支持，且会与 ES 保持同步更新，推荐使用官方的高阶 API。\n\nJest 由于是社区维护，所以更新会有一定延迟，目前最新版对接 ES6.3.1，近一个月只有四个 issue，说明整体活跃度较低，因此不推荐使用。\n\n此外推荐一份 TransportClient 的中文使用手册，翻译的很不错：[https://github.com/jackiehff/elasticsearch-client-java-api-cn](https://github.com/jackiehff/elasticsearch-client-java-api-cn)。\n\n### 3、ES 单分片使用 From/Size 分页遇到重复数据\n常规情况下 ES 单分片使用 From/Size 是不会遇到数据重复的，数据重复的可能原因有：\n- 没有添加排序；\n- 添加了按得分排序，但是查询语句全部为 filter 过滤条件（此时得分都一致）；\n- 添加了排序，但是有索引中文档的新增、修改、删除等操作。\n\n\u0026gt; 对于多分片，推荐添加 preference 参数来实现分页结果的一致性。\n\n### 4、The number of object passed must be even but was [1]\nES 在调用 setSource 的时候传入 Json 对象后会报错：The number of object passed must be even but was [1]，此时可以推荐将 Json 对象转为 Map 集合，或者把 Json 对象转为 json 字符串，不过传入字符串的时候需要设置类型。\n```\nIndexRequest indexRequest = new IndexRequest(\u0026quot;index\u0026quot;, \u0026quot;type\u0026quot;, \u0026quot;id\u0026quot;);\nJSONObject doc = new JSONObject();\n//indexRequest.source(jsonObject); 错误的使用方法\n//转为 Map 对象\nindexRequest.source(JSONObject.parseObject((String) doc.get(\u0026quot;json\u0026quot;), Map.class));\n//转为 Json 字符串（声明字符串类型）\nindexRequest.source(JSON.toJSONString(doc), XContentType.JSON);\n```\n\n### 5、跨集群搜索\nES 6.X 原生支持跨集群搜索，具体配置请参考：https://www.elastic.co/guide/en/kibana/current/management-cross-cluster-search.html\n```\nPUT _cluster/settings\n{\n  \u0026quot;persistent\u0026quot;: {\n    \u0026quot;cluster\u0026quot;: {\n      \u0026quot;remote\u0026quot;: {\n        \u0026quot;cluster_one\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: [\n            \u0026quot;127.0.0.1:9300\u0026quot;\n          ]\n        },\n        \u0026quot;cluster_two\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: [\n            \u0026quot;127.0.0.1:9301\u0026quot;\n          ]\n        },\n        \u0026quot;cluster_three\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: [\n            \u0026quot;127.0.0.1:9302\u0026quot;\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n\u0026gt; ES 6.5 推出了新功能，跨集群同步（Cross-cluster replication），感兴趣的可以自行了解。\n\n### 6、ES 排序时设置空值排序位置\n```\nGET /_search\n{\n    \u0026quot;sort\u0026quot; : [\n        { \u0026quot;price\u0026quot; : {\u0026quot;missing\u0026quot; : \u0026quot;_last\u0026quot;} }\n    ],\n    \u0026quot;query\u0026quot; : {\n        \u0026quot;term\u0026quot; : { \u0026quot;product\u0026quot; : \u0026quot;chocolate\u0026quot; }\n    }\n}\n```\n\n### 7、ES 冷归档数据如何处理\n使用相对低配的大磁盘机器配置为 ES 的 Warm Nodes，可以通过 `index.routing.allocation.require.box_type` 来设置索引是冷数据或者热数据。如果索引极少使用，可以 close 索引，然后在需要搜索的时候 open 即可。\n\n### 8、ES 相似文章检测\n对于大文本的去重，可以参考 SimHash 算法，通过 SimHash 可以提取到文档指纹（64位），两篇文章通过 SimHash 计算海明距离即可判断是否重复。海明距离计算，可以通过插件实现：https://github.com/joway/elasticsearch-hamming-plugin\n\n### 9、Terms 聚合查询优化\n- 如果只需要聚合后前 N 条记录，推荐在 Terms 聚合时添加上 `\u0026quot;collect_mode\u0026quot;: \u0026quot;breadth_first\u0026quot;`；\n- 此外可以通过设置 `\u0026quot;min_doc_count\u0026quot;: 10`来限制最小匹配文档数；\n- 如果对返回的 Term 有所要求，可以通过设置 `include` 和 `exclude` 来过滤 Term；\n- 如果想获取全部 Term 聚合结果，但是聚合结果又很多，可以考虑将聚合分成多个批次分别取回（Filtering Values with partitions）。\n\n### 10、Tomcat 字符集造成的 ES 查询无结果\n两个系统连接同一个 ES 服务，配置和代码完全一致，同一个搜索条件，一个能够搜索出来东西，一个什么都搜索不出来，排查结果是因为其中一个系统的 tomcat 配置有问题，导致请求的时候乱码了，所以搜不到数据。\n\n### 11、ES 索引设置默认分词器\n默认情况下，如果字段不指定分词器，ES 或使用 standard 分词器进行分词；可以通过下面的设置更改默认的分词器。\n\n\u0026gt; 2.X 支持设置默认的索引分词器（default_index）和默认的查询分词器（default_search），6.X 已经不再支持。\n\n```\nPUT /index\n{\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;analysis\u0026quot;: {\n      \u0026quot;analyzer\u0026quot;: {\n        \u0026quot;default\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n          \u0026quot;tokenizer\u0026quot;: \u0026quot;ik_max_word\u0026quot;\n        }\n      }\n    }\n  }\n}\n```\n\n### 12、ES 中的魔法参数\n- 索引名：_index\n- 类型名：_type\n- 文档Id：_id\n- 得分：_score\n- 索引排序：_doc\n\n\u0026gt; 如果你对排序没有特别的需求，推荐使用 _doc 进行排序，例如执行 Scroll 操作时。\n\n### 13、ES 延迟执行数据上卷（Rollup ）\nRollup job 有个 delay 参数控制 job 执行的延迟时间，默认情况下不延迟执行，这样如果某个 interval 的数据已经聚合好了，该 interval 迟到的数据是不会处理的。  \n\n好在 rollup api 可以支持同时搜索裸索引和 rollup 过的索引，所以如果数据经常有延迟的话，可以考虑设置一个合适的 delay，比如 1h、6h 甚至 24h，这样 rollup 的索引产生会有延迟，但是能确保迟到的数据被处理。\n\n从应用场景上看，rollup 一般是为了对历史数据做聚合存放，减少存储空间，所以延迟几个小时，甚至几天都是合理的。搜索的时候，同时搜索最近的裸索引和历史的 rollup 索引，就能将两者的数据组合起来，在给出正确的聚合结果的情况下，又兼顾了性能。\n\n\u0026gt; Rollup 是实验性功能，不过非常有用，特别是使用 ES 做数据仓库的场景。\n\n### 14、ES6.x 获取所有的聚合结果\nES2.x 版本中，在聚合查询时，通过设置 `setSize(0)` 就可以获取所有的聚合结果，在ES6.x 中直接设置 `setSize(Integer.MAX_VALUE)` 等效于 2.x 中设置为 0。\n\n### 15、ES Jar 包冲突问题\n经常会遇到 ES 与业务集成时出现 Jar 包冲突问题，推荐的解决方法是使用 `maven-shade-plugin` 插件，该插件通过将冲突的 Jar 包更换一个命名空间的方式来解决 Jar 包的冲突问题，具体使用可以参考文章：[https://www.jianshu.com/p/d9fb7afa634d](https://www.jianshu.com/p/d9fb7afa634d)。\n```\n\u0026lt;plugins\u0026gt;\n    \u0026lt;plugin\u0026gt;\n        \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\n        \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;2.4.1\u0026lt;/version\u0026gt;\n        \u0026lt;configuration\u0026gt;\n            \u0026lt;createDependencyReducedPom\u0026gt;false\u0026lt;/createDependencyReducedPom\u0026gt;\n        \u0026lt;/configuration\u0026gt;\n        \u0026lt;executions\u0026gt;\n            \u0026lt;execution\u0026gt;\n                \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\n                \u0026lt;goals\u0026gt;\n                    \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\n                \u0026lt;/goals\u0026gt;\n                \u0026lt;configuration\u0026gt;\n                    \u0026lt;relocations\u0026gt;\n                        \u0026lt;relocation\u0026gt;\n                            \u0026lt;pattern\u0026gt;com.google.guava\u0026lt;/pattern\u0026gt;\n                            \u0026lt;shadedPattern\u0026gt;net.luculent.elasticsearch.guava\u0026lt;/shadedPattern\u0026gt;\n                        \u0026lt;/relocation\u0026gt;\n                        \u0026lt;relocation\u0026gt;\n                            \u0026lt;pattern\u0026gt;com.fasterxml.jackson\u0026lt;/pattern\u0026gt;\n                            \u0026lt;shadedPattern\u0026gt;net.luculent.elasticsearch.jackson\u0026lt;/shadedPattern\u0026gt;\n                        \u0026lt;/relocation\u0026gt;\n                        \u0026lt;relocation\u0026gt;\n                            \u0026lt;pattern\u0026gt;org.joda\u0026lt;/pattern\u0026gt;\n                            \u0026lt;shadedPattern\u0026gt;net.luculent.elasticsearch.joda\u0026lt;/shadedPattern\u0026gt;\n                        \u0026lt;/relocation\u0026gt;\n                        \u0026lt;relocation\u0026gt;\n                            \u0026lt;pattern\u0026gt;com.google.common\u0026lt;/pattern\u0026gt;\n                            \u0026lt;shadedPattern\u0026gt;net.luculent.elasticsearch.common\u0026lt;/shadedPattern\u0026gt;\n                        \u0026lt;/relocation\u0026gt;\n                        \u0026lt;relocation\u0026gt;\n                            \u0026lt;pattern\u0026gt;com.google.thirdparty\u0026lt;/pattern\u0026gt;\n                            \u0026lt;shadedPattern\u0026gt;net.luculent.elasticsearch.thirdparty\u0026lt;/shadedPattern\u0026gt;\n                        \u0026lt;/relocation\u0026gt;\n                    \u0026lt;/relocations\u0026gt;\n                    \u0026lt;transformers\u0026gt;\n                        \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot; /\u0026gt;\n                        \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot;/\u0026gt;\n                    \u0026lt;/transformers\u0026gt;\n                \u0026lt;/configuration\u0026gt;\n            \u0026lt;/execution\u0026gt;\n        \u0026lt;/executions\u0026gt;\n    \u0026lt;/plugin\u0026gt;\n\u0026lt;/plugins\u0026gt;\n```\n### 16、ES 如何选择 Shard 存储文档?\nES 采用 djb2 哈希算法对要索引文档的指定（或者默认随机生成的）`_id` 进行哈希，得到哈希结果后对索引 shard 数目 n 取模，公式如下：`hash(_id) % n`；根据取模结果决定存储到哪一个 shard 。\n\n## 三、Kibana\n### 1、在 Kiabana 的 Discovery 界面显示自定义字段\nKibana 的 Discovery 界面默认只显示 time 和 _source 两个字段，这个界面的左半部分，在 Popular 下面展示了很多，你只需要在你需要展示的字段后面点击 add  即可将自定义的字段添加到 discovery 界面。 \n\n![在 Kiabana 的 Discovery 界面显示自定义字段](http://img.luooqi.com/Fv105mwWpbfcfBGfVNYDxFKaXxIa)\n\n### 2、filebeat 的 monitor 指标的说明\n- **Total**：'All events newly created in the publishing pipeline'\n- **Emitted**： 'Events processed by the output (including retries)'\n- **Acknowledged**：'Events acknowledged by the output (includes events dropped by the output)'\n- **Queued**：'Events added to the event pipeline queue'\n\n## 四、社区文章精选\n- [Elastic认证考试心得](https://note.youdao.com/)\n- [一文快速上手Logstash](https://elasticsearch.cn/article/6141)\n- [当Elasticsearch遇见Kafka--Kafka Connect](https://elasticsearch.cn/article/6140)\n- [elasticsearch冷热数据读写分离](https://elasticsearch.cn/article/6127)\n- [elasticsearch优秀实践](https://elasticsearch.cn/article/6126)\n- [ELK 使用小技巧（第 1 期）](https://elasticsearch.cn/article/1006)\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](http://img.luooqi.com/FoE5jYLo6p4UVmGN8GPjCZz8Xete)","title":"ELK 使用小技巧（第 2 期）","uid":"8031","views":"383","votes":"6"},"_type":"doc"}
{"_id":"6141","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542425085","category_id":"3","comments":"3","has_attach":"0","id":"6141","message":"*本文同步发布在腾讯云+社区Elasticsearch专栏：https://cloud.tencent.com/developer/column/4008*  \n**Elasticsearch**是当前主流的分布式大数据存储和搜索引擎，可以为用户提供强大的全文本检索能力，广泛应用于日志检索，全站搜索等领域。**Logstash**作为Elasicsearch常用的实时数据采集引擎，可以采集来自不同数据源的数据，并对数据进行处理后输出到多种输出源，是Elastic Stack 的重要组成部分。本文从Logstash的工作原理，使用示例，部署方式及性能调优等方面入手，为大家提供一个快速入门Logstash的方式。文章最后也给出了一些深入了解Logstash的的链接，以方便大家根据需要详细了解。\n\n![Logstash简介](https://main.qcloudimg.com/raw/8dcab6bc4b83d84cf4b2008a4df1c8f8.png)\n\n## 1 Logstash工作原理\n\n### 1.1 处理过程\n\n![Logstash处理过程](https://main.qcloudimg.com/raw/7367005a46890c48d27e8518a14a1772.png)\n\n如上图，Logstash的数据处理过程主要包括：**Inputs**, **Filters**, **Outputs** 三部分， 另外在Inputs和Outputs中可以使用**Codecs**对数据格式进行处理。这四个部分均以插件形式存在，用户通过定义pipeline配置文件，设置需要使用的input，filter，output, codec插件，以实现特定的数据采集，数据处理，数据输出等功能  \n\n- （1）**Inputs**：用于从数据源获取数据，常见的插件如file, syslog, redis, beats 等[[详细参考](https://www.elastic.co/guide/en/logstash/5.6/input-plugins.html)]  \n- （2）**Filters**：用于处理数据如格式转换，数据派生等，常见的插件如grok, mutate, drop,  clone, geoip等[[详细参考](https://www.elastic.co/guide/en/logstash/5.6/output-plugins.html)]  \n- （3）**Outputs**：用于数据输出，常见的插件如elastcisearch，file, graphite, statsd等[[详细参考](https://www.elastic.co/guide/en/logstash/5.6/filter-plugins.html)]  \n- （4）**Codecs**：Codecs不是一个单独的流程，而是在输入和输出等插件中用于数据转换的模块，用于对数据进行编码处理，常见的插件如json，multiline[[详细参考](https://www.elastic.co/guide/en/logstash/5.6/codec-plugins.html)]\n\n可以点击每个模块后面的_详细参考_链接了解该模块的插件列表及对应功能 \n\n### 1.2 执行模型：\n\n- （1）每个Input启动一个线程，从对应数据源获取数据  \n- （2）Input会将数据写入一个队列：默认为内存中的有界队列（意外停止会导致数据丢失）。为了防止数丢失Logstash提供了两个特性：\n[Persistent Queues](https://www.elastic.co/guide/en/logstash/current/persistent-queues.html)：通过磁盘上的queue来防止数据丢失\n [Dead Letter Queues](https://www.elastic.co/guide/en/logstash/current/dead-letter-queues.html)：保存无法处理的event（仅支持Elasticsearch作为输出源）  \n- （3）Logstash会有多个pipeline worker, 每一个pipeline worker会从队列中取一批数据，然后执行filter和output（worker数目及每次处理的数据量均由配置确定）\n\n## 2 Logstash使用示例\n\n### 2.1 Logstash Hello world\n\n第一个示例Logstash将采用标准输入和标准输出作为input和output，并且不指定filter\n\n- （1）下载Logstash并解压（需要预先安装JDK8）  \n- （2）cd到Logstash的根目录，并执行启动命令如下：\t \n\n```\n    cd logstash-6.4.0\n    bin/logstash -e 'input { stdin { } } output { stdout {} }'\n```\n\n- （3）此时Logstash已经启动成功，-e表示在启动时直接指定pipeline配置，当然也可以将该配置写入一个配置文件中，然后通过指定配置文件来启动\n- （4）在控制台输入：hello world，可以看到如下输出： \n\n```\n    {\n    \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n    \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;localhost\u0026quot;,\n    \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-09-18T12:39:38.514Z,\n    \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;hello world\u0026quot;\n    }  \n```\n\nLogstash会自动为数据添加@version, host, @timestamp等字段\n\n在这个示例中Logstash从标准输入中获得数据，仅在数据中添加一些简单字段后将其输出到标准输出。\n\n### 2.2 日志采集\n\n这个示例将采用Filebeat input插件(Elastic Stack中的轻量级数据采集程序)采集本地日志，然后将结果输出到标准输出\n\n- （1）下载示例使用的日志文件[[地址](https://download.elastic.co/demos/logstash/gettingstarted/logstash-tutorial.log.gz)]，解压并将日志放在一个确定位置\n- （2）安装filebeat，配置并启动[[参考](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-getting-started.html)]   \n\nfilebeat.yml配置如下（paths改为日志实际位置，不同版本beats配置可能略有变化，请根据情况调整）\n\n```\n    filebeat.prospectors:\n    - input\\_type: log\n        paths:\n            - /path/to/file/logstash-tutorial.log \n    output.logstash:\n        hosts: \u0026quot;localhost:5044\u0026quot;\n```\n\n启动命令：  \n\n```\n    ./filebeat -e -c filebeat.yml -d \u0026quot;publish\u0026quot;\n```\n\n- （3）配置logstash并启动\n\n1）创建first-pipeline.conf文件内容如下（该文件为pipeline配置文件，用于指定input，filter, output等）：\n\n```\n    input {\n        beats {\n            port =\u0026gt; \u0026quot;5044\u0026quot;\n        }\n    }\n    #filter {\n    #}\n    output {\n        stdout { codec =\u0026gt; rubydebug }\n    }\n```\n\ncodec =\u0026gt; rubydebug用于美化输出[[参考](https://www.elastic.co/guide/en/logstash/6.4/plugins-codecs-rubydebug.html)]  \n\n2）验证配置（注意指定配置文件的路径）：\n\n```\n    ./bin/logstash -f first-pipeline.conf --config.test_and_exit\n```\n\n3）启动命令：\n\n```\n    ./bin/logstash -f first-pipeline.conf --config.reload.automatic\n```\n\n--config.reload.automatic选项启用动态重载配置功能\n\n4）预期结果：\n\n可以在Logstash的终端显示中看到，日志文件被读取并处理为如下格式的多条数据  \n\n```\n    {\n        \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-10-09T12:22:39.742Z,\n            \u0026quot;offset\u0026quot; =\u0026gt; 24464,\n          \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n        \u0026quot;input_type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n              \u0026quot;beat\u0026quot; =\u0026gt; {\n                \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n            \u0026quot;hostname\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n             \u0026quot;version\u0026quot; =\u0026gt; \u0026quot;5.6.10\u0026quot;\n        },\n              \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n            \u0026quot;source\u0026quot; =\u0026gt; \u0026quot;/data/home/michelmu/workspace/logstash-tutorial.log\u0026quot;,\n           \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;86.1.76.62 - - [04/Jan/2015:05:30:37 +0000] \\\u0026quot;GET /style2.css HTTP/1.1\\\u0026quot; 200 4877 \\\u0026quot;http://www.semicomplete.com/projects/xdotool/\\\u0026quot; \\\u0026quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\\\u0026quot;\u0026quot;,\n              \u0026quot;type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n              \u0026quot;tags\u0026quot; =\u0026gt; [\n            [0] \u0026quot;beats_input_codec_plain_applied\u0026quot;\n        ]\n    }\n```\n\n相对于示例2.1，该示例使用了filebeat input插件从日志中获取一行记录，这也是Elastic stack获取日志数据最常见的一种方式。另外该示例还采用了rubydebug codec 对输出的数据进行显示美化。\n\n### 2.3 日志格式处理\n\n可以看到虽然示例2.2使用filebeat从日志中读取数据，并将数据输出到标准输出，但是日志内容作为一个整体被存放在message字段中，这样对后续存储及查询都极为不便。可以为该pipeline指定一个[grok filter](https://www.elastic.co/guide/en/logstash/6.4/plugins-filters-grok.html)来对日志格式进行处理\n\n- （1）在first-pipeline.conf中增加filter配置如下  \n\n```\n    input {\n        beats {\n            port =\u0026gt; \u0026quot;5044\u0026quot;\n        }\n    }\n    filter {\n        grok {\n            match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{COMBINEDAPACHELOG}\u0026quot;}\n        }\n    }\n    output {\n        stdout { codec =\u0026gt; rubydebug }\n    }\n```\n\n- （2）到filebeat的根目录下删除之前上报的数据历史(以便重新上报数据),并重启filebeat\t\n\n```\n    sudo rm data/registry\n    sudo ./filebeat -e -c filebeat.yml -d \u0026quot;publish\u0026quot;\n```\n\n- （3）由于之前启动Logstash设置了自动更新配置，因此Logstash不需要重新启动，这个时候可以获取到的日志数据如下：  \n\n```\n    {\n            \u0026quot;request\u0026quot; =\u0026gt; \u0026quot;/style2.css\u0026quot;,\n              \u0026quot;agent\u0026quot; =\u0026gt; \u0026quot;\\\u0026quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\\\u0026quot;\u0026quot;,\n             \u0026quot;offset\u0026quot; =\u0026gt; 24464,\n               \u0026quot;auth\u0026quot; =\u0026gt; \u0026quot;-\u0026quot;,\n              \u0026quot;ident\u0026quot; =\u0026gt; \u0026quot;-\u0026quot;,\n         \u0026quot;input_type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n               \u0026quot;verb\u0026quot; =\u0026gt; \u0026quot;GET\u0026quot;,\n             \u0026quot;source\u0026quot; =\u0026gt; \u0026quot;/data/home/michelmu/workspace/logstash-tutorial.log\u0026quot;,\n            \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;86.1.76.62 - - [04/Jan/2015:05:30:37 +0000] \\\u0026quot;GET /style2.css HTTP/1.1\\\u0026quot; 200 4877 \\\u0026quot;http://www.semicomplete.com/projects/xdotool/\\\u0026quot; \\\u0026quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\\\u0026quot;\u0026quot;,\n               \u0026quot;type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n               \u0026quot;tags\u0026quot; =\u0026gt; [\n            [0] \u0026quot;beats_input_codec_plain_applied\u0026quot;\n        ],\n           \u0026quot;referrer\u0026quot; =\u0026gt; \u0026quot;\\\u0026quot;http://www.semicomplete.com/projects/xdotool/\\\u0026quot;\u0026quot;,\n         \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-10-09T12:24:21.276Z,\n           \u0026quot;response\u0026quot; =\u0026gt; \u0026quot;200\u0026quot;,\n              \u0026quot;bytes\u0026quot; =\u0026gt; \u0026quot;4877\u0026quot;,\n           \u0026quot;clientip\u0026quot; =\u0026gt; \u0026quot;86.1.76.62\u0026quot;,\n           \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n               \u0026quot;beat\u0026quot; =\u0026gt; {\n                \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n            \u0026quot;hostname\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n             \u0026quot;version\u0026quot; =\u0026gt; \u0026quot;5.6.10\u0026quot;\n        },\n               \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n        \u0026quot;httpversion\u0026quot; =\u0026gt; \u0026quot;1.1\u0026quot;,\n          \u0026quot;timestamp\u0026quot; =\u0026gt; \u0026quot;04/Jan/2015:05:30:37 +0000\u0026quot;\n    }\n```\n\n可以看到message中的数据被详细解析出来了\n\n### 2.4 数据派生和增强\n\nLogstash中的一些filter可以根据现有数据生成一些新的数据，如[geoip](https://www.elastic.co/guide/en/logstash/6.4/plugins-filters-geoip.html)可以根据ip生成经纬度信息\n\n- （1）在first-pipeline.conf中增加geoip配置如下  \n\n```\n    input {\n        beats {\n            port =\u0026gt; \u0026quot;5044\u0026quot;\n        }\n    }\n     filter {\n        grok {\n            match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{COMBINEDAPACHELOG}\u0026quot;}\n        }\n        geoip {\n            source =\u0026gt; \u0026quot;clientip\u0026quot;\n        }\n    }\n    output {\n        stdout { codec =\u0026gt; rubydebug }\n    }\n```\n\n- （2）如2.3一样清空filebeat历史数据，并重启\n- （3）当然Logstash仍然不需要重启，可以看到输出变为如下：  \n\n```\n    {\n            \u0026quot;request\u0026quot; =\u0026gt; \u0026quot;/style2.css\u0026quot;,\n              \u0026quot;agent\u0026quot; =\u0026gt; \u0026quot;\\\u0026quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\\\u0026quot;\u0026quot;,\n              \u0026quot;geoip\u0026quot; =\u0026gt; {\n                  \u0026quot;timezone\u0026quot; =\u0026gt; \u0026quot;Europe/London\u0026quot;,\n                        \u0026quot;ip\u0026quot; =\u0026gt; \u0026quot;86.1.76.62\u0026quot;,\n                  \u0026quot;latitude\u0026quot; =\u0026gt; 51.5333,\n            \u0026quot;continent_code\u0026quot; =\u0026gt; \u0026quot;EU\u0026quot;,\n                 \u0026quot;city_name\u0026quot; =\u0026gt; \u0026quot;Willesden\u0026quot;,\n              \u0026quot;country_name\u0026quot; =\u0026gt; \u0026quot;United Kingdom\u0026quot;,\n             \u0026quot;country_code2\u0026quot; =\u0026gt; \u0026quot;GB\u0026quot;,\n             \u0026quot;country_code3\u0026quot; =\u0026gt; \u0026quot;GB\u0026quot;,\n               \u0026quot;region_name\u0026quot; =\u0026gt; \u0026quot;Brent\u0026quot;,\n                  \u0026quot;location\u0026quot; =\u0026gt; {\n                \u0026quot;lon\u0026quot; =\u0026gt; -0.2333,\n                \u0026quot;lat\u0026quot; =\u0026gt; 51.5333\n            },\n               \u0026quot;postal_code\u0026quot; =\u0026gt; \u0026quot;NW10\u0026quot;,\n               \u0026quot;region_code\u0026quot; =\u0026gt; \u0026quot;BEN\u0026quot;,\n                 \u0026quot;longitude\u0026quot; =\u0026gt; -0.2333\n        },\n             \u0026quot;offset\u0026quot; =\u0026gt; 24464,\n               \u0026quot;auth\u0026quot; =\u0026gt; \u0026quot;-\u0026quot;,\n              \u0026quot;ident\u0026quot; =\u0026gt; \u0026quot;-\u0026quot;,\n         \u0026quot;input_type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n               \u0026quot;verb\u0026quot; =\u0026gt; \u0026quot;GET\u0026quot;,\n             \u0026quot;source\u0026quot; =\u0026gt; \u0026quot;/data/home/michelmu/workspace/logstash-tutorial.log\u0026quot;,\n            \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;86.1.76.62 - - [04/Jan/2015:05:30:37 +0000] \\\u0026quot;GET /style2.css HTTP/1.1\\\u0026quot; 200 4877 \\\u0026quot;http://www.semicomplete.com/projects/xdotool/\\\u0026quot; \\\u0026quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\\\u0026quot;\u0026quot;,\n               \u0026quot;type\u0026quot; =\u0026gt; \u0026quot;log\u0026quot;,\n               \u0026quot;tags\u0026quot; =\u0026gt; [\n            [0] \u0026quot;beats_input_codec_plain_applied\u0026quot;\n        ],\n           \u0026quot;referrer\u0026quot; =\u0026gt; \u0026quot;\\\u0026quot;http://www.semicomplete.com/projects/xdotool/\\\u0026quot;\u0026quot;,\n         \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-10-09T12:37:46.686Z,\n           \u0026quot;response\u0026quot; =\u0026gt; \u0026quot;200\u0026quot;,\n              \u0026quot;bytes\u0026quot; =\u0026gt; \u0026quot;4877\u0026quot;,\n           \u0026quot;clientip\u0026quot; =\u0026gt; \u0026quot;86.1.76.62\u0026quot;,\n           \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n               \u0026quot;beat\u0026quot; =\u0026gt; {\n                \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n            \u0026quot;hostname\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n             \u0026quot;version\u0026quot; =\u0026gt; \u0026quot;5.6.10\u0026quot;\n        },\n               \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;VM_136_9_centos\u0026quot;,\n        \u0026quot;httpversion\u0026quot; =\u0026gt; \u0026quot;1.1\u0026quot;,\n          \u0026quot;timestamp\u0026quot; =\u0026gt; \u0026quot;04/Jan/2015:05:30:37 +0000\u0026quot;\n    }\n```\n\n可以看到根据ip派生出了许多地理位置信息数据\n\n### 2.5 将数据导入Elasticsearch\n\nLogstash作为Elastic stack的重要组成部分，其最常用的功能是将数据导入到Elasticssearch中。将Logstash中的数据导入到Elasticsearch中操作也非常的方便，只需要在pipeline配置文件中增加Elasticsearch的output即可。\n\n- （1）首先要有一个已经部署好的Logstash，当然可以使用腾讯云快速创建一个Elasticsearch[创建地址](https://console.cloud.tencent.com/es)\n- （2）在first-pipeline.conf中增加Elasticsearch的配置，如下  \n\n```\n   input {\n        beats {\n            port =\u0026gt; \u0026quot;5044\u0026quot;\n        }\n    }\n     filter {\n        grok {\n            match =\u0026gt; { \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;%{COMBINEDAPACHELOG}\u0026quot;}\n        }\n        geoip {\n            source =\u0026gt; \u0026quot;clientip\u0026quot;\n        }\n    }\n    output {\n        elasticsearch {\n            hosts =\u0026gt; [ \u0026quot;localhost:9200\u0026quot; ]\n        }\n    }\n```\n\n- （3）清理filebeat历史数据，并重启\n- （4）查询Elasticsearch确认数据是否正常上传（注意替换查询语句中的日期）  \n\n```\n    curl -XGET 'http://172.16.16.17:9200/logstash-2018.10.09/_search?pretty\u0026amp;q=response=200'\n```\n\n- （5）如果Elasticsearch关联了Kibana也可以使用kibana查看数据是否正常上报\n\n![kibana图示](https://main.qcloudimg.com/raw/2ff1b0162995971ff16e12d48dde3ce5.png)\n\nLogstash提供了大量的Input, filter, output, codec的插件，用户可以根据自己的需要，使用一个或多个组件实现自己的功能，当然用户也可以自定义插件以实现更为定制化的功能。自定义插件可以参考[[logstash input插件开发](https://cloud.tencent.com/developer/article/1171033)]\n\n## 3 部署Logstash\n\n演示过如何快速使用Logstash后，现在详细讲述一下Logstash的部署方式。\n\n### 3.1 安装\n\n- **安装JDK**：Logstash采用JRuby编写，运行需要JDK环境，因此安装Logstash前需要先安装JDK。（当前6.4仅支持JDK8）\n- **安装Logstash**：可以采用直接下载压缩包方式安装，也通过APT或YUM安装，另外Logstash支持安装到Docker中。[[Logstash安装参考](https://www.elastic.co/guide/en/logstash/current/installing-logstash.html)]\n- **安装X-PACK**：在6.3及之后版本X-PACK会随Logstash安装，在此之前需要手动安装[[参考链接](https://www.elastic.co/guide/en/logstash/6.2/installing-xpack-log.html)]\n\n### 3.2 目录结构\n\nlogstash的目录主要包括：**根目录**、**bin目录**、**配置目录**、**日志目录**、**插件目录**、**数据目录**  \n\n不同安装方式各目录的默认位置参考[[此处](https://www.elastic.co/guide/en/logstash/current/dir-layout.html)]  \n\n### 3.3 配置文件\n\n- Pipeline配置文件，名称可以自定义，在启动Logstash时显式指定，编写方式可以参考前面示例，对于具体插件的配置方式参见具体插件的说明(使用Logstash时必须配置)：\n用于定义一个pipeline，数据处理方式和输出源\n- Settings配置文件(可以使用默认配置)：\n在使用Logstash时可以不用设置，用于性能调优，日志记录等\n    - logstash.yml：用于控制logstash的执行过程[[参考链接](https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html)] \n    - pipelines.yml: 如果有多个pipeline时使用该配置来配置多pipeline执行[[参考链接](https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html)]\n    - jvm.options：jvm的配置\n    - log4j2.properties:log4j 2的配置，用于记录logstash运行日志[[参考链接](https://www.elastic.co/guide/en/logstash/current/logging.html#log4j2)]\n    - startup.options: 仅适用于Lniux系统，用于设置系统启动项目！\n- 为了保证敏感配置的安全性，logstash提供了配置加密功能[[参考链接](https://www.elastic.co/guide/en/logstash/current/keystore.html)]\n\n### 3.4 启动关闭方式\n\n#### 3.4.1 启动\n\n- [命令行启动](https://www.elastic.co/guide/en/logstash/current/running-logstash-command-line.html)\n- [在debian和rpm上以服务形式启动](https://www.elastic.co/guide/en/logstash/current/running-logstash.html) \n- [在docker中启动](https://www.elastic.co/guide/en/logstash/current/docker.html)3.4.2 关闭\n- [关闭Logstash](https://www.elastic.co/guide/en/logstash/current/shutdown.html)\n- Logstash的关闭时会先关闭input停止输入，然后处理完所有进行中的事件，然后才完全停止，以防止数据丢失，但这也导致停止过程出现延迟或失败的情况。\n\n### 3.5 扩展Logstash\n\n当单个Logstash无法满足性能需求时，可以采用横向扩展的方式来提高Logstash的处理能力。横向扩展的多个Logstash相互独立，采用相同的pipeline配置，另外可以在这多个Logstash前增加一个LoadBalance，以实现多个Logstash的负载均衡。\n\n## 4 性能调优\n\n[[详细调优参考](https://www.elastic.co/guide/en/logstash/current/performance-tuning.html)]\n\n- （1）**Inputs和Outputs的性能**：当输入输出源的性能已经达到上限，那么性能瓶颈不在Logstash，应优先对输入输出源的性能进行调优。  \n- （2）**系统性能指标**：\n    - **CPU**：确定CPU使用率是否过高，如果CPU过高则先查看JVM堆空间使用率部分，确认是否为GC频繁导致，如果GC正常，则可以通过调节Logstash worker相关配置来解决。\n    - **内存**：由于Logstash运行在JVM上，因此注意调整JVM堆空间上限，以便其有足够的运行空间。另外注意Logstash所在机器上是否有其他应用占用了大量内存，导致Logstash内存磁盘交换频繁。\n    - **I/O使用率**：\n1）_磁盘IO_：\n磁盘IO饱和可能是因为使用了会导致磁盘IO饱和的创建（如file output）,另外Logstash中出现错误产生大量错误日志时也会导致磁盘IO饱和。Linux下可以通过iostat, dstat等查看磁盘IO情况\n  2）_网络IO_：\n网络IO饱和一般发生在使用有大量网络操作的插件时。linux下可以使用dstat或iftop等查看网络IO情况\n- （3）**JVM堆检查**：      \n    - 如果JVM堆大小设置过小会导致GC频繁，从而导致CPU使用率过高  \n    - 快速验证这个问题的方法是double堆大小，看性能是否有提升。注意要给系统至少预留1GB的空间。  \n    - 为了精确查找问题可以使用jmap或VisualVM。[[参考](https://www.elastic.co/guide/en/logstash/current/tuning-logstash.html#profiling-the-heap)]  \n    - 设置Xms和Xmx为相同值，防止堆大小在运行时调整，这个过程非常消耗性能。  \n- （4）**Logstash worker设置**：\nworker相关配置在logstash.yml中，主要包括如下三个：\n    - _pipeline.workers_：\n    该参数用以指定Logstash中执行filter和output的线程数，当如果发现CPU使用率尚未达到上限，可以通过调整该参数，为Logstash提供更高的性能。建议将Worker数设置适当超过CPU核数可以减少IO等待时间对处理过程的影响。实际调优中可以先通过-w指定该参数，当确定好数值后再写入配置文件中。\n    - _pipeline.batch.size_:\n    该指标用于指定单个worker线程一次性执行flilter和output的event批量数。增大该值可以减少IO次数，提高处理速度，但是也以为这增加内存等资源的消耗。当与Elasticsearch联用时，该值可以用于指定Elasticsearch一次bluck操作的大小。\n    - _pipeline.batch.delay_:\n    该指标用于指定worker等待时间的超时时间，如果worker在该时间内没有等到pipeline.batch.size个事件，那么将直接开始执行filter和output而不再等待。\n\n### 结束语\n\nLogstash作为Elastic Stack的重要组成部分，在Elasticsearch数据采集和处理过程中扮演着重要的角色。本文通过简单示例的演示和Logstash基础知识的铺陈，希望可以帮助初次接触Logstash的用户对Logstash有一个整体认识，并能较为快速上手。对于Logstash的高阶使用，仍需要用户在使用过程中结合实际情况查阅相关资源深入研究。当然也欢迎大家积极交流，并对文中的错误提出宝贵意见。\n\n### MORE:\n\n- [Logstash数据处理常见示例](https://www.elastic.co/guide/en/logstash/current/transformation.html)\n- [Logstash日志相关配置参考](https://www.elastic.co/guide/en/logstash/current/logging.html)\n- [Kibana管理Logstash pipeline配置](https://www.elastic.co/guide/en/logstash/current/logstash-centralized-pipeline-management.html)\n- [LogstashModule](https://www.elastic.co/guide/en/logstash/current/logstash-modules.html)\n- [监控Logstash](https://www.elastic.co/guide/en/logstash/current/monitoring-logstash.html)","title":"一文快速上手Logstash","uid":"8587","views":"810","votes":"3"},"_type":"doc"}
{"_id":"6136","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542245221","category_id":"11","comments":"3","has_attach":"1","id":"6136","message":"由于 ES开源了X-PACK代码，现在6.4.3版本与6.3以及以下的有变化\n我基于最新的版本整理了下启用X-PACK功能。坑比较多，给我的感觉与searchguard 搞得越来越像了……\n比较坑的是 transport（9300） 必须要用SSL…… 大家注意下。 6比5复杂多了……\n \n[b]Configure each node to:\nRequired: Enable TLS on the transport layer.\nRecommended: Enable TLS on the HTTP layer.[/b]\n \n参考：\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.4/configuring-security.html\n[list=1]\n[*]ES 设置[/*]\n[*]配置 TLS/SSL[/*]\n[*]配置ES（x-pack认证）[/*]\n[*]启动ES[/*]\n[*]配置密码[/*]\n[*]配置kibana[/*]\n[/list]\n 1 Elasticsearch.yml 文件添加内容\nxpack.security.enabled: true\n2 .1生成CA证书\n./elasticsearch-certutil ca\n2.2 生成客户端证书\n./elasticsearch-certutil cert --ca\n2.3ES启用SSL配置文件\nxpack.security.transport.ssl.verification_mode: certificate\nxpack.security.transport.ssl.keystore.path: xxx.p12\nxpack.security.transport.ssl.truststore.path: xxx.p12\n2.4 keystore 添加内容\n./elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password\n3启用相关功能\n[quote]\nxpack.monitoring.enabled: true\nxpack.graph.enabled: true\nxpack.ml.enabled: true\nxpack.security.enabled: true\nxpack.watcher.enabled: true\nxpack.security.authc.accept_default_password: false\nxpack.security.transport.ssl.enabled: true\nxpack.monitoring.collection.cluster.stats.timeout: 30m\nxpack.monitoring.collection.index.stats.timeout: 30m\nxpack.monitoring.collection.index.recovery.active_only: true\nxpack.monitoring.collection.index.recovery.timeout: 30m\nxpack.monitoring.history.duration: 3650d\n[/quote]\n4 启动ES\n./elasticsearch -d 每台\n5配置密码\n./elasticsearch-setup-passwords\n 6汉化kibana 这玩意我还没有整理完，5差不多搞完了。\n7开始浪\n\n6版本\n[attach]3126[/attach]\n5版本\n\n[attach]3129[/attach]\n\n[attach]3127[/attach]\n\n[attach]3128[/attach]","title":"ES 6.4.3 X-PACK 启用安装配置","uid":"4062","views":"811","votes":"2"},"_type":"doc"}
{"_id":"6134","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542178061","category_id":"12","comments":"0","has_attach":"0","id":"6134","message":"[b]工作地点：上海[/b]\n[b]工作职责：[/b]\n负责网络游戏业务的部署、发布、变更；\n负责新游戏的接入、架构评估、痛点挖掘优化；\n负责监控网络游戏业务的运行状况，及时处理游戏运行中出现的故障，保障网络游戏服务的正常提供；\n负责与游戏运营项目组的日常沟通交流，接受并处理项目组提出的运维需求；\n针对各系统编写并维护自动化运维脚本；\n负责项目组相关运营支撑工具的开发(Python)；\n负责日常运维工作的自动化、工具化建设；\n参与游戏大数据挖掘与分析；\n[b]工作要求：[/b]\n本科以上学历，计算机类或相关专业；\n3年以上互联网行业经验、2年以上的批量服务器维护经验；\n有开发经验，掌握Python、Bash、Sed、Awk等编程语言；\n有较强的抗压能力、沟通能力、推动能力和较好的服务意识；\n善于团队协作、项目管理、主动思考、自我驱动强；\n优先（满足之一即可）：\n熟悉云技术应用阿里云，腾讯云，AWS者优先；\n有知名游戏维护经验者优先，有数据挖掘经验者优先；\n具有开源精神，能阅读源码，有DEVOPS/大数据平台运维管理经验者优先；\n熟悉ELK等实时日志处理相关工作经验优先；\n熟悉Docker、K8S原理，有Docker实际应用经验者优先；\n[b]联系方式：chen.yang@mihoyo.com[/b]\n","title":"上海米哈游高薪诚聘运维开发工程师，待遇15k-30k","uid":"10454","views":"321","votes":"0"},"_type":"doc"}
{"_id":"3698","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541201443","category_id":"18","comments":"0","has_attach":"0","id":"3698","message":"1、父子结构的排序方法\n     http://t.cn/EwiSWFC\n2、一款对聚合结果利用线性回归实时预测的插件\n     http://t.cn/EwiXJ9g\n3、一周热点：如果我在那辆重庆公交上\n     http://t.cn/Ewitdiv\n \n编辑: bsll\n归档：https://elasticsearch.cn/article/3698\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第437期 (2018-11-03）","uid":"1874","views":"203","votes":"0"},"_type":"doc"}
{"_id":"6122","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541510612","category_id":"18","comments":"0","has_attach":"0","id":"6122","message":"1.Beats 6.5 版本的大改进来了！集中配置管理、InfraUI、LogsUI，感兴趣的来看介绍！\nhttp://t.cn/Ewg9RGi\n\n2.(自备梯子)index 设置为 false 在 text 和 keyword 类型中表现是有差异的\nhttp://t.cn/Ewg9FFq\n3.(自备梯子)es 在电商中商品分析与排序的一点思路分享\nhttp://t.cn/EwgCLtk\n\n\n直播活动：\n1.Elastic 官方直播分享活动：Introduction To ElasticStack，快来报名吧！\nhttp://t.cn/EwgCtkP\n\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/6122\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第440期 (2018-11-06)","uid":"86","views":"271","votes":"0"},"_type":"doc"}
{"_id":"6210","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545219345","category_id":"18","comments":"0","has_attach":"0","id":"6210","message":"1、ECE 2.0:为你的使用场景助力加油。\nhttp://t.cn/E421UUE\n​2、(自备梯子)如何使用es和react构建电子商务搜索。\nhttp://t.cn/E42BSad\n​3、Elastic：Beyond Search！\nhttp://t.cn/E42dIzz\n\n编辑：wt\n归档：https://elasticsearch.cn/article/6210\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第483期 (2018-12-19)","uid":"3851","views":"171","votes":"0"},"_type":"doc"}
{"_id":"6206","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545029725","category_id":"13","comments":"0","has_attach":"1","id":"6206","message":"\u0026gt; ELK 从发布5.0之后加入了beats套件之后，就改名叫做elastic stack了。beats是一组轻量级的软件，给我们提供了简便，快捷的方式来实时收集、丰富更多的数据用以支撑我们的分析。但由于beats都需要安装在ELK集群之外，在宿主机之上，其对宿主机的性能的影响往往成为了考量其是否能被使用的关键，而不是它到底提供了什么样的功能。因为业务的稳定运行才是核心KPI，而其他因运维而生的数据永远是更低的优先级。影响宿主机性能的方面可能有很多，比如CPU占用率，网络吞吐占用率，磁盘IO，内存等，这里我们详细讨论一下内存泄漏的问题\n\n@[toc]\n\nfilebeat是beats套件的核心组件之一（另一个核心是metricbeat），用于采集文件内容并发送到收集端（ES），它一般安装在宿主机上，即生成文件的机器。根据文档的描述，filebeat是不建议用来采集NFS（网络共享磁盘）上的数据的，因此，我们这里只讨论filebeat对本地文件进行采集时的性能情况。\n\n当filebeat部署和运行之后，必定会对cpu，内存，网络等资源产生一定的消耗，当这种消耗能够限定在一个可接受的范围时，在企业内部的生产服务器上大规模部署filebeat是可行的。但如果出现一些非预期的情况，比如占用了大量的内存，那么运维团队肯定是优先保障核心业务的资源，把filebeat进程给杀了。很可惜的是，内存泄漏的问题，从filebeat的诞生到现在就一直没有完全解决过。（可以区社区讨论贴看看，直到现在V6.5.1都还有人在报告内存泄漏的问题）。在特定的场景和配置下，内存占用过多已经成为了抑止filebeat大规模部署的主要问题了。在这里，我主要描述一下我碰到的在filebeat 6.0上遇到的问题。\n\n## 问题场景和配置\n\n一开始我们在很多机器上部署了filebeat，并且使用了一套统一无差别的的简单配置。对于想要在企业内部大规模推广filebeat的同学来说，**这是大忌！！！** 合理的方式是具体问题具体分析，需对每台机器上产生文件的方式和rotate的方式进行充分的调研，针对不同的场景是做定制化的配置。以下是我们之前使用的配置：\n\n - `multiline`，多行的配置，当日志文件不符合规范，大量的匹配pattern的时候，会造成内存泄漏\n - `max_procs`，限制filebeat的进程数量，其实是内核数，建议手动设为1\n \n \n\n```yaml\nfilebeat.prospectors:\n- type: log\n  enabled: true\n  paths:\n    - /qhapp/*/*.log\n  tail_files: true\n  multiline.pattern: '^[[:space:]]+|^Caused by:|^.+Exception:|^\\d+\\serror'\n  multiline.negate: false\n  multiline.match: after\n  fields:\n    app_id: bi_lass\n    service: \u0026quot;{{ hostvars[inventory_hostname]['service'] }}\u0026quot;\n    ip_address: \u0026quot;{{ hostvars[inventory_hostname]['ansible_host'] }}\u0026quot;\n    topic: qh_app_raw_log\n\nfilebeat.config.modules:\n  path: ${path.config}/modules.d/*.yml\n  reload.enabled: false\n\nsetup.template.settings:\n  index.number_of_shards: 3\n  #index.codec: best_compression\n  #_source.enabled: false\noutput.kafka:\n  enabled: true\n  hosts: [{{kafka_url}}]\n\n  topic: '%{[fields][topic]}'\n\nmax_procs: 1\n\n```\n注意，以上的配置中，仅仅对cpu的内核数进行了限制，而没有对内存的使用率进行特殊的限制。从配置层面来说，影响filebeat内存使用情况的指标主要有两个：\n- `queue.mem.events `消息队列的大小，默认值是4096，这个参数在6.0以前的版本是`spool-size`，通过命令行，在启动时进行配置\n- `max_message_bytes` 单条消息的大小, 默认值是10M\n\nfilebeat最大的可能占用的内存是`max_message_bytes * queue.mem.events = 40G`，考虑到这个queue是用于存储encode过的数据，raw数据也是要存储的，所以，在没有对内存进行限制的情况下，最大的内存占用情况是可以达到超过**80G**。\n\n因此，**建议是同时对filebeat的CPU和内存进行限制。**\n\n下面，我们看看，使用以上的配置在什么情况下会观测到内存泄漏\n\n### 监控文件过多\n\n对于实时大量产生内容的文件，比如日志，常用的做法往往是将日志文件进行rotate，根据策略的不同，每隔一段时间或者达到固定大小之后，将日志rotate。\n这样，在文件目录下可能会产生大量的日志文件。\n如果我们使用通配符的方式，去监控该目录，则filebeat会启动大量的harvester实例去采集文件。但是，请记住，我这里不是说这样一定会产生内存泄漏，只是在这里观测到了内存泄漏而已，不是说这是造成内存泄漏的原因。\n\n\n[attach]3308[/attach]\n\n\n当filebeat运行了几个月之后，占用了超过10个G的内存\n\n\n[attach]3309[/attach]\n\n\n### 非常频繁的rotate日志\n\n另一个可能是，filebeat只配置监控了一个文件，比如test2.log，但由于test2.log不停的rotate出新的文件，虽然没有使用通配符采集该目录下的所有文件，但因为linux系统是使用inode number来唯一标示文件的，rotate出来的新文件并没有改变其inode number，因此，时间上filebeat还是同时开启了对多个文件的监控。\n\n[attach]3310[/attach]\n\n另外，因为对文件进行rotate的时候，一般会限制rotate的个数，即到达一定数量时，新rotate一个文件，必然会删除一个旧的文件，文件删除之后，inode number是可以复用的，如果不巧，新rotate出来的文件被分配了一个之前已删掉文件的inode number，而此时filebeat还没有监测之前持有该inode number的文件已删除，则会抛出以下异常：\n\n```\n2018-11-21T18:06:55+08:00 ERR  Harvester could not be started on truncated file: /qhapp/logs/bd-etl/logs/test2.log, Err: Error setting up harvester: Harvester setup failed. Unexpected file opening error: file info is not identical with opened file. Aborting harvesting and retrying file later again\n```\n\n而类似`Harvester setup failed.`的异常会导致内存泄漏\n\nhttps://github.com/elastic/beats/issues/6797\n\n\n\n### 因为multiline导致内存占用过多\n`multiline.pattern: '^[[:space:]]+|^Caused by:|^.+Exception:|^\\d+\\serror`，比如这个配置，认为空格或者制表符开头的line是上一行的附加内容，需要作为多行模式，存储到同一个event当中。当你监控的文件刚巧在文件的每一行带有一个空格时，会错误的匹配多行，造成filebeat解析过后，单条event的行数达到了上千行，大小达到了10M，并且在这过程中使用的是正则表达式，每一条event的处理都会极大的消耗内存。因为大多数的filebeat output是需应答的，buffer这些event必然会大量的消耗内存。\n\n## 模拟场景\n这里不多说，简单来一段python的代码：\n```ini\n[loggers]\nkeys=root\n\n[handlers]\nkeys=NormalHandler\n\n[formatters]\nkeys=formatter\n\n[logger_root]\nlevel=DEBUG\nhandlers=NormalHandler\n\n[handler_NormalHandler]\nclass=logging.handlers.TimedRotatingFileHandler\nformatter=formatter\nargs=('./test2.log', 'S', 10, 200)\n\n[formatter_formatter]\nformat=%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s\n```\n以上，每隔10秒（'S', 'M' = 分钟，'D'= 天）rotate一个文件，一共可以rotate 200个文件。\n然后，随便找一段日志，不停的打，以下是330条/秒\n\n```python\nimport logging\nfrom logging.config import fileConfig\nimport os\nimport time\nCURRENT_FOLDER = os.path.dirname(os.path.realpath(__file__))\n\nfileConfig(CURRENT_FOLDER + '/logging.ini')\nlogger = logging.getLogger()\n\nwhile True:\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!\u0026quot;)\n    logger.debug(\u0026quot;DEBUG 2018-11-26 09:31:35 com.sunyard.insurance.server.GetImage 43 - 资源请求:date=20181126\u0026amp;file_name=/imagedata/imv2/pool1/images/GXTB/2017/11/14/57/06b6bcdd31763b70b20f56c689e51f5e_1/06b6bcdd31763b70b20f56c689e51f5e_2.syd\u0026amp;file_encrypt=0\u0026amp;token=HUtGGG20GH4GAqq209R9tc9UGtAURR0b DEBUG 2018-11-26 09:31:40 com.sunyard.insurance.scheduler.job.DbEroorHandleJob 26 - [数据库操作异常处理JOB]处理异常文件，本机不运行，退出任务!!@#!@#!@#!@#!@#!@#!@#!@#!@#!@#!@#!#@!!!@##########################################################################################################################################################\u0026quot;)\n    time.sleep(0.03)\n```\n\n\n## 如何观察filebeat的内存\n\n在6.3版本之前，我们是无法通过xpack的monitoring功能来观察beats套件的性能的。因此，这里讨论的是没有monitoring时，我们如何去检测filebeat的性能。当然，简单的方法是通过`top`,`ps`等操作系统的命令进行查看，但这些都是实时的，无法做趋势的观察，并且都是进程级别的，无法看到filebeat内部的真是情况。因此，这里介绍如何通过filebeat的日志和pprof这个工具来观察内存的使用情况\n\n### 通过filebeat的日志\n\n#### filebeat文件解读\n其实filebeat的日志，已经包含了很多参数用于实时观测filebeat的资源使用情况，以下是filebeat的一个日志片段（这里的日志片段是6.0版本的，6.3版本之后，整个日志格式变了，从kv格式变成了json对象格式，xpack可以直接通过日志进行filebeat的monitoring）：\n\n```shell\n2018-11-02T17:40:01+08:00 INFO Non-zero metrics in the last 30s: beat.memstats.gc_next=623475680 beat.memstats.memory_alloc=391032232 beat.memstats.memory_total=155885103371024 filebeat.events.active=-402 filebeat.events.added=13279 filebeat.events.done=13681 filebeat.harvester.closed=1 filebeat.harvester.open_files=7 filebeat.harvester.running=7 filebeat.harvester.started=2 libbeat.config.module.running=0 libbeat.output.events.acked=13677 libbeat.output.events.batches=28 libbeat.output.events.total=13677 libbeat.outputs.kafka.bytes_read=12112 libbeat.outputs.kafka.bytes_write=1043381 libbeat.pipeline.clients=1 libbeat.pipeline.events.active=0 libbeat.pipeline.events.filtered=4 libbeat.pipeline.events.published=13275 libbeat.pipeline.events.total=13279 libbeat.pipeline.queue.acked=13677 registrar.states.cleanup=1 registrar.states.current=8 registrar.states.update=13681 registrar.writes=28\n\n```\n里面的参数主要分成三个部分：\n\n - `beat.*`，包含memstats.gc_next，memstats.memory_alloc，memstats.memory_total，这个是所有beat组件都有的指标，是filebeat继承来的，主要是内存相关的，**我们这里特别关注`memstats.memory_alloc`，alloc的越多，占用内存越大**\n - `filebeat.*`，这部分是filebeat特有的指标，通过event相关的指标，我们知道吞吐，通过harvester，我们知道正在监控多少个文件，**未消费event堆积的越多，havester创建的越多，消耗内存越大**\n - `libbeat.*`，也是beats组件通用的指标，包含outputs和pipeline等信息。这里要主要**当outputs发生阻塞的时候，会直接影响queue里面event的消费，造成内存堆积**\n - `registrar`，filebeat将监控文件的状态放在registry文件里面，当监控文件非常多的时候，比如10万个，而且没有合理的设置`close_inactive`参数，这个文件能达到100M，载入内存后，直接占用内存\n\n#### filebeat日志解析\n当然，我们不可能直接去读这个日志，既然我们使用ELK，肯定是用ELK进行解读。因为是kv格式，很方便，用logstash的kv plugin：\n```ruby\nfilter {\n  kv {}\n}\n```\nkv无法指定properties的type，所以，我们需要稍微指定了一下索引的模版：\n```\nPUT _template/template_1\n{\n  \u0026quot;index_patterns\u0026quot;: [\u0026quot;filebeat*\u0026quot;],\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;number_of_shards\u0026quot;: 1\n  },\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;doc\u0026quot;: {\n      \u0026quot;_source\u0026quot;: {\n        \u0026quot;enabled\u0026quot;: false\n      },\n      \u0026quot;dynamic_templates\u0026quot;: [\n        {\n          \u0026quot;longs_as_strings\u0026quot;: {\n            \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot;,\n            \u0026quot;path_match\u0026quot;:   \u0026quot;*beat.*\u0026quot;,\n            \u0026quot;path_unmatch\u0026quot;: \u0026quot;*.*name\u0026quot;,\n            \u0026quot;mapping\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n上面的模版，将kv解析出的properties都mapping到`long`类型，但注意`\u0026quot;path_match\u0026quot;:   \u0026quot;*beat.*\u0026quot;`无法match到`registrar`的指标，读者可以自己写一个更完善的mapping。\n这样，我们就可以通过kibana可视化组件，清楚的看到内存泄漏的过程\n\n[attach]3311[/attach]\n\n以及资源的使用情况：\n\n[attach]3312[/attach]\n\n将信息可视化之后，我们可以明显的发现，内存的突变和ERR是同时发生的\n\n[attach]3313[/attach]\n\n即以下error：\n`2018-11-27T09:05:44+08:00 ERR  Harvester could not be started on new file: /qhapp/logs/bd-etl/logs/test2.log, Err: Error setting up harvester: Harvester setup failed. Unexpected file opening error: file info is not identical with opened file. Aborting harvesting and retrying file later again`\n\n会导致filebeat突然申请了额外的内存。具体请查看[issue](https://github.com/elastic/beats/issues/6797)\n\n### 通过pprof\n众所周知，filebeat是用go语言实现的，而go语言本身的基础库里面就包含pprof这个功能极其强大的性能分析工具，只是这个工具是用于debug的，在正常模式下，filebeat是不会启动这个选贤的，并且很遗憾，在官方文档里面根本没有提及我们可以使用pprof来观测filebeat。我们接下来可以通过6.3上修复的一个内存泄漏的[issue](https://github.com/elastic/beats/issues/6797)，来学习怎么使用pprof进行分析\n\n#### 启动pprof监测\n\n首先，需要让filebeat在启动的时候运行pprof，具体的做法是在启动是加上参数` -httpprof localhost:6060 `，即`/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat -httpprof localhost:6060`。这里只绑定了localhost，无法通过远程访问，如果想远程访问，应该使用`0.0.0.0`。\n这时，你就可以通过`curl http://localhost:6060/debug/pprof/heap \u0026gt; profile.txt`等命令，获取filebeat的实时堆栈信息了。\n\n#### 远程连接\n\n当然，你也可以通过在你的本地电脑上安装go，然后通过go tool远程连接pprof。\n因为我们是需要研究内存的问题，所以以下连接访问的是`/heap`子路径\n`go tool pprof http://10.60.x.x:6060/debug/pprof/heap`\n\n#### top 命令\n\n连接之后，你可以通过`top`命令，查看消耗内存最多的几个实例：\n```\n33159.58kB of 33159.58kB total (  100%)\nDropped 308 nodes (cum \u0026lt;= 165.80kB)\nShowing top 10 nodes out of 51 (cum \u0026gt;= 512.04kB)\n      flat  flat%   sum%        cum   cum%\n19975.92kB 60.24% 60.24% 19975.92kB 60.24%  runtime.malg\n 7680.66kB 23.16% 83.40%  7680.66kB 23.16%  github.com/elastic/beats/filebeat/channel.SubOutlet\n 2048.19kB  6.18% 89.58%  2048.19kB  6.18%  github.com/elastic/beats/filebeat/prospector/log.NewHarvester\n 1357.91kB  4.10% 93.68%  1357.91kB  4.10%  runtime.allgadd\n 1024.08kB  3.09% 96.76%  1024.08kB  3.09%  runtime.acquireSudog\n  544.67kB  1.64% 98.41%   544.67kB  1.64%  github.com/elastic/beats/libbeat/publisher/queue/memqueue.NewBroker\n  528.17kB  1.59%   100%   528.17kB  1.59%  regexp.(*bitState).reset\n         0     0%   100%   528.17kB  1.59%  github.com/elastic/beats/filebeat/beater.(*Filebeat).Run\n         0     0%   100%   512.04kB  1.54%  github.com/elastic/beats/filebeat/channel.CloseOnSignal.func1\n         0     0%   100%   512.04kB  1.54%  github.com/elastic/beats/filebeat/channel.SubOutlet.func1\n```\n#### 查看堆栈调用图\n输入`web`命令，会生产堆栈调用关系的svg图，在这个svg图中，你可以结合top命令一起查看，在top中，我们已经知道`github.com/elastic/beats/filebeat/channel.SubOutlet`占用了很多的内存，在图中，展现的是调用关系栈，你可以看到这个类是怎么被实例化的，并且在整个堆中，内存是怎么分布的。最直观的是，实例所处的长方形面积越大，代表占用的内存越多。：\n\n[attach]3314[/attach]\n\n#### 查看源码\n通过`list`命令，可以迅速查看可以实例的问题源码，比如在之前的top10命令中，我们已经看到`github.com/elastic/beats/filebeat/channel.SubOutlet`这个类的实例占用了大量的内存，我们可以通过`list`做进一步的分析，看看这个类内部在哪个语句开始出现内存的占用：\n```\n(pprof) list SubOutlet\nTotal: 32.38MB\nROUTINE ======================== github.com/elastic/beats/filebeat/channel.SubOutlet in /home/jeremy/src/go/src/github.com/elastic/beats/filebeat/channel/util.go\n    7.50MB     7.50MB (flat, cum) 23.16% of Total\n         .          .     15:// SubOutlet create a sub-outlet, which can be closed individually, without closing the\n         .          .     16:// underlying outlet.\n         .          .     17:func SubOutlet(out Outleter) Outleter {\n         .          .     18:\ts := \u0026amp;subOutlet{\n         .          .     19:\t\tisOpen: atomic.MakeBool(true),\n       1MB        1MB     20:\t\tdone:   make(chan struct{}),\n       2MB        2MB     21:\t\tch:     make(chan *util.Data),\n    4.50MB     4.50MB     22:\t\tres:    make(chan bool, 1),\n         .          .     23:\t}\n         .          .     24:\n         .          .     25:\tgo func() {\n         .          .     26:\t\tfor event := range s.ch {\n         .          .     27:\t\t\ts.res \u0026lt;- out.OnEvent(event) \n```\n\n## 如何调优\n其实调优的过程就是调整参数的过程，之前说过了，和内存相关的参数, `max_message_bytes`,`queue.mem.events`,`queue.mem.flush.min_events`，以及队列占用内存的公式:`max_message_bytes * queue.mem.events`\n```\noutput.kafka:\n  enabled: true\n#  max_message_bytes: 1000000\n  hosts: [\u0026quot;10.60.x.x:9092\u0026quot;]\n  topic: '%{[fields][topic]}'\nmax_procs: 1 \n#queue.mem.events: 256\n#queue.mem.flush.min_events: 128\n```\n但其实，不同的环境下，不同的原因都可能会造成filebeat占用的内存过大，此时，需要仔细的确认你的上下文环境：\n\n - 是否因为通配符的原因，造成同时监控数量巨大的文件，这种情况应该避免用通配符监控无用的文件。\n - 是否文件的单行内容巨大，确定是否需要改造文件内容，或者将其过滤\n - 是否过多的匹配了multiline的pattern，并且多行的event是否单条体积过大。这时，就需要暂时关闭multiline，修改文件内容或者multiline的pattern。\n - 是否output经常阻塞，event queue里面总是一直缓存event。这时要检查你的网络环境或者消息队列等中间件是否正常\n\n\n\n\n","title":"Day 18: 记filebeat内存泄漏问题分析及调优","uid":"5649","views":"490","votes":"4"},"_type":"doc"}
{"_id":"6204","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545015941","category_id":"18","comments":"0","has_attach":"0","id":"6204","message":"1.在Elastic Stack 中统一集中管理 Beats\nhttp://t.cn/EUn1Wa2\n2.ElasticSearch 和 lucene 本周发展详情\nhttp://t.cn/EUnBPRV\n3.Elasticsearch 自动在文档中添加时间戳\nhttp://t.cn/EUfESt7\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6204\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第481期 (2018-12-17)","uid":"4063","views":"193","votes":"0"},"_type":"doc"}
{"_id":"6203","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545015812","category_id":"16","comments":"0","has_attach":"0","id":"6203","message":"### 一、活动介绍\nOpenResty 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。目前 OpenResty 是全球占有率排名第五的 Web 服务器，超过 1 万多家商业公司都在使用 OpenResty，比如又拍云、腾讯、奇虎360、京东、12306、Kong 等公司，应用在 CDN、广告系统、搜索、实现业务逻辑、余票查询、网关、ingress controller 等各种不同的场景下。\n\n又拍云 Open Talk 是由又拍云发起的系列主题分享沙龙，秉承又拍云帮助企业提升发展速度的初衷，从 2015 年开启以来，Open Talk 至今已成功举办 45 期，辐射线上线下近十万技术人群，分别在北京、上海、广州、深圳、杭州等 12 座城市举办，覆盖腾讯、华为、网易、京东、唯品会、哔哩哔哩、美团点评、有赞、无码科技等诸多知名企业，往期的活动的讲稿及视频详见：https://opentalk.upyun.com。\n\n为促进 OpenResty 在技术圈的发展，增进 OpenResty 使用者的交流与学习，OpenResty 中国社区联合又拍云，举办 “OpenResty × Open Talk” 全国巡回沙龙，邀请业内资深的 OpenResty 技术专家，分享 OpenResty 实战经验，推动 OpenResty 开源项目的发展，促进互联网技术的教育。\n\n### 二、活动时间\n\n2019 年 01 月 12 日（周六）\n\n### 三、活动地址\n\n广东省深圳市南山区深圳虚拟大学园 R3-B 栋一楼触梦社区\n\n### 四、报名地址\n\nhttp://www.huodongxing.com/event/5470242889300\n\n### 五、嘉宾及议题介绍\n\n![alt](http://musee20160425.b0.upaiyun.com/fileimage/weming.jpg)\n\n**分享嘉宾一：温铭 / OpenResty 软件基金会主席**\n\nOpenResty 软件基金会主席，前360开源委员会委员；现为 OpenResty Inc. 合伙人，致力于打造基于 OpenResty、Linux 内核等基础平台的企业级产品和解决方案。创业之前在互联网安全公司工作了 10 年，主要从事服务端的开发和架构，负责开发过木马云查杀、反钓鱼系统和企业安全产品。\n\n**分享主题：《 使用 OpenResty 实现 memcached server 》**\n\nOpenResty 软件基金会主席，前360开源委员会委员；现为 OpenResty Inc. 合伙人，致力于打造基于 OpenResty、Linux 内核等基础平台的企业级产品和解决方案。创业之前在互联网安全公司工作了 10 年，主要从事服务端的开发和架构，负责开发过木马云查杀、反钓鱼系统和企业安全产品。\n\n![alt](http://musee20160425.b0.upaiyun.com/fileimage/zhangcong.jpg)\n\n**分享嘉宾二：张聪 /  又拍云首席架构师**\n\n多年 CDN 行业产品设计、技术开发和团队管理相关经验，个人技术方向集中在 Nginx、OpenResty 等高性能 Web 服务器方面，国内 OpenResty 技术早期推广者之一；目前担任又拍云内容加速部技术负责人，主导又拍云 CDN 技术平台的建设和发展。\n\n**分享主题：《 OpenResty 动态流控的几种姿势 》**\n\n本次分享主要介绍 OpenResty 上几种常用的请求限制和流量整形的方式，特别值得一提的是，详细介绍在又拍云网关层的实际应用案例，以及又拍云贡献的开源 Resty 库。\n\n![alt](http://musee20160425.b0.upaiyun.com/fileimage/zhangbo.jpg)\n\n**分享嘉宾三：张波 / 虎牙直播运维研发架构师**\n\n目前主要负责虎牙直播运维体系的建设，主要针对 web 和后台类程序的发布、监控、运维自动化相关的运维系统的设计和开发。\n\n**分享主题：《 掘金 Nginx 日志 》**\n\nNginx 是现在最流行的负载均衡和反向代理服务器之一，如果你是一位中小微型网站的开发运维人员，可能仅 Nginx 每天就会产生上百 M 甚至数以十 G 的日志文件，Nginx 日志被删除以前，或者我们可以想想，其中是否蕴含着位置的金矿等待挖掘？\n\n![alt](http://musee20160425.b0.upaiyun.com/fileimage/chenqianlong.jpg)\n\n**分享嘉宾四：陈乾龙 / 京东微信手 Q 业务部**\n\n负责微信、手Q抢购后台，以及 OpenResty 入口流量的网关\n\n**分享主题：《 基于 OpenResty 流量的防刷及容灾 》**\n\n本次分享主要介绍基于 OpenResty 搭建流量网关的实践以及开发过程中碰到的问题及优化。\n\n### 六、现场礼品\n\n![alt](http://musee20160425.b0.upaiyun.com/fileimage/ot46lipin.jpg)","title":"【2019.01.12】OpenResty x Open Talk 丨深圳站","uid":"2840","views":"114","votes":"0"},"_type":"doc"}
{"_id":"6195","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544683474","category_id":"18","comments":"0","has_attach":"0","id":"6195","message":"1.如何在Elasticsearch中查找和删除重复文档\nhttp://t.cn/EUxkESo\n2.Elasticsearch线程池分析\nhttp://t.cn/EUxkDNg\n3.Elasticsearch Pipeline Aggregations指南\nhttp://t.cn/EUxFzZX\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6195\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第477期 (2018-12-13)","uid":"668","views":"185","votes":"0"},"_type":"doc"}
{"_id":"6208","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545149711","category_id":"14","comments":"1","has_attach":"0","id":"6208","message":"      相信不少人都把es当做一个主要的搜索引擎来使用，但是对于搜索结果之后的点击反馈，es没有很好的方案。比如说用户搜索了某些关键词，点击了某些结果，而这些结果并不是排在最前面的，但确实是用户最想要的。那有没有什么方法可以使它们排在前面呢？一种简单的做法就是就是离线统计文档的点击率，然后在排序时根据这个点击率进行加权，但这样笼统的算法不一定适合所有情况。现在就来简单介绍下learning to rank，翻译过来就是学习排序，可以根据点击日志里面的记录，来反向影响搜索结果的排序。刚好这个库也有es的插件，下面以这个插件的官方demo来解释下如何使用。\ndemo的下载地址如下，都是python脚本，环境需求：python3+，es\n[url]https://github.com/o19s/elasticsearch-learning-to-rank/tree/master/demo[/url]\n1.准备数据\npython prepare.py\n下载RankLib.jar (用来训练模型) 和tmdb.json (测试数据集，tmdb的电影数据)\n2.导测试数据入es\npython index_ml_tmdb.py\n3.训练模型\npython train.py\n训练脚本很简单，但是脚本里面有丰富的实现，下面介绍下主要方法。\nload_features(FEATURE_SET_NAME)\n这个是读取特征信息，demo定义了两个特征，分别在1.json[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;match\u0026quot;: {\n            \u0026quot;title\u0026quot;: \u0026quot;{{keywords}}\u0026quot;\n        }\n    }\n}[/code]和2.json[code]{\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;match\u0026quot;: {\n            \u0026quot;overview\u0026quot;: \u0026quot;{{keywords}}\u0026quot;\n        }\n    }\n}[/code]1就是查title，2就是查overview，生成训练数据时就是需要根据特征的查询语法，去es里面匹配相关得分作为特征分数。[code]movieJudgments = judgments_by_qid(judgments_from_file(filename=JUDGMENTS_FILE))[/code]读取生成训练数据的原始数据，官方称其为决策列表（Judgment list），第一列是数值为0-4的权重，数值越大，相关性越高。回到我们最初的需求就是越多人点击的文档，那么这个权重就越大。第二列是queryid，同次查询结果中的queryid一样，第三列是文档id，这里就是电影id，第四列是文档标题，这里就是电影名。\n4   qid:1 #    7555   Rambo\n3  qid:1 #    1370   Rambo III\n3  qid:1 #    1369   Rambo: First Blood Part II\n3  qid:1 #    1368   First Blood\n0  qid:1 #    136278 Blood\n4  qid:2 #    1366   Rocky\n3  qid:2 #    1246   Rocky Balboa\n3  qid:2 #    60375  Rocky VI\n3  qid:2 #    1371   Rocky III\n3  qid:2 #    1375   Rocky V[code]log_features(es, judgments_dict=movieJudgments, search_index=INDEX_NAME)\nbuild_features_judgments_file(movieJudgments, filename=JUDGMENTS_FILE_FEATURES)[/code]之后就是生成特征集，就是把上面的每条训练数据根据特征查询语句扔进es里面进行查询，把得分放到1和2特征后面，如:下面数据第一条中的，1:12.318446就表示1特征的分数，2:10.573845表示2特征的分数，然后把特征集写到文件。\n生成完的特征集如下：\n4   qid:1  1:12.318446    2:10.573845 # 7555 rambo\n3  qid:1  1:10.357836    2:11.950331 # 1370 rambo\n3  qid:1  1:7.0104666    2:11.220029 # 1369 rambo\n3  qid:1  1:0.0  2:11.220029 # 1368 rambo\n0  qid:1  1:0.0  2:0.0 # 136278 rambo\n4  qid:2  1:10.686367    2:8.814796 # 1366  rocky\n3  qid:2  1:8.985519 2:9.984467 # 1246  rocky\n3  qid:2  1:8.985519 2:8.067647 # 60375 rocky\n3  qid:2  1:8.985519 2:5.6604943 # 1371 rocky\n3  qid:2  1:8.985519 2:7.3007236 # 1375 rocky\n特征集出来后就是训练了，demo提供10总不同的算法，训练好之后把结果传到es提供服务[code]for modelType in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n    # 0, MART\n    # 1, RankNet\n    # 2, RankBoost\n    # 3, AdaRank\n    # 4, coord Ascent\n    # 6, LambdaMART\n    # 7, ListNET\n    # 8, Random Forests\n    # 9, Linear Regression\n    Logger.logger.info(\u0026quot;*** Training %s \u0026quot; % modelType)\n    train_model(judgments_with_features_file=JUDGMENTS_FILE_FEATURES, model_output='model.txt',\n                which_model=modelType)\n    save_model(script_name=\u0026quot;test_%s\u0026quot; % modelType, feature_set=FEATURE_SET_NAME,       model_fname='model.txt')[/code]4.最后搜索数据\npython search.py Rambo\n搜索时主要用到了es里面的rescore特性，就是对前面topn条记录根据模型进行再排序，查询dsl如下：[code]{\n  \u0026quot;query\u0026quot;: {\n      \u0026quot;multi_match\u0026quot;: {\n          \u0026quot;query\u0026quot;: \u0026quot;Rambo\u0026quot;,\n          \u0026quot;fields\u0026quot;: [\u0026quot;title\u0026quot;, \u0026quot;overview\u0026quot;]\n       }\n   },\n  \u0026quot;rescore\u0026quot;: {\n      \u0026quot;query\u0026quot;: {\n        \u0026quot;rescore_query\u0026quot;: {\n            \u0026quot;sltr\u0026quot;: {\n                \u0026quot;params\u0026quot;: {\n                    \u0026quot;keywords\u0026quot;: \u0026quot;Rambo\u0026quot;\n                },\n                \u0026quot;model\u0026quot;: \u0026quot;test_1\u0026quot;,\n            }\n         }\n      }\n   }\n}[/code]\n得到结果\nRambo\nRambo III\nRambo: First Blood Part II\nFirst Blood\nIn the Line of Duty: The F.B.I. Murders\nSon of Rambow\nSpud\n当然这个是最简单的一个例子，深入研究可以参考官方文档，很详细：[url]https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/[/url]\n ","title":"Day 19 - 通过点击反馈优化es搜索结果排序","uid":"8","views":"462","votes":"6"},"_type":"doc"}
{"_id":"6197","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544772272","category_id":"2","comments":"0","has_attach":"1","id":"6197","message":"[size=16]       ElasticSearch分布式搜索储存集群的引入，主要是为了解决订单数据的存储与搜索的问题。[/size]\n\n[size=18]项目背景：[/size]\n[size=16]      15年去哪儿网酒店日均订单量达到30w+，随着多平台订单的聚合日均订单能达到100w左右。原来采用的热表分库方式，即将最近6个月的订单的放置在一张表中，将历史订单放在在history表中。history表存储全量的数据，当用户查询的下单时间跨度超过6个月即查询历史订单表，此分表方式热表的数据量为4000w左右，当时能解决的问题。但是显然不能满足携程艺龙订单接入的需求。如果继续按照热表方式，数据量将超过1亿条。全量数据表保存2年的可能就超过4亿的数据量。所以寻找有效途径解决此问题迫在眉睫。由于对这预计4亿的数据量还需按照预定日期、入住日期、离店日期、订单号、联系人姓名、电话、酒店名称、订单状态……等多个条件查询。所以简单按照某一个维度进行分表操作没有意义。ElasticSearch分布式搜索储存集群的引入，就是为了解决订单数据的存储与搜索的问题。[/size]\n\n[size=18]具体解决方案：[/size]\n\n[size=16]1、系统性能\n        对订单模型进行抽象和分类，将常用搜索字段和基础属性字段剥离DB做分库分表。存储订单详情,ElasticSearch存储搜素字段。订单复杂查询直接走ElasticSearch。如下图：\n\n[attach]3292[/attach][/size]\n[size=16]       通用数据存储模型\n\n[attach]3294[/attach]\n\n关键字段\n    ■ 业务核心字段，用于查询过滤\n系统字段\n    ■ version 避免高并发操作导致数据覆盖\n大字段\n    ■ order_data订单详情数据(JSON)\n    ■ 可灵活需要索引的字段返回的字段[/size]\n \n \n[size=16]2、系统可用性\n     系统可用性保障：双机房高可用如下图。[/size]\n       [attach]3295[/attach]\n[size=16]     数据可用性保障：\n            一、异步多写保证数据一致性。[/size]\n[size=16]                \n二、数据补充机制：\n  1、每天凌晨task扫描数据库热表数据与es数据版本进行比较。\n  2、将第三方推送过来数据中的，订单号即时插入订单同步队列表中。如果数据模型解析转换、持久化成功。删除队列中订单号。同时设置1分钟一次的task 扫描队列表。\n  3、推送第三方的数据也采用同样的方式。保证给第三方数据的准确性。\n\n\n[attach]3293[/attach]\n\n3、系统伸缩性\n      elasticSearch中索引设置了8个分片，目前Es单个索引的文档达到到1.4亿,合计达到2亿条数据占磁盘大小64G，集群机器磁盘容量240G。[/size]\n \n \n ","title":"Day 14 - 订单中心基于elasticsearch 的解决方案","uid":"528","views":"687","votes":"0"},"_type":"doc"}
{"_id":"6189","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544584060","category_id":"1","comments":"0","has_attach":"1","id":"6189","message":"@[toc]\n搭建Elasitc stack集群时，我们往往把大部分注意力放在集群的搭建，索引的优化，分片的设置上等具体的调优参数上，很少有人会去关心Elasitc stack的日志配置的问题，大概是觉得，日志应该是一个公共的问题，默认的配置应该已经为我们处理好了。但很不幸，在不同的机器配置或者不同的运营策略下，如果采用默认的配置，会给我们带来麻烦。\n### 默认配置带来的麻烦\n以下例子是默认情况下，当Elasitc stack集群运行超过3个月之后的情况：\n\n#### elasticsearch\nelasticsearch默认情况下会每天rolling一个文件，当到达2G的时候，才开始清除超出的部分，当一个文件只有几十K的时候，文件会一直累计下来。\n\n[attach]3318[/attach]\n\n\n#### logstash\n一直增长的gc文件和不停增多的rolling日志文件\n[attach]3316[/attach]\n\n#### kibana\n默认日志输出到`kibana.out`文件当中，这个文件会变得越来越大\n[attach]3315[/attach]\n\n#### kafka\n这里提到kafka是因为在大部分的架构当中，我们都会用到kafka作为中间件数据缓冲区，因此不得不维护kafka集群。同样，如果不做特定的配置，也会遇到日志的问题：不停增多的rolling日志文件\n[attach]3317[/attach]\n\n原因是kafka的默认log4j配置是使用`DailyRollingFileAppender`每隔一个小时生成一个文件 `'.'yyyy-MM-dd-HH`：\n```\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.kafkaAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log\nlog4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.stateChangeAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.stateChangeAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change.log\nlog4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.requestAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request.log\nlog4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.cleanerAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.cleanerAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner.log\nlog4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.controllerAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.controllerAppender.File=${kafka.logs.dir}/controller.log\nlog4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.authorizerAppender=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.authorizerAppender.DatePattern='.'yyyy-MM-dd-HH\nlog4j.appender.authorizerAppender.File=${kafka.logs.dir}/kafka-authorizer.log\nlog4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n```\n\n### 解决方案\n因此，对于我们需要维护的这几个组件，需要配置合理的日志rotate策略。一个比较常用的策略就是时间+size，每天rotate一个日志文件或者每当日志文件大小超过256M，rotate一个新的日志文件，并且最多保留7天之内的日志文件。\n\n#### elasticsearch \n通过修改`log4j2.properties`文件来解决。该文件在`/etc/elasticsesarch`目录下（或者`config`目录）。\n默认配置是：\n```\nappender.rolling.type = RollingFile \nappender.rolling.name = rolling\nappender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log \nappender.rolling.layout.type = PatternLayout\nappender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %.-10000m%n\nappender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.log.gz \nappender.rolling.policies.type = Policies\nappender.rolling.policies.time.type = TimeBasedTriggeringPolicy \nappender.rolling.policies.time.interval = 1 \nappender.rolling.policies.time.modulate = true \nappender.rolling.policies.size.type = SizeBasedTriggeringPolicy \nappender.rolling.policies.size.size = 256MB \nappender.rolling.strategy.type = DefaultRolloverStrategy\nappender.rolling.strategy.fileIndex = nomax\nappender.rolling.strategy.action.type = Delete \nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\nappender.rolling.strategy.action.condition.type = IfFileName \nappender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* \nappender.rolling.strategy.action.condition.nested_condition.type = IfAccumulatedFileSize \nappender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB \n```\n以上默认配置，会保存2GB的日志，只有累计的日志大小超过2GB的时候，才会删除旧的日志文件。\n建议改为如下配置，仅保留最近7天的日志\n```\nappender.rolling.strategy.type = DefaultRolloverStrategy\nappender.rolling.strategy.action.type = Delete\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\nappender.rolling.strategy.action.condition.type = IfFileName\nappender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-*\nappender.rolling.strategy.action.condition.nested_condition.type = IfLastModified\nappender.rolling.strategy.action.condition.nested_condition.age = 7D\n```\n**这里必须注意，log4j2会因为末尾的空格导致无法识别配置**\n#### logstash\n\n与elasticsearch类似，通过修改`log4j2.properties`文件来解决。该文件在`/etc/logstash`目录下（或者`config`目录）。\n默认配置是不会删除历史日志的：\n```\nstatus = error\nname = LogstashPropertiesConfig\n\nappender.console.type = Console\nappender.console.name = plain_console\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n\n\nappender.json_console.type = Console\nappender.json_console.name = json_console\nappender.json_console.layout.type = JSONLayout\nappender.json_console.layout.compact = true\nappender.json_console.layout.eventEol = true\n\nappender.rolling.type = RollingFile\nappender.rolling.name = plain_rolling\nappender.rolling.fileName = ${sys:ls.logs}/logstash-${sys:ls.log.format}.log\nappender.rolling.filePattern = ${sys:ls.logs}/logstash-${sys:ls.log.format}-%d{yyyy-MM-dd}.log\nappender.rolling.policies.type = Policies\nappender.rolling.policies.time.type = TimeBasedTriggeringPolicy\nappender.rolling.policies.time.interval = 1\nappender.rolling.policies.time.modulate = true\nappender.rolling.layout.type = PatternLayout\nappender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %-.10000m%n\n```\n需手动加上：\n```\nappender.rolling.strategy.type = DefaultRolloverStrategy\nappender.rolling.strategy.action.type = Delete\nappender.rolling.strategy.action.basepath = ${sys:ls.logs}\nappender.rolling.strategy.action.condition.type = IfFileName\nappender.rolling.strategy.action.condition.glob = ${sys:ls.logs}/logstash-${sys:ls.log.format}\nappender.rolling.strategy.action.condition.nested_condition.type = IfLastModified\nappender.rolling.strategy.action.condition.nested_condition.age = 7D\n```\n\n#### kibana\n在kibana的配置文件中，只有以下几个选项：\n```\nlogging.dest:\nDefault: stdout Enables you specify a file where Kibana stores log output.\nlogging.quiet:\nDefault: false Set the value of this setting to true to suppress all logging output other than error messages.\nlogging.silent:\nDefault: false Set the value of this setting to true to suppress all logging output.\nlogging.verbose:\nDefault: false Set the value of this setting to true to log all events, including system usage information and all requests. Supported on Elastic Cloud Enterprise.\nlogging.timezone\nDefault: UTC Set to the canonical timezone id (e.g. US/Pacific) to log events using that timezone. A list of timezones can be referenced at https://en.wikipedia.org/wiki/List_of_tz_database_time_zones.\n```\n我们可以指定输出的日志文件与日志内容，但是却不可以配置日志的rotate。这时，我们需要使用logrotate，这个linux默认安装的工具。\n首先，我们要在配置文件里面指定生成pid文件：\n```\npid.file: \u0026quot;pid.log\u0026quot;\n```\n然后，修改`/etc/logrotate.conf`:\n```\n/var/log/kibana {\n    missingok\n    notifempty\n    sharedscripts\n    daily\n    rotate 7\n    copytruncate\n    /bin/kill -HUP $(cat /usr/share/kibana/pid.log 2\u0026gt;/dev/null) 2\u0026gt;/dev/null\n    endscript\n}\n```\n#### kafka\n如果不想写脚本清理过多的文件的话，需要修改`config/log4j.properties`文件。使用RollingFileAppender代替DailyRollingFileAppender，同时设置`MaxFileSize`和`MaxBackupIndex`。即修改为：\n```\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nlog4j.rootLogger=INFO, stdout\n\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.kafkaAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log\nlog4j.appender.kafkaAppender.MaxFileSize=10MB\nlog4j.appender.kafkaAppender.MaxBackupIndex=10\nlog4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.stateChangeAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change.log\nlog4j.appender.stateChangeAppender.MaxFileSize=10M\nlog4j.appender.stateChangeAppender.MaxBackupIndex=10\nlog4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.requestAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request.log\nlog4j.appender.requestAppender.MaxFileSize=10MB\nlog4j.appender.requestAppender.MaxBackupIndex=10\nlog4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.cleanerAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner.log\nlog4j.appender.cleanerAppender.MaxFileSize=10MB\nlog4j.appender.cleanerAppender.MaxBackupIndex=10\nlog4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.controllerAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.controllerAppender.File=${kafka.logs.dir}/controller.log\nlog4j.appender.controllerAppender.MaxFileSize=10MB\nlog4j.appender.controllerAppender.MaxBackupIndex=10\nlog4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\nlog4j.appender.authorizerAppender=org.apache.log4j.RollingFileAppender\nlog4j.appender.authorizerAppender.File=${kafka.logs.dir}/kafka-authorizer.log\nlog4j.appender.authorizerAppender.MaxFileSize=10MB\nlog4j.appender.authorizerAppender.MaxBackupIndex=10\nlog4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\nlog4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n# Turn on all our debugging info\n#log4j.logger.kafka.producer.async.DefaultEventHandler=DEBUG, kafkaAppender\n#log4j.logger.kafka.client.ClientUtils=DEBUG, kafkaAppender\n#log4j.logger.kafka.perf=DEBUG, kafkaAppender\n#log4j.logger.kafka.perf.ProducerPerformance$ProducerThread=DEBUG, kafkaAppender\n#log4j.logger.org.I0Itec.zkclient.ZkClient=DEBUG\nlog4j.logger.kafka=INFO, kafkaAppender\n\nlog4j.logger.kafka.network.RequestChannel$=WARN, requestAppender\nlog4j.additivity.kafka.network.RequestChannel$=false\n\n#log4j.logger.kafka.network.Processor=TRACE, requestAppender\n#log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender\n#log4j.additivity.kafka.server.KafkaApis=false\nlog4j.logger.kafka.request.logger=WARN, requestAppender\nlog4j.additivity.kafka.request.logger=false\n\nlog4j.logger.kafka.controller=TRACE, controllerAppender\nlog4j.additivity.kafka.controller=false\n\nlog4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender\nlog4j.additivity.kafka.log.LogCleaner=false\n\nlog4j.logger.state.change.logger=TRACE, stateChangeAppender\nlog4j.additivity.state.change.logger=false\n\n#Change this to debug to get the actual audit log for authorizer.\nlog4j.logger.kafka.authorizer.logger=WARN, authorizerAppender\nlog4j.additivity.kafka.authorizer.logger=false\n```\n\n\n\n\n","title":"搭建Elasitc stack集群需要注意的日志问题","uid":"5649","views":"174","votes":"1"},"_type":"doc"}
{"_id":"6186","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544493655","category_id":"2","comments":"0","has_attach":"1","id":"6186","message":"[b]本次分享包括两篇文章[/b]\n[list]\n[*]父子关系维护检索实战一 Elasticsearch 5.x 父子关系维护检索实战[/*]\n[*]父子关系维护检索实战二 Elasticsearch 6.x 父子关系维护检索实战\n[/*]\n[/list]\n[b]本文是其中第一篇[/b]- Elasticsearch 5.x 父子关系维护检索实战，涵盖以下部分内容：\n[list=1]\n[*]Elasticsearch 5.x 中父子关系mapping结构设计[/*]\n[*]Elasticsearch 5.x 中维护父子关系数据[/*]\n[*]Elasticsearch 5.x 中has_child和has_parent查询的基本用法[/*]\n[*]Elasticsearch 5.x 中如何在检索中同时返回父子数据\n[/*]\n[/list]\n[b]案例说明[/b]\n以一个体检记录相关的数据来介绍本文涉及的相关功能，体检数据包括客户基本信息basic和客户医疗记录medical、客户体检记录exam、客户体检结果分析记录diagnosis，它们之间的关系图如下：\n[attach]3258[/attach]\n\n我们采用Elasticsearch java客户端 [url=https://www.oschina.net/p/bboss-elastic]bboss-elastic[/url] 来实现本文相关功能。\n\n[b]1.准备工作[/b]\n参考文档《[url=https://my.oschina.net/bboss/blog/1556866]高性能elasticsearch ORM开发库使用介绍[/url]》导入和配置bboss客户端\n\n[b]2.定义mapping结构-Elasticsearch 5.x 中父子关系mapping结构设计[/b]\nElasticsearch 5.x中一个indice mapping支持多个mapping type，通过在子类型mapping中指定父类型的mapping type名字来设置父子关系，例如：\n父类型\n\u0026quot;basic\u0026quot;: {\n....\n}\n子类型：\n\u0026quot;medical\u0026quot;: { \n      \u0026quot;_parent\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot; },\n     .................\n}\n新建dsl配置文件-esmapper/Client_Info.xml，定义完整的mapping结构：createClientIndice[code]\u0026lt;properties\u0026gt;\n  \n    \u0026lt;!--\n   创建客户信息索引索引表\n   --\u0026gt;\n    \u0026lt;property name=\u0026quot;createClientIndice\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[{\n            \u0026quot;settings\u0026quot;: {\n                \u0026quot;number_of_shards\u0026quot;: 6,\n                \u0026quot;index.refresh_interval\u0026quot;: \u0026quot;5s\u0026quot;\n            },\n            \u0026quot;mappings\u0026quot;: {\n                \u0026quot;basic\u0026quot;: {  ##基本信息\n                    \u0026quot;properties\u0026quot;: {\n                        \u0026quot;party_id\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;sex\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;mari_sts\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;ethnic\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;prof\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;province\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;city\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;client_type\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;client_name\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;age\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n                        },\n                        \u0026quot;id_type\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;idno\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;education\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;created_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;birth_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;last_modified_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;etl_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        }\n                    }\n                },\n                \u0026quot;diagnosis\u0026quot;: { ##结果分析\n                    \u0026quot;_parent\u0026quot;: {\n                        \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot;\n                    },\n                    \u0026quot;properties\u0026quot;: {\n                        \u0026quot;party_id\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;provider\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;subject\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;diagnosis_type\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;icd10_code\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;sd_disease_name\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;created_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;last_modified_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;etl_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        }\n                    }\n                },\n                \u0026quot;medical\u0026quot;: { ##医疗情况\n                    \u0026quot;_parent\u0026quot;: {\n                        \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot;\n                    },\n                    \u0026quot;properties\u0026quot;: {\n                        \u0026quot;party_id\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;hos_name_yb\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;eivisions_name\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;medical_type\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;medical_common_name\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;medical_sale_name\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;medical_code\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;specification\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;usage_num\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;unit\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;usage_times\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;created_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;last_modified_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;etl_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        }\n                    }\n                },\n                \u0026quot;exam\u0026quot;: { ##检查结果\n                    \u0026quot;_parent\u0026quot;: {\n                        \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot;\n                    },\n                    \u0026quot;properties\u0026quot;: {\n                        \u0026quot;party_id\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n                        },\n                        \u0026quot;hospital\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;dept\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;is_ok\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;exam_result\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld1\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld2\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld3\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld4\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld5\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld901\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld6\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld902\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld14\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld20\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld21\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld23\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld24\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld65\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld66\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld67\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;fld68\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n                        },\n                        \u0026quot;created_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;last_modified_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        },\n                        \u0026quot;etl_date\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n                            \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss.SSS||yyyy-MM-dd'T'HH:mm:ss.SSS||yyyy-MM-dd HH:mm:ss||epoch_millis\u0026quot;\n                        }\n                    }\n                }\n            }\n        }]]\u0026gt;\n    \u0026lt;/property\u0026gt;\n\u0026lt;/properties\u0026gt;[/code]\n这个mapping中定义了4个索引类型：basic,exam,medical,diagnosis,其中basic是其他类型的父类型。\n通过bboss客户端创建名称为client_info 的索引：[code]\tpublic void createClientIndice(){\n\t\t//定义客户端实例，加载上面建立的dsl配置文件\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_Info.xml\u0026quot;);\n\t\ttry {\n\t\t\t//client_info存在返回true，不存在返回false\n\t\t\tboolean exist = clientUtil.existIndice(\u0026quot;client_info\u0026quot;);\n\n\t\t\t//如果索引表client_info已经存在先删除mapping\n\t\t\tif(exist) {//先删除mapping client_info\n\t\t\t\tclientUtil.dropIndice(\u0026quot;client_info\u0026quot;);\n\t\t\t}\n\t\t} catch (ElasticSearchException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\t//创建mapping client_info\n\t\tclientUtil.createIndiceMapping(\u0026quot;client_info\u0026quot;,\u0026quot;createClientIndice\u0026quot;);\n\t\tString client_info = clientUtil.getIndice(\u0026quot;client_info\u0026quot;);//获取最新建立的索引表结构client_info\n\t\tSystem.out.println(\u0026quot;after createClientIndice clientUtil.getIndice(\\\u0026quot;client_info\\\u0026quot;) response:\u0026quot;+client_info);\n\t}[/code]\n\n[b]3.维护父子关系数据-Elasticsearch 5.x 中维护父子关系数据[/b]\n[list]\n[*][b]定义对象[/b][/*]\n[/list]\n首先定义四个对象，分别对应mapping中的四个索引类型，篇幅关系只列出主要属性\n[list]\n[*]Basic[/*]\n[*]Medical[/*]\n[*]Exam[/*]\n[*]Diagnosis[/*]\n[/list]\n通过注解@ESId指定基本信息文档_id[code]public class Basic extends ESBaseData {\n    /**\n     *  索引_id\n     */\n    @ESId\n    private String party_id;\n    private String sex;                     // 性别\n    ......\n}    \n通过注解@ESParentId指定Medical关联的基本信息文档_id，Medical文档_id由ElasticSearch自动生成\npublic class Medical extends ESBaseData {\n    @ESParentId\n    private String party_id;          //父id\n    private String hos_name_yb;         //就诊医院\n    ...\n}\n通过注解@ESParentId指定Exam关联的基本信息文档_id，Exam文档_id由ElasticSearch自动生成\npublic class Exam extends ESBaseData {\n    @ESParentId\n    private String party_id;          //父id\n    private String  hospital;           // 就诊医院\n    ....\n}    \n通过注解@ESParentId指定Diagnosis关联的基本信息文档_id，Diagnosis文档_id由ElasticSearch自动生成\npublic class Diagnosis extends ESBaseData {\n    @ESParentId\n    private String party_id;          //父id\n    private String provider;            //诊断医院\n    private String subject;             //科室\n    ......\n}    [/code]\n[list]\n[*][b]通过api维护测试数据[/b][/*]\n[/list]\n对象定义好了后，通过bboss客户数据到之前建立好的索引client_info中。[code]\t/**\n\t * 录入体检医疗信息\n\t */\n\tpublic void importClientInfoDataFromBeans()  {\n\t\tClientInterface clientUtil = ElasticSearchHelper.getRestClientUtil();\n\n\t\t//导入基本信息,并且实时刷新，测试需要，实际环境不要带refresh\n\t\tList\u0026lt;Basic\u0026gt; basics = buildBasics();\n\t\tclientUtil.addDocuments(\u0026quot;client_info\u0026quot;,\u0026quot;basic\u0026quot;,basics,\u0026quot;refresh\u0026quot;);\n\n\t\t//导入医疗信息,并且实时刷新，测试需要，实际环境不要带refresh\n\t\tList\u0026lt;Medical\u0026gt; medicals = buildMedicals();\n\t\tclientUtil.addDocuments(\u0026quot;client_info\u0026quot;,\u0026quot;medical\u0026quot;,medicals,\u0026quot;refresh\u0026quot;);\n\n\t\t//导入体检结果数据,并且实时刷新，测试需要，实际环境不要带refresh\n\t\tList\u0026lt;Exam\u0026gt; exams = buildExams();\n\t\tclientUtil.addDocuments(\u0026quot;client_info\u0026quot;,\u0026quot;exam\u0026quot;,exams,\u0026quot;refresh\u0026quot;);\n\n\t\t//导入结果诊断数据,并且实时刷新，测试需要，实际环境不要带refresh\n\t\tList\u0026lt;Diagnosis\u0026gt; diagnosiss = buildDiagnosiss();\n\t\tclientUtil.addDocuments(\u0026quot;client_info\u0026quot;,\u0026quot;diagnosis\u0026quot;,diagnosiss,\u0026quot;refresh\u0026quot;);\n\t}\n\t//构建基本信息集合\n\tprivate List\u0026lt;Basic\u0026gt; buildBasics() {\n\t\tList\u0026lt;Basic\u0026gt; basics = new ArrayList\u0026lt;Basic\u0026gt;();\n\t\tBasic basic = new Basic();\n\t\tbasic.setParty_id(\u0026quot;1\u0026quot;);\n\t\tbasic.setAge(60);\n\t\tbasics.add(basic);\n\t\t//继续添加其他数据\n\t\treturn basics;\n\n\t}\n\t//\n构建医疗信息集合\n\tprivate List\u0026lt;Medical\u0026gt; buildMedicals() {\n\t\tList\u0026lt;Medical\u0026gt; medicals = new ArrayList\u0026lt;Medical\u0026gt;();\n\t\tMedical medical = new Medical();\n\t\tmedical.setParty_id(\u0026quot;1\u0026quot;);//设置父文档id-基本信息文档_id\n\t\tmedical.setCreated_date(new Date());\n\t\tmedicals.add(medical);\n\t\t//继续添加其他数据\n\t\treturn medicals;\n\n\t}\n\t//构建体检结果数据集合\n\tprivate List\u0026lt;Exam\u0026gt; buildExams() {\n\t\tList\u0026lt;Exam\u0026gt; exams = new ArrayList\u0026lt;Exam\u0026gt;();\n\t\tExam exam = new Exam();\n\t\texam.setParty_id(\u0026quot;1\u0026quot;);//设置父文档id-基本信息文档_id\n\t\texams.add(exam);\n\t\t//继续添加其他数据\n\t\treturn exams;\n\t}\n\t//构建结果诊断数据集合\n\tprivate List\u0026lt;Diagnosis\u0026gt; buildDiagnosiss() {\n\t\tList\u0026lt;Diagnosis\u0026gt; diagnosiss = new ArrayList\u0026lt;Diagnosis\u0026gt;();\n\t\tDiagnosis diagnosis = new Diagnosis();\n\t\tdiagnosis.setParty_id(\u0026quot;1\u0026quot;);//设置父文档id-基本信息文档_id\n\t\tdiagnosiss.add(diagnosis);\n\t\t//继续添加其他数据\n\t\treturn diagnosiss;\n\t}[/code]\n[list]\n[*][b]通过json报文批量导入测试数据[/b][/*]\n[/list]\n除了通过addDocuments录入数据，还可以通过json报文批量导入数据\n在配置文件esmapper/Client_Info.xml增加以下内容：[code]    \u0026lt;!--\n   导入基本信息：\n   --\u0026gt;\n    \u0026lt;property name=\u0026quot;bulkImportBasicData\u0026quot; trim=\u0026quot;false\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;1\u0026quot; }}\n            {  \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;男\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;不详\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;蒙古族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;放牧\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1966-2-14 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;内蒙古\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;赤峰市\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;安\u0026quot;, \u0026quot;age\u0026quot;:52,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;初中\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2013-04-24 00:00:00\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-04-24 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-04-24 00:00:00\u0026quot;}\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;2\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;2\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;已婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;公务员\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1986-07-06 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;广东\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;深圳\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;彭\u0026quot;, \u0026quot;age\u0026quot;:32,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;2\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;本科\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2013-05-09 15:49:47\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-05-09 15:49:47\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-05-09 15:49:47\u0026quot;}\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;3\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;3\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;男\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;未婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;无业\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;2000-08-15 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;广东\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;佛山\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;浩\u0026quot;, \u0026quot;age\u0026quot;:18,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;3\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;高中\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2014-09-01 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-09-01 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-09-01 09:49:27\u0026quot; }\n             { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;4\u0026quot; }}\n             { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;未婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;满族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;工人\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1996-03-14 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;江苏\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;扬州\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;慧\u0026quot;, \u0026quot;age\u0026quot;:22,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;高中\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2014-09-16 09:30:37\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-09-16 09:30:37\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-09-16 09:30:37\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;5\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;5\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;已婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;教师\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1983-08-14 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;宁夏\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;灵武\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;英\u0026quot;, \u0026quot;age\u0026quot;:35,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;5\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;本科\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2015-09-16 09:30:37\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2015-09-16 09:30:37\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2015-09-16 09:30:37\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;6\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;已婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;工人\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1959-07-04 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;山东\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;青岛\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;岭\u0026quot;, \u0026quot;age\u0026quot;:59,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;小学\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2015-09-01 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2015-09-01 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2015-09-01 09:49:27\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;7\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;7\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;未婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;学生\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1999-02-18 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;山东\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;青岛\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;欣\u0026quot;, \u0026quot;age\u0026quot;:19,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;7\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;高中\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2016-12-01 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-12-01 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-12-01 09:49:27\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;8\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;8\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;女\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;未婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;学生\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;2007-11-18 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;山东\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;青岛\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;梅\u0026quot;, \u0026quot;age\u0026quot;:10,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;8\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;小学\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2016-11-21 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-11-21 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-11-21 09:49:27\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;9\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;9\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;男\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;不详\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;回族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;个体户\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1978-03-29 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;北京\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;北京\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;磊\u0026quot;, \u0026quot;age\u0026quot;:40,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;9\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;高中\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2017-09-01 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2017-09-01 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2017-09-01 09:49:27\u0026quot; }\n            { \u0026quot;index\u0026quot;: { \u0026quot;_id\u0026quot;: \u0026quot;10\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;10\u0026quot;, \u0026quot;sex\u0026quot;:\u0026quot;男\u0026quot;, \u0026quot;mari_sts\u0026quot;:\u0026quot;已婚\u0026quot;, \u0026quot;ethnic\u0026quot;:\u0026quot;汉族\u0026quot;, \u0026quot;prof\u0026quot;:\u0026quot;农民\u0026quot;,\u0026quot;birth_date\u0026quot;:\u0026quot;1970-11-14 00:00:00\u0026quot;, \u0026quot;province\u0026quot;:\u0026quot;浙江\u0026quot;, \u0026quot;city\u0026quot;:\u0026quot;台州\u0026quot;,\u0026quot;client_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;client_name\u0026quot;:\u0026quot;强\u0026quot;, \u0026quot;age\u0026quot;:47,\u0026quot;id_type\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;idno\u0026quot;:\u0026quot;10\u0026quot;, \u0026quot;education\u0026quot;:\u0026quot;初中\u0026quot;, \u0026quot;created_date\u0026quot;:\u0026quot;2018-09-01 09:49:27\u0026quot;,\u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-09-01 09:49:27\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-09-01 09:49:27\u0026quot; }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;\n    \u0026lt;!--\n  导入诊断信息\n  --\u0026gt;\n    \u0026lt;property name=\u0026quot;bulkImportDiagnosisData\u0026quot; trim=\u0026quot;false\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;J31.0\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;鼻炎\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;M47.8\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;E78.1\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;甘油三脂增高\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;4\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;江苏医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;J00\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;6\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;H44\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;眼疾\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;6\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;M47.8\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-04-08 10:42:18\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;7\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;7\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;J00\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2017-04-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2017-04-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2017-04-08 10:42:18\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;8\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;8\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;J00\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;9\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;9\u0026quot;, \u0026quot;provider\u0026quot;:\u0026quot;朝阳医院\u0026quot;, \u0026quot;subject\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;diagnosis_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;icd10_code\u0026quot;:\u0026quot;A03.901\u0026quot;, \u0026quot;sd_disease_name\u0026quot;:\u0026quot;急性细菌性痢疾\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot; }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;\n\n    \u0026lt;!--\n 导入医疗信息\n --\u0026gt;\n    \u0026lt;property name=\u0026quot;bulkImportMedicalData\u0026quot; trim=\u0026quot;false\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;氟化钠\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AA01\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;四环素\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB13\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2016-05-31 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-05-31 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-05-31 00:00:00\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;盐酸多西环素胶丸\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB22\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2016-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2016-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2016-03-18 00:00:00\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;盐酸多西环素分散片\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB22\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-07-23 20:56:44\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;地塞米松\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AC02\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2013-09-23 20:56:44\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;内蒙古医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;肾上腺素\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AD01\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-09-20 09:27:44\u0026quot; }\n\n                 { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;4\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;江苏医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;地塞米松\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AC02\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2011-05-19 15:52:55\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;4\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;江苏医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;四环素\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB13\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-04-08 10:42:18\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;4\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;江苏医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;诺氟沙星胶囊\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AD01\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2015-06-08 10:42:18\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;6\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;盐酸异丙肾上腺素片\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AD01\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;6\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;山东医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;甲硝唑栓\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB17\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2018-06-08 10:42:18\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2018-06-08 10:42:18\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2018-06-08 10:42:18\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;9\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;9\u0026quot;, \u0026quot;hos_name_yb\u0026quot;:\u0026quot;朝阳医院\u0026quot;, \u0026quot;eivisions_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_type\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;medical_common_name\u0026quot;:\u0026quot;复方克霉唑乳膏\u0026quot;, \u0026quot;medical_sale_name\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;medical_code\u0026quot;:\u0026quot;A01AB18\u0026quot;, \u0026quot;specification\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;usage_num\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;unit\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;usage_times\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-01-23 20:56:44\u0026quot;}\n         ]]\u0026gt;\n    \u0026lt;/property\u0026gt;\n\n    \u0026lt;!--\n     导入体检信息\n--\u0026gt;\n    \u0026lt;property name=\u0026quot;bulkImportExamData\u0026quot; trim=\u0026quot;false\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;1\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;高血压\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;2\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;2\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;Y\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;轻度脂肪肝\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;3\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;3\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;急性细菌性痢疾\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;4\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;4\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;5\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;5\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;6\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;6\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;感冒\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;7\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;7\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;8\u0026quot; }}\n            { \u0026quot;party_id\u0026quot;:\u0026quot;1\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n            { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;9\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;9\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n\n                { \u0026quot;index\u0026quot;: { \u0026quot;parent\u0026quot;: \u0026quot;10\u0026quot; }}\n                { \u0026quot;party_id\u0026quot;:\u0026quot;10\u0026quot;, \u0026quot;hospital\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;dept\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;is_ok\u0026quot;:\u0026quot;N\u0026quot;, \u0026quot;exam_result\u0026quot;:\u0026quot;颈椎病\u0026quot;,\u0026quot;fld1\u0026quot;:\u0026quot;158\u0026quot;, \u0026quot;fld2\u0026quot;:\u0026quot;63\u0026quot;, \u0026quot;fld3\u0026quot;:\u0026quot;94\u0026quot;, \u0026quot;fld4\u0026quot;:\u0026quot;85\u0026quot;, \u0026quot;fld5\u0026quot;:\u0026quot;131\u0026quot;, \u0026quot;fld901\u0026quot;:\u0026quot;89\u0026quot;, \u0026quot;fld6\u0026quot;:\u0026quot;4.9\u0026quot;,\u0026quot;fld902\u0026quot;:\u0026quot;4.8\u0026quot;,\u0026quot;fld14\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld21\u0026quot;:\u0026quot;78\u0026quot;, \u0026quot;fld23\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld24\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld65\u0026quot;:\u0026quot;5.5\u0026quot;, \u0026quot;fld66\u0026quot;:\u0026quot;1.025\u0026quot;,\u0026quot;fld67\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;fld68\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;created_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;last_modified_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot;, \u0026quot;etl_date\u0026quot;:\u0026quot;2014-03-18 00:00:00\u0026quot; }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;\n\n\n\n\n\n\n\n[/code]通过bboss提供的通用api，导入上面定义的数据：[code]\t/**\n\t * 通过读取配置文件中的dsl json数据导入医疗数据\n\t */\n\tpublic void importClientInfoFromJsonData(){\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_Info.xml\u0026quot;);\n\n\t\tclientUtil.executeHttp(\u0026quot;client_info/basic/_bulk?refresh\u0026quot;,\u0026quot;bulkImportBasicData\u0026quot;,ClientUtil.HTTP_POST);\n\t\tclientUtil.executeHttp(\u0026quot;client_info/diagnosis/_bulk?refresh\u0026quot;,\u0026quot;bulkImportDiagnosisData\u0026quot;,ClientUtil.HTTP_POST);\n\t\tclientUtil.executeHttp(\u0026quot;client_info/medical/_bulk?refresh\u0026quot;,\u0026quot;bulkImportMedicalData\u0026quot;,ClientUtil.HTTP_POST);\n\t\tclientUtil.executeHttp(\u0026quot;client_info/exam/_bulk?refresh\u0026quot;,\u0026quot;bulkImportExamData\u0026quot;,ClientUtil.HTTP_POST);[/code]统计导入的数据[code]\t\t\n\t\tlong basiccount = clientUtil.countAll(\u0026quot;client_info/basic\u0026quot;);\n\t\tSystem.out.println(basiccount);\n\t\tlong medicalcount = clientUtil.countAll(\u0026quot;client_info/medical\u0026quot;);\n\t\tSystem.out.println(medicalcount);\n\t\tlong examcount = clientUtil.countAll(\u0026quot;client_info/exam\u0026quot;);\n\t\tSystem.out.println(examcount);\n\t\tlong diagnosiscount = clientUtil.countAll(\u0026quot;client_info/diagnosis\u0026quot;);\n\t\tSystem.out.println(diagnosiscount);\n\t}[/code][b]4.父子关系查询-Elasticsearch 5.x 中has_child和has_parent查询的基本用法​[/b]\n[list]\n[*][b]根据父查子-通过客户名称信息查询客户端体检结果[/b][/*]\n[/list]\n在配置文件esmapper/Client_Info.xml增加dsl语句：queryExamSearchByClientName[code]   \u0026lt;!--根据客户名称查询客户体检报告--\u0026gt;\n    \u0026lt;property name=\u0026quot;queryExamSearchByClientName\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            {\n              \u0026quot;query\u0026quot;: {\n                ## 最多返回size变量对应的记录条数\n                \u0026quot;size\u0026quot;:#[size],\n                \u0026quot;has_parent\u0026quot;: {\n                  \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot;,\n                  \u0026quot;query\u0026quot;: {\n                    \u0026quot;match\u0026quot;: {\n                      \u0026quot;client_name\u0026quot;: #[clientName] ## 通过变量clientName设置客户名称\n                    }\n                  }\n                }\n              }\n            }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;[/code]\n 执行查询，通过bboss的searchList 方法获取符合条件的体检报告以及总记录数据，返回size对应的1000条数据[code]\t/**\n\t * 根据客户名称查询客户体检报告\n\t */\n\tpublic void queryExamSearchByClientName(){\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_info.xml\u0026quot;);\n\t\tMap\u0026lt;String,Object\u0026gt; params = new HashMap\u0026lt;String,Object\u0026gt;();\n\t\tparams.put(\u0026quot;clientName\u0026quot;,\u0026quot;张三\u0026quot;);\n\t\tparams.put(\u0026quot;size\u0026quot;,1000);\n\t\tESDatas\u0026lt;Exam\u0026gt; exams = clientUtil.searchList(\u0026quot;client_info/exam/_search\u0026quot;,\u0026quot;queryExamSearchByClientName\u0026quot;,params,Exam.class);\n\t\tList\u0026lt;Exam\u0026gt; examList = exams.getDatas();//获取符合条件的体检数据\n\t\tlong totalSize = exams.getTotalSize();//符合条件的总记录数据\n\t}[/code] \n[list]\n[*][b]根据子查父数据-[/b][b]通过医疗信息编码查找客户基本数据[/b][/*]\n[/list]\n在配置文件esmapper/Client_Info.xml增加查询dsl语句：queryClientInfoByMedicalName[code]    \u0026lt;!--通过医疗信息编码查找客户基本数据--\u0026gt;\n    \u0026lt;property name=\u0026quot;queryClientInfoByMedicalName\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            {\n              \u0026quot;query\u0026quot;: {\n                ## 最多返回size变量对应的记录条数\n                \u0026quot;size\u0026quot;:#[size],\n                \u0026quot;has_child\u0026quot;: {\n                  \u0026quot;type\u0026quot;:       \u0026quot;medical\u0026quot;,\n                  \u0026quot;score_mode\u0026quot;: \u0026quot;max\u0026quot;,\n                  \u0026quot;query\u0026quot;: {\n                    \u0026quot;match\u0026quot;: {\n                      \u0026quot;medical_code\u0026quot;: #[medicalCode] ## 通过变量medicalCode设置医疗编码\n                    }\n                  }\n                }\n              }\n            }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;[/code]执行查询，通过bboss的searchList 方法获取符合条件的客户端基本信息以及总记录数据[code]\t/**\n\t * 通过医疗信息编码查找客户基本数据\n\t */\n\tpublic void queryClientInfoByMedicalName(){\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_info.xml\u0026quot;);\n\t\tMap\u0026lt;String,Object\u0026gt; params = new HashMap\u0026lt;String,Object\u0026gt;();\n\t\tparams.put(\u0026quot;medicalCode\u0026quot;,\u0026quot;A01AA01\u0026quot;); //通过变量medicalCode设置医疗编码\n\t\tparams.put(\u0026quot;size\u0026quot;,1000); //最多返回size变量对应的记录条数\n\t\tESDatas\u0026lt;Basic\u0026gt; bascis = clientUtil.searchList(\u0026quot;client_info/basic/_search\u0026quot;,\u0026quot;queryClientInfoByMedicalName\u0026quot;,params,Basic.class);\n\t\tList\u0026lt;Basic\u0026gt; bascisList = bascis.getDatas();//获取符合条件的客户信息\n\t\tlong totalSize = bascis.getTotalSize();\n\t}[/code][b]5.同时返回父子数据-Elasticsearch 5.x 中如何在检索中同时返回父子数据[/b]\n这一节中我们介绍同时返回父子数据的玩法 ：inner_hits的妙用\n[list]\n[*][b]根据父条件查询所有子数据集合并返回父数据，根据客户名称查询所有体检数据，同时返回客户信息[/b]\n[/*]\n[/list]\n在配置文件esmapper/Client_Info.xml增加检索dsl-queryDiagnosisByClientName[code]    \u0026lt;!--根据客户名称获取客户体检诊断数据，并返回客户信息--\u0026gt;\n    \u0026lt;property name=\u0026quot;queryDiagnosisByClientName\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n            {\n              \u0026quot;query\u0026quot;: {\n                ## 最多返回size变量对应的记录条数\n                \u0026quot;size\u0026quot;:#[size],\n                \u0026quot;has_parent\u0026quot;: {\n                  \u0026quot;type\u0026quot;: \u0026quot;basic\u0026quot;,\n                  \u0026quot;query\u0026quot;: {\n                    \u0026quot;match\u0026quot;: {\n                      \u0026quot;client_name\u0026quot;: #[clientName] ## 通过变量clientName设置客户名称\n                    }\n                  },\n                  \u0026quot;inner_hits\u0026quot;: {}  ## 通过变量inner_hits表示要返回对应的客户信息\n                }\n              }\n            }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;[/code]执行检索并遍历结果[code]\t/**\n\t * 根据客户名称获取客户体检诊断数据，并返回客户数据\n\t */\n\tpublic void queryDiagnosisByClientName(){\n\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_info.xml\u0026quot;);\n\t\tMap\u0026lt;String,Object\u0026gt; params = new HashMap\u0026lt;String,Object\u0026gt;();\n\t\tparams.put(\u0026quot;clientName\u0026quot;,\u0026quot;张三\u0026quot;);\n\t\tparams.put(\u0026quot;size\u0026quot;,1000);\n\n\t\ttry {\n\t\t\tESInnerHitSerialThreadLocal.setESInnerTypeReferences(Basic.class);//指定inner查询结果对应的客户基本信息类型,Basic只有一个文档类型，索引不需要显示指定basic对应的mapping type名称\n\t\t\tESDatas\u0026lt;Diagnosis\u0026gt; diagnosiss = clientUtil.searchList(\u0026quot;client_info/diagnosis/_search\u0026quot;,\n\t\t\t\t\t\u0026quot;queryDiagnosisByClientName\u0026quot;,params,Diagnosis.class);\n\t\t\tList\u0026lt;Diagnosis\u0026gt; diagnosisList = diagnosiss.getDatas();//获取符合条件的体检报告数据\n\t\t\tlong totalSize = diagnosiss.getTotalSize();\n\t\t\t//遍历诊断报告信息，并查看报告对应的客户基本信息\n\t\t\tfor(int i = 0;  diagnosisList != null \u0026amp;\u0026amp; i \u0026lt; diagnosisList.size(); i ++) {\n\t\t\t\tDiagnosis diagnosis = diagnosisList.get(i);\n\t\t\t\tList\u0026lt;Basic\u0026gt; basics = ResultUtil.getInnerHits(diagnosis.getInnerHits(), \u0026quot;basic\u0026quot;);\n\t\t\t\tif(basics != null) {\n\t\t\t\t\tSystem.out.println(basics.size());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfinally{\n\t\t\tESInnerHitSerialThreadLocal.clean();//清空inner查询结果对应的客户基本信息类型\n\t\t}\n\t}[/code]\n[list]\n[*] [b]根据子条件查询父数据并返回符合条件的父的子数据集合，查询客户信息，同时返回客户对应的所有体检报告、医疗记录、诊断记录[/b]\n[/*]\n[/list]\n在配置文件esmapper/Client_Info.xml增加检索dsl-queryClientAndAllSons[code]    \u0026lt;!--查询客户信息，同时返回客户对应的所有体检报告、医疗记录、诊断记录--\u0026gt;\n    \u0026lt;property name=\u0026quot;queryClientAndAllSons\u0026quot;\u0026gt;\n        \u0026lt;![CDATA[\n        {\n          \u0026quot;query\u0026quot;: {\n            \u0026quot;bool\u0026quot;: {\n              \u0026quot;should\u0026quot;: [\n                {\n                    \u0026quot;match_all\u0026quot;:{}\n                }\n              ]\n              ,\u0026quot;must\u0026quot;: [\n                {\n                  \u0026quot;has_child\u0026quot;: {\n                    \u0026quot;score_mode\u0026quot;: \u0026quot;none\u0026quot;,\n                    \u0026quot;type\u0026quot;: \u0026quot;diagnosis\u0026quot;\n                    ,\u0026quot;query\u0026quot;: {\n                      \u0026quot;bool\u0026quot;: {\n                        \u0026quot;must\u0026quot;: [\n                          {\n                            \u0026quot;term\u0026quot;: {\n                              \u0026quot;icd10_code\u0026quot;: {\n                                \u0026quot;value\u0026quot;: \u0026quot;J00\u0026quot;\n                              }\n                            }\n                          }\n                        ]\n                      }\n                    },\u0026quot;inner_hits\u0026quot;:{}\n                  }\n                }\n                ]\n              ,\u0026quot;should\u0026quot;: [\n                  {\n                  \u0026quot;has_child\u0026quot;: {\n                    \u0026quot;score_mode\u0026quot;: \u0026quot;none\u0026quot;,\n                    \u0026quot;type\u0026quot;: \u0026quot;medical\u0026quot;\n                    ,\u0026quot;query\u0026quot;: {\n                      \u0026quot;match_all\u0026quot;: {}\n\n                    },\u0026quot;inner_hits\u0026quot;:{}\n                  }\n                }\n              ]\n              ,\u0026quot;should\u0026quot;: [\n                {\n                  \u0026quot;has_child\u0026quot;: {\n                    \u0026quot;type\u0026quot;: \u0026quot;exam\u0026quot;,\n                    \u0026quot;query\u0026quot;: {\n                      \u0026quot;match_all\u0026quot;: {}\n                    },\u0026quot;inner_hits\u0026quot;:{}\n                  }\n                }\n              ]\n            }\n          }\n        }\n        ]]\u0026gt;\n    \u0026lt;/property\u0026gt;[/code]执行查询：[code]\t/**\n\t * 查询客户信息，同时返回客户对应的所有体检报告、医疗记录、诊断记录\n\t */\n\tpublic void queryClientAndAllSons(){\n\t\tClientInterface clientUtil = ElasticSearchHelper.getConfigRestClientUtil(\u0026quot;esmapper/Client_Info.xml\u0026quot;);\n\t\tMap\u0026lt;String,Object\u0026gt; params = null;//没有检索条件，构造一个空的参数对象\n\n\t\ttry {\n\t\t\t//设置子文档的类型和对象映射关系\n\t\t\tESInnerHitSerialThreadLocal.setESInnerTypeReferences(\u0026quot;exam\u0026quot;,Exam.class);//指定inner查询结果对于exam类型和对应的对象类型Exam\n\t\t\tESInnerHitSerialThreadLocal.setESInnerTypeReferences(\u0026quot;diagnosis\u0026quot;,Diagnosis.class);//指定inner查询结果对于diagnosis类型和对应的对象类型Diagnosis\n\t\t\tESInnerHitSerialThreadLocal.setESInnerTypeReferences(\u0026quot;medical\u0026quot;,Medical.class);//指定inner查询结果对于medical类型和对应的对象类型Medical\n\t\t\tESDatas\u0026lt;Basic\u0026gt; escompanys = clientUtil.searchList(\u0026quot;client_info/basic/_search\u0026quot;,\n\t\t\t\t\t\u0026quot;queryClientAndAllSons\u0026quot;,params,Basic.class);\n\t\t\t//String response = clientUtil.executeRequest(\u0026quot;client_info/basic/_search\u0026quot;,\u0026quot;queryClientAndAllSons\u0026quot;,params);直接获取原始的json报文\n//\t\t\tescompanys = clientUtil.searchAll(\u0026quot;client_info\u0026quot;,Basic.class);\n\t\t\tlong totalSize = escompanys.getTotalSize();\n\t\t\tList\u0026lt;Basic\u0026gt; clientInfos = escompanys.getDatas();//获取符合条件的数据\n\t\t\t//查看公司下面的雇员信息（符合检索条件的雇员信息）\n\t\t\tfor (int i = 0; clientInfos != null \u0026amp;\u0026amp; i \u0026lt; clientInfos.size(); i++) {\n\t\t\t\tBasic clientInfo = clientInfos.get(i);\n\t\t\t\tList\u0026lt;Exam\u0026gt; exams = ResultUtil.getInnerHits(clientInfo.getInnerHits(), \u0026quot;exam\u0026quot;);\n\t\t\t\tif(exams != null)\n\t\t\t\t\tSystem.out.println(exams.size());\n\t\t\t\tList\u0026lt;Diagnosis\u0026gt; diagnosiss = ResultUtil.getInnerHits(clientInfo.getInnerHits(), \u0026quot;diagnosis\u0026quot;);\n\t\t\t\tif(diagnosiss != null)\n\t\t\t\t\tSystem.out.println(diagnosiss.size());\n\t\t\t\tList\u0026lt;Medical\u0026gt; medicals = ResultUtil.getInnerHits(clientInfo.getInnerHits(), \u0026quot;medical\u0026quot;);\n\t\t\t\tif(medicals != null)\n\t\t\t\t\tSystem.out.println(medicals.size());\n\n\t\t\t}\n\t\t}\n\t\tfinally{\n\t\t\tESInnerHitSerialThreadLocal.clean();//清空inner查询结果对于各种类型信息\n\t\t}\n\t}[/code]最后我们按顺序执行所有方法，验证功能：[code]\t@Test\n\tpublic void testMutil(){\n\t\tthis.createClientIndice();//创建indice client_info\n//\t\tthis.importClientInfoDataFromBeans(); //通过api添加测试数据\n\t\tthis.importClientInfoFromJsonData();//导入测试数据\n\t\tthis.queryExamSearchByClientName(); //根据客户端名称查询提交报告\n\t\tthis.queryClientInfoByMedicalName();//通过医疗信息编码查找客户基本数据\n\t\tthis.queryDiagnosisByClientName();//根据客户名称获取客户体检诊断数据，并返回客户数据\n\t\tthis.queryClientAndAllSons();//查询客户信息，同时返回客户对应的所有体检报告、医疗记录、诊断记录\n\t}[/code]可以下载完整的demo工程运行本文中的测试用例方法，地址见相关资料。\n到此Elasticsearch 5.x 父子关系维护检索实战介绍完毕，谢谢大家！\n\n[b]相关资料[/b]\n完整demo工程  [url]https://github.com/bbossgroups/eshelloword-booter[/url]\n对应的类文件和配置文件\n[url=https://github.com/bbossgroups/eshelloword-booter/blob/master/src/test/java/org/bboss/elasticsearchtest/parentchild/ParentChildTest.java]org.bboss.elasticsearchtest.parentchild.ParentChildTest[/url]\n[url=https://github.com/bbossgroups/eshelloword-booter/blob/master/src/main/resources/esmapper/indexparentchild.xml]esmapper/Client_Info.xml[/url]\n \n[b]开发交流[/b]\nbboss交流群 166471282\nbboss公众号\n[attach]3259[/attach]\n \n敬请关注：父子关系维护检索实战二 Elasticsearch 6.x 父子关系维护检","title":"Day 11 -父子关系维护检索实战一 - Elasticsearch 5.x-父子关系维护","uid":"3989","views":"728","votes":"2"},"_type":"doc"}
{"_id":"6185","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544442967","category_id":"3","comments":"0","has_attach":"0","id":"6185","message":"logstash作为一个数据管道中间件，支持对各种类型数据的采集与转换，并将数据发送到各种类型的存储库，比如实现消费kafka数据并且写入到Elasticsearch, 日志文件同步到对象存储S3等，mysql数据同步到Elasticsearch等。\n\nlogstash内部主要包含三个模块：\n\t\n\t* input: 从数据源获取数据\n\t* filter: 过滤、转换数据\n\t* output: 输出数据\n\n![](https://main.qcloudimg.com/raw/33410bdc40269b8c8f506c74be97f5ee.png)\n\n不同类型的数据都可以通过对应的input-plugin， output-plugin完成数据的输入与输出。如需要消费kafka中的数据并写入到Elasticsearch中，则需要使用logstash的kafka-input-plugin完成数据输入，logstash-output-elasticsearch完成数据输出。如果需要对输入数据进行过滤或者转换，比如根据关键词过滤掉不需要的内容，或者时间字段的格式转换，就需要又filter-plugin完成了。\n\nlogstash的input插件目前已经有几十种了，支持大多数比较通用或开源的数据源的输入。但如果公司内部开发的数据库或其它存储类的服务不能和开源产品在接口协议上兼容，比如腾讯自研的消息队列服务CMQ不依赖于其它的开源消息队列产品，所以不能直接使用logstash的logstash-input-kafka或logstash-input-rabbitmq同步CMQ中的数据；腾讯云对象存储服务COS， 在鉴权方式上和AWS的S3存在差异，也不能直接使用logstash-input-s3插件从COS中读取数据，对于这种情况，就需要自己开发logstash的input插件了。\n\n本文以开发logstash的cos input插件为例，介绍如何开发logstash的input插件。\n\nlogstash官方提供了有个简单的input plugin example可供参考:\n[https://github.com/logstash-plugins/logstash-input-example/](https://github.com/logstash-plugins/logstash-input-example/)\n\n\n## 环境准备\n\nlogstash使用jruby开发，首先要配置jruby环境：\n\n1. 安装rvm:\n\t\n\trvm是一个ruby管理器，可以安装并管理ruby环境，也可以通过命令行切换到不同的ruby版本。\n\t\n\t```\n\tgpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB\n\t```\n\t\n\t```\n\t\\curl -sSL https://get.rvm.io | bash -s stable\n\t```\n\t\n\t```\n   source /etc/profile.d/rvm.sh\n   ```\n2. 安装jruby\n\n   ```\n   rvm install jruby\n   ```\n   \n   ```\n   rvm use jruby\n   ```\n3. 安装包管理工具bundle和测试工具rspec\n\n  ```\n  gem install bundle\n  gem install rspec\n  ```\n  \n## 从example开始\n\n1. clone logstash-input-example\n\n\t```\n\tgit clone https://github.com/logstash-plugins/logstash-input-example.git\n\t```\n2. 将clone出来的logstash-input-example源码copy到logstash-input-cos目录，并删除.git文件夹，目的是以logstash-input-example的源码为参考进行开发，同时把需要改动名称的地方修改一下：\n\n   ```\n\tmv logstash-input-example.gemspec logstash-input-cos.gemspec\nmv lib/logstash/inputs/example.rb lib/logstash/inputs/cos.rb\nmv spec/inputs/example_spec.rb spec/inputs/cos_spec.rb\n   ```\n3. 建立的源码目录结构如图所示：\n\n![](https://main.qcloudimg.com/raw/a21a1e87825e5e1b9bd919ed2e927a7d.png)\n\n其中，重要文件的作用说明如下：\n\n* cos.rb: 主文件，在该文件中编写logstash配置文件的读写与源数据获取的代码，需要继承LogStash::Inputs::Base基类\n* cos_spec.rb: 单元测试文件，通过rspec可以对cos.rb中的代码进行测试\n* logstash-input-cos.gemspec: 类似于maven中的pom.xml文件，配置工程的版本、名称、licene,包依赖等，通过bundle命令可以下载依赖包\n\n## 配置并下载依赖\n\n因为腾讯云COS服务没有ruby sdk, 因为只能依赖其Java sdk进行开发，首先添加对cos java sdk的依赖。在logstash-input-cos.gemspec中Gem dependencies配置栏中增加以下内容：\n\n```\n# Gem dependencies\n  s.requirements \u0026lt;\u0026lt; \u0026quot;jar 'com.qcloud:cos_api', '5.4.4'\u0026quot;\n  s.add_runtime_dependency \u0026quot;logstash-core-plugin-api\u0026quot;, \u0026quot;\u0026gt;= 1.60\u0026quot;, \u0026quot;\u0026lt;= 2.99\u0026quot;\n  s.add_runtime_dependency 'logstash-codec-plain'\n  s.add_runtime_dependency 'stud', '\u0026gt;= 0.0.22'\n  s.add_runtime_dependency 'jar-dependencies'\n  s.add_development_dependency 'logstash-devutils', '1.3.6'\n```\n相比logstash-input-example.gemspec，增加了对com.qcloud:cos_api包以及jar-dependencies包的依赖,jar-dependencies用于在ruby环境中管理jar包，并且可以跟踪jar包的加载状态。\n\n然后，在logstash-input-cos.gemspec中增加配置：\n\n```\ns.platform = 'java'\n```\n这样可以成功下载java依赖包，并且可以在ruby代码中直接调用java代码。\n\n最后，执行以下命令下载依赖：\n\n```\nbundle install\n```\n\n## 编写代码\n\nlogstash-input-cos的代码逻辑其实比较简单，主要是通过执行定时任务，调用cos java sdk中的listObjects方法，获取到指定bucket里的数据，并在每次定时任务执行结束后设置marker保存在本地，再次执行时从marker位置获取数据，以实现数据的增量同步。\n\n### jar包的引用\n因为要调用cos java sdk中的代码，先引用该jar包：\n\n```\nrequire 'cos_api-5.4.4.jar'\njava_import com.qcloud.cos.COSClient;\njava_import com.qcloud.cos.ClientConfig;\njava_import com.qcloud.cos.auth.BasicCOSCredentials;\njava_import com.qcloud.cos.auth.COSCredentials;\njava_import com.qcloud.cos.exception.CosClientException;\njava_import com.qcloud.cos.exception.CosServiceException;\njava_import com.qcloud.cos.model.COSObjectSummary;\njava_import com.qcloud.cos.model.ListObjectsRequest;\njava_import com.qcloud.cos.model.ObjectListing;\njava_import com.qcloud.cos.region.Region;\n```\n\n### 读取配置文件\n\nlogstash配置文件读取的代码如图所示：\n![](https://main.qcloudimg.com/raw/f53d82f47602b9d19e6c294f350ce112.png)\n\nconfig_name为cos,其它的配置项读取代码按照ruby的代码规范编写，添加类型校验与默认值，就可以从以下配置文件中读取配置项：\n\n```\ninput {\n    cos {\n        \u0026quot;endpoint\u0026quot; =\u0026gt; \u0026quot;cos.ap-guangzhou.myqcloud.com\u0026quot;\n        \u0026quot;access_key_id\u0026quot; =\u0026gt; \u0026quot;*****\u0026quot;\n        \u0026quot;access_key_secret\u0026quot; =\u0026gt; \u0026quot;****\u0026quot;\n        \u0026quot;bucket\u0026quot; =\u0026gt; \u0026quot;******\u0026quot;\n\t    \u0026quot;region\u0026quot; =\u0026gt; \u0026quot;ap-guangzhou\u0026quot;\n\t    \u0026quot;appId\u0026quot; =\u0026gt; \u0026quot;**********\u0026quot;\n        \u0026quot;interval\u0026quot; =\u0026gt; 60\n    }\n}\n\noutput {\n    stdout {\n        codec=\u0026gt;rubydebug\n    }\n}\n```\n\n### 实现register方法\n\nlogstash input插件必须实现另个方法：register 和run\n\nregister方法类似于初始化方法，在该方法中可以直接使用从配置文件读取并赋值的变量，完成cos client的初始化，代码如下：\n\n```\n    # 1 初始化用户身份信息(appid, secretId, secretKey)\n    cred = com.qcloud.cos.auth.BasicCOSCredentials.new(@access_key_id, @access_key_secret)\n    # 2 设置bucket的区域, COS地域的简称请参照 https://www.qcloud.com/document/product/436/6224\n    clientConfig = com.qcloud.cos.ClientConfig.new(com.qcloud.cos.region.Region.new(@region))\n    # 3 生成cos客户端\n    @cosclient = com.qcloud.cos.COSClient.new(cred, clientConfig)\n    # bucket名称, 需包含appid\n    bucketName = @bucket + \u0026quot;-\u0026quot;+ @appId\n    @bucketName = bucketName\n\n    @listObjectsRequest = com.qcloud.cos.model.ListObjectsRequest.new()\n    # 设置bucket名称\n    @listObjectsRequest.setBucketName(bucketName)\n    # prefix表示列出的object的key以prefix开始\n    @listObjectsRequest.setPrefix(@prefix)\n    # 设置最大遍历出多少个对象, 一次listobject最大支持1000\n    @listObjectsRequest.setMaxKeys(1000)\n    @listObjectsRequest.setMarker(@markerConfig.getMarker)\n```\n示例代码中设置了@cosclient和@listObjectRequest为全局变量， 因为在run方法中会用到这两个变量。\n\n注意在ruby中调用java代码的方式：没有变量描述符；不能直接new Object()，而只能Object.new().\n\n### 实现run方法\n\nrun方法获取数据并将数据流转换成event事件\n\n最简单的run方法为：\n\n```\ndef run(queue)\n    Stud.interval(@interval) do\n      event = LogStash::Event.new(\u0026quot;message\u0026quot; =\u0026gt; @message, \u0026quot;host\u0026quot; =\u0026gt; @host)\n      decorate(event)\n      queue \u0026lt;\u0026lt; event\n    end # loop\n  end # def run\n```\n代码说明：\n\n* 通过Stud ruby模块执行定时任务，interval可自定义，从配置文件中读取\n* 生成event, 示例代码生成了一个包含两个字段数据的event\n* 调用decorate()方法， 给该event打上tag，如果配置的话\n* queue\u0026lt;\u0026lt;event, 将event插入到数据管道中，发送给filter处理\n\n\nlogstash-input-cos的run方法实现为：\n\n```\ndef run(queue)\n    @current_thread = Thread.current\n    Stud.interval(@interval) do\n      process(queue)\n    end\nend\n \ndef process(queue)\n\t@logger.info('Marker from: ' + @markerConfig.getMarker)\n\t\n\tobjectListing = @cosclient.listObjects(@listObjectsRequest)\n\tnextMarker = objectListing.getNextMarker()\n\tcosObjectSummaries = objectListing.getObjectSummaries()\n\tcosObjectSummaries.each do |obj|\n\t   # 文件的路径key\n\t   key = obj.getKey()\n\t\n\t   if stop?\n\t     @logger.info(\u0026quot;stop while attempting to read log file\u0026quot;)\n\t     break\n\t   end\n\t   # 根据key获取内容\n\t   getObject(key) { |log|\n\t     # 发送消息\n\t     @codec.decode(log) do |event|\n           decorate(event)\n           queue \u0026lt;\u0026lt; event\n         end\n       }\n\n       #记录 marker\n       @markerConfig.setMarker(key)\n       @logger.info('Marker end: ' + @markerConfig.getMarker)\n    end\n  end\n\n\n  # 获取下载输入流\n def getObject(key, \u0026amp;block)\n    getObjectRequest = com.qcloud.cos.model.GetObjectRequest.new(@bucketName, key)\n    cosObject = @cosclient.getObject(getObjectRequest)\n    cosObjectInput = cosObject.getObjectContent()\n    buffered =BufferedReader.new(InputStreamReader.new(cosObjectInput))\n    while (line = buffered.readLine())\n      block.call(line)\n    end\n  end\n```\n\n## 测试代码\n在spec/inputs/cos_spec.rb中增加如下测试代码:\n\n```\n# encoding: utf-8\nrequire \u0026quot;logstash/devutils/rspec/spec_helper\u0026quot;\nrequire \u0026quot;logstash/inputs/cos\u0026quot;\n\ndescribe LogStash::Inputs::Cos do\n\n  it_behaves_like \u0026quot;an interruptible input plugin\u0026quot; do\n    let(:config) { {\n        \u0026quot;endpoint\u0026quot; =\u0026gt; 'cos.ap-guangzhou.myqcloud.com',\n        \u0026quot;access_key_id\u0026quot; =\u0026gt; '*',\n        \u0026quot;access_key_secret\u0026quot; =\u0026gt; '*',\n        \u0026quot;bucket\u0026quot; =\u0026gt; '*',\n\t     \u0026quot;region\u0026quot; =\u0026gt; 'ap-guangzhou',\n\t     \u0026quot;appId\u0026quot; =\u0026gt; '*',\n        \u0026quot;interval\u0026quot; =\u0026gt; 60 } }\n  end\nend\n\n```\n\nrspec是一个ruby测试库，通过bundle命令执行rspec：\n\n```\nbundle exec rspec\n```\n如果cos.rb中的代码没有语法或运行时错误，则会出现如果信息表明测试成功：\n\n```\nFinished in 0.8022 seconds (files took 3.45 seconds to load)\n1 example, 0 failures\n```\n\n## 构建并测试input-plugin-cos\n\n### build\n\n使用gem对input-plugin-cos插件源码进行build:\n\n```\ngem build logstash-input-cos.gemspec\n```\n构建完成后会生成一个名为logstash-input-cos-0.0.1-java.gem的文件\n\n### test\n在logstash的解压目录下，执行一下命令安装logstash-input-cos plugin:\n\n```\n./bin/logstash-plugin install /usr/local/githome/logstash-input-cos/logstash-input-cos-0.0.1-java.gem\n```\n执行结果为：\n\n```\nValidating /usr/local/githome/logstash-input-cos/logstash-input-cos-0.0.1-java.gem\nInstalling logstash-input-cos\nInstallation successful\n```\n\n另外，可以通过./bin/logstash-plugin list命令查看logstash已经安装的所有input/output/filter/codec插件。\n\n生成配置文件cos.logstash.conf,内容为：\n\n```\ninput {\n    cos {\n        \u0026quot;endpoint\u0026quot; =\u0026gt; \u0026quot;cos.ap-guangzhou.myqcloud.com\u0026quot;\n        \u0026quot;access_key_id\u0026quot; =\u0026gt; \u0026quot;*****\u0026quot;\n        \u0026quot;access_key_secret\u0026quot; =\u0026gt; \u0026quot;****\u0026quot;\n        \u0026quot;bucket\u0026quot; =\u0026gt; \u0026quot;******\u0026quot;\n\t    \u0026quot;region\u0026quot; =\u0026gt; \u0026quot;ap-guangzhou\u0026quot;\n\t    \u0026quot;appId\u0026quot; =\u0026gt; \u0026quot;**********\u0026quot;\n        \u0026quot;interval\u0026quot; =\u0026gt; 60\n    }\n}\n\noutput {\n    stdout {\n        codec=\u0026gt;rubydebug\n    }\n}\n```\n该配置文件使用腾讯云官网账号的secret\\_id和secret\\_key进行权限验证，拉取指定bucket里的数据，为了测试，将output设置为标准输出。\n\n执行logstash:\n\n```\n./bin/logstash -f cos.logstash.conf\n```\n\n输出结果为：\n\n```\nSending Logstash's logs to /root/logstash-5.6.4/logs which is now configured via log4j2.properties\n[2018-07-30T19:26:17,039][WARN ][logstash.runner          ] --config.debug was specified, but log.level was not set to 'debug'! No config info will be logged.\n[2018-07-30T19:26:17,048][INFO ][logstash.modules.scaffold] Initializing module {:module_name=\u0026gt;\u0026quot;netflow\u0026quot;, :directory=\u0026gt;\u0026quot;/root/logstash-5.6.4/modules/netflow/configuration\u0026quot;}\n[2018-07-30T19:26:17,049][INFO ][logstash.modules.scaffold] Initializing module {:module_name=\u0026gt;\u0026quot;fb_apache\u0026quot;, :directory=\u0026gt;\u0026quot;/root/logstash-5.6.4/modules/fb_apache/configuration\u0026quot;}\n[2018-07-30T19:26:17,252][INFO ][logstash.inputs.cos      ] Using version 0.1.x input plugin 'cos'. This plugin isn't well supported by the community and likely has no maintainer.\n[2018-07-30T19:26:17,341][INFO ][logstash.pipeline        ] Starting pipeline {\u0026quot;id\u0026quot;=\u0026gt;\u0026quot;main\u0026quot;, \u0026quot;pipeline.workers\u0026quot;=\u0026gt;4, \u0026quot;pipeline.batch.size\u0026quot;=\u0026gt;125, \u0026quot;pipeline.batch.delay\u0026quot;=\u0026gt;5, \u0026quot;pipeline.max_inflight\u0026quot;=\u0026gt;500}\n[2018-07-30T19:26:17,362][INFO ][logstash.inputs.cos      ] Registering cos input {:bucket=\u0026gt;\u0026quot;bellengao\u0026quot;, :region=\u0026gt;\u0026quot;ap-guangzhou\u0026quot;}\n[2018-07-30T19:26:17,528][INFO ][logstash.pipeline        ] Pipeline main started\n[2018-07-30T19:26:17,530][INFO ][logstash.inputs.cos      ] Marker from:\nlog4j:WARN No appenders could be found for logger (org.apache.http.client.protocol.RequestAddCookies).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n[2018-07-30T19:26:17,574][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u0026gt;9600}\n[2018-07-30T19:26:17,714][INFO ][logstash.inputs.cos      ] Marker end: access.log\n{\n       \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;77.179.66.156 - - [25/Oct/2016:14:49:33 +0200] \\\u0026quot;GET / HTTP/1.1\\\u0026quot; 200 612 \\\u0026quot;-\\\u0026quot; \\\u0026quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.59 Safari/537.36\\\u0026quot;\u0026quot;,\n      \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n    \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-07-30T11:26:17.710Z\n}\n{\n       \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;77.179.66.156 - - [25/Oct/2016:14:49:34 +0200] \\\u0026quot;GET /favicon.ico HTTP/1.1\\\u0026quot; 404 571 \\\u0026quot;http://localhost:8080/\\\u0026quot; \\\u0026quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.59 Safari/537.36\\\u0026quot;\u0026quot;,\n      \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n    \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-07-30T11:26:17.711Z\n}\n```\n在cos中的bucket里上传了名为access.log的nginx日志，上述输出结果中最后打印出来的每个json结构体构成一个event， 其中message消息即为access.log中每一条日志。\n\n\n","title":"logstash input插件开发","uid":"8905","views":"290","votes":"2"},"_type":"doc"}
{"_id":"6180","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544239391","category_id":"18","comments":"0","has_attach":"0","id":"6180","message":"1. 用于ES数据警报的实时守护进程。\n[http://t.cn/EyQmiuE](http://t.cn/EyQmiuE) \n\n2. 最小的ibana Docker镜像。\n[http://t.cn/EyQbwGk](http://t.cn/EyQbwGk) \n\n3. Lucene列式存储格式DocValues详解。\n[http://t.cn/EyQ6pkK](http://t.cn/EyQ6pkK) \n\n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6180 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第472期 (2018-12-08）","uid":"1874","views":"170","votes":"0"},"_type":"doc"}
{"_id":"6179","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544234336","category_id":"14","comments":"0","has_attach":"1","id":"6179","message":"# 如何使用Spark快速将数据写入Elasticsearch\n\n\n说到数据写入Elasticsearch，最先想到的肯定是Logstash。Logstash因为其简单上手、可扩展、可伸缩等优点被广大用户接受。但是尺有所短，寸有所长，Logstash肯定也有它无法适用的应用场景，比如：\n\n   * 海量数据ETL\n   * 海量数据聚合\n   * 多源数据处理\n   \n为了满足这些场景，很多同学都会选择Spark，借助Spark算子进行数据处理，最后将处理结果写入Elasticsearch。\n\n我们部门之前利用Spark对Nginx日志进行分析，统计我们的Web服务访问情况，将Nginx日志每分钟聚合一次最后将结果写入Elasticsearch，然后利用Kibana配置实时监控Dashboard。Elasticsearch和Kibana都很方便、实用，但是随着类似需求越来越多，如何快速通过Spark将数据写入Elasticsearch成为了我们的一大问题。\n\n今天给大家推荐一款能够实现数据快速写入的黑科技——[Waterdrop](https://github.com/InterestingLab/waterdrop)，一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上，简单易用，灵活配置，无需开发。\n\n[attach]3245[/attach]\n\n\n## Kafka to Elasticsearch\n\n和Logstash一样，Waterdrop同样支持多种类型的数据输入，这里我们以最常见的Kakfa作为输入源为例，讲解如何使用Waterdrop将数据快速写入Elasticsearch\n\n### Log Sample\n\n原始日志格式如下:\n```\n127.0.0.1 elasticsearch.cn 114.250.140.241 0.001s \u0026quot;127.0.0.1:80\u0026quot; [26/Oct/2018:21:54:32 +0800] \u0026quot;GET /article HTTP/1.1\u0026quot; 200 123 \u0026quot;-\u0026quot; - \u0026quot;Dalvik/2.1.0 (Linux; U; Android 7.1.1; OPPO R11 Build/NMF26X)\u0026quot;\n```\n\n### Elasticsearch Document\n\n我们想要统计，一分钟每个域名的访问情况，聚合完的数据有以下字段:\n```\ndomain String\nhostname String\nstatus int\ndatetime String\ncount int\n```\n\n## Waterdrop with Elasticsearch\n\n接下来会给大家详细介绍，我们如何通过Waterdrop读取Kafka中的数据，对数据进行解析以及聚合，最后将处理结果写入Elasticsearch中。\n\n### Waterdrop\n\n[Waterdrop](https://github.com/InterestingLab/waterdrop)同样拥有着非常丰富的插件，支持从Kafka、HDFS、Hive中读取数据，进行各种各样的数据处理，并将结果写入Elasticsearch、Kudu或者Kafka中。\n\n### Prerequisites\n\n首先我们需要安装Waterdrop，安装十分简单，无需配置系统环境变量\n1. 准备Spark环境\n2. 安装Waterdrop\n3. 配置Waterdrop\n\n以下是简易步骤，具体安装可以参照[Quick Start](https://interestinglab.github.io/waterdrop/#/zh-cn/quick-start)\n\n```yaml\ncd /usr/local\nwget https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz\ntar -xvf https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz\nwget https://github.com/InterestingLab/waterdrop/releases/download/v1.1.1/waterdrop-1.1.1.zip\nunzip waterdrop-1.1.1.zip\ncd waterdrop-1.1.1\n\nvim config/waterdrop-env.sh\n# 指定Spark安装路径\nSPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.2.0-bin-hadoop2.7}\n```\n\n### Waterdrop Pipeline\n\n与Logstash一样，我们仅需要编写一个Waterdrop Pipeline的配置文件即可完成数据的导入，相信了解Logstash的朋友可以很快入手Waterdrop配置。\n\n配置文件包括四个部分，分别是Spark、Input、filter和Output。\n\n#### Spark\n\n\n这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。\n```\nspark {\n  spark.app.name = \u0026quot;Waterdrop\u0026quot;\n  spark.executor.instances = 2\n  spark.executor.cores = 1\n  spark.executor.memory = \u0026quot;1g\u0026quot;\n}\n```\n\n#### Input\n\n这一部分定义数据源，如下是从Kafka中读取数据的配置案例，\n\n```\nkafkaStream {\n    topics = \u0026quot;waterdrop-es\u0026quot;\n    consumer.bootstrap.servers = \u0026quot;localhost:9092\u0026quot;\n    consumer.group.id = \u0026quot;waterdrop_es_group\u0026quot;\n    consumer.rebalance.max.retries = 100\n}\n```\n\n#### Filter\n\n在Filter部分，这里我们配置一系列的转化，包括正则解析将日志进行拆分、时间转换将HTTPDATE转化为Elasticsearch支持的日期格式、对Number类型的字段进行类型转换以及通过SQL进行数据聚合\n```yaml\nfilter {\n    # 使用正则解析原始日志\n    # 最开始数据都在raw_message字段中\n    grok {\n        source_field = \u0026quot;raw_message\u0026quot;\n        pattern = '%{NOTSPACE:hostname}\\\\s%{NOTSPACE:domain}\\\\s%{IP:remote_addr}\\\\s%{NUMBER:request_time}s\\\\s\\\u0026quot;%{DATA:upstream_ip}\\\u0026quot;\\\\s\\\\[%{HTTPDATE:timestamp}\\\\]\\\\s\\\u0026quot;%{NOTSPACE:method}\\\\s%{DATA:url}\\\\s%{NOTSPACE:http_ver}\\\u0026quot;\\\\s%{NUMBER:status}\\\\s%{NUMBER:body_bytes_send}\\\\s%{DATA:referer}\\\\s%{NOTSPACE:cookie_info}\\\\s\\\u0026quot;%{DATA:user_agent}'\n   }\n    # 将\u0026quot;dd/MMM/yyyy:HH:mm:ss Z\u0026quot;格式的数据转换为\n    # Elasticsearch中支持的格式\n    date {\n        source_field = \u0026quot;timestamp\u0026quot;\n        target_field = \u0026quot;datetime\u0026quot;\n        source_time_format = \u0026quot;dd/MMM/yyyy:HH:mm:ss Z\u0026quot;\n        target_time_format = \u0026quot;yyyy-MM-dd'T'HH:mm:ss.SSS+08:00\u0026quot;\n    }\n    ## 利用SQL对数据进行聚合\n    sql {\n        table_name = \u0026quot;access_log\u0026quot;\n        sql = \u0026quot;select domain, hostname, int(status), datetime, count(*) from access_log group by domain, hostname, status, datetime\u0026quot;\n    }\n }\n```\n\n#### Output\n最后我们将处理好的结构化数据写入Elasticsearch。\n\n```yaml\noutput {\n    elasticsearch {\n        hosts = [\u0026quot;localhost:9200\u0026quot;]\n        index = \u0026quot;waterdrop-${now}\u0026quot;\n        es.batch.size.entries = 100000\n        index_time_format = \u0026quot;yyyy.MM.dd\u0026quot;\n    }\n}\n```\n\n### Running Waterdrop\n\n我们将上述四部分配置组合成为我们的配置文件`config/batch.conf`。\n\n    vim config/batch.conf\n\n```\nspark {\n  spark.app.name = \u0026quot;Waterdrop\u0026quot;\n  spark.executor.instances = 2\n  spark.executor.cores = 1\n  spark.executor.memory = \u0026quot;1g\u0026quot;\n}\ninput {\n    kafkaStream {\n        topics = \u0026quot;waterdrop-es\u0026quot;\n        consumer.bootstrap.servers = \u0026quot;localhost:9092\u0026quot;\n        consumer.group.id = \u0026quot;waterdrop_es_group\u0026quot;\n        consumer.rebalance.max.retries = 100\n    }\n}\nfilter {\n    # 使用正则解析原始日志\n    # 最开始数据都在raw_message字段中\n    grok {\n        source_field = \u0026quot;raw_message\u0026quot;\n        pattern = '%{IP:hostname}\\\\s%{NOTSPACE:domain}\\\\s%{IP:remote_addr}\\\\s%{NUMBER:request_time}s\\\\s\\\u0026quot;%{DATA:upstream_ip}\\\u0026quot;\\\\s\\\\[%{HTTPDATE:timestamp}\\\\]\\\\s\\\u0026quot;%{NOTSPACE:method}\\\\s%{DATA:url}\\\\s%{NOTSPACE:http_ver}\\\u0026quot;\\\\s%{NUMBER:status}\\\\s%{NUMBER:body_bytes_send}\\\\s%{DATA:referer}\\\\s%{NOTSPACE:cookie_info}\\\\s\\\u0026quot;%{DATA:user_agent}'\n   }\n    # 将\u0026quot;dd/MMM/yyyy:HH:mm:ss Z\u0026quot;格式的数据转换为\n    # Elasticsearch中支持的格式\n    date {\n        source_field = \u0026quot;timestamp\u0026quot;\n        target_field = \u0026quot;datetime\u0026quot;\n        source_time_format = \u0026quot;dd/MMM/yyyy:HH:mm:ss Z\u0026quot;\n        target_time_format = \u0026quot;yyyy-MM-dd'T'HH:mm:00.SSS+08:00\u0026quot;\n    }\n    ## 利用SQL对数据进行聚合\n    sql {\n        table_name = \u0026quot;access_log\u0026quot;\n        sql = \u0026quot;select domain, hostname, status, datetime, count(*) from access_log group by domain, localhost, status, datetime\u0026quot;\n    }\n }\noutput {\n    elasticsearch {\n        hosts = [\u0026quot;localhost:9200\u0026quot;]\n        index = \u0026quot;waterdrop-${now}\u0026quot;\n        es.batch.size.entries = 100000\n        index_time_format = \u0026quot;yyyy.MM.dd\u0026quot;\n    }\n}\n```\n\n执行命令，指定配置文件，运行Waterdrop，即可将数据写入Elasticsearch。这里我们以本地模式为例。\n\n    ./bin/start-waterdrop.sh --config config/batch.conf -e client -m 'local[2]'\n\n最后，写入Elasticsearch中的数据如下，再配上Kibana就可以实现Web服务的实时监控了^_^.\n\n```\n\u0026quot;_source\u0026quot;: {\n    \u0026quot;domain\u0026quot;: \u0026quot;elasticsearch.cn\u0026quot;,\n    \u0026quot;hostname\u0026quot;: \u0026quot;localhost\u0026quot;,\n    \u0026quot;status\u0026quot;: \u0026quot;200\u0026quot;,\n    \u0026quot;datetime\u0026quot;: \u0026quot;2018-11-26T21:54:00.000+08:00\u0026quot;,\n    \u0026quot;count\u0026quot;: 26\n  }\n```\n\n## Conclusion\n\n在这篇文章中，我们介绍了如何通过Waterdrop将Kafka中的数据写入Elasticsearch中。仅仅通过一个配置文件便可快速运行一个Spark Application，完成数据的处理、写入，无需编写任何代码，十分简单。\n\n当数据处理过程中有遇到Logstash无法支持的场景或者Logstah性能无法达到预期的情况下，都可以尝试使用Waterdrop解决问题。\n\n希望了解Waterdrop与Elasticsearch、Kafka、Hadoop结合使用的更多功能和案例，可以直接进入项目主页[https://github.com/InterestingLab/waterdrop](https://github.com/InterestingLab/waterdrop)\n\n\n**我们近期会再发布一篇《如何用Spark和Elasticsearch做交互式数据分析》，敬请期待.**\n\n## Contract us\n\n欢迎联系我们交流Spark和Elasticsearch:\n\n\u0026gt; Garyelephant：  微信: garyelephant\n\n\u0026gt; RickyHuo：  微信: chodomatte1994\n","title":"Day 8 - 如何使用Spark快速将数据写入Elasticsearch","uid":"4629","views":"1848","votes":"2"},"_type":"doc"}
{"_id":"6155","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543113743","category_id":"18","comments":"0","has_attach":"0","id":"6155","message":"1.ElasticSearch搜索语法及Boolean和聚合搜索。\nhttp://t.cn/E20PxFB\n2.ElasticSearch命令备忘单。\nhttp://t.cn/ELzpeNp\n3.(自备梯子)抵制谷歌让你成为机器人的企图。\nhttp://t.cn/ELz8ybs\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6155\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第459期 (2018-11-25)","uid":"4460","views":"226","votes":"0"},"_type":"doc"}
{"_id":"6157","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543197651","category_id":"18","comments":"0","has_attach":"0","id":"6157","message":"1.了解和es同类型的分布式系统TIDB如何做分布式调度\nhttp://t.cn/RTKEZ0U\n\n2.ElasticSearch集群故障案例分析: 警惕通配符查询\nhttps://elasticsearch.cn/article/171\n\n3.分析elk中kibana查询数据返回为空\nhttp://t.cn/ELbN7ti\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6157\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第460期 (2018-11-26)","uid":"4063","views":"238","votes":"0"},"_type":"doc"}
{"_id":"6162","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543552657","category_id":"18","comments":"0","has_attach":"0","id":"6162","message":"1、python实现MongoDB数据同步到ES\nhttp://t.cn/ELYKOXo\n2、Elasticsearch搜索引擎性能调优实践\nhttp://t.cn/ELRuqLN\n3、全文检索ElasticSearch与Spring boot集成实例\nhttp://t.cn/ELRuKal\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6162\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第464期 (2018-11-30)","uid":"1341","views":"178","votes":"0"},"_type":"doc"}
{"_id":"6164","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543632039","category_id":"18","comments":"0","has_attach":"0","id":"6164","message":"1. 适用于ES 6.0之后的Field Stats插件。\n[http://t.cn/ELmZMFl](http://t.cn/ELmZMFl) \n\n2. 你知道ICU分析器支持emoji表情了吗？。\n[http://t.cn/ELmw4aF](http://t.cn/ELmw4aF) \n\n3. Canvas中数据表和调试元素的使用示例。\n[http://t.cn/ELmX7Tc](http://t.cn/ELmX7Tc) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6164 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第465期 (2018-12-01）","uid":"1874","views":"184","votes":"0"},"_type":"doc"}
{"_id":"6169","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543802965","category_id":"18","comments":"0","has_attach":"0","id":"6169","message":"1. Opbeat已死，请用Elastic APM\nhttp://t.cn/EyhRQRJ\n\n2.Amazon Elasticsearch Service 中的韩语分析程序支持\nhttp://t.cn/EyhmEHc\n\n3. Elasticsearch在华泰证券内部的应用实践\nhttp://t.cn/EyhuaFC\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6169\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第467期 (2018-12-03)","uid":"4063","views":"188","votes":"0"},"_type":"doc"}
{"_id":"6175","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544080004","category_id":"18","comments":"0","has_attach":"0","id":"6175","message":"1.图解 Elasticsearch2.2.0 原理\nhttp://t.cn/Eybu8a3\n2.ElasticSearch 恢复类型之对等恢复\nhttp://t.cn/EyaCYFV\n3.使用带注释的文本插件搜索事物\nhttp://t.cn/EyaCntg\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6175\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第470期 (2018-12-06)","uid":"668","views":"188","votes":"0"},"_type":"doc"}
{"_id":"6153","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542947319","category_id":"18","comments":"0","has_attach":"0","id":"6153","message":"1、批量加载json/csv等数据到ElasticSearch工具推荐\nhttp://t.cn/E23BXY3\n2、Elasticsearch和Hive集成实战\nhttp://t.cn/RToSes4\n3、浅谈Elasticsearch基础与架构\nhttp://t.cn/EwklpZS\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6153\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第457期 (2018-11-23)","uid":"1341","views":"222","votes":"0"},"_type":"doc"}
{"_id":"51","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452656344","category_id":"8","comments":"4","has_attach":"1","id":"51","message":"为大家准备了一个测试Elasticsearch/Kibana功能的地方 (Found实例)：\n Kibana:\n[url]https://6e0ccaba29cd55a7f07f831365a114f1.us-east-1.aws.found.io/app/kibana[/url]\n\n[attach]93[/attach]\n \n用户名/密码：elasticsearch-cn\n \n集群名：\u0026quot;e064eb\u0026quot;，使用Java客户端的时候需要，如何连接，参考：http://elasticsearch.cn/article/46[code]HTTP http://e064eb4b0aa993db28ad513e4d2df5e3.us-east-1.aws.found.io:9200\nHTTPS https://e064eb4b0aa993db28ad513e4d2df5e3.us-east-1.aws.found.io:9243[/code] \n[code] curl -u elasticsearch-cn:elasticsearch-cn http://e064eb4b0aa993db28ad513e4d2df5e3.us-east-1.aws.found.io:9200/\n{\n  \u0026quot;name\u0026quot; : \u0026quot;instance-0000000009\u0026quot;,\n  \u0026quot;cluster_name\u0026quot; : \u0026quot;e064eb4b0aa993db28ad513e4d2df5e3\u0026quot;,\n  \u0026quot;version\u0026quot; : {\n    \u0026quot;number\u0026quot; : \u0026quot;2.1.1\u0026quot;,\n    \u0026quot;build_hash\u0026quot; : \u0026quot;40e2c53a6b6c2972b3d13846e450e66f4375bd71\u0026quot;,\n    \u0026quot;build_timestamp\u0026quot; : \u0026quot;2015-12-15T13:05:55Z\u0026quot;,\n    \u0026quot;build_snapshot\u0026quot; : false,\n    \u0026quot;lucene_version\u0026quot; : \u0026quot;5.3.1\u0026quot;\n  },\n  \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot;\n}[/code] \n\n内置常用插件，有其他插件要安装的请留言。","title":"社区福利：Elastic-playground","uid":"1","views":"2981","votes":"5"},"_type":"doc"}
{"_id":"54","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452853957","category_id":"13","comments":"12","has_attach":"0","id":"54","message":" 书接上回：[url]http://elasticsearch.cn/article/53[/url]\n \n前面介绍了Packetbeat的项目结构，今天终于要开始写代码了，想想还是有点小激动呢。（你快点吧，拖半天了）\n网络传输两大协议TCP和UDP，我们的所有协议都不离这两种，HTTP、MySQL走的是TCP传输协议，DNS走的是UDP协议，在Packetbeat里面，实现一个自己的协议非常简单，继承并实现这两者对应的接口就行了，我们看一下长什么样：\n打开一个现有的UDP和HTTP协议接口定义：\n/~/go/src/github.com/elastic/beats/packetbeat/protos/protos.go[code]// Functions to be exported by a protocol plugin\ntype ProtocolPlugin interface {\n\t// Called to initialize the Plugin\n\tInit(test_mode bool, results publisher.Client) error\n \n\t// Called to return the configured ports\n\tGetPorts() int\n}\n \ntype TcpProtocolPlugin interface {\n\tProtocolPlugin\n \n\t// Called when TCP payload data is available for parsing.\n\tParse(pkt *Packet, tcptuple *common.TcpTuple,\n\t\tdir uint8, private ProtocolData) ProtocolData\n \n\t// Called when the FIN flag is seen in the TCP stream.\n\tReceivedFin(tcptuple *common.TcpTuple, dir uint8,\n\t\tprivate ProtocolData) ProtocolData\n \n\t// Called when a packets are missing from the tcp\n\t// stream.\n\tGapInStream(tcptuple *common.TcpTuple, dir uint8, nbytes int,\n\t\tprivate ProtocolData) (priv ProtocolData, drop bool)\n \n\t// ConnectionTimeout returns the per stream connection timeout.\n\t// Return \u0026lt;=0 to set default tcp module transaction timeout.\n\tConnectionTimeout() time.Duration\n}\n \ntype UdpProtocolPlugin interface {\n\tProtocolPlugin\n \n\t// ParseUdp is invoked when UDP payload data is available for parsing.\n\tParseUdp(pkt *Packet)\n}[/code]TcpProtocolPlugin：TCP协议插件的接口定义，依次是：Parse() 解析Packet，ReceivedFin()处理TCP断开连接，GapInStream()处理空包丢包，ConnectionTimeout()超时时间；\nUdpProtocolPlugin: UDP协议的接口定义，UDP协议是不需要握手和保障数据可靠性的，扔出去就结束，速度快，不保证数据可靠送达，所以只有ParseUdp一个方法需要实现，比较简单；\nProtocolPlugin：TCP和UDP都需要实现ProtocolPlugin的基础接口，其实就定义了获取端口和初始化接口。\n\n请问：\nPacketbeat怎么工作的？\n\n回答：\n每一个协议都有一个固定的端口用于通信，你要做的事情就是定义协议端口，然后按协议是TCP还是UDP来实现对应的接口，Packetbeat将会截获指定端口的数据包（Packet），然后如果交给你定义的方法来进行解析，TCP是Parse，UDP是ParseUdp，都在上面的接口定义好的，然后将解析出来的结构化数据封装成Json，然后扔给Elasticsearch，后续的就的如何对这些数据做一些有趣的分析和应用了。\n\n貌似很简单嘛！\n\n进入每个端口的数据包，我们假设是一个自来水管，拧开80端口，哗啦啦出来的全是HTTP请求的数据包，Packetbeat里面Http协议监听的是80端口啊，所有这些包统统都交给Packetbeat里面的Http协议模块来进行解析，Http协议会一个个的检查这些数据包，也就是每个数据包都会调用一次Parse接口，到这里提到了传过来一个Packet，我们看看它的数据结构长什么样？[code]type Packet struct {\n\tTs      time.Time\n\tTuple   common.IpPortTuple\n\tPayload byte\n}[/code]Packet结构简单，\nTs是收到数据包的时间戳；\nTuple是一个来源IP+来源端口和目的IP+目的端口的元组；\nPayload就是这个包里面的传输的有用的数据，应用层的字节数据，不包括IP和TCP/UDP头信息，是不是处理起来简单许多。\n\n首选我们确定SMTP协议的配置，每个协议在packetbeat.yml的protocol下面都应该有一个配置节点，如下：[code]protocols:\n  smtp:\n    # Configure the ports where to listen for Smtp traffic. You can disable\n    # the Smtp protocol by commenting out the list of ports.\n    ports: [25][/code]还需要在对应的config类文件：packetbeat/config/config.go，增加SMTP的结构体，目前只支持一个端口参数，继承基类ProtocolCommon就行，如下：[code]git diff config/config.go\n@@ -42,6 +42,7 @@ type Protocols struct {\n        Pgsql    Pgsql\n        Redis    Redis\n        Thrift   Thrift\n+       Smtp     Smtp\n }\n \n type Dns struct {\n@@ -118,5 +119,9 @@ type Redis struct {\n        Send_response *bool\n }\n \n+type Smtp struct {\n+\tProtocolCommon        `yaml:\u0026quot;,inline\u0026quot;`\n+}\n+\n // Config Singleton\n var ConfigSingleton Config[/code]在protos文件夹下面，新增smtp目录，并新增空白文件smtp.go，路径：packetbeat/protos/smtp/smtp.go，\n这里就是解析SMTP协议的地方，也是我们扩展协议的主要的工作。[code]...TODO...[/code]修改protos/protos.go，增加SMTP协议枚举，这里记得保证顺序一致，并且protocol名称必须和配置的节点名称一致，如这里都是smtp。[code]git diff protos/protos.go\n@@ -103,6 +103,7 @@ const (\n        MongodbProtocol\n        DnsProtocol\n        MemcacheProtocol\n+       SmtpProtocol\n )\n \n // Protocol names\n@@ -116,6 +117,7 @@ var ProtocolNames = string{\n        \u0026quot;mongodb\u0026quot;,\n        \u0026quot;dns\u0026quot;,\n        \u0026quot;memcache\u0026quot;,\n+       \u0026quot;smtp\u0026quot;,\n }\n\n[/code]继续修改packetbeat.go主文件，允许SMTP协议并加载。[code]git diff packetbeat.go\n@@ -27,6 +27,7 @@ import (\n        \u0026quot;github.com/elastic/packetbeat/protos/tcp\u0026quot;\n        \u0026quot;github.com/elastic/packetbeat/protos/thrift\u0026quot;\n        \u0026quot;github.com/elastic/packetbeat/protos/udp\u0026quot;\n+       \u0026quot;github.com/elastic/packetbeat/protos/smtp\u0026quot;\n        \u0026quot;github.com/elastic/packetbeat/sniffer\u0026quot;\n )\n \n@@ -43,6 +44,7 @@ var EnabledProtocolPlugins map[protos.Protocol]protos.ProtocolPlugin = map[proto\n        protos.ThriftProtocol:   new(thrift.Thrift),\n        protos.MongodbProtocol:  new(mongodb.Mongodb),\n        protos.DnsProtocol:      new(dns.Dns),\n+       protos.SmtpProtocol:      new(smtp.Smtp),\n }\n\n[/code]做完上面一系列修改之后，一个空白的SMTP协议的插件的架子就搭好了，并且插件也注册到了Packetbeat里面了，接下来我们再把packetbeat/protos/smtp/smtp.go按照TCPplugin接口的要求实现一下。\n\n说实话TCP处理起来很难，开始之前，我们先明确几个概念，TCP协议是有状态的，并且是流式的，我们关注的是七层应用层的消息，如HTTP里面的一个HTTP请求和返回，但是TCP底层都是一系列数据包，并且不同的请求的数据包是混杂在一起的，也就是说一个数据包里面可能只是一个HTTP请求的一部分也可能包含多条HTTP请求的一部分，所以Parse()里面需要处理跨数据包的状态信息，我们要把这些数据包和具体的七层的应用层的消息关联起来。\n\n现在我们仔细看看Parse()接口的各个参数定义是做什么用的[code]Parse(pkt *Packet, tcptuple *common.TcpTuple,\n\t\tdir uint8, private ProtocolData) ProtocolData\n\n[/code]pkt不用说了，是送进来的数据包，前面已经介绍了其数据结构，tcptuple是该数据包所属的TCP数据流所在的唯一标示（一个未关闭的TCP数据量包含若干数据包，直到TCP链接关闭），使用tcptuple.Hashable()获取唯一值；dir参数标示数据包在TCP数据流中的流向，和第一个TCP数据包方向一致是TcpDirectionOriginal，否则是TcpDirectionReverse；private参数可用来在TCP流中存储状态信息，可在运行时转换成具体的强类型，任意修改和传递给下一个Parse方法，简单来说就是进行中间数据的共享。\n\n下面看段MySQL模块里面的例子[code] priv := mysqlPrivateData{}\n        if private != nil {\n                var ok bool\n                priv, ok = private.(mysqlPrivateData)\n                if !ok {\n                        priv = mysqlPrivateData{}\n                }\n        }\n \n        [ ... ]\n \n        return priv[/code]上面的代码就是将private强制转换成mysqlPrivateData结构，然后再使用。\n我们再继续看后续怎么处理这些包的一个逻辑例子[code]ok, complete := mysqlMessageParser(priv.Data[dir])\n                if !ok {\n                        // drop this tcp stream. Will retry parsing with the next\n                        // segment in it\n                        priv.Data[dir] = nil\n                        logp.Debug(\u0026quot;mysql\u0026quot;, \u0026quot;Ignore MySQL message. Drop tcp stream.\u0026quot;)\n                        return priv\n                }\n \n                if complete {\n                        mysql.messageComplete(tcptuple, dir, stream)\n                } else {\n                        // wait for more data\n                        break\n                }\n                [/code]mysqlMessageParser是一个解析mysql消息的方法，细节我们忽略，我们只需要关心它的返回，ok标示成功或者失败，true则继续处理，false表示数据包不能用，那就直接忽略；第二个参数complete表示判断这一个MySQL消息是否已经完整了，如果完整了，我们就可以扔出去了，否则继续等待剩下的消息内容。\n\n好的，我们看看SMTP协议怎么折腾吧，先看看一个邮件交互的流程图，来自[url=https://tools.ietf.org/html/rfc5321]RFC5321[/url]：\n[img]http://log.medcl.net/wp-content/uploads/2016/01/Snip20160115_12.png[/img]\n由上图可见，发送端和邮件服务器通过一系列命令来执行邮件的发送，下面看看一个具体的命令操作流程(来源：[url]https://zh.wikipedia.org/wiki/简单邮件传输协议)[/url][code]S: 220 www.example.com ESMTP Postfix\nC: HELO mydomain.com\nS: 250 Hello mydomain.com\nC: MAIL FROM: \nS: 250 Ok\nC: RCPT TO: \nS: 250 Ok\nC: DATA\nS: 354 End data with .\nC: Subject: test message\nC: From:\u0026quot;\u0026quot;\u0026lt; sender@mydomain.com\u0026gt;\nC: To:\u0026quot;\u0026quot;\u0026lt; friend@example.com\u0026gt;\nC:\nC: Hello,\nC: This is a test.\nC: Goodbye.\nC: .\nS: 250 Ok: queued as 12345\nC: quit\nS: 221 Bye[/code]上面的过程可以看到就几个命令就能将邮件发送出去，但是其实SMTP协议比较复杂，还包括身份认证、附件、多媒体编码等等，我们今天精简一下，我们目前只关心谁给谁发了邮件，发送内容先不管，这样相比完整的SMTP协议(RFC5321)，我们只需要关注以下几个命令：\nMAIL：开始一份邮件 mail　from: xxx@xx.com\nRCPT: 标识单个的邮件接收人；常在mail命令后面 可有多个rcpt　to: xx@xx.com\nQUIT：结束SMTP会话，不一定发送了邮件，注意\nRESET:重置会话，当前传输被取消 \n\n最终希望通过Packetbeat将这些数据解析并处理成我们想要的如下JSON数据，即大功告成：[code]{\n\u0026quot;timestamp\u0026quot;:\u0026quot;2016-1-15 12:00:00\u0026quot;,\n\u0026quot;from\u0026quot;:\u0026quot;medcl@example.co\u0026quot;,\n\u0026quot;to\u0026quot;:[\u0026quot;lcdem@example.co\u0026quot;]\n}[/code]我们还需要一个测试数据，这里有一个下载各种协议测试数据包的地方，由wireshark站点提供：https://wiki.wireshark.org/SampleCaptures/\nCtrl+F找到SMTP的下载地址：[url=https://wiki.wireshark.org/SampleCaptures?action=AttachFile\u0026amp;do=get\u0026amp;target=smtp.pcap]smtp.pcap[/url]\n用wireshark打开我们刚刚下载的smtp.pcap文件，然后再输入过滤条件：tcp.port == 25，只看25端口的数据，如下图：\n[img]http://log.medcl.net/wp-content/uploads/2016/01/Snip20160115_9.png[/img]\n上图可以看到25端口的跑的数据有很多，不过我们只关心我们需要的那几个命令就好了。\n\n打开/~/go/src/github.com/elastic/beats/packetbeat/protos/smtp/smtp.go\n定义smtpPrivateData，里面的Data是一个数组，分别是TCP两个方向的数据，SmtpMessage是解析出来的邮件信息[code]type smtpPrivateData struct{\n\tData [2]*SmtpStream\n}\n\ntype SmtpStream struct {\n\ttcptuple *common.TcpTuple\n\n\tdata byte\n\n\tparseOffset int\n\tisClient    bool\n\tmessage *SmtpMessage\n}\n\ntype SmtpMessage struct {\n\tTs   time.Time\n\tFrom string\n\tTo string\n}[/code]然后参照MySQL协议，定义相应的方法，最终如下：[code]package smtp\n\nimport (\n\t\u0026quot;github.com/elastic/beats/libbeat/common\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/logp\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/publisher\u0026quot;\n\t\u0026quot;github.com/elastic/beats/packetbeat/config\u0026quot;\n\t\u0026quot;github.com/elastic/beats/packetbeat/protos\u0026quot;\n\t\u0026quot;github.com/elastic/beats/packetbeat/protos/tcp\u0026quot;\n\t\u0026quot;bytes\u0026quot;\n\t\u0026quot;time\u0026quot;\n\t\u0026quot;strings\u0026quot;\n)\n\ntype smtpPrivateData struct{\n\tData [2]*SmtpStream\n}\n\ntype SmtpStream struct {\n\ttcptuple *common.TcpTuple\n\n\tdata byte\n\n\tparseOffset int\n\tisClient    bool\n\n\tmessage *SmtpMessage\n}\n\ntype SmtpMessage struct {\n\tstart int\n\tend   int\n\n\tTs   time.Time\n\tFrom string\n\tTo string\n\tIgnoreMessage bool\n}\n\ntype Smtp struct {\n\tSendRequest         bool\n\tSendResponse        bool\n\ttransactionTimeout time.Duration\n\tPorts         int\n\tresults publisher.Client\n}\n\nfunc (smtp *Smtp) initDefaults() {\n\tsmtp.SendRequest = false\n\tsmtp.SendResponse = false\n\tsmtp.transactionTimeout = protos.DefaultTransactionExpiration\n}\n\nfunc (smtp *Smtp) setFromConfig(config config.Smtp) error {\n\tsmtp.Ports = config.Ports\n\tif config.SendRequest != nil {\n\t\tsmtp.SendRequest = *config.SendRequest\n\t}\n\tif config.SendResponse != nil {\n\t\tsmtp.SendResponse = *config.SendResponse\n\t}\n\n\tif config.TransactionTimeout != nil \u0026amp;\u0026amp; *config.TransactionTimeout \u0026gt; 0 {\n\t\tsmtp.transactionTimeout = time.Duration(*config.TransactionTimeout) * time.Second\n\t}\n\n\treturn nil\n}\n\nfunc (smtp *Smtp) GetPorts() int {\n\treturn smtp.Ports\n}\n\nfunc (smtp *Smtp) Init(test_mode bool, results publisher.Client) error {\n\tsmtp.initDefaults()\n\n\tif !test_mode {\n\t\terr := smtp.setFromConfig(config.ConfigSingleton.Protocols.Smtp)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tsmtp.results = results\n\n\treturn nil\n}\n\nfunc readLine(data byte, offset int) (bool, string, int) {\n\tq := bytes.Index(data[offset:], byte(\u0026quot;\\r\\n\u0026quot;))\n\tif q == -1 {\n\t\treturn false, \u0026quot;\u0026quot;, 0\n\t}\n\treturn true, string(data[offset : offset+q]), offset + q + 2\n}\n\nfunc (smtp *Smtp) Parse(pkt *protos.Packet, tcptuple *common.TcpTuple, dir uint8, private protos.ProtocolData, ) protos.ProtocolData {\n\n\tdefer logp.Recover(\u0026quot;ParseSmtp exception\u0026quot;)\n\n\tpriv := smtpPrivateData{}\n\tif private != nil {\n\t\tvar ok bool\n\t\tpriv, ok = private.(smtpPrivateData)\n\t\tif !ok {\n\t\t\tpriv = smtpPrivateData{}\n\t\t}\n\t}\n\n\tif priv.Data[dir] == nil {\n\t\tpriv.Data[dir] = \u0026amp;SmtpStream{\n\t\t\ttcptuple: tcptuple,\n\t\t\tdata:     pkt.Payload,\n\t\t\tmessage:  \u0026amp;SmtpMessage{Ts: pkt.Ts},\n\t\t}\n\t} else {\n\t\t// concatenate bytes\n\t\tpriv.Data[dir].data = append(priv.Data[dir].data, pkt.Payload...)\n\t\tif len(priv.Data[dir].data) \u0026gt; tcp.TCP_MAX_DATA_IN_STREAM {\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;Stream data too large, dropping TCP stream\u0026quot;)\n\t\t\tpriv.Data[dir] = nil\n\t\t\treturn priv\n\t\t}\n\t}\n\n\tstream := priv.Data[dir]\n\tfor len(stream.data) \u0026gt; 0 {\n\t\tif stream.message == nil {\n\t\t\tstream.message = \u0026amp;SmtpMessage{Ts: pkt.Ts}\n\t\t}\n\n\t\tok, complete := stmpMessageParser(priv.Data[dir])\n\t\tif !ok {\n\t\t\t// drop this tcp stream. Will retry parsing with the next\n\t\t\t// segment in it\n\t\t\tpriv.Data[dir] = nil\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;Ignore SMTP message. Drop tcp stream. Try parsing with the next segment\u0026quot;)\n\t\t\treturn priv\n\t\t}\n\n\t\tif complete {\n\t\t\tsmtp.messageComplete(tcptuple, dir, stream)\n\t\t} else {\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;,\u0026quot;still wait message...\u0026quot;)\n\t\t\t// wait for more data\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn priv\n}\n\nfunc (smtp *Smtp) ConnectionTimeout() time.Duration {\n\treturn smtp.transactionTimeout\n}\n\nfunc stmpMessageParser(s *SmtpStream) (bool, bool) {\n\n\tvar value string=\u0026quot;\u0026quot;\n\n\tfor s.parseOffset \u0026lt; len(s.data) {\n\n\n\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;Parse message: %s\u0026quot;, string(s.data[s.parseOffset]))\n\n\n\t\tif strings.HasPrefix(string(s.data[s.parseOffset]),\u0026quot;MAIL\u0026quot; ) {\n\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;Hit MAIL command: %s\u0026quot;, string(s.data[s.parseOffset]))\n\n\t\t\tfound, line, off := readLine(s.data, s.parseOffset)\n\t\t\tif !found {\n\t\t\t\treturn true, false\n\t\t\t}\n\n\t\t\tvalue = line[1:]\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;value  %s\u0026quot;, value)\n\n\t\t\ts.parseOffset = off\n\t\t} else {\n\t\t\tlogp.Debug(\u0026quot;smtp\u0026quot;, \u0026quot;Unexpected message starting with %s\u0026quot;, s.data[s.parseOffset:])\n\t\t\treturn false, false\n\t\t}\n\t}\n\n\treturn true, false\n}\n\nfunc handleSmtp(stmp *Smtp, m *SmtpMessage, tcptuple *common.TcpTuple,\ndir uint8, raw_msg byte) {\n\tlogp.Info(\u0026quot;smtp\u0026quot;,\u0026quot;handle smtp message...\u0026quot;)\n\n\t//TODO\n\n}\n\n// Called when the parser has identified a full message.\nfunc (smtp *Smtp) messageComplete(tcptuple *common.TcpTuple, dir uint8, stream *SmtpStream) {\n\n\tlogp.Info(\u0026quot;smtp\u0026quot;,\u0026quot;message completed...\u0026quot;)\n\n\t// all ok, ship it\n\tmsg := stream.data[stream.message.start:stream.message.end]\n\n\tif !stream.message.IgnoreMessage {\n\t\thandleSmtp(smtp, stream.message, tcptuple, dir, msg)\n\t}\n\n\t// and reset message\n\tstream.PrepareForNewMessage()\n}\n\nfunc (stream *SmtpStream) PrepareForNewMessage() {\n\tlogp.Info(\u0026quot;smtp\u0026quot;,\u0026quot;prepare for new message...\u0026quot;)\n\n\tstream.data = stream.data[stream.parseOffset:]\n\tstream.parseOffset = 0\n\tstream.isClient = false\n\tstream.message = nil\n}\n\n\n\nfunc (smtp *Smtp) GapInStream(tcptuple *common.TcpTuple, dir uint8,\nnbytes int, private protos.ProtocolData) (priv protos.ProtocolData, drop bool) {\n\n\tdefer logp.Recover(\u0026quot;GapInStream(smtp) exception\u0026quot;)\n\n\tif private == nil {\n\t\treturn private, false\n\t}\n\n\treturn private, true\n}\n\nfunc (smtp *Smtp) ReceivedFin(tcptuple *common.TcpTuple, dir uint8,\nprivate protos.ProtocolData) protos.ProtocolData {\n\n\tlogp.Info(\u0026quot;smtp\u0026quot;,\u0026quot;stream closed...\u0026quot;)\n\n\t// TODO: check if we have data pending and either drop it to free\n\t// memory or send it up the stack.\n\treturn private\n}\n\n[/code]现在切换到命令行，编译一下[code]cd ~/go/src/github.com/elastic/beats/packetbeat\nmake\n\n[/code]编译成功，一个滚烫的packetbeat可执行文件就躺在当前目录下了，运行一下先，参数-I 指定pcap文件（还记得前面下载的那个测试文件吧）[code]./packetbeat -d \u0026quot;smtp\u0026quot; -c etc/packetbeat.yml -I ~/Downloads/smtp.pcap  -e -N\n\n[/code]运行查看控制台输出结果:[code]➜  packetbeat git:(smtpbeat) ✗ ./packetbeat -d \u0026quot;smtp\u0026quot; -c etc/packetbeat.yml -I ~/Downloads/smtp.pcap  -e -N \n2016/01/15 10:12:19.058535 publish.go:191: INFO Dry run mode. All output types except the file based one are disabled.\n2016/01/15 10:12:19.058570 geolite.go:24: INFO GeoIP disabled: No paths were set under output.geoip.paths\n2016/01/15 10:12:19.058592 publish.go:262: INFO Publisher name: medcls-MacBook.local\n2016/01/15 10:12:19.058724 beat.go:145: INFO Init Beat: packetbeat; Version: 1.0.0\n2016/01/15 10:12:19.059758 beat.go:171: INFO packetbeat sucessfully setup. Start running.\n2016/01/15 10:12:20.155335 smtp.go:163: DBG  Parse message: 2\n2016/01/15 10:12:20.155416 smtp.go:180: DBG  Unexpected message starting with 250-xc90.websitewelcome.com Hello GP [122.162.143.157]\n250-SIZE 52428800\n250-PIPELINING\n250-AUTH PLAIN LOGIN\n250-STARTTLS\n250 HELP\n2016/01/15 10:12:22.310974 smtp.go:163: DBG  Parse message: F\n2016/01/15 10:12:22.311025 smtp.go:180: DBG  Unexpected message starting with From: \u0026quot;Gurpartap Singh\u0026quot; \nTo: \nSubject: SMTP\nDate: Mon, 5 Oct 2009 11:36:07 +0530\nMessage-ID: \u0026lt;000301ca4581$ef9e57f0$cedb07d0$@in\u0026gt;\nMIME-Version: 1.0\n...\n\n[/code]成功了，邮件内容都在控制台输出了，但这还不是我们要的最终结果，我需要里面的关键信息，我们继续修改smtp.go这个文件。\n留待下回分解。","title":"Packetbeat协议扩展开发教程（3）","uid":"1","views":"6122","votes":"2"},"_type":"doc"}
{"_id":"55","_index":"forum-mysql","_score":1,"_source":{"addtime":"1453038038","category_id":"2","comments":"1","has_attach":"0","id":"55","message":"nest驱动访问ES，按照官网文档，使用如下程序可以正常索引：\nstatic void Main()\n        {\n            var node = new Uri(\u0026quot;http://localhost:9200\u0026quot;);\n\n            var settings = new ConnectionSettings(\n                node,\n                defaultIndex: \u0026quot;my-application\u0026quot;\n            );\n            var client = new ElasticClient(settings);\n            var person = new Person\n            {\n                Id = \u0026quot;1\u0026quot;,\n                Firstname = \u0026quot;Martijn\u0026quot;,\n                Lastname = \u0026quot;Laarman\u0026quot;\n            };\n            var index = client.Index(person);\n        }\n调整为手动设置indexName时出错，示例代码如下：\nstatic void Main()\n        {\n            var node = new Uri(\u0026quot;http://localhost:9200\u0026quot;);\n\n            var settings = new ConnectionSettings(\n                node,\n                defaultIndex: \u0026quot;my-application\u0026quot;\n            );\n            settings.MapDefaultTypeIndices(d =\u0026gt; d.Add(typeof(Person), \u0026quot;constIndex\u0026quot;));\n            var client = new ElasticClient(settings);\n            var person = new Person\n            {\n                Id = \u0026quot;1\u0026quot;,\n                Firstname = \u0026quot;Martijn\u0026quot;,\n                Lastname = \u0026quot;Laarman\u0026quot;\n            };\n            var index = client.Index(person);\n        }\n出错提示为：\n{StatusCode: 400,\n Method: PUT,\n Url: http://localhost:9200/constIndex/automobile/1,\n Request: {\n  \u0026quot;firstname\u0026quot;: \u0026quot;Martijn\u0026quot;,\n  \u0026quot;lastname\u0026quot;: \u0026quot;Laarman\u0026quot;,\n  \u0026quot;id\u0026quot;: \u0026quot;1\u0026quot;\n},\n Response: \u0026lt;Response stream not captured or already read to completion by serializer, set ExposeRawResponse() on connectionsettings to force it to be set on\u0026gt;}\n \n [code]using System;\nusing Nest;\n\nnamespace ConsoleApplication1\n{\n    class Program\n    {\n        private static IIndexResponse Index\u0026lt;T\u0026gt;(T person, string indexName) where T : class\n        {\n            var node = new Uri(\u0026quot;http://localhost:9200\u0026quot;);\n\n            var settings = new ConnectionSettings(node,defaultIndex: indexName);\n            var client = new ElasticClient(settings);\n            return client.Index(person);\n        }\n\n        static void Main()\n        {\n            string indexNameError = typeof(Person).FullName\n                .Substring(typeof(Person).FullName.LastIndexOf(\u0026quot;.\u0026quot;, StringComparison.Ordinal) + 1) + \u0026quot;Indexs\u0026quot;;\n            const string indexNameOk = \u0026quot;test\u0026quot;;\n            var person = new Person\n            {\n                Id = \u0026quot;1\u0026quot;,\n                Firstname = \u0026quot;Martijn\u0026quot;,\n                Lastname = \u0026quot;Laarman\u0026quot;\n            };\n            var ok = Index(person, indexNameOk);\n            Console.WriteLine(\u0026quot;Result:\u0026quot; + ok.IsValid);\n            var error = Index(person, indexNameError);\n            Console.WriteLine(\u0026quot;Result:\u0026quot; + error.IsValid);\n            Console.ReadKey();\n        }\n       \n    }\n\n   [Serializable]\n    public class Person\n    {\n        public string Firstname { get; set; }\n        public string Lastname { get; set; }\n        public string Id { get; set; }\n    }\n}\n[/code]\n ","title":"nest驱动IndexName问题","uid":"586","views":"2150","votes":"0"},"_type":"doc"}
{"_id":"57","_index":"forum-mysql","_score":1,"_source":{"addtime":"1454376548","category_id":"2","comments":"2","has_attach":"1","id":"57","message":"\r\n目前最新版ES超级详细的安装、配置流程。\r\n根据自己真实的安装过程以及多篇博客文章的重要提示编写。\r\n按照文档中的说明一步一步操作，分分钟就能开始ES2.1.1的非凡体验！","title":"ElasticSearch2.1.1安装及简单配置说明","uid":"825","views":"3895","votes":"2"},"_type":"doc"}
{"_id":"80","_index":"forum-mysql","_score":1,"_source":{"addtime":"1464160816","category_id":"1","comments":"8","has_attach":"1","id":"80","message":"[b]PPT下载地址:[/b]\n[b] 百度云盘:  [url]http://pan.baidu.com/s/1slQn93v[/url]   提取码:jqqi[/b]\n[b] 淘云盘： [url]http://yunpan.taobao.com/s/E2TDSFivxt[/url]  提取码: vwIWlm[/b]\n[b]  [/b]\n [b]Elastic 中文社区联手杭州码耘网络共同举办第一次线下聚会，欢迎对elastic、搜索、大数据等技术感兴趣的朋友来玩玩[/b]\n[list]\n[*]时间：2016-6-18 13:00:00[/*]\n[*]地点：杭州市滨江区上峰电商产品园1-227(从聚才路门口进来会比较近，离阿里网易5分钟路程)[/*]\n[/list]\n\n[b]                               [img]http://img2.mangoerp.com/userbucket/test4444/2016-05-25/1464161219856.png[/img][/b]\n \n \n[b]分享主题 :   [/b]\n[list]\n[*][b]  [/b]有赞搜索引擎实践   ——   洪斌@有赞大数据团队负责人[/*]\n[*]   Elastic结合Hbase的应用实践  —— 汪兴@浙大中控[/*]\n[*]   购阿购数据分析平台对Elasticsearch使用实践     —— 万斌@北京购阿购技术服务有限公司[/*]\n[*]   beats介绍与扩展   ——  曾勇@elastic[/*]\n[*]   基于ELK的云日志产品实践 —— 宁海元@袋鼠云[/*]\n[*]   elasticsearch-jdbc介绍以及基于binlog的增量数据同步方案 —— 卢栋@码耘网络[b]  [/b][/*]\n[/list]\n \n \n[b]报名方式：[/b]\n[list]\n[*]  扫描下面微信二维码加入杭州Elastic聚会群，成功加入即算报名成功[/*]\n[*]  无法扫描的同学加我微信(573513542)，我来拉你进群[/*]\n[/list]\n\n[b]                     [/b][b][attach]220[/attach][/b]\n\n\n[b]乘车[/b]：  \n   附近公交站: \n[list]\n[*]秋溢路聚才路口(139路直达)[/*]\n[*]江虹路秋溢路口(139路、175路)[/*]\n[*]滨安路江虹路口(225、B支6 路）[/*]\n[/list]\n   地铁：\n[list]\n[*] 坐到滨和路站或者西兴站，然后打车过来起步价[/*]\n[/list]\n \n    ps :  如果到了滨江不认识路，可以打我手机(15858279062) 我可以来接你。\n ","title":"杭州 Elastic社区第一次线下活动 开始报名啦！！！","uid":"1033","views":"3063","votes":"5"},"_type":"doc"}
{"_id":"85","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466737611","category_id":"15","comments":"0","has_attach":"0","id":"85","message":"[code]前言\n\n上一篇博文，笔者相当于了解了Lucene是干嘛的，然后写了个hello World增进下对Lucene的感觉。个人觉得，学习一个新的东西时，首先从demo入手，能增加你对这个技术的兴趣，然后慢慢的深入其中的原理，就会有种拨开乌云见明月的感觉。当然，有的人喜欢从原理入手，这个见仁见智。总结来说，不管从哪里入手，对一门新的技术而言总归要知道其所有然\n\n正文\n\n\nLucene是一个高效的，基于Java的全文检索库。\n\n所以在了解Lucene之前要费一番工夫了解一下全文检索。\n\n那么什么叫做全文检索呢？这要从我们生活中的数据说起。\n\n我们生活中的数据总体分为两种：结构化数据和非结构化数据。\n\n结构化数据：指具有固定格式或有限长度的数据，如数据库，元数据等。\n非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等。\n当然有的地方还会提到第三种，半结构化数据，如XML，HTML等，当根据需要可按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。\n\n非结构化数据又一种叫法叫全文数据。\n\n\n按照数据的分类，搜索也分为两种：\n\n对结构化数据的搜索：如对数据库的搜索，用SQL语句。再如对元数据的搜索，如利用windows搜索对文件名，类型，修改时间进行搜索等。\n对非结构化数据的搜索：如利用windows的搜索也可以搜索文件内容，Linux下的grep命令，再如用Google和百度可以搜索大量内容数据。\n对非结构化数据也即对全文数据的搜索主要有两种方法：\n\n一种是顺序扫描法(Serial Scanning)：所谓顺序扫描，比如 要找内容包含某一个字符串的文件，就是一个文档一个文档的看，对于每一个文档，从头看到尾，如果此文档包含此字符串，则此文档为我们要找的文件，接着看下 一个文件，直到扫描完所有的文件。如利用windows的搜索也可以搜索文件内容，只是相当的慢。如果你有一个80G硬盘，如果想在上面找到一个内容包含 某字符串的文件，不花他几个小时，怕是做不到。Linux下的grep命令也是这一种方式。大家可能觉得这种方法比较原始，但对于小数据量的文件，这种方 法还是最直接，最方便的。但是对于大量的文件，这种方法就很慢了。\n\n有人可能会说，对非结构化数据顺序扫描很慢，对结构化数据的搜索却相对较快（由于结构化数据有一定的结构可以采取一定的搜索算法加快速度），那么把我们的非结构化数据想办法弄得有一定结构不就行了吗？\n\n这种想法很天然，却构成了全文检索的基本思路，也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。\n\n这部分从非结构化数据中提取出的然后重新组织的信息，我们称之索引。\n\n这种说法比较抽象，举几个例子就很容易明白，比如字典，字典的拼音表和部首检字表就相当于字典的索引，对每一个字的解释是非结构化的，如果字典没有 音节表和部首检字表，在茫茫辞海中找一个字只能顺序扫描。然而字的某些信息可以提取出来进行结构化处理，比如读音，就比较结构化，分声母和韵母，分别只有 几种可以一一列举，于是将读音拿出来按一定的顺序排列，每一项读音都指向此字的详细解释的页数。我们搜索时按结构化的拼音搜到读音，然后按其指向的页数， 便可找到我们的非结构化数据——也即对字的解释。\n\n\n这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search)。[/code][code]全文检索大体分两个过程，索引创建(Indexing)和搜索索引(Search)。\n\n索引创建：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。\n搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程。\n于是全文检索就存在三个重要问题：\n\n1. 索引里面究竟存些什么？(Index)\n\n2. 如何创建索引？(Indexing)\n\n3. 如何对索引进行搜索？(Search)\n\n下面我们顺序对每个个问题进行研究。\n\n\n二、索引里面究竟存些什么\n\n索引里面究竟需要存些什么呢？\n\n首先我们来看为什么顺序扫描的速度慢：\n\n其实是由于我们想要搜索的信息和非结构化数据中所存储的信息不一致造成的。\n\n非结构化数据中所存储的信息是每个文件包含哪些字符串，也即已知文件，欲求字符串相对容易，也即是从文件到字符串的映射。而我们想搜索的信息是哪些 文件包含此字符串，也即已知字符串，欲求文件，也即从字符串到文件的映射。两者恰恰相反。于是如果索引总能够保存从字符串到文件的映射，则会大大提高搜索 速度。\n\n由于从字符串到文件的映射是文件到字符串映射的反向过程，于是保存这种信息的索引称为反向索引。\n\n反向索引的所保存的信息一般如下：\n\n假设我的文档集合里面有100篇文档，为了方便表示，我们为文档编号从1到100，得到下面的结构\n\nLucene全文检索的基本原理\n\n左边保存的是一系列字符串，称为词典。\n\n每个字符串都指向包含此字符串的文档(Document)链表，此文档链表称为倒排表(Posting List)。\n\n有了索引，便使保存的信息和要搜索的信息一致，可以大大加快搜索的速度。\n\n比如说，我们要寻找既包含字符串“lucene”又包含字符串“solr”的文档，我们只需要以下几步：\n\n1. 取出包含字符串“lucene”的文档链表。\n\n2. 取出包含字符串“solr”的文档链表。\n\n3. 通过合并链表，找出既包含“lucene”又包含“solr”的文件。\n\nLucene全文检索的基本原理\n\n看到这个地方，有人可能会说，全文检索的确加快了搜索的速度，但是多了索引的过程，两者加起来不一定比顺序扫描快多少。的确，加上索引的过程，全文检索不一定比顺序扫描快，尤其是在数据量小的时候更是如此。而对一个很大量的数据创建索引也是一个很慢的过程。\n\n然而两者还是有区别的，顺序扫描是每次都要扫描，而创建索引的过程仅仅需要一次，以后便是一劳永逸的了，每次搜索，创建索引的过程不必经过，仅仅搜索创建好的索引就可以了。\n\n这也是全文搜索相对于顺序扫描的优势之一：一次索引，多次使用。\n\n\n三、如何创建索引\n\n全文检索的索引创建过程一般有以下几步：\n\n第一步：一些要索引的原文档(DOCUMENT)。\n\n为了方便说明索引创建过程，这里特意用两个文件为例：\n\n文件一：Students should be allowed to go out with their friends, but not allowed to drink beer.\n\n文件二：My friend Jerry went to school to see his students but found them drunk which is not allowed.\n\n\n第二步：将原文档传给分次组件(TOKENIZER)。\n\n分词组件(Tokenizer)会做以下几件事情(此过程称为Tokenize)：\n\n1. 将文档分成一个一个单独的单词。\n\n2. 去除标点符号。\n\n3. 去除停词(Stop word)。\n\n所谓停词(Stop word)就是一种语言中最普通的一些单词，由于没有特别的意义，因而大多数情况下不能成为搜索的关键词，因而创建索引时，这种词会被去掉而减少索引的大小。\n\n英语中挺词(Stop word)如：“the”,“a”，“this”等。\n\n对于每一种语言的分词组件(Tokenizer)，都有一个停词(stop word)集合。\n\n\n经过分词(Tokenizer)后得到的结果称为词元(Token)。\n\n在我们的例子中，便得到以下词元(Token)：\n\n“Students”，“allowed”，“go”，“their”，“friends”，“allowed”，“drink”，\n\n“beer”，“My”，“friend”，“Jerry”，“went”，“school”，“see”，“his”，“\n\nstudents”，“found”，“them”，“drunk”，“allowed”。\n\n第三步：将得到的词元(TOKEN)传给语言处理组件(LINGUISTIC PROCESSOR)。\n\n语言处理组件(linguistic processor)主要是对得到的词元(Token)做一些同语言相关的处理。\n\n对于英语，语言处理组件(Linguistic Processor)一般做以下几点：\n\n1. 变为小写(Lowercase)。\n\n2. 将单词缩减为词根形式，如“cars”到“car”等。这种操作称为：stemming。\n\n3. 将单词转变为词根形式，如“drove”到“drive”等。这种操作称为：lemmatization。\n\n\nStemming 和 lemmatization的异同：\n\n相同之处：Stemming和lemmatization都要使词汇成为词根形式。\n两者的方式不同：\nStemming采用的是“缩减”的方式：“cars”到“car”，“driving”到“drive”。\nLemmatization采用的是“转变”的方式：“drove”到“drove”，“driving”到“drive”。\n两者的算法不同：\nStemming主要是采取某种固定的算法来做这种缩减，如去除“s”，去除“ing”加“e”，将“ational”变为“ate”，将“tional”变为“tion”。\nLemmatization主要是采用保存某种字典的方式做这种转变。比如字典中有“driving”到“drive”，“drove”到“drive”，“am, is, are”到“be”的映射，做转变时，只要查字典就可以了。\nStemming和lemmatization不是互斥关系，是有交集的，有的词利用这两种方式都能达到相同的转换。\n\n语言处理组件(linguistic processor)的结果称为词(Term)。\n\n在我们的例子中，经过语言处理，得到的词(Term)如下：\n\n“student”，“allow”，“go”，“their”，“friend”，“allow”，“drink”，\n\n“beer”，“my”，“friend”，“jerry”，“go”，“school”，“see”，“his”，\n\n“student”，“find”，“them”，“drink”，“allow”。\n也正是因为有语言处理的步骤，才能使搜索drove，而drive也能被搜索出来。\n\n\n第四步：将得到的词(TERM)传给索引组件(INDEXER)。\n\n原文地址：[url]http://www.kailing.pub/article/index/arcid/72.html[/url]\n[/code][code]再次吐槽这个编辑器，想要发个图片并茂的不容易\n[/code]","title":"Lucene5.5入门第二篇——Lucene全文检索的基本原理","uid":"1032","views":"4668","votes":"3"},"_type":"doc"}
{"_id":"93","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738852","category_id":"15","comments":"0","has_attach":"0","id":"93","message":"[code]前言\n\n我们在使用百度和谷歌等搜索引擎的时候，你会发现，搜索引擎会把和我们输入的关键字以红色的字体显示，来突出显示结果的准确性，这就是高亮显示的使用场景\n\n准备\n\n使用Highlighter需要导入相应的jar包，maven项目可以加入如下依赖\n\n\u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.apache.lucene\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;lucene-highlighter\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;5.5.0\u0026lt;/version\u0026gt;\n   \u0026lt;/dependency\u0026gt;\n\n直接看代码\n\n\n/**\n * @author kl by 2016/3/19\n * @boke www.kailing.pub\n */\npublic class FieldSetBoostTest {\n    //索引目录\n    String indexDir=\u0026quot;E:\\\\LuceneIndex\u0026quot;;\n    //测试数据\n    String theme=\u0026quot;中国\u0026quot;;\n    String []title={\u0026quot;中国是一个伟大的国家\u0026quot;,\u0026quot;我爱你的的祖国,美丽的中国\u0026quot;,\u0026quot;是什么，中国令美日等国虎视眈眈\u0026quot;};\n    /**\n     * Lucence5.5返回IndexWriter实例\n     * @param directory\n     * @return\n     */\n    public IndexWriter getIndexWriter(Directory directory){\n        Analyzer analyzer=new CJKAnalyzer();//中日韩二元分词\n        IndexWriterConfig writerConfig=new IndexWriterConfig(analyzer);\n        IndexWriter writer=null;\n        try {\n            writer =new IndexWriter(directory,writerConfig);\n        }catch (Exception e){\n            e.printStackTrace();\n        }\n        return writer;\n    }\n    public Directory getDirctory(String indexDir){\n        Directory directory=null;\n        try {\n            directory=FSDirectory.open(Paths.get(indexDir));\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n        return directory;\n    }\n    /**\n     * 创建索引不加权\n     * @throws Exception\n     */\n    public void Indexer()throws Exception{\n       IndexWriter writer=getIndexWriter(getDirctory(indexDir));\n        Document doc=null;\n        for(String str:title){\n            doc=new Document();\n            //Lucence5.5 Fileld有多个实现，StringFIeld不分词  TextField分词\n            doc.add(new StringField(\u0026quot;theme\u0026quot;,theme, Field.Store.YES));\n            Field field=new TextField(\u0026quot;title\u0026quot;,str, Field.Store.YES);\n            doc.add(field);\n            writer.addDocument(doc);\n        }\n        writer.close();\n    }\n\n    /**\n     * 关键命中词高亮输出处理\n     * @param query\n     * @param context\n     * @return\n     * @throws Exception\n     */\n    public static String getHighlighterString(Query query,String context)throws Exception{\n        //对促成文档匹配的实际项进行评分\n        QueryScorer scorer=new QueryScorer(query);\n        //设置高亮的HTML标签格式\n        Formatter  simpleHTMLFormatter=new SimpleHTMLFormatter(\u0026quot;\u0026quot;,\u0026quot;\u0026quot;);\n        //实例化高亮分析器\n        Highlighter highlighter=new Highlighter(simpleHTMLFormatter,scorer);\n        //提供静态方法，支持从数据源中获取TokenStream，进行token处理\n        TokenStream tokenStream=new CJKAnalyzer().tokenStream(\u0026quot;title\u0026quot;, new StringReader(context));\n        return highlighter.getBestFragment(tokenStream, context);\n    }\n    @Test\n    public void searcherTest()throws Exception{\n        //  Indexer();\n        IndexReader reader= DirectoryReader.open(getDirctory(indexDir));\n        IndexSearcher is=new IndexSearcher(reader);\n        System.out.println(\u0026quot;总的文档数：\u0026quot;+reader.numDocs());\n        QueryParser qp=new QueryParser(\u0026quot;title\u0026quot;,new CJKAnalyzer());\n        String q=\u0026quot;中国\u0026quot;;\n        Query query=qp.parse(q);\n        TopDocs tDocs=is.search(query,11);\n        System.out.println(\u0026quot;查询-》\u0026quot;+q+\u0026quot;《-总共命中【\u0026quot;+tDocs.totalHits+\u0026quot;】条结果\u0026quot;);\n        for (ScoreDoc scoredoc:tDocs.scoreDocs){\n            Document doc = is.doc(scoredoc.doc);\n            String context=doc.get(\u0026quot;title\u0026quot;);\n            if(context!=null){\n                System.out.println(getHighlighterString(query,context));\n            }\n\n        }\n    }\n}\n查询效果如下：\n\n[/code]原文地址：[url]http://www.kailing.pub/article/index/arcid/82.html[/url]","title":"Lucene5.5入门第十篇完结篇——使用Highlighter使关键词高亮","uid":"1032","views":"3387","votes":"0"},"_type":"doc"}
{"_id":"106","_index":"forum-mysql","_score":1,"_source":{"addtime":"1477556910","category_id":"5","comments":"0","has_attach":"1","id":"106","message":"[attach]305[/attach]\n作者：Shay Banon，原文：[url]https://www.elastic.co/blog/elastic-stack-5-0-0-released[/url] \n\n记得在 2016 年 2 月份，就在 Elastic{ON} 16 大会之后，我写了一篇标题为 [Heya, Elastic Stack and X-Pack] ([url]https://www.elastic.co/blog/heya-elastic-stack-and-x-pack[/url] ) 的博客。经过了几乎整整一年的努力，中间发布了 5  个 Alpha，1 个 Beta 和一个 RC 版本，今天我们非常高兴的正式宣布发布 Elastic Stack 的 GA 正式版本。\n\n并且，重要的是，于此同时，在我们的 [Elastic Cloud]([url]https://www.elastic.co/cloud/as-a-service/signup[/url] ) 上面也同步进行了更新。所以如果你需要托管的 Elasticsearch 和 Kibana ，那么没有其它地方比这里更及时了。我们致力于让 Elastic Cloud 成为一个托管 Elasticsearch 的最佳场所。事实上，在正式版发布之前，我们也提供了 RC 版本方便你用于测试。\n\n我们的团队今天正在庆祝这一时刻，我希望你能加入我们。\n\nGA 版本今天已经可以下载了，如果要加入 Elastic 团队 11 月 3 号的线上活动，了解更多有关于本次发布和向工程师提问，请点击这里 [注册!]([url]https://www.elastic.co/live/v5[/url] )\n \n\n在开始探索发布详情之前，我想借此机会来回顾一下有哪些背后的事情让我们走到今天。\n\n[b]## 我们的社区[/b]\n\n最近的 Elastic{ON} Tour，在每场活动的开场我会讨论我们公司过去几年的简短历史。最近一次活动的高潮是当我宣布我们的累计下载总数达到了七千五百万。当我第一次开始这个项目的时候，我希望她能够被能够被广泛使用，但是我们的社区的热情和激情总是不断的给我快乐和惊喜。\n\n[b]## 先驱者计划[/b]\n\n考虑到这一点，我想分享一下 [先驱者计划]([url]https://www.elastic.co/blog/elastic-pioneer-program[/url] ) 的一些结果。该计划开始于一个简单的前提，你如何使用 Elastic Stack 对我们来说非常重要，不管是产品研发还是确保发布高质量的可用版本。我非常高兴的告诉大家自四月份发布的第一个Alpha版本，我们的社区一共提交了146个issue。\n\n我们的社区是Elastic其中一个最宝贵的财产。事实上，在这次发布中讨论的最多的就是为什么命名为 \u0026quot;Elastic Stack\u0026quot;。\n\n[b]## Elastic Stack[/b]\n\n过去一年，我们收购了Packetbeat 团队，然后Beats 就诞生了。这是一个开源的用于构建轻量级数据收集的平台，可用于日志、基础设施监控指标、网络流量等数据的收集，并且以前所未有的简单方式来将数据发送至Logstash或Elasticsearch。同时我们热爱那些已经习惯于将 ELK 作为代表我们软件栈的你们，只不过加上Beats，我们不知道如何将“B”和E-L-K组合在一起。（NOTE：过去用过ELKB）\n\n但Elastic Stack 远不只是一个名字。当我们开始发布一个周期，我们开发提交、构建、测试和发布的是一整个软件栈。这个很重要，从内部来保证兼容性。并且，对你来说，它可以帮助你提升部署速度，减少版本冲突，让开发者轻松的处理整个 Elastic Stack的兼容性问题。\n\n[b]## 一场特性之旅[/b]\n\n在我开始这篇博客之前，我打算列举每个产品的一些主要特性，但是发现好像很难确定从哪里开始和结束。我们每个产品和技术的leader 已经创建了单独的博客来讨论各自产品的特性，没人比他们更适合介绍其中的故事。 我个人，更是对其中的一些特性感到非常兴奋，相较于简单的罗列，我会提供一些简短概要并且鼓励你去阅读每个产品详细的博客。\n\n\n[b]Ingest Node[/b]\n\nIngest Node 是Elasticsearch 的一个节点类型，允许你对数据做一些加工，比如：grok、geoip、date和其它索引（或重建）过程中的基本数据操作。 通过访问REST API的时候指定一个参数“?pipeline=x”来使用由一系列处理器（processors）构造的管道，它可用帮你对文档进行预处理，原生的在Elasticsearch内部，在索引之前做灵活的 ingest部署。这不代表要替换掉Logstash，也不会移除对Beats的需要，只为你设计数据采集架构时提供一种更加灵活的可能性。\n\n[b]Elasticsearch 性能[/b]\n\n性能报告倾向于提供一个大纲，尤其是比较性的性能测试报告，基于此，我们花了很大力气来比较5.0.0 与之前发布的版本。数据现在已经可用了，这个数据也是我们用来检查和确保我们正在做正确的事情来保证性能，我们是如此的公开来避免由性能测试数字引起的所谓秘密和怀疑。事实上，不止测试结果，我们还公布了我们的硬件和配置，我们还开源了我们的工具链(叫做 [Rally]([url]https://github.com/elastic/rally[/url] )) 和测试记录本身([Rally-Tracks]([url]https://github.com/elastic/rally-tracks[/url] ))。\n\n[b]Metricbeat[/b]\n\nMetricbeat 替换 Topbeat 成为Elastic Stack里主要的收集度量指标的工具。和Topbeat一样，Metricbeat 收集和“top” 类似的诸如机器及进程的资源(CPU, memory, disk, network)统计信息。和Topbeat不同的是，Metricbeat 同时也收集其它系统的指标信息，如：Apache、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、 Redis和 Zookeeper，并且在不久的将来还会支持更多应用和系统。\n\nLogstash 监控 API** - 这是一个新的监控特性提供Logstash 管道及其插件在运行时的可视状态。这个组件收集Logstash处理你数据的各种操作性统计指标信息，所有的这些信息都可通过简单的API来进行查询。\n\n[b]Timelion[/b]\n\n以前以re{Search} 项目介绍过，现在Timelion 作为Kibana原生的核心组件可直接可用。Timelion 提供一个查询表达式和可视化类型让你探索基于时间的数据。\n\n再列举几个，诸如BKD 树、scaled_float 和 half_float ，我们投入了大量的精力到 [Elasticsearch 可靠性]([url]https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html[/url] ) 中，另外Kibana惊艳的重新设计（我从来不知道我们以前有这么讨厌这些边框直到移除）， Beats 支持的Kafaka输出，等等，还有很多很多。\n\n这是一个非常大的版本发布，非常有必要阅读相关独立的博客来了解更多范围内的改进。\n[list]\n[*][Elasticsearch]([url]https://www.elastic.co/blog/elasticsearch-5-0-0-released[/url] )[/*]\n[/list]\n[list]\n[*][Kibana]([url]https://www.elastic.co/blog/kibana-5-0-0[/url] )[/*]\n[/list]\n[list]\n[*][Logstash]([url]https://www.elastic.co/blog/logstash-5-0-0-released[/url] )[/*]\n[/list]\n[list]\n[*][Beats]([url]https://www.elastic.co/blog/beats-5-0-0-released[/url] )[/*]\n[/list]\n[list]\n[*][X-Pack]([url]https://www.elastic.co/blog/x-pack-5-0-0-released[/url] )[/*]\n[/list]\n\n[b]## X-Pack[/b]\n\n在Elastic 我们热爱扩展。太多我们构建的东西我们给他们起了非常有趣的名字，如：Shield、Marvel和Watcher，作为提供给我们客户的额外的插件，独立闭源但没限制开源部分的能力的特性，随着后面又增加了Graph 和Reporting，安装流程也变得困难和困惑。\n\n[i]来和X-Pack 打个招呼吧![/i]\n\n一个包含了security、alerting、monitoring \u0026amp; management、reporting和graph 能力的Elastic Stack的插件。我们对5.0的工程不仅限于Elastic Stack，同时也包括给X-Pack 添加如下：\n[list=1]\n[*]Kibana里的管理和监控的UI界面[/*]\n[*]Kibana里创建用户和角色的UI界面[/*]\n[*]非常简化的安装流程[/*]\n[/list]\n\nX-Pack 可以试用，同时提供商业和免费（基本）授权证书选项。我们尤其兴奋的将X-Pack的某些特性开放出来免费使用，详细请见 [Subscriptions]([url]https://www.elastic.co/subscriptions[/url] ) 页。\n\n[b]## 放在最后[/b]\n\n我敬畏发布此次版本所做的所有努力，来自我们社区和客户的共同参与，以及为了将来发布所做的一系列背地里的工作。一如既往，理解一个版本的最好方式就是去体验它。\n[list]\n[*][Elasticsearch 5.0.0 下载]([url]https://www.elastic.co/downloads/elasticsearch[/url] )[/*]\n[/list]\n[list]\n[*][Kibana 5.0.0 下载]([url]https://www.elastic.co/downloads/kibana[/url] )[/*]\n[/list]\n[list]\n[*][X-Pack 5.0.0 安装指南]([url]https://www.elastic.co/downloads/x-pack[/url] )[/*]\n[/list]\n[list]\n[*][Logstash 5.0.0 下载]([url]https://www.elastic.co/downloads/logstash[/url] )[/*]\n[/list]\n[list]\n[*][Beats 5.0.0 下载]([url]https://www.elastic.co/downloads/beats[/url] )[/*]\n[/list]\n[list]\n[*][ES-Hadoop 5.0.0 下载]([url]https://www.elastic.co/downloads/hadoop[/url] )[/*]\n[/list]\n\n   \n ","title":"Elastic Stack 5.0 正式发布","uid":"1","views":"4153","votes":"3"},"_type":"doc"}
{"_id":"109","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480037628","category_id":"2","comments":"18","has_attach":"0","id":"109","message":" [code]Settings settings = Settings.builder().put(\u0026quot;cluster.name\u0026quot;, \u0026quot;xxx\u0026quot;)\n                    .put(\u0026quot;xpack.security.transport.ssl.enabled\u0026quot;, false)\n                    .put(\u0026quot;xpack.security.user\u0026quot;, \u0026quot;xxx:xxx\u0026quot;)\n                    .put(\u0026quot;client.transport.sniff\u0026quot;, true).build();\ntry {\n    client = new PreBuiltXPackTransportClient(settings)\n            .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;xxx.xxx.xxx.xxx\u0026quot;), 9300))\n            .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;xxx.xxx.xxx.xxx\u0026quot;), 9300));\n} catch (UnknownHostException e) {\n    e.printStackTrace();\n}[/code]","title":"java客户端连接es5.0（基于xpack安全管理）","uid":"1609","views":"11507","votes":"3"},"_type":"doc"}
{"_id":"114","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480864991","category_id":"14","comments":"6","has_attach":"1","id":"114","message":"es现在几乎已经是开源搜索引擎的事实标准了，搭建简易，使用方便。不过在很多公司里(包括我司的部分部门)，并不是把它当搜索引擎来用，而是当db来用。因为本身查询/搜索原理的区别，使es在千万或者亿级的数据中进行逻辑筛选相对高效。例如一些wms、工单查询系统，单表几十个甚至上百个字段，如果在数据库里为每种类型的查询都建立合适的索引，成本比较高，更不用说索引建多了还会影响到插入速度，后期的索引优化也是比较麻烦的问题。\n\n不过如果把es当db来使的话，始终会有一个绕不过去的坎。就是es的DSL。让所有业务开发去学习dsl的话也不是不可以，但DSL真的有点反人类(不要打我)。简单的a and b或者a or b还比较容易写，如果我要的是a and (b and (c or d) and e)的查询逻辑，那我觉得谁写都会晕。即使是用官方或者第三方提供的client，如果需求多种多样的话，想要灵活地实现`需求=\u0026gt;DSL`的过程还是比较痛苦。\n\n对于业务开发来说，当然是sql更平易近人(毕竟写了这么多年CRUD)。所以还有一种歪门邪道的流派，直接把sql转成DSL。要做sql和DSL转换的工作，需要进行sql的解析，先不要怵，这个年代找一个靠谱的sql parser还是比较容易的。比如阿里开源的druid连接池里的sql模块：\n \nhttps://github.com/alibaba/druid/tree/master/src/main/java/com/alibaba/druid/sql\n\n因为笔者的实现是用的下面这个golang版的parser：\n\nhttps://github.com/xwb1989/sqlparser\n\n所以用这个来举例吧~\n\n这个是其作者从youtube/vitness里提取并进行改进的一个parser，我们能用到的是一部分子集功能，只需要解析select类的sql。\n\n先举个简单的sql的例子：[code]select * from x_order where userId = 1 order by id desc limit 10,1;\n\n解析之后会变成golang的一个struct，来看看具体的定义：\n\n\u0026amp;sqlparser.Select{\n    Comments:sqlparser.Comments(nil),\n    Distinct:\u0026quot;\u0026quot;,\n    SelectExprs:sqlparser.SelectExprs{(*sqlparser.StarExpr)(0xc42000aee0)},\n    From:sqlparser.TableExprs{(*sqlparser.AliasedTableExpr)(0xc420016930)},\n    Where:(*sqlparser.Where)(0xc42000afa0),\n    GroupBy:sqlparser.GroupBy(nil),\n    Having:(*sqlparser.Where)(nil),\n    OrderBy:sqlparser.OrderBy{(*sqlparser.Order)(0xc42000af20)},\n    Limit:(*sqlparser.Limit)(0xc42000af80),\n    Lock:\u0026quot;\u0026quot;\n}[/code]\n\nsql的select语句在被解析之后生成一个Select的结构体，如果我们不关心使用者需要的字段的话，可以先把SelectExprs/Distinct/Comments/Lock里的内容忽略掉。如果不是分组统计类的需求，也可以先把GroupBy/Having忽略掉。这里我们关心的就剩下From、Where、OrderBy和Limit。\n\nFrom对应的TableExprs实际上可以认为是简单的字符串，这里的值其实就是`x_order`。\n\nOrderBy实际上是一个元素为[code]type Order struct {\n    Expr      ValExpr\n    Direction string\n}\\[/code]\n的数组。\n\nLimit也很简单，[code]type Limit struct {\n    Offset, Rowcount ValExpr\n}[/code]\n其实就是俩数字。\n\n那么剩下的就是这个Where结构了。where会被解析为AST(`https://en.wikipedia.org/wiki/Abstract_syntax_tree`)，中文是抽象语法树。在不说子查询之类的情况下，这个AST也不会太复杂，毕竟where后面的情况比起编译原理里的程序语言来说情况还是要少得多的。以上述的sql为例，这里解析出来的Where结构是这样的：[code]\u0026amp;sqlparser.Where{\n    Type:\u0026quot;where\u0026quot;,\n    Expr:(*sqlparser.ComparisonExpr)(0xc420016a50)\n}[/code]\n\n只有一个节点，一个ComparisonExpr表达式，这个ComparisonExpr，中文比较表达式，指代的就是我们sql里的`user_id = 1`。实际上我们可以认为这个\u0026quot;比较表达式\u0026quot;即是所有复杂AST的叶子节点。叶子结点在AST遍历的时候一般也就是递归的终点。因为这里的查询比较简单，整棵AST只有一个节点，即根节点和叶子节点都是这个ComparisonExpr。\n\n再来一个复杂点的例子。[code]select * from users where user_id = 1 and product_id =2\n\n=\u0026gt;\n\n\u0026amp;sqlparser.Where{\n    Type:\u0026quot;where\u0026quot;,\n    Expr:(*sqlparser.AndExpr)(0xc42000b020)\n}\n\nAndExpr有Left和Right两个成员，分别是：\n\nLeft:\n\u0026amp;sqlparser.ComparisonExpr{\n    Operator:\u0026quot;=\u0026quot;,\n    Left:(*sqlparser.ColName)(0xc4200709c0),\n    Right:sqlparser.NumVal{0x31}\n}\n\nRight:\n\u0026amp;sqlparser.ComparisonExpr{\n    Operator:\u0026quot;=\u0026quot;,\n    Left:(*sqlparser.ColName)(0xc420070a50),\n    Right:sqlparser.NumVal{0x32}\n}[/code]\n\n稍微有一些二叉树的样子了吧。把这棵简单的树画出来：\n\n\n[attach]349[/attach]\n\n\n回到文章开头的那个复杂的例子：[code]a and (b and (c or d) and e)\n\n=\u0026gt;\n\nselect * from user_history where user_id = 1 and (product_id = 2 and (star_num = 4 or star_num = 5) and banned = 1)\n[/code]\n\n看着真够麻烦的，我们把这棵树画出来：\n\n\n[attach]350[/attach]\n\n\n这样看着就直观多了。我们有了AST的结构，那要怎么对应到es的查询DSL呢？少安毋躁。\n\n我们知道es的bool query是可以进行嵌套的，所以实际上我们可以同样可以构造出树形结构的bool query。这里把bool嵌套must和bool嵌套should简化一下，写成boolmust和boolshould：\n\n例如a and (b and c)[code]query {\n    boolmust {\n        a,\n        boolmust {\n            b,\n            c\n        }\n    }\n}[/code]\n\n我们把query内部的第一个boolmust当作根节点，内部嵌套的a和另一个boolmust当作它的两个子节点，然后b和c又是这个boolmust的子节点。可以看出来，实际上这棵树和AST的节点可以一一对应。\n\n再回到文章开头的例子，a and (b and (c or d) and e)：[code]query {\n    boolmust {\n        a,\n        boolmust {\n            b,\n            boolshould {\n                c,\n                d\n            },\n            e\n        }\n    }\n}[/code]\n和前文中ast来做个简单的结构对比~\n\n\n[attach]351[/attach]\n\n\n\n和前文中sql的where解析后的AST树也是完全匹配的。思路来了，只要对sql解析生成的AST进行递归，即可得到这棵树。当然了，这里还可以进行一些优化，如果子节点的类型和父\n节点的类型一致，例如都是and表达式或者都是or表达式，我们可以在生成dsl的时候将其作为并列的节点进行合并，这里不再赘述。\n\n\n在递归中有这么几种情况：[code]AndExpr =\u0026gt; bool must [{left}, {right}]\nOrExpr =\u0026gt; bool should [{left}, {right}]\nComparisonExpr =\u0026gt; 一般是叶子节点\nParenBoolExpr =\u0026gt; 指代括号表达式，其实内部是上述三种节点的某一种，所以直接取出内部节点按上述方法来处理[/code]\n\n这样问题就变成了如何处理AST的叶子节点。前面提到了叶子节点实际上就是Comparison Expression。只要简单进行一些对应即可，下面是我们的项目里的一些对应关系，仅供参考：\n\n\n[attach]352[/attach]\n最后再附上demo\n \nhttps://github.com/cch123/elasticsql","title":"Day4: 《将sql转换为es的DSL》","uid":"946","views":"12125","votes":"9"},"_type":"doc"}
{"_id":"118","_index":"forum-mysql","_score":1,"_source":{"addtime":"1481600986","category_id":"2","comments":"4","has_attach":"0","id":"118","message":"\n一.前言\n应medcl写es文章的时候，其实这段时间es研究的不多，感觉没什么新东西可写。\n考虑只有这次调优心得可与大家分享，文笔有限，见谅！\n二.背景\n先交代一下背景，调优的项目是某电商类搜索项目，流量来自于前端的app和h5。\n搜索主要是根据用户的地理位置和关键字等条件搜索附近的商家和商品。\n商品数据大概在5000w左右，商品更新很频繁，更新量大概是每天2000w条左右，（因商家经常会促销、或者调上下架状态、改价格等）查询也相当频繁。\n集群有2个集群，一个主一个备，用于有问题的时候随时切换。主集群有8个节点，配置是32核，\n32g内存的docker的机器。给es jvm分配20g内存，jdk 版本是1.7，gc 是使用parnew/cms gc。\n这个项目我是后期加入的，来的时候项目已上线。由于参与进来的时候es跑的也还是比较稳定，所以也一直\n没调过es的参数。程序，参数基本上也就保持上线的时候那个样子。\nes上线的时候是用的1.5版本，后期没升过级。\n三.问题\n项目大概跑了一年多，时间来到大概16年的9月份。搜索请求响应时间开始出现几秒才完成的情况，\n我就被拉过来调优了。通过我们自己内部的调用方法监控，tp99和avg这些值还好，维持在200ms以下。max 最大有5,6s的情况，而且次数有点多。\n这里没怎么折腾，很快定位就是es gc导致的。翻了一下es gc日志，就是cms remark这个阶段时间特别长，\n而且 这个阶段是stop the world的。\n四.解决\n为什么remark阶段这么长时间？ 直接上结论，就是一次cms 周期内，并发标记后到remark这个期间jvm 堆内存对象\n变化很大。说白了对应我们的场景就是一大波 es bulk操作。对应Bigdesk观察，几秒的卡顿基本都出现在一大波 es bulk操作之后。\n这里解释一下，引用网上文章的说法：\nremark如果耗时较长，通常原因是在cms gc已经结束了concurrent-mark步骤后，旧生代的引用关系仍然发生了很多的变化，旧生代的引用关系发生变化的原因主要是：\n* 在这个间隔时间段内，新生代晋升到旧生代的对象比较多；\n* 在这个间隔时间段内，新生代没怎么发生ygc，但创建出来的对象又比较多，这种通常就只能是新生代比较大的原因；\n原文地址：\nhttp://hellojava.info/?tag=cms-gc-remark\n\n调整一：\n加cms gc 的 线程\n直接从根源入手，你remark 慢，我就让你跑快点。\n因为我们是32 核的cpu ，cpu 利用率用bigdesk观察还是很低的，5%左右。这么低，那就加点线程呗。\n-XX:ParallelGCThreads= N\n-XX:ParallelCMSThreads= M\n调整这2个参数都可以，它们的关系：ParallelCMSThreads = (ParallelGCThreads + 3)/4)\n调整后情况缓解了一些，remark还是有3,4秒的情况。\n调整二：\n关于这点是我们自己的问题。一次bulk 操作就写1条数据。\n是的，你没有看错，我们这边的工程师就是这么干的。\n一年以前提过这里最好是能合并写，但现在还是这个样子。\n这里有一些业务上的原因，合并写会导致一些字段值不准确。\n合并写暂时没办法，只能调整es 了。(这里说明一下，其实合并写应该是本次优化比较有效果的办法，可惜这招不让我用。)\n通过bigdesk观察，bulk线程池有reject的情况。\n但就增加bulk线程池的消费线程，加快数据的消费速度，减少对象驻留在jvm 的时间。\n调整后情况没有明显的好转，\n但肯定有用，能优化一点是一点嘛。\n\n调整三：\n再次从gc入手， -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark\n这个是网上找的办法：\n为了减少第二次暂停的时间，开启并行remark: -XX:+CMSParallelRemarkEnabled。 如果remark还是过长的话，可以开启-XX:+CMSScavengeBeforeRemark选项，强制 remark之前开始一次minor gc，减少remark的暂停时间，但是在remark之后也将立即开始又一次minor gc。调整后情况也没有特别的好转。\n以上都是从减小单次cms gc的开销的方向去解决问题，然后我就换了个方向，降低cms gc发生的次数，让它少发生或者不发生。\n调整四:\n这里调整了一共5个参数，\nXmn10g ==\u0026gt; 8g\nCMSInitiatingOccupancyFraction=70 ==\u0026gt;80\n\nindex.cache.filter.max_size 2g==\u0026gt;1g\nindex.cache.filter.expire 2m==\u0026gt;40s\nindex.refresh_interval 20s==\u0026gt;30s\n\n前2个参数没什么好说的，提高cms gc 被触发的条件，降低cms gc 触发几率。\n后3个参数是本文的重点，这里大概讲下es 对于filter cache的管理。\n这部分是通过阅读源码分析出来的，涉及代码还挺多，有点复杂，还有很大一部分还是lucene的代码。\n这里就不贴大段代码了。\nes 对于 filter cache管理是内部维护了一个map的结构（实际是利用com.google.common.cache实现的），关键是这个map 的key 是个它自己定义的类\n叫 FilterCacheKey，它override了equals方法\npublic FilterCacheKey(Object readerKey, Object filterKey) {\n    this.readerKey = readerKey;\n    this.filterKey = filterKey;\n}\n...\n@Override\npublic boolean equals(Object o) {\n    if (this == o) return true;\n//            if (o == null || getClass() != o.getClass()) return false;\n    FilterCacheKey that = (FilterCacheKey) o;\n    return (readerKey().equals(that.readerKey()) \u0026amp;\u0026amp; filterKey.equals(that.filterKey));\n}\n从这里可以看出，filter cache 能否被再次利用到就跟readerKey和filterKey 有关。\nfilterkey如果你build 查询语句的时候什么都没设置的话，就是filter对象本身。\n举个例子，TermFilter，如果term一样，那前后2次查询filterKey是一致的。\n关键是这个readerKey是否一致呢？这个readerKey其实就是lucene 的 indexReader，如果前后2次查询有数据更新并且\nindex.refresh_interval 这个参数设置的比较小，es 会去刷新indexReader，那么很有可能readerKey不一致。\n对应我们的场景，数据更新频繁，而且index.refresh_interval 比较小，那么缓存利用率就不太高。\n后一次查询的filter cache 会重新put 到上面提到的map里，然后这个index.cache.filter.max_size 2g \n就迅速占满（我们程序代码里很多地方使用到了filter），配多大都有可能占满。那这个filter cache什么时候被移除呢,index.cache.filter.expire 2m管移除这个事，当然应该还有size满了移除的策略。\n这就造成了缓存没什么用，还占这么大地方，还占那么久。\n然后这个filter cache就很可能跑到 old gen去了。\n那么就让它占少点，不干活就快点走：\nindex.cache.filter.max_size 2g==\u0026gt;1g\nindex.cache.filter.expire 2m==\u0026gt;40s\nindex.refresh_interval 20s==\u0026gt;30s\n这些调整完毕，重启es ，通过bigdesk ,gc a线图好看多了，cms gc 基本没了，monitor gc 也顺畅多了。\n五.总结和备注\n总结：\n1.优化这个事，我认为是业务上的优化要比技术上优化有效的多\n2.日志和监控是你最好的朋友，仔细的看，你总会看出什么\n3.es 缓存要利用好，还是需要好好去设计，回头考虑单独写一篇。\n备注：\n因为这次优化后，我就离开了原来的公司，没有了原来的环境。所以本文\n部分参数和数字可能不准确，我仅凭记忆完成。\n ","title":"Day6：《记一次es性能调优》","uid":"2091","views":"6068","votes":"11"},"_type":"doc"}
{"_id":"131","_index":"forum-mysql","_score":1,"_source":{"addtime":"1486099612","category_id":"5","comments":"1","has_attach":"1","id":"131","message":"本周三，Elastic 发布了 ElasticStack 的全新版本5.2.0，包含了很多激动人心的特性，让我们 一起来看看吧，\n（Elastic Stack 包括 Elasticsearch、Logstash、Kibana、Beats）：\n [b]Elasticsearch 5.2.0 主要亮点:[/b]\n[list=1]\n[*]新增数字和日期范围字段类型，非常方便对范围类型进行交并集的查询，比如你的数据是日历类型的数据，每天都有一些会议信息，会议的开始和结束时间都不同，你想看本周那天有空，可以使用 range fields 很方便的进行查询。[url=https://www.elastic.co/blog/numeric-and-date-ranges-in-elasticsearch-just-another-brick-in-the-wall]了解更多[/url][/*]\n[*]新增分片分配解释 API，会告知分片失败的具体原因，如分片损坏、磁盘写满还是配置错误，进行快速运维，以前只能根据经验到处寻找可能是什么问题，费事费力，[url=https://www.elastic.co/blog/red-elasticsearch-cluster-panic-no-longer]了解更多[/url]。[/*]\n[*]对 Keyword 类型标准化，在5.0将 string 类型拆成了 text 和 keyword两种类型，text 支持分词，keyword 则不分词默认支持 doc values，不过有时候你还需要对 keyword 类型进行一些标准化处理，如都转成小写，现在可以使用 normalizers 参数来指定标准化的 filter。[/*]\n[*]Terms 聚合的分区，terms 聚合默认返回10个 term，以前如果你需要返回全部的 term 列表是不可能的任务（基于内存压力），现在你可以通过将请求分区，以多次请求的方式来取回这些数据，[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-aggregations-bucket-terms-aggregation.html#_filtering_values_with_partitions]了解更多[/url]。[/*]\n[*]字段折叠，在搜索时可以按某个字段的值进行折叠，在每个折叠的值内进行排序选取 topN，[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.x/search-request-collapse.html]了解更多[/url]。[/*]\n[/list]\n \n相关链接：\n[url=https://www.elastic.co/downloads/elasticsearch]Download Elasticsearch 5.2.0[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.2/release-notes-5.2.0.html]Elasticsearch 5.2.0 release notes[/url]\n[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.2/breaking-changes-5.2.html]Elasticsearch 5.2.0 breaking changes[/url]\n[url=https://www.elastic.co/guide/en/x-pack/current/xpack-release-notes.html#xpack-5.2.0]X-Pack 5.2.0 release notes[/url]\n \n[b]Logstash 5.2.0 主要亮点：[/b]\n[list=1]\n[*]新的监控 UI，现在 X-Pack 也能监控 logstash 了，[url=https://www.elastic.co/products/x-pack/monitoring]X-Pack 基础免费版[/url]就包括，如下图：\n[attach]408[/attach]\n[attach]409[/attach][/*]\n[*]更多的监控 API，新增3个类型的统计信息：cgroup、持久化队列和 output新增持续时间字段。[/*]\n[*]离线插件管理，在很多没有公网的部署环境，都需要离线安装，以前的离线安装不够完善，尽管大部分插件没问题，但是还是存在个别插件的依赖链下载不完整的问题，为了解决这个问题，我们基本上重新设计了整个工作流程使用了新的方式来打包插件和他所有的依赖，[url=https://www.elastic.co/guide/en/logstash/current/offline-plugins.html#_building_the_offline_package]了解更多[/url]。[/*]\n[/list]\n \n相关连接：\n[url=https://www.elastic.co/downloads/logstash]Download Logstash 5.2.0[/url]\n[url=https://www.elastic.co/guide/en/logstash/5.2/logstash-5-2-0.html]Logstash 5.2.0 release notes[/url]\n \n[b]Kibana 5.2.0 主要亮点：[/b]\n[list=1]\n[*]支持 Elasticsearch Tribe 节点，在“admin”集群的基础上，引入了新的“data”集群，“data”集群可以理解成 Kibana 后面的数据来源，可以是 tribe 节点，而“admin”集群是存放 kibana 可视化信息“。kibana”索引的地方，默认 data 和 admin 集群都是在同一个集群，且不能是 tribe 节点，目前还有一些细节正在处理，如 console 还不能很好的工作。[/*]\n[*]增加新的可视化类型：热点图（heatmap），可以很方便的按区间和按时间来显示数据的范围分布，如下图：\n[attach]405[/attach][/*]\n[*]开始进行国际化的支持，感谢 IBM 团队的努力，目前已经提供了基础的框架支持，虽然是万里长征的第一大步，但也是非常激动人心的。[/*]\n[*]地图服务的改进，Elastic 自己的 Tile 地图服务已经上线几个月了，我们现在能提供10个级别的缩放了，X-Pack 基础用户可以达到12个级别的缩放，并且我们正在尝试18个级别的缩放，并且从5.2开始，我们能让这些级别动态调整，不用发布新的 Kibana。[/*]\n[*]监控容器中的 Elasticsearch，现在我们可以监控容器里面的 Elasticsearch 实例的运行情况了，CPU 利用率、GC、堆栈使用情况等，如下图：\n[attach]406[/attach][/*]\n[/list]\n \n相关连接：\n[url=https://www.elastic.co/downloads/kibana]Download Kibana 5.2.0[/url]\n[url=https://www.elastic.co/guide/en/kibana/5.2/release-notes-5.2.0.html]Kibana 5.2.0 release notes[/url]\n \n[b]Beats 5.2.0 主要亮点：[/b]\n[list=1]\n[*]新增 Beat：Heartbeat，一个新的正式的官方beat 成员，用于可用性监控，和所有的 beat 一样，轻量级，Heartbeat 可以用于很多场景，比如安全，你不希望暴露某个端口时，使用 Heartbeat，当你发现该端口对外开启了，就可以触发通知，或者服务/网站可用性检测，服务down 了可以及时感知，目前支持：ICMP、TCP 和 HTTP 类型的监控，目前 Heartbeat还处于 beat 阶段，暂不推荐用于生产环境。[/*]\n[*]Metricbeat 可跟踪网络连接，从5.2开始，Metricbeat 导出了 linux 系统的应用程序的网络连接信息，每个进程打开的 tcp 套接字，本地及远程的 ip 都包含在内，基于它，你可以进行如下的图分析：\n[attach]407[/attach][/*]\n[*]收集Prometheus导出的指标，从5.2开始，监控系统普罗米修斯的收集模块导出的数据可以提供给 Metricbeat 然后索引进 Elasticsearch。[/*]\n[/list]\n \n相关连接：\n[url=https://www.elastic.co/downloads/beats]Download Beats 5.2.0[/url]\n[url=https://www.elastic.co/guide/en/beats/libbeat/5.2/release-notes-5.2.0.html]Beats 5.2.0 release notes[/url]\n \nElastic Stack 下载链接：https://www.elastic.co/downloads\nBug 反馈：http://github.com/elastic\n\n以后有版本的更新消息都会在这里发布一份中文版，欢迎大家关注。","title":"Elastic Stack 5.2.0 发布","uid":"1","views":"4396","votes":"0"},"_type":"doc"}
{"_id":"150","_index":"forum-mysql","_score":1,"_source":{"addtime":"1492087437","category_id":"3","comments":"1","has_attach":"0","id":"150","message":"我们都知道如果文档中有表示时间的字段时可以用如下方法将字段转化为date(timestamp)格式导入[code]date {\n        match =\u0026gt; [ \u0026quot;submission_time\u0026quot;, \u0026quot;yyyyMMdd\u0026quot; ]\n    }[/code]但是如果一条记录中有多个字段需要使用date类型呢？有人遇到了 同样的问题[url=https://discuss.elastic.co/t/how-to-parse-multiple-date-fields/1208]How to parse multiple date fields?[/url]其实[b]多次使用date{}语法[/b]就行了，例如：[code]date {\n        match =\u0026gt; [ \u0026quot;submission_time\u0026quot;, \u0026quot;UNIX_MS\u0026quot; ]\n        target =\u0026gt; \u0026quot;@timestamp\u0026quot;\n        }\ndate {\n        match =\u0026gt; [ \u0026quot;submission_time\u0026quot;, \u0026quot;UNIX_MS\u0026quot; ]\n        target =\u0026gt; \u0026quot;submission_time\u0026quot;\n        }\ndate {\n        match =\u0026gt; [ \u0026quot;start_time\u0026quot;, \u0026quot;UNIX_MS\u0026quot; ]\n        target =\u0026gt; \u0026quot;start_time\u0026quot;\n        }\ndate {\n        match =\u0026gt; [ \u0026quot;end_time\u0026quot;, \u0026quot;UNIX_MS\u0026quot; ]\n        target =\u0026gt; \u0026quot;end_time\u0026quot;\n        }[/code]查看[url=https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html#plugins-filters-date-target]官方文档[/url]后， 发现一直使用的date是省去了参数target的，而target默认值为@timestamp。","title":"logstash多时间（date）字段文档导入","uid":"2668","views":"2518","votes":"0"},"_type":"doc"}
{"_id":"159","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493946745","category_id":"5","comments":"3","has_attach":"1","id":"159","message":"出大事了，Elastic Stack 今日发布 5.4 版本，X-Pack 新增机器学习模块！\r\n[url]https://www.elastic.co/cn/blog/introducing-machine-learning-for-the-elastic-stack[/url]\r\n 今天，我们非常荣幸地宣布，首次发布通过 X-Pack 提供的 Elastic Stack Machine Learning 功能。加入 Elastic 就像跳上了火箭船，但是经过 7 个月不可思议的工作，我们现已将 Prelert Machine Learning 技术完全集成到 Elastic Stack。这让我们很激动，而且我们非常迫切地想要收到用户的反馈。\r\n\r\n温馨提示：请注意，不要太过激动，这项功能在 5.4.0 版本中尚标记为 beta。\r\n\r\n[b]Machine Learning[/b]\r\n\r\n我们的目标是通过一系列工具为用户赋能，让他们可以从自己的 Elasticsearch 数据中获取价值和洞察。与此同时，我们将 Machine Learning 视为 Elasticsearch 搜索和分析能力的自然延伸。举例来说，Elasticsearch 能够让您在大量数据中，实时地搜索用户“steve”的交易，或者利用聚合和可视化，展示一段时间以来的十大畅销产品或交易趋势。而现在有了 Machine Learning 功能，您就可以更加深入地探究数据，例如 “有没有哪项服务的行为发生了变化？” 或者 “主机上是否运行有异常进程？” 那么要想回答这些问题，就必须要利用 Machine Learning 技术，通过数据自动构建主机或服务的行为模式。\r\n\r\n不过， Machine Learning 目前是软件行业最被夸大其词的术语之一，因为从本质上来讲，它就是用来实现数据驱动型预测、决策和建模的一系列广泛的算法和方法。因此，我们有必要隔绝干扰信息，具体说说我们所做的工作。\r\n\r\n[b]时间序列异常检测[/b]\r\n\r\n目前，X-Pack Machine Learning 功能的着眼点是，利用无监督式机器学习，提供 “时间序列异常检测” 功能。\r\n\r\n随着时间的推移，我们计划增加更多 Machine Learning 功能，但是我们目前只专注于为用户存储的时间序列数据（例如日志文件、应用程序和性能指标、网络流量或 Elasticsearch 中的财务/交易数据）提供附加值。\r\n\r\n示例 1 - 自动提醒关键绩效指标值的异常变化\r\n\r\n要说这项技术最直观的用例，那就是可以识别指标值或事件速率偏离正常行为的情况。例如，服务响应时间有没有显著增加？网站访客预期数量与同一时段正常情况相比，是否存在明显差异？传统情况下，人们会利用规则、阈值或简单的统计方法来进行此类分析。但遗憾的是，这些简单的方法鲜少能够高效地处理实际数据，原因在于此类方法往往是基于无效的统计假设（例如：高斯分布），因此不支持趋势分析（长期性或周期性趋势），或者在信号发生变化时缺乏稳定性。\r\n\r\n所以说， Machine Learning 功能的首个切入点是单一指标作业，您可以借此了解该产品如何学习正常模式，如何识别单变量时间序列数据中存在的异常。如果您发现的异常是有意义的，您就可以连续地实时运行这项分析，并在发生异常时发出警报。\r\n\r\n尽管这看上去像是一个比较简单的用例，但是产品后台包含大量复杂的无监督式机器学习算法和统计模型，因此我们对于任意信号具有鲁棒性，并且能够准确反映。\r\n\r\n此外，为了让该功能可以在 Elasticsearch 集群中像原生程序一样运行，我们对功能实现进行了优化，因此几秒钟即可分析数以百万计的事件。\r\n\r\n[attach]562[/attach]\r\n\r\n\r\n示例 2 - 自动追踪数以千计的指标\r\n\r\nMachine Learning 产品可以扩展到数十万指标和日志文件，那么下一步就是要同时分析多个指标。这些指标可能是来自同一个主机的多个相关指标，可能是来自同一个数据库或应用程序的性能指标，也可能是来自多个主机的多个日志文件。在这种情况下，我们可以直接单独分析，再将结果聚合到同一个窗口，展示整体的系统异常情况。\r\n\r\n例如，假设我要处理来自一大组应用程序服务的响应时间，我可以直接分析各个服务一段时间以来的响应时间，分别确认各个行为异常的服务，同时展示整体的系统异常情况：\r\n\r\n[attach]563[/attach]\r\n\r\n示例 3 - 高级作业\r\n\r\n最后，我们的产品还有大量更高级的用途。比方说，如果您想找出与整体相比行为异常的用户、异常的 DNS 流量，或者伦敦街头的拥堵路段，这时您就可以利用高级作业，灵活地分析 Elasticsearch 中存储的任何时间序列数据。\r\n\r\n[b]Elastic Stack 整合[/b]\r\n\r\nMachine Learning 是 X-Pack 中的一项功能。这就意味着，安装 X-Pack 之后，就可以使用 Machine Learning 功能实时分析 Elasticsearch 中的时间序列数据。 Machine Learning 作业与索引和分片基本类似，能够跨 Elasticsearch 集群自动分布和管理。这还意味着 Machine Learning 作业对节点故障有很好的适应性。从性能角度看，紧密集成意味着数据永远不需要离开集群，而且我们可以利用 Elasticsearch 聚合极大地提高某些作业类型的性能。而紧密集成带来的另外一个好处就是，您可以直接从 Kibana 创建异常检测作业并查看结果。\r\n\r\n由于这种方法对数据进行原位分析，数据从不离开集群，因此与将 Elasticsearch 数据集成到外部数据科学工具相比，这种方法能够带来显著的性能和运维优势。随着我们在这个领域开发出越来越多的技术，这种架构的优势将会更加显著。\r\n\r\n\r\n[attach]561[/attach]\r\n\r\n\r\n[b]立即试用并反馈[/b]\r\n\r\n这些 Machine Learning 功能是 X-Pack 5.4 中的 beta 功能，现已可用。我们急切地想要听听您的使用体会，所以请下载 5.4 版本，安装 X-Pack，然后直接联系我们，或者通过我们的讨论论坛联系我们。\r\n下载地址：[url]https://www.elastic.co/cn/downloads[/url]\r\n ","title":" Elasticsearch 5.4 发布，新增机器学习功能","uid":"1","views":"4263","votes":"1"},"_type":"doc"}
{"_id":"161","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494051530","category_id":"2","comments":"0","has_attach":"0","id":"161","message":"https://vastxiao.github.io/zabbixMonitorES/","title":"用zabbix监控es","uid":"739","views":"3011","votes":"0"},"_type":"doc"}
{"_id":"162","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494060613","category_id":"2","comments":"1","has_attach":"0","id":"162","message":"ES5.2.2真的 支持geo排序+聚合\n具体查询条件，这里不写了；\n查询结果如下：\n\n{ \u0026quot;took\u0026quot;: 90, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 5, \u0026quot;successful\u0026quot;: 5, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: 10, \u0026quot;max_score\u0026quot;: null, \u0026quot;hits\u0026quot;: [ { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1-1000000\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 1, \u0026quot;comName\u0026quot;: \u0026quot;佛山消防支队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000000\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂0\u0026quot;, \u0026quot;equipValue\u0026quot;: 73, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.027237, \u0026quot;lon\u0026quot;: 113.123618 }, \u0026quot;phone\u0026quot;: \u0026quot;15986190299\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;李成龙\u0026quot; }, \u0026quot;sort\u0026quot;: [ 3740.583503580435 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1-1000003\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 1, \u0026quot;comName\u0026quot;: \u0026quot;佛山消防支队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000003\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂3\u0026quot;, \u0026quot;equipValue\u0026quot;: 47, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.027237, \u0026quot;lon\u0026quot;: 113.123618 }, \u0026quot;phone\u0026quot;: \u0026quot;15986190299\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;李成龙\u0026quot; }, \u0026quot;sort\u0026quot;: [ 3740.583503580435 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1-1000001\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 1, \u0026quot;comName\u0026quot;: \u0026quot;佛山消防支队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000001\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂1\u0026quot;, \u0026quot;equipValue\u0026quot;: 12, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.027237, \u0026quot;lon\u0026quot;: 113.123618 }, \u0026quot;phone\u0026quot;: \u0026quot;15986190299\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;李成龙\u0026quot; }, \u0026quot;sort\u0026quot;: [ 3740.583503580435 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1-1000004\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 1, \u0026quot;comName\u0026quot;: \u0026quot;佛山消防支队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000004\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂4\u0026quot;, \u0026quot;equipValue\u0026quot;: 2, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.027237, \u0026quot;lon\u0026quot;: 113.123618 }, \u0026quot;phone\u0026quot;: \u0026quot;15986190299\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;李成龙\u0026quot; }, \u0026quot;sort\u0026quot;: [ 3740.583503580435 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1-1000002\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 1, \u0026quot;comName\u0026quot;: \u0026quot;佛山消防支队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000002\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂2\u0026quot;, \u0026quot;equipValue\u0026quot;: 57, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.027237, \u0026quot;lon\u0026quot;: 113.123618 }, \u0026quot;phone\u0026quot;: \u0026quot;15986190299\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;李成龙\u0026quot; }, \u0026quot;sort\u0026quot;: [ 3740.583503580435 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;2-1000018\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 2, \u0026quot;comName\u0026quot;: \u0026quot;禅城大队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000018\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂8\u0026quot;, \u0026quot;equipValue\u0026quot;: 61, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.057237, \u0026quot;lon\u0026quot;: 113.103618 }, \u0026quot;phone\u0026quot;: \u0026quot;13925403119\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;郭武斌\u0026quot; }, \u0026quot;sort\u0026quot;: [ 7648.2045946025555 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;2-1000014\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 2, \u0026quot;comName\u0026quot;: \u0026quot;禅城大队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000014\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂4\u0026quot;, \u0026quot;equipValue\u0026quot;: 81, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.057237, \u0026quot;lon\u0026quot;: 113.103618 }, \u0026quot;phone\u0026quot;: \u0026quot;13925403119\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;郭武斌\u0026quot; }, \u0026quot;sort\u0026quot;: [ 7648.2045946025555 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;2-1000016\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 2, \u0026quot;comName\u0026quot;: \u0026quot;禅城大队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000016\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂6\u0026quot;, \u0026quot;equipValue\u0026quot;: 81, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.057237, \u0026quot;lon\u0026quot;: 113.103618 }, \u0026quot;phone\u0026quot;: \u0026quot;13925403119\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;郭武斌\u0026quot; }, \u0026quot;sort\u0026quot;: [ 7648.2045946025555 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;2-1000015\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 2, \u0026quot;comName\u0026quot;: \u0026quot;禅城大队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000015\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂5\u0026quot;, \u0026quot;equipValue\u0026quot;: 87, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.057237, \u0026quot;lon\u0026quot;: 113.103618 }, \u0026quot;phone\u0026quot;: \u0026quot;13925403119\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;郭武斌\u0026quot; }, \u0026quot;sort\u0026quot;: [ 7648.2045946025555 ] }, { \u0026quot;_index\u0026quot;: \u0026quot;testindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;testdoc07\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;2-1000017\u0026quot;, \u0026quot;_score\u0026quot;: null, \u0026quot;_source\u0026quot;: { \u0026quot;comId\u0026quot;: 2, \u0026quot;comName\u0026quot;: \u0026quot;禅城大队\u0026quot;, \u0026quot;elemetType\u0026quot;: 2, \u0026quot;equipCode\u0026quot;: \u0026quot;1000017\u0026quot;, \u0026quot;equipName\u0026quot;: \u0026quot;灭火剂7\u0026quot;, \u0026quot;equipValue\u0026quot;: 90, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 23.057237, \u0026quot;lon\u0026quot;: 113.103618 }, \u0026quot;phone\u0026quot;: \u0026quot;13925403119\u0026quot;, \u0026quot;userName\u0026quot;: \u0026quot;郭武斌\u0026quot; }, \u0026quot;sort\u0026quot;: [ 7648.2045946025555 ] } ] }, \u0026quot;aggregations\u0026quot;: { \u0026quot;aggEquip\u0026quot;: { \u0026quot;doc_count_error_upper_bound\u0026quot;: 0, \u0026quot;sum_other_doc_count\u0026quot;: 0, \u0026quot;buckets\u0026quot;: [ { \u0026quot;key\u0026quot;: \u0026quot;1000000\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 73 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000001\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 12 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000002\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 57 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000003\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 47 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000004\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 2 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000014\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 81 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000015\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 87 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000016\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 81 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000017\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 90 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000018\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 61 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000210\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 70 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000211\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 55 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000027\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 19 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000028\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 25 } }, { \u0026quot;key\u0026quot;: \u0026quot;1000029\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 3 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000311\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 97 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000312\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 79 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000313\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 95 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000314\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 6 } }, { \u0026quot;key\u0026quot;: \u0026quot;10000315\u0026quot;, \u0026quot;doc_count\u0026quot;: 1, \u0026quot;sumEquipValue\u0026quot;: { \u0026quot;value\u0026quot;: 8 } } ] } } }\n ","title":"ES5.2.2支持geo排序+聚合","uid":"2580","views":"1968","votes":"0"},"_type":"doc"}
{"_id":"163","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494211645","category_id":"16","comments":"2","has_attach":"1","id":"163","message":"[b]主办[/b]：Elastic 中文社区\n\n[attach]572[/attach]\n\n[b]协办[/b]：众安保险\n\n[attach]571[/attach]\n\n[b]时间[/b]：2017-05-14 13:30PM-18:00PM\n[b]地点[/b]：上海市虹口区四川北路859号中信广场42楼\n \nPPT 下载：[url]https://pan.baidu.com/s/1eS157I6#list/path=%2F%E7%BA%BF%E4%B8%8B%E6%B4%BB%E5%8A%A8%2F%E4%B8%8A%E6%B5%B7%2F2017-5-14\u0026amp;parentPath=%2F[/url]\n \n[b]分享主题：[/b]\n\n\n[attach]566[/attach]\n\n个人介绍：杨智健, 众安保险搜索组负责人。\n主题：[b]es在众安保险的实践[/b]\n内容介绍： es在众安保险业务线和日志类的实践，和相关平台化建设。\n录像：[url]https://v.qq.com/x/page/x0509wkr513.html[/url] \n \n\n[attach]565[/attach]\n\n个人介绍：Medcl, Elastic工程师与布道师，2015年加入Elastic公司, Elastic中文社区的发起人。\n主题：ElasticStack 5.x 最新进展\n内容介绍：ElasticStack 5.x 新增了很多新的激动人心的特性，本次分享将为大家一一解读。\n录像：https://v.qq.com/x/page/m0509dt9f80.html\n\n\n\n[attach]567[/attach]\n\n个人介绍：魏彬, rockybean，穿衣助手技术负责人，Elastic Stack 粉丝。\n主题：[b]用 Elastic Stack 来诊断下你的redis slowlog[/b]\n内容介绍：\n1. Elastic Stack 之 ElasticSearch Beats Kibana 简介\n2. redis 和 slowlog 简介\n3. 实现原理介绍\n4. Kibana图形化结果展示介绍\n5. 代码解析\n6. 开源过程中的几点心得分享\n录像：[url]https://v.qq.com/x/page/m0509j6kyzj.html[/url] \n\n\n[attach]568[/attach]\n\n个人介绍: 柯诗豪，携程旅行网高级软件工程师。\n主题：[b]基于Docker的ES PaaS云平台[/b]\n内容介绍：伴随着公司越来越多的团队开始使用ES，部署和管理ES集群成本增加。所以建立了基于Docker通过Mesos提供的资源管理机制的ES PaaS平台，用户可以在平台上快捷的创建、配置和管理ES集群。\n录像：[url]https://v.qq.com/x/page/n0509pzjgxq.html[/url] \n \n\n[attach]569[/attach]\n\n个人介绍: 彭科，13年从武汉理工毕业 ，16年进入斗鱼大数据基础架构组，主要负责日志监控平台和一些大数据技术的预研。目前已经从斗鱼离职，接下来会去一家云计算创业公司，从事大数据产品研发和AI方向研究。\n主题：[b]基于Elastic Stack+Kafka的日志监控平台架构演进[/b]\n内容介绍：基于在斗鱼的工作经验，基于Elastic Stack和kafka做TB级日志监控平台搭建，架构演讲，踩过哪些坑，如何调优，与大数据组件技术对比，如何结合使用，如何监控基础组件与业务，分享一些自己的心得。\n录像：[url]https://v.qq.com/x/page/m05099qj8f9.html[/url]","title":"[线下活动] 2017-05-14 Elastic Meetup 上海日程","uid":"1","views":"3159","votes":"4"},"_type":"doc"}
{"_id":"170","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494495592","category_id":"16","comments":"0","has_attach":"0","id":"170","message":"[b]活动时间[/b]\n2017年5月13日14：00-17：00\n\n[b]活动场地[/b]\n杭州市拱墅区丰潭路430号丰元国际大厦A座B1楼硬趣空间（城西银泰对面）\n \n[b]报名链接[/b]\n[b][url]http://t.cn/RX8xsh6[/url] [/b]\n \n[b]活动流程[/b]\n13:30-14:00 签 到\n\n14:00-14:10 开 场\n\n14:10-15:00 无 相 蘑菇街稳定性 \u0026amp; 性能工作负责人  《蘑菇街稳定性实践》\n\n15:00-15:50 民 达 美丽联合集团图像算法技术专家 《电商中的图像算法与应用》\n\n15:50-16:00 茶 歇\n\n16:00-16:50 吴 邪 美丽联合集团无线应用团队工程师 《无线端面向数据设计实践与可视化编程语言Dson》\n\n16:50-17:30 自由交流\n \n[b]讲师介绍[/b]\n无相 蘑菇街稳定性\u0026amp;性能工作负责人\n2014年底加入蘑菇街，一直参与稳定性工具和平台的开发与建设，包括全链路监控和压测系统的设计和开发。\n《蘑菇街稳定性实践》\n本次分享主要介绍：蘑菇街大促保障流程，稳定性平台和工具支持：开关预案系统、限流降级系统、全链路监控系统、强弱依赖系统、全链路压测系统、单机压测系统、容量规划系统、业务全息监控系统、java性能在线分析系统等内容。\n \n民达 美丽联合集团图像算法技术专家\n2015年加入蘑菇街，现任美丽联合集团（美丽说X蘑菇街）图像算法技术专家，负责图像技术研发工作，带领算法团队与工程和业务团队合作，为集团提供图像技术支持。主要工作包括：图像搜索、图像识别、商品图像内容分析等；业务涉及电商导购、直播等场景。在加入蘑菇街之前，分别在NEC中国研究院、阿里巴巴集团，从事图像技术和机器学习的研究和应用。\n《电商中的图像算法与应用》\n本次分享主要介绍从电商业务中发现图像算法的价值和利用图像算法，提升电商业务中的用户体验。\n \n吴邪，美丽联合集团无线应用团队工程师\n2013年毕业于浙江大学，并加入淘宝从事服务端相关开发工作，后加入阿里云rds团队从事数据库云平台建设。2016年加入美丽联合集团，目前主要负责无线网关数据聚合层。对服务端高性能、高可用设计与编码比较感兴趣。\n《无线端面向数据设计实践与可视化编程语言Dson》\n本次分享主要介绍mwp-dsl、无线领域前后端开发现状、业界相关内容、mwp-dsl目标、dsl的挑战与核心设计（业务建模，性能与稳定性、安全、易用性）、数据可视化语言Dson、周边配套（开发、测试、管理、运维后台，相关运维体系）、适合的业务场景、后续工作等内容。\n \n往期讲稿/视频回顾\nhttps://opentalk.upyun.com","title":" [杭州活动][2017年5月13日] Open Talk 美联集团（蘑菇街）技术专场","uid":"2840","views":"1732","votes":"0"},"_type":"doc"}
{"_id":"169","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494399700","category_id":"13","comments":"21","has_attach":"1","id":"169","message":"oracle由于是商用软件，协议并不公开，而且相比mysql等开源数据库软件，协议复杂度加了不止一个量级。\r\n出于版权考虑，packetbeat并没有加入oracle协议的支持，只能自己动手。\r\n好在beats充分考虑了扩展性，把公共的基础工作抽象成框架，新协议的扩展只需要专注于协议的分析和解码。\r\ntns协议是oracle客户端和服务端通信协议，应用可以通过OCI、JDBC等接口去访问数据库。\r\ntns协议有多个版本，不同版本之间差异也比较大，11g是主流tns版本为314。\r\n目前完成308、310、313、314、315版本的解析\r\n \r\npacketbeat支持pcap、pf_ring等抓包方式，通过kafka+es+kibana展示，效果如图\r\n ","title":"packetbeat的oracle协议扩展","uid":"2157","views":"2819","votes":"2"},"_type":"doc"}
{"_id":"175","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495093473","category_id":"2","comments":"1","has_attach":"0","id":"175","message":"1.下面简述下如何根据explain解释TFIDF和BM25的评分计算\n2.首先是TFIDF\n使用ik_smart分词器，ES为2.3.3\n文档是：分词结果是\n\u0026quot;伟业我爱我家\u0026quot;     分词结果：【伟业，我，爱我，家】\n\u0026quot;我爱我家\u0026quot;     【我，爱我，家】\n这两个。\nmulti_match  匹配，query=我爱我家\n排名如下\n-----------------------------------------------------------\n\u0026quot;伟业我爱我家\u0026quot;    \u0026quot;_score\u0026quot;: 6.8563557,\n详细参数 \n\u0026quot;我\u0026quot;：tf=1,idf=6.7638364,fieldNorm=0.5，queryNorm=0.07292504,\n“爱我”： tf=1,idf=6.7638364,fieldNorm=0.5，queryNorm=0.07292504\n“家”： tf=1,idf=6.278329,fieldNorm=0.5，queryNorm=0.07292504\n----------------------------------------------------------\n\u0026quot;我爱我家\u0026quot;          \u0026quot;_score\u0026quot;: 6.7839246,\n\u0026quot;我\u0026quot;：tf=1,idf=6.9336233,fieldNorm=0.5，queryNorm=0.07370365,\n“爱我”： tf=1,idf=6.9336233,fieldNorm=0.5，queryNorm=0.07370365\n“家”： tf=1,idf=6.9336233,fieldNorm=0.5，queryNorm=0.07370365\n---------------------------------------------------------\n其中queryNorm是由每个term词项的idf综合计算而来，所以在每个文档中，他都是一样的。\n然后仔细比较得分，觉得每个得分都可以被推算出来\n但是排序结果不符合期望：\nqueryNorm 官方文档也说了基本没有什么用\ntf=1没什么可说\nidf有些问题，比如\u0026quot;爱我\u0026quot;在这两个文档中是不同的(这是因为这两个文档在不同的分片中引起的)\n[b][i]那这么说来，TFIDF的得分就仅仅受tf,idf，fieldNorm控制，\n而idf因为分片不均匀可能会出现一点差异，fieldNorm又犹由于精度让长度为3或者4 的文档值都为0.5\n。综上：tfidf在这种量不多(200万)的短文本检索下，效果很差。[/i][/b]\n这种情况下，我该怎么优化这个排序呢（让“我爱我家”，排在\u0026quot;伟业我爱我家\u0026quot;前面呢？）\n \n \n \n------------------BM25的详情稍后补上-------------------------\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ","title":"找寻TF_IDF和BM25的评分计算优化排序","uid":"2015","views":"2499","votes":"0"},"_type":"doc"}
{"_id":"176","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495165939","category_id":"12","comments":"0","has_attach":"0","id":"176","message":"Elastic search 服务供应商需要招聘培训师/项目经理\n\n薪酬： 月工资20k +\n工作地点：北京/上海/深圳                     愿意出差，因工作情况会全国飞\n\n任职要求：\n\n1、计算机相关专业，本科以上学历，具有3年以上搜索引擎及相关开发经验；\n\n2、较强的java编程基础，熟悉Git代码管理，有多分支并行开发经验；\n\n3、熟练使用开源搜索工具Logstash，ElasticSearch，熟悉其原理和源代码，能熟练的修改开源工具以适合业务场景的需求；\n\n4、熟悉Lucene以及Kibana，有实际的产品使用经历；\n\n5、具有良好的沟通能力和责任心。\n ","title":" 招聘 Elastic search 培训师/项目经理 20k +","uid":"2780","views":"2034","votes":"2"},"_type":"doc"}
{"_id":"180","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495863423","category_id":"12","comments":"0","has_attach":"0","id":"180","message":"职位描述：\n岗位描述：\n1、负责商城网站的设计、开发工作，制定和落实解决方案。\n2、 保证平台的稳定性，并不断提升平台性能，协助解决系统中的问题和技术难题。\n\n任职资格：\n1、对高并发、多线程、缓存等技术和业务场景有实际操作经验；\n2、JAVA基础扎实，对于中间件、SOA框架等原理有一定理解；\n3、熟悉Linux下的常用操作，熟悉MySQL、Redis、MongoDB、elasticsearch、等开源数据库；\n4、熟悉互联网产品架构，有大型分布式、高并发、高负载、高可用性系统设计开发经验者优先。\n5、强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长；\n\n在这里：\n有最前沿技术的最佳实践场景：golang，nginx+lua，java，redis，docker，hadoop，storm，机器学习、elasticsearch。\n有高并发，分布式，大数据挖掘的业务场景。\n我们将为你提供跟身边大牛接触学习的机会。\n我们将为你提供一个开放的技术环境，一个自由高效的团队，和一个改变现有技术的机会。\n分享、自由、协作是我们的处事法则。\n\n福利：\n弹性工作时间，巨大的发展空间。\n年假，双休，法定节假日。\n六险一金，补充商业保险，丰厚的餐补，全面保障。\n绝对竞争力的薪资及年终奖金，股票激励机制。\n伴随公司发展的升职机会，及每年两次的调薪机会。","title":"java招聘","uid":"2957","views":"2477","votes":"0"},"_type":"doc"}
{"_id":"178","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495600425","category_id":"2","comments":"10","has_attach":"0","id":"178","message":"[携程旅行网  吴晓刚]\n\n近期公司某个线上JAVA应用出现内存泄漏问题，整个排查过程颇费周折，前后耗费了近2周才定位到问题根源并予以修复。排查问题过程中在网上翻查了大量的资料，发现国内几乎没有文章能对同类问题做透彻的分析和找到问题真正根源的。即使国外的各类博客和文章，也少有正确的分析。因此感觉有必要对问题根源和相关案例做一个总结，希望能为国内开发者避免踩上同类陷阱提供一些帮助。\n\n开门见山，先列一下收集到的同类问题案例集：\n[list]\n[*][url=http://www.evanjones.ca/java-native-leak-bug.html]Debugging Java Native Memory Leaks[/url][/*]\n[*][url=https://www.elastic.co/blog/tracking-down-native-memory-leaks-in-elasticsearch]Tracking Down Native Memory Leaks in Elasticsearch[/url][/*]\n[*][url=https://issues.apache.org/jira/browse/LUCENE-7647]CompressingStoredFieldsFormat should reclaim memory more aggressively[/url][/*]\n[*][url=https://github.com/elastic/elasticsearch/pull/22711]Close InputStream when receiving cluster state in PublishClusterStateAction[/url][/*]\n[*][url=https://issues.apache.org/jira/browse/KAFKA-3933]Kafka OOM During Log Recovery Due to Leaked Native Memory[/url][/*]\n[/list]\n\n这些案例涉及到的不乏一些流行的开源软件如Lucene, Elasticsearch, Kafka，并且某些Bug版本在大量公司有线上部署。这些案例的问题根源都惊人的一致，即在JAVA里使用GZIP库进行数据流的压缩/解压之后，忘记调用流的close()方法，从而造成native memory的泄漏。\n\n关于这类问题的分析方法和工具，上面收集的案例集里有非常详尽的描述，这里就不再班门弄斧一一赘述了。只结合我们自己的案例，做一个比较简短的介绍和总结。\n\n我们公司这个案例的排查之所以花了近2个礼拜，其中一个重要原因是这个应用是通过Docker部署的。应用上线运行一段时间后，会被Docker的OOM killer给Kill掉，查看JVM监控数据却发现Heap使用得很少，甚至都没有old GC发生过，top里看这个JAVA进程的RSS内存占用远高于分配的Heap大小。很自然的，研发人员第一反应是底层系统的问题，注意力被转移到研究各种Docker内存相关的参数上。 而我知道ElasticCloud曾经也被某些版本的linux内核bug困扰，docker可能会误杀JVM (参见 [url=https://www.elastic.co/blog/memory-issues-well-remember]Memory Issues We'll Remember[/url])，bug的内核版本和docker版本和我们线上部署的又很接近，因此这个内核bug也被加入到了怀疑列表中。 事后证明这个方向是错误的，浪费了一些时间。\n\n在一段时间排查无果后，为了缩小排查范围，我们决定将这个应用部署到VM上做对比测试。结果内存泄漏问题依然存在，因而排除掉了Linux内核和docker本身的问题。\n\n同期也参考过一篇关于DirectByteByffer造成堆外内存泄漏问题的分析博客，[url=http://lovestblog.cn/blog/2015/05/12/direct-buffer/]JVM源码分析之堆外内存完全解读[/url] ，考虑到问题现象和我们类似，我们的应用也有用到netty，DBB泄漏也被列为怀疑对象。然而在JVM启动里参数里对MaxDirectMemorySize做了限制后，经过一段时间对外服务，JAVA进程的RSS仍然会远超过HEAP + MDM设置的大小。\n\n这期间我们也使用过[url=https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr007.html]NMT[/url] 工具分析HEAP内存占用情况，然而这个工具报告出来的内存远小于RSS，也就是说这多出来的内存并没有被JVM本身用到，泄漏的是native memory。 JAVA应用产生native memory泄漏通常是在使用某些native库时造成的，因此注意力转移到JNI。\n\n最终帮助我们找到正确方向的是开头列的 Debugging Java Native Memory Leaks 这篇由Twitter工程师写的博客。 博客里介绍了如何使用jemalloc来替换glibc的malloc，通过拦截和追踪JVM对native memory的分配申请，从而可以分析出HEAP以外的内存分配由哪些方法调用产生的。博客里提到产生泄漏的原因是忘记关闭GZIPOutputStream，巧合的是我们线上应用也使用了gzip压缩服务请求数据，于是查看了一下相关的代码，果然发现有忘记关闭的stream。 找到根源后，解决问题就简单了，一行代码修复。\n \n对于ElasticSearch用户，要注意的是某些版本存在这个泄漏问题，对于小内存机器上运行的ES服务可能会有较大的影响。 可是官方没有明确列出所有受影响的版本，只在博客里提到5.2.1修复了这些问题。 因此如果你有顾虑的话，可以用top命令看一下ES JAVA进程的RSS消耗，如果大大于分配的HEAP，有可能就是中招啦。 ","title":"GZIP造成JAVA Native Memory泄漏案例","uid":"81","views":"2577","votes":"6"},"_type":"doc"}
{"_id":"268","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505117236","category_id":"2","comments":"4","has_attach":"0","id":"268","message":"报错如下：\njava.lang.ClassNotFoundException: org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1\nat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\nat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\nat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\nat java.lang.Class.forName0(Native Method)\nat java.lang.Class.forName(Class.java:348)\nat org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:66)\nat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)\nat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)\nat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)\nat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)\nat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)\nat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)\nat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)\nat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)\nat java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)\nat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:71)\nat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:97)\nat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\nat org.apache.spark.scheduler.Task.run(Task.scala:90)\nat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:253)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\n\n 写了一个elasticspark demo  如下：\n```\npackage com.sydney.dream.elasticspark\n\nimport org.elasticsearch.spark._\nimport org.apache.spark.{SparkConf, SparkContext}\n\n/**\n  * 需要手动引入org.elasticsearch.spark._\n  * 这样使得所有的RDD 都拥有saveToEs 的方法\n  */\nobject ElasticSparkFirstDemo {\n    def main(args: Array[String]): Unit = {\n        val conf = new SparkConf()\n            .setAppName(\u0026quot;ElaticSparkFirsDemo\u0026quot;)\n            .set(\u0026quot;es.nodes\u0026quot;, \u0026quot;172.18.18.114\u0026quot;)\n            .set(\u0026quot;es.port\u0026quot;, \u0026quot;9200\u0026quot;)\n            .set(\u0026quot;es.index.auto.create\u0026quot;, \u0026quot;true\u0026quot;)\n        val sc = new SparkContext(conf)\n        val numbers = Map(\u0026quot;one\u0026quot; -\u0026gt; 1, \u0026quot;two\u0026quot; -\u0026gt; 2, \u0026quot;three\u0026quot; -\u0026gt; 3)\n        val airports = Map(\u0026quot;arrival\u0026quot; -\u0026gt; \u0026quot;Otopeni\u0026quot;, \u0026quot;SFO\u0026quot; -\u0026gt; \u0026quot;San Fran\u0026quot;)\n        sc.makeRDD(Seq(numbers, airports)).saveToEs(\u0026quot;spark/docs\u0026quot;)\n    }\n}\n \n \npom 文件如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\n\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot;\n         xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\n         xsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\n    \u0026lt;parent\u0026gt;\n        \u0026lt;artifactId\u0026gt;spark\u0026lt;/artifactId\u0026gt;\n        \u0026lt;groupId\u0026gt;com.sydney.dream\u0026lt;/groupId\u0026gt;\n        \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt;\n    \u0026lt;/parent\u0026gt;\n    \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\n\n    \u0026lt;groupId\u0026gt;com.sydney.dream\u0026lt;/groupId\u0026gt;\n    \u0026lt;artifactId\u0026gt;ElasticSpark\u0026lt;/artifactId\u0026gt;\n    \u0026lt;dependencies\u0026gt;\n        \u0026lt;!--\u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;elasticsearch-hadoop\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;5.5.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;--\u0026gt;\n       \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;elasticsearch-spark-20_2.10\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;5.5.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n        \u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;spark-core_2.10\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt;\n        \u0026lt;/dependency\u0026gt;\n        \u0026lt;!--\u0026lt;dependency\u0026gt;\n            \u0026lt;groupId\u0026gt; org.apache.storm\u0026lt;/groupId\u0026gt;\n            \u0026lt;artifactId\u0026gt;storm-core\u0026lt;/artifactId\u0026gt;\n            \u0026lt;version\u0026gt;1.0.1\u0026lt;/version\u0026gt;\n            \u0026lt;exclusions\u0026gt;\n                \u0026lt;exclusion\u0026gt;\n                    \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt;\n                    \u0026lt;artifactId\u0026gt;log4j-over-slf4j\u0026lt;/artifactId\u0026gt;\n                \u0026lt;/exclusion\u0026gt;\n            \u0026lt;/exclusions\u0026gt;\n        \u0026lt;/dependency\u0026gt;--\u0026gt;\n    \u0026lt;/dependencies\u0026gt;\n\n   \u0026lt;build\u0026gt;\n        \u0026lt;plugins\u0026gt;\n            \u0026lt;plugin\u0026gt;\n                \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\n                \u0026lt;artifactId\u0026gt;maven-jar-plugin\u0026lt;/artifactId\u0026gt;\n                \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt;\n                \u0026lt;configuration\u0026gt;\n                    \u0026lt;archive\u0026gt;\n                        \u0026lt;manifest\u0026gt;\n                            \u0026lt;addClasspath\u0026gt;true\u0026lt;/addClasspath\u0026gt;\n                            \u0026lt;classpathPrefix\u0026gt;lib/\u0026lt;/classpathPrefix\u0026gt;\n                            \u0026lt;mainClass\u0026gt;com.sydney.dream.elasticspark.ElasticSparkFirstDemo\u0026lt;/mainClass\u0026gt;\n                        \u0026lt;/manifest\u0026gt;\n                    \u0026lt;/archive\u0026gt;\n                \u0026lt;/configuration\u0026gt;\n            \u0026lt;/plugin\u0026gt;\n            \u0026lt;plugin\u0026gt;\n                \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\n                \u0026lt;artifactId\u0026gt;maven-dependency-plugin\u0026lt;/artifactId\u0026gt;\n                \u0026lt;version\u0026gt;2.10\u0026lt;/version\u0026gt;\n                \u0026lt;executions\u0026gt;\n                    \u0026lt;execution\u0026gt;\n                        \u0026lt;id\u0026gt;copy-dependencies\u0026lt;/id\u0026gt;\n                        \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\n                        \u0026lt;goals\u0026gt;\n                            \u0026lt;goal\u0026gt;copy-dependencies\u0026lt;/goal\u0026gt;\n                        \u0026lt;/goals\u0026gt;\n                        \u0026lt;configuration\u0026gt;\n                            \u0026lt;outputDirectory\u0026gt;${project.build.directory}/lib\u0026lt;/outputDirectory\u0026gt;\n                        \u0026lt;/configuration\u0026gt;\n                    \u0026lt;/execution\u0026gt;\n                \u0026lt;/executions\u0026gt;\n            \u0026lt;/plugin\u0026gt;\n           \u0026lt;plugin\u0026gt;\n                \u0026lt;groupId\u0026gt;org.scala-tools\u0026lt;/groupId\u0026gt;\n                \u0026lt;artifactId\u0026gt;maven-scala-plugin\u0026lt;/artifactId\u0026gt;\n                \u0026lt;version\u0026gt;2.15.2\u0026lt;/version\u0026gt;\n                \u0026lt;executions\u0026gt;\n                    \u0026lt;execution\u0026gt;\n                        \u0026lt;goals\u0026gt;\n                            \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt;\n                            \u0026lt;goal\u0026gt;testCompile\u0026lt;/goal\u0026gt;\n                        \u0026lt;/goals\u0026gt;\n                    \u0026lt;/execution\u0026gt;\n                \u0026lt;/executions\u0026gt;\n            \u0026lt;/plugin\u0026gt;\n            \u0026lt;!--\n            \u0026lt;plugin\u0026gt;\n                \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\n                \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\n                \u0026lt;version\u0026gt;2.4.1\u0026lt;/version\u0026gt;\n                \u0026lt;configuration\u0026gt;\n                    \u0026lt;createDependencyReducedPom\u0026gt;false\u0026lt;/createDependencyReducedPom\u0026gt;\n                \u0026lt;/configuration\u0026gt;\n                \u0026lt;executions\u0026gt;\n                    \u0026lt;execution\u0026gt;\n                        \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\n                        \u0026lt;goals\u0026gt;\n                            \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\n                        \u0026lt;/goals\u0026gt;\n                        \u0026lt;configuration\u0026gt;\n                            \u0026lt;transformers\u0026gt;\n                                \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot; /\u0026gt;\n                                \u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot;/\u0026gt;\n                            \u0026lt;/transformers\u0026gt;\n                        \u0026lt;/configuration\u0026gt;\n                    \u0026lt;/execution\u0026gt;\n                \u0026lt;/executions\u0026gt;\n            \u0026lt;/plugin\u0026gt;--\u0026gt;\n        \u0026lt;/plugins\u0026gt;\n    \u0026lt;/build\u0026gt;\n\u0026lt;/project\u0026gt;\n \n \nspark-submit 提交：\n spark-submit --class com.sydney.dream.elasticspark.ElasticSparkFirstDemo --master yarn --deploy-mode client --executor-memory 5G --num-executors 10 --jars /home/ldl/sparkdemo/ElasticSpark-1.0.0.jar  /home/ldl/sparkdemo/lib/activation-1.1.1.jar /home/ldl/sparkdemo/lib/antlr4-runtime-4.5.3.jar /home/ldl/sparkdemo/lib/aopalliance-repackaged-2.4.0-b34.jar /home/ldl/sparkdemo/lib/apacheds-i18n-2.0.0-M15.jar /home/ldl/sparkdemo/lib/apacheds-kerberos-codec-2.0.0-M15.jar /home/ldl/sparkdemo/lib/api-asn1-api-1.0.0-M20.jar /home/ldl/sparkdemo/lib/api-util-1.0.0-M20.jar /home/ldl/sparkdemo/lib/avro-1.7.7.jar /home/ldl/sparkdemo/lib/avro-ipc-1.7.7.jar /home/ldl/sparkdemo/lib/avro-ipc-1.7.7-tests.jar /home/ldl/sparkdemo/lib/base64-2.3.8.jar /home/ldl/sparkdemo/lib/bcprov-jdk15on-1.51.jar /home/ldl/sparkdemo/lib/chill_2.10-0.8.0.jar /home/ldl/sparkdemo/lib/chill-java-0.8.0.jar /home/ldl/sparkdemo/lib/commons-beanutils-1.7.0.jar /home/ldl/sparkdemo/lib/commons-beanutils-core-1.8.0.jar /home/ldl/sparkdemo/lib/commons-cli-1.2.jar /home/ldl/sparkdemo/lib/commons-codec-1.8.jar /home/ldl/sparkdemo/lib/commons-collections-3.2.2.jar /home/ldl/sparkdemo/lib/commons-compiler-3.0.0.jar /home/ldl/sparkdemo/lib/commons-compress-1.4.1.jar /home/ldl/sparkdemo/lib/commons-configuration-1.6.jar /home/ldl/sparkdemo/lib/commons-crypto-1.0.0.jar /home/ldl/sparkdemo/lib/commons-digester-1.8.jar /home/ldl/sparkdemo/lib/commons-httpclient-3.1.jar /home/ldl/sparkdemo/lib/commons-io-2.4.jar /home/ldl/sparkdemo/lib/commons-lang-2.6.jar /home/ldl/sparkdemo/lib/commons-lang3-3.5.jar /home/ldl/sparkdemo/lib/commons-math3-3.4.1.jar /home/ldl/sparkdemo/lib/commons-net-2.2.jar /home/ldl/sparkdemo/lib/compress-lzf-1.0.3.jar /home/ldl/sparkdemo/lib/curator-client-2.6.0.jar /home/ldl/sparkdemo/lib/curator-framework-2.6.0.jar /home/ldl/sparkdemo/lib/curator-recipes-2.6.0.jar /home/ldl/sparkdemo/lib/gson-2.2.4.jar /home/ldl/sparkdemo/lib/guava-16.0.1.jar /home/ldl/sparkdemo/lib/hk2-api-2.4.0-b34.jar /home/ldl/sparkdemo/lib/hk2-locator-2.4.0-b34.jar /home/ldl/sparkdemo/lib/hk2-utils-2.4.0-b34.jar /home/ldl/sparkdemo/lib/htrace-core-3.0.4.jar /home/ldl/sparkdemo/lib/httpclient-4.3.6.jar /home/ldl/sparkdemo/lib/httpcore-4.3.3.jar /home/ldl/sparkdemo/lib/ivy-2.4.0.jar /home/ldl/sparkdemo/lib/jackson-annotations-2.6.5.jar /home/ldl/sparkdemo/lib/jackson-core-2.6.5.jar /home/ldl/sparkdemo/lib/jackson-core-asl-1.9.13.jar /home/ldl/sparkdemo/lib/jackson-databind-2.6.5.jar /home/ldl/sparkdemo/lib/jackson-jaxrs-1.9.13.jar /home/ldl/sparkdemo/lib/jackson-mapper-asl-1.9.13.jar /home/ldl/sparkdemo/lib/jackson-module-paranamer-2.6.5.jar /home/ldl/sparkdemo/lib/jackson-xc-1.9.13.jar /home/ldl/sparkdemo/lib/janino-3.0.0.jar /home/ldl/sparkdemo/lib/javassist-3.18.1-GA.jar /home/ldl/sparkdemo/lib/javax.annotation-api-1.2.jar /home/ldl/sparkdemo/lib/javax.inject-2.4.0-b34.jar /home/ldl/sparkdemo/lib/java-xmlbuilder-1.0.jar /home/ldl/sparkdemo/lib/javax.servlet-api-3.1.0.jar /home/ldl/sparkdemo/lib/javax.ws.rs-api-2.0.1.jar /home/ldl/sparkdemo/lib/jaxb-api-2.2.2.jar /home/ldl/sparkdemo/lib/jcl-over-slf4j-1.7.16.jar /home/ldl/sparkdemo/lib/jersey-client-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-common-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-container-servlet-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-container-servlet-core-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-guava-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-media-jaxb-2.22.2.jar /home/ldl/sparkdemo/lib/jersey-server-2.22.2.jar /home/ldl/sparkdemo/lib/jets3t-0.9.3.jar /home/ldl/sparkdemo/lib/jetty-util-6.1.26.jar /home/ldl/sparkdemo/lib/json4s-ast_2.10-3.2.11.jar /home/ldl/sparkdemo/lib/json4s-core_2.10-3.2.11.jar /home/ldl/sparkdemo/lib/json4s-jackson_2.10-3.2.11.jar /home/ldl/sparkdemo/lib/jsr305-1.3.9.jar /home/ldl/sparkdemo/lib/jul-to-slf4j-1.7.16.jar /home/ldl/sparkdemo/lib/kryo-shaded-3.0.3.jar /home/ldl/sparkdemo/lib/leveldbjni-all-1.8.jar /home/ldl/sparkdemo/lib/log4j-1.2.17.jar /home/ldl/sparkdemo/lib/lz4-1.3.0.jar /home/ldl/sparkdemo/lib/mail-1.4.7.jar /home/ldl/sparkdemo/lib/metrics-core-3.1.2.jar /home/ldl/sparkdemo/lib/metrics-graphite-3.1.2.jar /home/ldl/sparkdemo/lib/metrics-json-3.1.2.jar /home/ldl/sparkdemo/lib/metrics-jvm-3.1.2.jar /home/ldl/sparkdemo/lib/minlog-1.3.0.jar /home/ldl/sparkdemo/lib/mx4j-3.0.2.jar /home/ldl/sparkdemo/lib/netty-3.9.9.Final.jar /home/ldl/sparkdemo/lib/netty-all-4.0.43.Final.jar /home/ldl/sparkdemo/lib/objenesis-2.1.jar /home/ldl/sparkdemo/lib/oro-2.0.8.jar /home/ldl/sparkdemo/lib/osgi-resource-locator-1.0.1.jar /home/ldl/sparkdemo/lib/paranamer-2.3.jar /home/ldl/sparkdemo/lib/parquet-column-1.8.1.jar /home/ldl/sparkdemo/lib/parquet-common-1.8.1.jar /home/ldl/sparkdemo/lib/parquet-encoding-1.8.1.jar /home/ldl/sparkdemo/lib/parquet-format-2.3.0-incubating.jar /home/ldl/sparkdemo/lib/parquet-jackson-1.8.1.jar /home/ldl/sparkdemo/lib/protobuf-java-2.5.0.jar /home/ldl/sparkdemo/lib/py4j-0.10.4.jar /home/ldl/sparkdemo/lib/pyrolite-4.13.jar /home/ldl/sparkdemo/lib/RoaringBitmap-0.5.11.jar /home/ldl/sparkdemo/lib/slf4j-api-1.7.16.jar /home/ldl/sparkdemo/lib/slf4j-log4j12-1.7.16.jar /home/ldl/sparkdemo/lib/snappy-java-1.1.2.6.jar /home/ldl/sparkdemo/lib/stax-api-1.0-2.jar /home/ldl/sparkdemo/lib/stream-2.7.0.jar /home/ldl/sparkdemo/lib/univocity-parsers-2.2.1.jar /home/ldl/sparkdemo/lib/unused-1.0.0.jar /home/ldl/sparkdemo/lib/validation-api-1.1.0.Final.jar /home/ldl/sparkdemo/lib/xbean-asm5-shaded-4.4.jar /home/ldl/sparkdemo/lib/xercesImpl-2.9.1.jar /home/ldl/sparkdemo/lib/xml-apis-1.3.04.jar /home/ldl/sparkdemo/lib/xmlenc-0.52.jar /home/ldl/sparkdemo/lib/xz-1.0.jar /home/ldl/sparkdemo/lib/zookeeper-3.4.6.jar\n ","title":"elastic-spark classNotFount EsSpark","uid":"3729","views":"665","votes":"1"},"_type":"doc"}
{"_id":"188","_index":"forum-mysql","_score":1,"_source":{"addtime":"1497948317","category_id":"1","comments":"1","has_attach":"1","id":"188","message":"ELK入门搭建参考文章","title":"ELK使用不完全记录","uid":"2927","views":"2184","votes":"0"},"_type":"doc"}
{"_id":"198","_index":"forum-mysql","_score":1,"_source":{"addtime":"1500972330","category_id":"12","comments":"0","has_attach":"0","id":"198","message":"[b]岗位职责：[/b]\n负责参与搜索业务的系统架构及研发，对现有搜索业务系统进行改进和优化\n1．负责搜索服务端的开发工作； \n2． 负责分词，索引和查询的算法优化；\n3．研究数据的存储、传输，优化系统架构，不断提升系统时效性、灵活性及性能；\n4． 对代码和设计质量有严格要求，重视Code Review，知道良好编程习惯的标准；\n5． 参与搜索系统分布式架构设计，研究分布式信息检索的服务架构，分析和修改相关性算法、策略，构建高性能，灵活易调研的分布式检索系统。\n\n[b]任职要求：[/b]\n1. 计算机或相关专业本科及以上学历，2年以上搜索引擎相关的研发经验；\n2. 有自然语言处理、相关性算法、rerank等经验者或数据挖掘实践经验者优先；\n3. 深刻理解企业应用设计模式，有大型分布式，高并发，高负载，高可用性系统设计开发经验；\n4. 有扎实的Java基础(熟悉io、多线程、集合等基础框架，熟悉分布式、缓存、消息、搜索等机制） ；\n5. 熟悉Elasticsearch 对分布式搜索有一定实战经验；\n6. 对互联网产品敏感，学习能力强\n7. 熟悉数理统计和机器学习的基础理论，并有一定的实战经验者优先（可选）；\n8. 熟悉常见机器学习排序方法，如：GBDT、LTR或随机森林，熟悉特征处理方法者优先（可选）；\n \n[b]薪酬范围: [/b] \n10k - 20k /月 + 年终奖 \n \n有意者邮件联系: ckjiang@ctrip.com ","title":"【携程招聘】高级搜索研发工程师","uid":"81","views":"1620","votes":"5"},"_type":"doc"}
{"_id":"199","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501054718","category_id":"12","comments":"0","has_attach":"0","id":"199","message":"岗位职责：\n\n1，负责个性化推荐系统的算法和架构研发, 实现在相关产品中的精准推荐；\n\n2，负责产品、内容的推荐与其他场景的基础数据挖掘；\n\n3，根据海量用户行为的分析和挖掘，构建用户画像、标签系统等。\n\n \n任职要求：\n\n1、两年以上相关工作经验；\n\n2、有推荐系统或搜索排序研发经验, 熟悉常用的推荐算法，有实际算法调优经验；\n\n3、熟悉Hadoop、HBase、Spark、Kafka等计算平台和工具；\n\n4、掌握自然语言处理、协同推荐算法方面的基本知识；\n\n5、良好的沟通和学习能力，团队合作精神，能独立承担工作。\n\n \n加分项：\n\n1，有大规模海量数据机器学习、数据挖掘、计算广告、搜索引擎相关经验；\n\n2，有互联网电商行业数据经验。\n\n\n易所试集团（Www.liketry.com），新三板上市公司，市值10亿左右，组建北京研发中心，13薪起，正常基数五险一金并提供商业保险（补充医疗+意外等），10天年假起，弹性工作制，薪资可根据能力商议。工作地点：北京望京SOHO，简历请发送至邮箱：hang.song@liketry.com。","title":"【急聘】搜索推荐系统研发工程师 12-20K","uid":"3637","views":"1247","votes":"4"},"_type":"doc"}
{"_id":"304","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506683913","category_id":"2","comments":"5","has_attach":"0","id":"304","message":"【携程旅行网  吴晓刚】 \n\n\u0026gt;注：本文是针对Elastic中文社区问题[question#2484](https://elasticsearch.cn/question/2484) 的分析和总结。\n\n#问题概述\n\n一个线上集群，执行的Query DSL都是一样的，只是参数不同。 统计数据显示98-99%的查询响应速度都很快，只需要4 -6ms， 但有1%左右的查询响应时间在100ms - 200ms。 集群硬件配置较高，使用的SSD，系统可用内存远高于索引文件大小总和，并且线上已经运行有一段时间，数据应该已经充分预热。\n\n***\n#诊断过程及结论\n\n比较巧的是，问题提出者刚好是我们自家公司的开发者，因此内部联系沟通了下，为问题的快速诊断提供了不少便利。\n\n首先用公司的监控系统排查了一遍集群所有关键数据，未发现任何可能引起查询耗时高的性能瓶颈问题。 因此初步怀疑就是有查询本身比较慢。 幸好公司有应用埋点系统和日志系统，因此很方便的拿到了应用端发出的一些慢查询样例，包括请求体以及耗时。\n\n以下是埋点系统里记录的一个耗时150ms的查询 (隐去了敏感信息，去掉了非关键部分):\n\n```json\nPOST /xxxindex/xxxdb/_search?routing=Mxxxxxxx\n{\n  \u0026quot;from\u0026quot;: 0,\n  \u0026quot;size\u0026quot;: 100,\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;bool\u0026quot;: {\n      \u0026quot;filter\u0026quot;: [\n        {\n          \u0026quot;bool\u0026quot;: {\n            \u0026quot;must\u0026quot;: [\n              {\n                \u0026quot;bool\u0026quot;: {\n                  \u0026quot;must\u0026quot;: [\n                    {\n                      \u0026quot;bool\u0026quot;: {\n                        \u0026quot;should\u0026quot;: [\n                          {\n                            \u0026quot;match_phrase\u0026quot;: {\n                              \u0026quot;ord_orders_uid\u0026quot;: {\n                                \u0026quot;query\u0026quot;: \u0026quot;Mxxxxxxx\u0026quot;,\n                                \u0026quot;slop\u0026quot;: 0,\n                                \u0026quot;boost\u0026quot;: 1\n                              }\n                            }\n                          }\n                        ],\n                        \u0026quot;disable_coord\u0026quot;: false,\n                        \u0026quot;adjust_pure_negative\u0026quot;: true,\n                        \u0026quot;boost\u0026quot;: 1\n                      }\n                    },\n                    {\n                      \u0026quot;range\u0026quot;: {\n                        \u0026quot;ord_orders_orderdate\u0026quot;: {\n                          \u0026quot;from\u0026quot;: \u0026quot;1405032032\u0026quot;,\n                          \u0026quot;to\u0026quot;:   \u0026quot;1504014193\u0026quot;,\n                          \u0026quot;include_lower\u0026quot;: true,\n                          \u0026quot;include_upper\u0026quot;: true,\n                          \u0026quot;boost\u0026quot;: 1\n                        }\n                      }\n                    },\n                    {\n                      \u0026quot;term\u0026quot;: {\n                        \u0026quot;ord_orders_ispackageorder\u0026quot;: {\n                          \u0026quot;value\u0026quot;: 0,\n                          \u0026quot;boost\u0026quot;: 1\n                        }\n                      }\n                    },\n                    {\n                      \u0026quot;bool\u0026quot;: {\n                        \u0026quot;must_not\u0026quot;: [\n                          {\n                            \u0026quot;exists\u0026quot;: {\n                              \u0026quot;field\u0026quot;: \u0026quot;ord_hideorder_orderid\u0026quot;,\n                              \u0026quot;boost\u0026quot;: 1\n                            }\n                          }\n                        ],\n                        \u0026quot;disable_coord\u0026quot;: false,\n                        \u0026quot;adjust_pure_negative\u0026quot;: true,\n                        \u0026quot;boost\u0026quot;: 1\n                      }\n                    }\n                  ],\n                  \u0026quot;disable_coord\u0026quot;: false,\n                  \u0026quot;adjust_pure_negative\u0026quot;: true,\n                  \u0026quot;boost\u0026quot;: 1\n                }\n              }\n            ],\n            \u0026quot;disable_coord\u0026quot;: false,\n            \u0026quot;adjust_pure_negative\u0026quot;: true,\n            \u0026quot;boost\u0026quot;: 1\n          }\n        }\n      ],\n      \u0026quot;disable_coord\u0026quot;: false,\n      \u0026quot;adjust_pure_negative\u0026quot;: true,\n      \u0026quot;boost\u0026quot;: 1\n    }\n  }\n}\n```\n\n拿到查询后，自己手动执行了一下，0 hits，耗时1ms。  心里明白，命中了Query Cache，所以才会这么快。 \n\n于是用clear api清掉Query Cache，然后再执行几次，有以下发现：\n\n-  头两次查询耗时38ms左右。 这是因为没有cache，需要访问倒排索引，耗时符合预期。 之所以两次同样耗时，是因为索引有1个复制片，两次查询分别分配到主和副片上。\n- 接下来两次查询耗时150ms左右。  **这里要打一个大大的问号？？？**\n-  之后不管再查询多少次， 耗时全部是1ms，因为又开始命中Cache。\n\n至此，大致明白，埋点系统里记录到的高耗时查询，是步骤2的两次操作。 什么操作耗时这么久呢？ 根据经验，我判断主要是用于为range filter生成缓存，也就生成生成文档列表的bitmap，然后存放到Query Cache里。 \n\n这个集群版本是5.1.1， 而我记得ES某个5版本开始，去掉了对term filter的cache，理由是term filter速度足够快，缓存term filter往往得不偿失。 查了官方release notes，证实这个改变正好是从5.1.1开始的[#21566](https://github.com/elastic/elasticsearch/pull/21566)，因此上面查询里的term filters被排除掉，注意力集中到了查询里唯一的一个range filter。 \n\n单独执行了一下这个range filter，match的文档是千万数量级的。 询问用户，为何这个range filter会hit这么多文档，得知用户主要就是查询从当前时间开始至过去1年的数据，类似于做了一个`now-1y  TO now`这样的过滤。至此初步得出结论，因为这个range filter匹配的文档太多了，在Query Cache里为这个filter构建bitmap耗时会有些高，应该就是它带来了那额外的100多个ms。\n\n但是还有一个待解释的问题，这种高耗时查询比例为何这么高？ 再仔细想想也就明白了：因为这个集群的搜索并发量还是有点高，300 -400/s的样子，加上时间字段的精度是秒，所以，在某一秒刚开始的时候，头2次查询因为没有cache，耗时可能在38ms左右，之后会有2次查询因为需要缓存range filter，耗时会增加到150-200ms的样子，之后这1秒里剩余的查询都会命中cache，全部是几个ms， 直到下一秒开始， 周而复始。 因为每秒钟都产生2个这样需要构建缓存的查询，耗时较高，对比每秒几百次的查询量，换算成百分比就有点高了。\n\n那么怎么解决这个问题？ 对于大量含有从`now-xxx TO now`这样的range查询，实际上官方的文档有对应的加速技巧介绍：[tune-for-search-speed.html#_search_rounded_dates](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html#_search_rounded_dates) 。也就是说，将查询时间的上下限round到整分钟，或者整小时，让range filter可以缓存得更久，避免出现这种过于频繁重建cache的情况。\n```json\n{\n   \u0026quot;range\u0026quot;: {\n       \u0026quot;my_date\u0026quot;: {\n       \u0026quot;gte\u0026quot;: \u0026quot;now-1y/h\u0026quot;,\n        \u0026quot;lte\u0026quot;: \u0026quot;now-1y/h\u0026quot;\n      }\n    }\n}\n```\n\n在原始Query里，将range filter写成上述形式，手动测试证实可行，range filter有效期延长到1小时，从而每个小时里，只需要为range filter重建2次Cache，至此问题解决。\n\n---\n#总结:\n\n1.  Cache并非建得越多越好，因为Cache的生成和Evict会带来额外的开销。特别是结果集非常大的filter，缓存的代价相对查询本身可能非常高。\n2.  ES 5.1.1开始取消了Terms filter Cache，因为Terms filter执行非常快，取消缓存多数情况下反而可以提高性能。\n3.  大量用到`Now-xxxd To Now`这样的Range filter时，可以借助round date技巧，提高Cache的有效期，减轻频繁重建Cache带来的性能问题。","title":"一例Query Cache引起的性能问题分析","uid":"81","views":"2336","votes":"19"},"_type":"doc"}
{"_id":"305","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506733023","category_id":"18","comments":"0","has_attach":"0","id":"305","message":"1、你知道es提取词干的算法原理吗？\nhttp://t.cn/R0Y5CoA\n2、利用机器学习来分析你的nginx日志吧\nhttp://t.cn/R0Yc58j\n3、如何最大程度地保证es集群安全？\nhttp://t.cn/R0Y9vxc\n4、Elastic线下活动已有5个主题，欢迎报名分享：\nhttps://elasticsearch.cn/article/261\n编辑：bsll\n归档：https://www.elasticsearch.cn/article/305\n订阅：https://tinyletter.com/elastic-daily\nPS: 预祝大家国庆节快乐，然后中秋节快乐！节日里多吃多睡多玩多开心，日报编辑们也要去过节了，因此日报暂停更新8日，节日后再见啦！\n ","title":"Elastic日报 第63期 (2017-09-30)","uid":"1874","views":"890","votes":"1"},"_type":"doc"}
{"_id":"306","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507512778","category_id":"18","comments":"0","has_attach":"0","id":"306","message":"1、Elastic十年工程师老司机带你了解timelion的魔力\nhttp://t.cn/Rowh1dl\n\n2、即刻技术团队带来的的mongodb-elasticsearch 数据同步方案。\nhttp://t.cn/RaOonLb\n\n3、集群太多？数据不方便管理？来看看Netflix的es自动化管理运维工具:Raigad\nhttp://t.cn/ROGTENC\n\n编辑：cyberdak\n归档：[url]https://www.elasticsearch.cn/article/[/url]306\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第64期 (2017-10-09)","uid":"4063","views":"563","votes":"0"},"_type":"doc"}
{"_id":"310","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507846178","category_id":"18","comments":"0","has_attach":"0","id":"310","message":"1、一个不错的 Elasticsearch API 兼容性的实时监控\nhttp://t.cn/RO5pcz3\n2、性能优化，带主键的索引场景性能提升 ~9% ！\nhttp://t.cn/RoJex1R\n3、比一比 | ES中文分词哪家强？\nhttp://t.cn/ROyBcAB\n\n编辑：laoyang360\n归档：[url]https://elasticsearch.cn/article/310[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n ","title":" Elastic日报 第68期 (2017-10-13)","uid":"1341","views":"550","votes":"1"},"_type":"doc"}
{"_id":"321","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508377704","category_id":"18","comments":"0","has_attach":"0","id":"321","message":"1.yahoo开源的低延迟大数据引擎vespa和lucece的对比\nhttp://t.cn/ROg0Fs2\n2.如何在高可用的elasticstack上部署和扩展logstash\nhttp://t.cn/ROgOwOC\n3.Elasticsearch 5.x 源码分析-Shard Allocation 和Cluster Reroute\nhttp://t.cn/ROgO4fF\n活动预告：Elastic 长沙交流会 \nhttps://elasticsearch.cn/article/320\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/321\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第74期 (2017-10-19)","uid":"668","views":"514","votes":"0"},"_type":"doc"}
{"_id":"330","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508896625","category_id":"18","comments":"0","has_attach":"0","id":"330","message":"1. B站日志系统的前世今生\n[url]http://t.cn/ROkvWTg[/url]\n2. Elasticsearch监控实战 补充昨天的\n集群 [url]http://t.cn/RO8N2iL[/url]\n单节点 [url]http://t.cn/RW5Qm8f[/url]\n3. 沪江网校的日志系统实战\n[url]http://t.cn/ROriZLw[/url]\n活动预告：Elastic 长沙交流会\n[url]https://elasticsearch.cn/article/320[/url]\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/330[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第80期 (2017-10-25)","uid":"3828","views":"486","votes":"0"},"_type":"doc"}
{"_id":"333","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508981893","category_id":"18","comments":"0","has_attach":"0","id":"333","message":"1.基于elasticsearch的现代银行监控api架构\npart1: http://t.cn/RWaeGMB\npart2: http://t.cn/RWagoth\n2.父子查询？看看es的祖孙关系怎么玩\nhttp://t.cn/RWXkPyZ\n3.elasticsearch与influxdb在时序数据分析的对比\nhttp://t.cn/RWXk46L\n活动预告：Elastic 长沙交流会 \nhttps://elasticsearch.cn/article/320\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/333\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第81期 (2017-10-26)","uid":"668","views":"499","votes":"0"},"_type":"doc"}
{"_id":"336","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509017778","category_id":"2","comments":"1","has_attach":"0","id":"336","message":"[b]一：cross-cluster-search简述：[/b]\n\ncross cluster search（跨集群搜索）功能允许任何节点在多个集群之间充当federated client（联合客户端）。 与tribe node（部落节点）功能相比，进行cross cluster search（跨集群搜索）的节点将不会加入远程集群，而是以轻量的方式连接到远程集群，以便执行联合搜索请求。\ncross cluster search（跨集群搜索）的工作原理是在集群状态中配置一个远程集群，并且仅连接到远程集群中有限数量的节点。 每个远程集群都由一个名称和一个seed nodes（种子节点）的列表引用。 这些seed nodes（种子节点）用于发现远程集群中有资格作为gateway nodes（网关节点）的节点。 集群中配置了远程集群的每个节点都连接到一个或多个gateway nodes（网关节点），并使用它们将搜索请求联合到远程集群。\n注意\n此功能处于测试阶段，可能会发生变化。设计和代码不如官方GA功能成熟。弹性将采取最大的努力来解决任何问题，但beta功能不受SLA官方GA功能的支持。\n\n[b]二：配置跨集群搜索：[/b]\n远程集群可以通过cluster settings API（集群设置api）来全局性地指定（可以动态更新），或者在各个节点的elasticsearch.yml文件中单独设定\n如果通过elasticsearch.yml配置远程集群，则只有具有该配置的节点才能连接到远程集群。 换句话说，联合搜索请求必须被专门发送到那些节点。 通过cluster settings API（集群设置api）设置的远程集群在集群中的每个节点上都可用。\n注意\n此功能已添加到Elasticsearch v5.3中，并且要求gateway eligible（具有网关资格）的节点在v5.3之后。\n\n对于cross cluster search（跨集群搜索）节点的elasticsearch.yml配置文件只需要列出应连接到远程集群，例如：[code]search:\n    remote:\n        cluster_one: \n            seeds: 127.0.0.1:9300\n        cluster_two: \n            seeds: 127.0.0.1:9301[/code]\n\ncluster_one和cluster_two是表示与每个集群的连接的任意集群别名。 这些名称随后用于区分本地和远程索引。\n\n使用cluster settings API（集群设置api）将远程集群添加到集群中的所有节点的示例如下：[code]PUT _cluster/settings\n{\n  \u0026quot;persistent\u0026quot;: {\n    \u0026quot;search\u0026quot;: {\n      \u0026quot;remote\u0026quot;: {\n        \u0026quot;cluster_one\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: [\n            \u0026quot;127.0.0.1:9300\u0026quot;\n          ]\n        },\n        \u0026quot;cluster_two\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: [\n            \u0026quot;127.0.0.1:9301\u0026quot;\n          ]\n        }\n      }\n    }\n  }\n}[/code]\n\n通过将其种子设置为null，可以从群集设置中删除远程群集：:[code]PUT _cluster/settings\n{\n  \u0026quot;persistent\u0026quot;: {\n    \u0026quot;search\u0026quot;: {\n      \u0026quot;remote\u0026quot;: {\n        \u0026quot;cluster_one\u0026quot;: {\n          \u0026quot;seeds\u0026quot;: null \n        }\n      }\n    }\n  }\n}[/code]\n\ncluster_one将从集群设置中删除，cluster_two保持不变。\n\n使用跨集群搜索\n要搜索远程群集cluster_one上的twitter索引，index（索引）名称必须带有以:字符分隔的群集别名的前缀：[code]POST /cluster_one:twitter/tweet/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match_all\u0026quot;: {}\n  }\n}[/code]\n\n与tribe（部落）功能相反，cross cluster search（跨群集搜索）还可以搜索具有相同名称的不同群集的索引：[code]POST /cluster_one:twitter,twitter/tweet/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match_all\u0026quot;: {}\n  }\n}[/code]\n搜索结果的消歧与在请求中消除索引歧义的方法相同。 即使索引名称相同，当结果合并时，这些索引将被视为不同的索引。 从远程索引检索的所有结果将以其远程集群名称作为前缀：[code]{\n  \u0026quot;took\u0026quot; : 89,\n  \u0026quot;timed_out\u0026quot; : false,\n  \u0026quot;_shards\u0026quot; : {\n    \u0026quot;total\u0026quot; : 10,\n    \u0026quot;successful\u0026quot; : 10,\n    \u0026quot;failed\u0026quot; : 0\n  },\n  \u0026quot;hits\u0026quot; : {\n    \u0026quot;total\u0026quot; : 2,\n    \u0026quot;max_score\u0026quot; : 1.0,\n    \u0026quot;hits\u0026quot; : [\n      {\n        \u0026quot;_index\u0026quot; : \u0026quot;cluster_one:twitter\u0026quot;,\n        \u0026quot;_type\u0026quot; : \u0026quot;tweet\u0026quot;,\n        \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;,\n        \u0026quot;_score\u0026quot; : 1.0,\n        \u0026quot;_source\u0026quot; : {\n          \u0026quot;user\u0026quot; : \u0026quot;kimchy\u0026quot;,\n          \u0026quot;postDate\u0026quot; : \u0026quot;2009-11-15T14:12:12\u0026quot;,\n          \u0026quot;message\u0026quot; : \u0026quot;trying out Elasticsearch\u0026quot;\n        }\n      },\n      {\n        \u0026quot;_index\u0026quot; : \u0026quot;twitter\u0026quot;,\n        \u0026quot;_type\u0026quot; : \u0026quot;tweet\u0026quot;,\n        \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;,\n        \u0026quot;_score\u0026quot; : 1.0,\n        \u0026quot;_source\u0026quot; : {\n          \u0026quot;user\u0026quot; : \u0026quot;kimchy\u0026quot;,\n          \u0026quot;postDate\u0026quot; : \u0026quot;2009-11-15T14:12:12\u0026quot;,\n          \u0026quot;message\u0026quot; : \u0026quot;trying out Elasticsearch\u0026quot;\n        }\n      }\n    ]\n  }\n}[/code]\n跨集群搜索配置\nsearch.remote.connections_per_cluster\n要连接到每个远程集群的节点数。 默认值为3。 \nsearch.remote.initial_connect_timeout\n节点启动时与远程节点建立连接的等待时间。 默认是30秒。 \nsearch.remote.node.attr\n过滤掉远程集群中有资格作为gateway node（网关节点）的节点的节点属性。 例如，节点可以具有节点属性node.attr.gateway：true，如果search.remote.node.attr设置为gateway，只有具有此属性的节点才能将连接到。 \nsearch.remote.connect\n默认情况下，群集中的任何节点都可以充当 cross-cluster client（跨群集客户端）并连接到远程群集。 search.remote.connect设置可以设置为false（默认为true），以防止某些节点连接到远程群集。 Cross-cluster search（跨群集搜索）请求必须发送到允许充当跨群集客户端的节点。\n\n[b]三：官方文档[/b]\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.3/modules-cross-cluster-search.html#_cross_cluster_search_settings\n","title":"【源码篇】elasticsearch 搜索模块之cross-cluster-search","uid":"6245","views":"1820","votes":"0"},"_type":"doc"}
{"_id":"342","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509239213","category_id":"18","comments":"0","has_attach":"0","id":"342","message":"1.使用机器学习任务监测异常并向可视化的时间序列添加注释。\nhttp://t.cn/RWH0Oyg\n2.父子关系在Elasticsearch中的性能考量。\nhttp://t.cn/RWH0TH3\n3.(自备梯子)5天在5家硅谷顶级公司面试，作者如何拿到5份offer。\nhttp://t.cn/RWinyw9\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/342\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第84期 (2017-10-29)","uid":"4460","views":"444","votes":"0"},"_type":"doc"}
{"_id":"352","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509757286","category_id":"18","comments":"0","has_attach":"0","id":"352","message":"1、作为工程师需要知道的搜索引擎知识\nhttp://t.cn/RWqayNZ\n2、.Net开发者使用ES教程\nhttp://t.cn/RlGuApp\n3、一款与位置有关的相似插件\nhttp://t.cn/RlqbzDF\n编辑：bsll\n归档：https://www.elasticsearch.cn/article/352\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第90期 (2017-11-04)","uid":"1874","views":"441","votes":"0"},"_type":"doc"}
{"_id":"355","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509986340","category_id":"2","comments":"1","has_attach":"0","id":"355","message":"原文地址：http://www.54tianzhisheng.cn/2017/10/18/ElasticSearch-nodes-metrics/\n \n\n![](http://ohfk1r827.bkt.clouddn.com/cb6.jpeg-1)\n\n集群健康监控是对集群信息进行高度的概括，节点统计值 API 提供了集群中每个节点的统计值。节点统计值很多，在监控的时候仍需要我们清楚哪些指标是最值得关注的。\n\n集群健康监控可以参考这篇文章：[ElasticSearch 集群监控](http://www.54tianzhisheng.cn/2017/10/15/ElasticSearch-cluster-health-metrics/)\n\n### 节点信息   Node Info :\n\n```\ncurl -XGET 'http://localhost:9200/_nodes'\n```\n\n执行上述命令可以获取所有 node 的信息\n\n```json\n_nodes: {\n  total: 2,\n  successful: 2,\n  failed: 0\n},\ncluster_name: \u0026quot;elasticsearch\u0026quot;,\nnodes: {\n    MSQ_CZ7mTNyOSlYIfrvHag: {\n    name: \u0026quot;node0\u0026quot;,\n    transport_address: \u0026quot;192.168.180.110:9300\u0026quot;,\n    host: \u0026quot;192.168.180.110\u0026quot;,\n    ip: \u0026quot;192.168.180.110\u0026quot;,\n    version: \u0026quot;5.5.0\u0026quot;,\n    build_hash: \u0026quot;260387d\u0026quot;,\n    total_indexing_buffer: 103887667,\n    roles:{...},\n    settings: {...},\n    os: {\n      refresh_interval_in_millis: 1000,\n      name: \u0026quot;Linux\u0026quot;,\n      arch: \u0026quot;amd64\u0026quot;,\n      version: \u0026quot;3.10.0-229.el7.x86_64\u0026quot;,\n      available_processors: 4,\n      allocated_processors: 4\n    },\n    process: {\n      refresh_interval_in_millis: 1000,\n      id: 3022,\n      mlockall: false\n    },\n    jvm: {\n      pid: 3022,\n      version: \u0026quot;1.8.0_121\u0026quot;,\n      vm_name: \u0026quot;Java HotSpot(TM) 64-Bit Server VM\u0026quot;,\n      vm_version: \u0026quot;25.121-b13\u0026quot;,\n      vm_vendor: \u0026quot;Oracle Corporation\u0026quot;,\n      start_time_in_millis: 1507515225302,\n      mem: {\n      heap_init_in_bytes: 1073741824,\n      heap_max_in_bytes: 1038876672,\n      non_heap_init_in_bytes: 2555904,\n      non_heap_max_in_bytes: 0,\n      direct_max_in_bytes: 1038876672\n      },\n      gc_collectors: [],\n      memory_pools: [],\n      using_compressed_ordinary_object_pointers: \u0026quot;true\u0026quot;,\n      input_arguments:{}\n    }\n    thread_pool:{\n      force_merge: {},\n      fetch_shard_started: {},\n      listener: {},\n      index: {},\n      refresh: {},\n      generic: {},\n      warmer: {},\n      search: {},\n      flush: {},\n      fetch_shard_store: {},\n      management: {},\n      get: {},\n      bulk: {},\n      snapshot: {}\n    }\n    transport: {...},\n    http: {...},\n    plugins: [],\n    modules: [],\n    ingest: {...}\n }\n```\n\n上面是我已经简写了很多数据之后的返回值，但是指标还是很多，有些是一些常规的指标，对于监控来说，没必要拿取。从上面我们可以主要关注以下这些指标:\n\n```\nos, process, jvm, thread_pool, transport, http, ingest and indices\n```\n\n\n### 节点统计     nodes-statistics\n\n节点统计值 API 可通过如下命令获取：\n\n```\nGET /_nodes/stats\n```\n\n得到：\n\n```json\n_nodes: {\n  total: 2,\n  successful: 2,\n  failed: 0\n},\ncluster_name: \u0026quot;elasticsearch\u0026quot;,\nnodes: {\n  MSQ_CZ7mTNyOSlYI0yvHag: {\n    timestamp: 1508312932354,\n    name: \u0026quot;node0\u0026quot;,\n    transport_address: \u0026quot;192.168.180.110:9300\u0026quot;,\n    host: \u0026quot;192.168.180.110\u0026quot;,\n    ip: \u0026quot;192.168.180.110:9300\u0026quot;,\n    roles: [],\n    indices: {\n      docs: {\n           count: 6163666,\n           deleted: 0\n        },\n      store: {\n           size_in_bytes: 2301398179,\n           throttle_time_in_millis: 122850\n        },\n      indexing: {},\n      get: {},\n      search: {},\n      merges: {},\n      refresh: {},\n      flush: {},\n      warmer: {},\n      query_cache: {},\n      fielddata: {},\n      completion: {},\n      segments: {},\n      translog: {},\n      request_cache: {},\n      recovery: {}\n  },\n  os: {\n    timestamp: 1508312932369,\n    cpu: {\n      percent: 0,\n      load_average: {\n        1m: 0.09,\n        5m: 0.12,\n        15m: 0.08\n      }\n    },\n    mem: {\n      total_in_bytes: 8358301696,\n      free_in_bytes: 1381613568,\n      used_in_bytes: 6976688128,\n      free_percent: 17,\n      used_percent: 83\n    },\n    swap: {\n      total_in_bytes: 8455712768,\n      free_in_bytes: 8455299072,\n      used_in_bytes: 413696\n    },\n    cgroup: {\n      cpuacct: {},\n      cpu: {\n        control_group: \u0026quot;/user.slice\u0026quot;,\n        cfs_period_micros: 100000,\n        cfs_quota_micros: -1,\n        stat: {}\n      }\n  }\n},\nprocess: {\n  timestamp: 1508312932369,\n  open_file_descriptors: 228,\n  max_file_descriptors: 65536,\n  cpu: {\n    percent: 0,\n    total_in_millis: 2495040\n  },\n  mem: {\n    total_virtual_in_bytes: 5002465280\n  }\n},\njvm: {\n  timestamp: 1508312932369,\n  uptime_in_millis: 797735804,\n  mem: {\n    heap_used_in_bytes: 318233768,\n    heap_used_percent: 30,\n    heap_committed_in_bytes: 1038876672,\n    heap_max_in_bytes: 1038876672,\n    non_heap_used_in_bytes: 102379784,\n    non_heap_committed_in_bytes: 108773376,\n  pools: {\n    young: {\n      used_in_bytes: 62375176,\n      max_in_bytes: 279183360,\n      peak_used_in_bytes: 279183360,\n      peak_max_in_bytes: 279183360\n    },\n    survivor: {\n      used_in_bytes: 175384,\n      max_in_bytes: 34865152,\n      peak_used_in_bytes: 34865152,\n      peak_max_in_bytes: 34865152\n    },\n    old: {\n      used_in_bytes: 255683208,\n      max_in_bytes: 724828160,\n      peak_used_in_bytes: 255683208,\n      peak_max_in_bytes: 724828160\n    }\n  }\n  },\n  threads: {},\n  gc: {},\n  buffer_pools: {},\n  classes: {}\n},\n  thread_pool: {\n    bulk: {},\n    fetch_shard_started: {},\n    fetch_shard_store: {},\n    flush: {},\n    force_merge: {},\n    generic: {},\n    get: {},\n    index: {\n       threads: 1,\n       queue: 0,\n       active: 0,\n       rejected: 0,\n       largest: 1,\n       completed: 1\n    }\n    listener: {},\n    management: {},\n    refresh: {},\n    search: {},\n    snapshot: {},\n    warmer: {}\n  },\n  fs: {},\n  transport: {\n    server_open: 13,\n    rx_count: 11696,\n    rx_size_in_bytes: 1525774,\n    tx_count: 10282,\n    tx_size_in_bytes: 1440101928\n  },\n  http: {\n    current_open: 4,\n    total_opened: 23\n  },\n  breakers: {},\n  script: {},\n  discovery: {},\n  ingest: {}\n}\n```\n\n节点名是一个 UUID，上面列举了很多指标，下面讲解下：\n\n#### 索引部分 indices\n\n这部分列出了这个节点上所有索引的聚合过的统计值 ：\n\n- `docs` 展示节点内存有多少文档，包括还没有从段里清除的已删除文档数量。\n\n- `store` 部分显示节点耗用了多少物理存储。这个指标包括主分片和副本分片在内。如果限流时间很大，那可能表明你的磁盘限流设置得过低。\n\n- `indexing` 显示已经索引了多少文档。这个值是一个累加计数器。在文档被删除的时候，数值不会下降。还要注意的是，在发生内部 索引操作的时候，这个值也会增加，比如说文档更新。\n\n  还列出了索引操作耗费的时间，正在索引的文档数量，以及删除操作的类似统计值。\n\n- `get` 显示通过 ID 获取文档的接口相关的统计值。包括对单个文档的 `GET` 和 `HEAD` 请求。\n\n- `search` 描述在活跃中的搜索（ `open_contexts` ）数量、查询的总数量、以及自节点启动以来在查询上消耗的总时间。用 `query_time_in_millis / query_total` 计算的比值，可以用来粗略的评价你的查询有多高效。比值越大，每个查询花费的时间越多，你应该要考虑调优了。\n\n  fetch 统计值展示了查询处理的后一半流程（query-then-fetch 里的 *fetch* ）。如果 fetch 耗时比 query 还多，说明磁盘较慢，或者获取了太多文档，或者可能搜索请求设置了太大的分页（比如， `size: 10000` ）。\n\n- `merges` 包括了 Lucene 段合并相关的信息。它会告诉你目前在运行几个合并，合并涉及的文档数量，正在合并的段的总大小，以及在合并操作上消耗的总时间。\n\n- `filter_cache` 展示了已缓存的过滤器位集合所用的内存数量，以及过滤器被驱逐出内存的次数。过多的驱逐数 *可能* 说明你需要加大过滤器缓存的大小，或者你的过滤器不太适合缓存（比如它们因为高基数而在大量产生，就像是缓存一个 `now` 时间表达式）。\n\n  不过，驱逐数是一个很难评定的指标。过滤器是在每个段的基础上缓存的，而从一个小的段里驱逐过滤器，代价比从一个大的段里要廉价的多。有可能你有很大的驱逐数，但是它们都发生在小段上，也就意味着这些对查询性能只有很小的影响。\n\n  把驱逐数指标作为一个粗略的参考。如果你看到数字很大，检查一下你的过滤器，确保他们都是正常缓存的。不断驱逐着的过滤器，哪怕都发生在很小的段上，效果也比正确缓存住了的过滤器差很多。\n\n- `field_data` 显示 fielddata 使用的内存， 用以聚合、排序等等。这里也有一个驱逐计数。和 `filter_cache` 不同的是，这里的驱逐计数是很有用的：这个数应该或者至少是接近于 0。因为 fielddata 不是缓存，任何驱逐都消耗巨大，应该避免掉。如果你在这里看到驱逐数，你需要重新评估你的内存情况，fielddata 限制，请求语句，或者这三者。\n\n- `segments` 会展示这个节点目前正在服务中的 Lucene 段的数量。 这是一个重要的数字。大多数索引会有大概 50–150 个段，哪怕它们存有 TB 级别的数十亿条文档。段数量过大表明合并出现了问题（比如，合并速度跟不上段的创建）。注意这个统计值是节点上所有索引的汇聚总数。记住这点。\n\n  `memory` 统计值展示了 Lucene 段自己用掉的内存大小。 这里包括底层数据结构，比如倒排表，字典，和布隆过滤器等。太大的段数量会增加这些数据结构带来的开销，这个内存使用量就是一个方便用来衡量开销的度量值。\n\n#### 操作系统和进程部分\n\n`OS` 和 `Process` 部分基本是自描述的，不会在细节中展开讲解。它们列出来基础的资源统计值，比如 CPU 和负载。`OS` 部分描述了整个操作系统，而 `Process` 部分只显示 Elasticsearch 的 JVM 进程使用的资源情况。\n\n这些都是非常有用的指标，不过通常在你的监控技术栈里已经都测量好了。统计值包括下面这些：\n\n- CPU\n- 负载\n- 内存使用率 （mem.used_percent）\n- Swap 使用率\n- 打开的文件描述符 （open_file_descriptors）\n\n#### JVM 部分\n\n`jvm` 部分包括了运行 Elasticsearch 的 JVM 进程一些很关键的信息。 最重要的，它包括了垃圾回收的细节，这对你的 Elasticsearch 集群的稳定性有着重大影响。\n\n```json\njvm: {\n  timestamp: 1508312932369,\n  uptime_in_millis: 797735804,\n  mem: {\n    heap_used_in_bytes: 318233768,\n    heap_used_percent: 30,\n    heap_committed_in_bytes: 1038876672,\n    heap_max_in_bytes: 1038876672,\n    non_heap_used_in_bytes: 102379784,\n    non_heap_committed_in_bytes: 108773376,\n  }\n}\n```\n\n`jvm` 部分首先列出一些和 heap 内存使用有关的常见统计值。你可以看到有多少 heap 被使用了，多少被指派了（当前被分配给进程的），以及 heap 被允许分配的最大值。理想情况下，`heap_committed_in_bytes` 应该等于 `heap_max_in_bytes` 。如果指派的大小更小，JVM 最终会被迫调整 heap 大小——这是一个非常昂贵的操作。如果你的数字不相等，阅读 [堆内存:大小和交换](https://www.elastic.co/guide/cn/elasticsearch/guide/current/heap-sizing.html) 学习如何正确的配置它。\n\n`heap_used_percent` 指标是值得关注的一个数字。Elasticsearch 被配置为当 heap 达到 75% 的时候开始 GC。如果你的节点一直 \u0026gt;= 75%，你的节点正处于 *内存压力* 状态。这是个危险信号，不远的未来可能就有慢 GC 要出现了。\n\n如果 heap 使用率一直 \u0026gt;=85%，你就麻烦了。Heap 在 90–95% 之间，则面临可怕的性能风险，此时最好的情况是长达 10–30s 的 GC，最差的情况就是内存溢出（OOM）异常。\n\n#### 线程池部分\n\nElasticsearch 在内部维护了线程池。 这些线程池相互协作完成任务，有必要的话相互间还会传递任务。通常来说，你不需要配置或者调优线程池，不过查看它们的统计值有时候还是有用的，可以洞察你的集群表现如何。\n\n每个线程池会列出已配置的线程数量（ `threads` ），当前在处理任务的线程数量（ `active` ），以及在队列中等待处理的任务单元数量（ `queue` ）。\n\n如果队列中任务单元数达到了极限，新的任务单元会开始被拒绝，你会在 `rejected` 统计值上看到它反映出来。这通常是你的集群在某些资源上碰到瓶颈的信号。因为队列满意味着你的节点或集群在用最高速度运行，但依然跟不上工作的蜂拥而入。\n\n这里的一系列的线程池，大多数你可以忽略，但是有一小部分还是值得关注的：\n\n- `indexing`    普通的索引请求的线程池\n- `bulk`    批量请求，和单条的索引请求不同的线程池\n- `get`     Get-by-ID 操作\n- `search`    所有的搜索和查询请求\n- `merging`   专用于管理 Lucene 合并的线程池\n\n#### 网络部分\n\n- `transport` 显示和 *传输地址* 相关的一些基础统计值。包括节点间的通信（通常是 9300 端口）以及任意传输客户端或者节点客户端的连接。如果看到这里有很多连接数不要担心；Elasticsearch 在节点之间维护了大量的连接。\n- `http` 显示 HTTP 端口（通常是 9200）的统计值。如果你看到 `total_opened` 数很大而且还在一直上涨，这是一个明确信号，说明你的 HTTP 客户端里有没启用 keep-alive 长连接的。持续的 keep-alive 长连接对性能很重要，因为连接、断开套接字是很昂贵的（而且浪费文件描述符）。请确认你的客户端都配置正确。\n\n### 参考资料\n\n1、[nodes-info](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-info.html)\n\n2、[nodes-stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html)\n\n3、[ES监控指标](http://www.oneapm.com/ci/elasticsearch.html)\n\n### 最后：\n\n转载请注明地址：http://www.54tianzhisheng.cn/2017/10/18/ElasticSearch-nodes-metrics/","title":"ElasticSearch 单个节点监控","uid":"6576","views":"1370","votes":"2"},"_type":"doc"}
{"_id":"769","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535082922","category_id":"16","comments":"8","has_attach":"0","id":"769","message":"打算弄一个 Elastic Tips 的社区项目，希望能找到志同道合的小伙伴一起来弄。\n \n场景：\n大家是不是觉得 Elastic 的知识很多，需要学习的很多，常见问题经常问。\n \n目的：\n[list]\n[*]汇集 Elastic Stack 的奇巧赢技[/*]\n[*]随手可得的小技巧，温故知新[/*]\n[*]分享和学习，共同进步[/*]\n[*]积少成多，知识库[/*]\n[/list]\n \n细节\n[list]\n[*]贴士的内容要小且精要，简单，适合阅读和分享（限制为Twitter长度）[/*]\n[*]大家都可以发表贴士，社区一起参与贡献内容[/*]\n[*]贴士需要标识适用的版本号和对应的开源项目，如：Elasticsearch 6.x[/*]\n[*]贴士在得到3个赞之后，表示受到大家的认可，可以提供出现分享功能[/*]\n[*]分享功能要支持外部引用，生成 JS 脚本，随机显示一条贴士，可以挂在个人博客和网站上[/*]\n[*]可以对单条贴士生成一个图片，嵌入二维码，方便微信微博分享，显示贡献者和贡献者的个人签名[/*]\n[*]贴士不单独存储，还是在社区的文章模块，只不过发布的时候，需要选择分类为 “ElasticTips” 目录[/*]\n[*]搞一个微信小程序，方便分享传播贴士内容[/*]\n[/list]\n \n开发内容：\n[list]\n[*]API 模块：Golang 编写，负责读取数据库内容和生成 JS，RSS 订阅[/*]\n[*]JS 渲染模块：Golang 编写，负责渲染生成 JS[/*]\n[*]静态图片生成：Golang 编写，基于图片模板，渲染分享用的图片[/*]\n[*]单独的页面来展示贴士，主要要求是要酷炫?[/*]\n[*]微信小程序：貌似没得选，再者我也不懂[/*]\n[/list]\n \n好了，听起来有点意思，是不是很兴奋，那么问题来了，有没有兴趣一起来弄的呢？\n有兴趣的请加入 [url=https://join.slack.com/t/elastic-cn/shared_invite/enQtNDIzMzY5OTQ0MTY0LTc2NTU2M2E0NmRhYmVkM2YzZGNjNjI2ZTdmZmIxOWIxMjMzMDgwOWRlODg3MGE1NmFlYjBjZWI4MjVmMzk3YWI] Slack 讨论组[/url]。\n ","title":"Elastic Tips 项目","uid":"1","views":"366","votes":"8"},"_type":"doc"}
{"_id":"375","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510630201","category_id":"18","comments":"9","has_attach":"0","id":"375","message":"![community](https://mmbiz.qpic.cn/mmbiz_png/aX3kvnG35lD1KOqtPeTAKoz1q8rzRPxvEV2DYB3mNzYPvBH4BYzrPibT9ffKLC3BFLAxODOmCMspfK2zFKJhMMw/0?wx_fmt=png)\n\n我一直有看[湾区日报](http://wanqu.co/)的习惯，后来看到 Golang 中国社区的 astaxie 也在做 [GoCN 每日新闻](https://gocn.io/explore/category-14) 的事情。日报对社区来讲是一件持续输出的事情，对个人来讲是一件持续输入的事情，于是我决定在 Elastic 社区也做这么一件事情，在2017年7月30日我发布了 [Elastic日报 第1期](https://elasticsearch.cn/article/201)。\n\n当天和 medcl 聊过后，他建议发动社区的力量来做，这样才能保证日报做好做久。于是我们开始在社区里面招募日报编辑，很快便有很多同学响应，接着 `Elastic日报编辑部`成立。到今天，我们一共有8位社区编辑，其中7位负责每周固定一天的日报，另一位负责审稿和公众号文章发布。他们分别是：\n\n* 江水\n* 金桥\n* bsll\n* 至尊宝\n* 叮咚光军\n* laoyang360\n* cyberdak\n* 陶文\n\n感谢社区编辑们的付出，我们一同做了一件了不起的事情——持续100天的知识输出。如果有同学把这100天的日报内容都看完吃透，那它的Elastic 技术水准肯定提升了不止1个档次。\n\n现在想来，如果是我一个人做这件事情，恐怕日报不会超过30期。个人的力量是有限的，而社区的力量是无限的。每天看到编辑们精挑细选的文章，我都会诧异 Elastic 相关的优秀文章可真是多啊！\n\n相信社区的力量，让我们期待Elastic日报200期、300期甚至1000期的到来！","title":"写在 Elastic 日报100期时 —— 相信社区的力量","uid":"86","views":"604","votes":"11"},"_type":"doc"}
{"_id":"376","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510651342","category_id":"2","comments":"0","has_attach":"0","id":"376","message":"\n[b]org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Too many elements to create a power set 54[/b]\nat org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:50)\nat org.elasticsearch.hadoop.rest.ShardSorter$PowerSet.(ShardSorter.java:218)\nat org.elasticsearch.hadoop.rest.ShardSorter.powerList(ShardSorter.java:202)\nat org.elasticsearch.hadoop.rest.ShardSorter.checkCombo(ShardSorter.java:89)\nat org.elasticsearch.hadoop.rest.ShardSorter.find(ShardSorter.java:85)\nat org.elasticsearch.hadoop.rest.RestRepository.doGetReadTargetShards(RestRepository.java:352)\nat org.elasticsearch.hadoop.rest.RestRepository.getReadTargetShards(RestRepository.java:295)\nat org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:253)\nat org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute(AbstractEsRDD.scala:61)\nat org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions(AbstractEsRDD.scala:60)\nat org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions(AbstractEsRDD.scala:27)\nat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\nat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\nat scala.Option.getOrElse(Option.scala:120)\nat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\nat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\nat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\nat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)Users with the same issue\n \n解释：\nRead failure when index/alias spread among 32 or more nodes\n \nhttps://github.com/elastic/elasticsearch-hadoop/issues/737","title":"spark elasticsearch 异常： PowerSet: Too many elements to create a power set 40","uid":"3073","views":"416","votes":"0"},"_type":"doc"}
{"_id":"377","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510711997","category_id":"18","comments":"0","has_attach":"0","id":"377","message":"1、Elastic stack 6.0正式亮相\nhttps://www.elastic.co/blog/elastic-stack-6-0-0-released\n2、vts数据处理搜索引擎选型 \nhttp://t.cn/RjfQx01 \n3、如何监控、调优golang应用程序且看下文分晓 \nhttp://t.cn/RlA4biz \n4、elasticsearch性能分析123 \nhttp://t.cn/RjfEjN3 \n5、只等你来 | Elastic Meetup 广州交流会 \nhttps://elasticsearch.cn/article/364 \n \n编辑：wt \n归档：https://elasticsearch.cn/article/377\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第101期 (2017-11-15)","uid":"3851","views":"439","votes":"0"},"_type":"doc"}
{"_id":"379","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510724050","category_id":"5","comments":"2","has_attach":"1","id":"379","message":"[attach]1279[/attach]\r\n\r\n[https://www.elastic.co/cn/blog/elastic-stack-6-0-0-released](https://www.elastic.co/cn/blog/elastic-stack-6-0-0-released) \r\n\r\n全新推出 6.0.0。\r\n\r\n无需多说。你应该立即下载试用，或者通过你最喜欢的托管式 Elasticsearch 和 Kibana 提供平台 [Elastic Cloud](https://www.elastic.co/cn/cloud/as-a-service/signup) 亲身体验。\r\n\r\n如果你在过去几个月没有跟上我们的发布节奏，可能会对今天的公告感到意外。今天标志着成千上万的 pull 请求和成百上千位代码提交者的努力终见成效。期间共有两个 alpha 版本、两个 beta 版本、两个候选版本以及最终的通用版本 (GA)。这个里程碑离不开 Elastic 各路团队的努力。还要感谢参与[先锋计划](https://www.elastic.co/cn/blog/elastic-pioneer-program-6-0)的用户提出的意见和反馈。\r\n\r\n今天，我们不仅发布了整套 Elastic Stack，还发布了 [Elastic Cloud Enterprise 1.1](https://www.elastic.co/cn/cloud/enterprise)，其中包括 6.0 支持、离线安装，并且对用户体验进行了一系列改进，旨在简化集群的配置、管理和监控。同天发布多款产品的正式版本还不够……还有仍是 Alpha 版本的 APM ，我们邀请大家在 6.0.0 中对它进行测试。\r\n\r\n一个版本有如此多的亮点，该从哪里说起呢？你们撰文细述也好，提供详情链接也好，祝你们有愉快的阅读体验……更重要的是……祝你们有愉快的搜索、分析和可视化体验。\r\n\r\n## Elasticsearch\r\n\r\n全新零停机升级体验，增加了序列 ID、改进了对稀疏数据的处理、加快了查询速度、分布式执行 watch 等等。功能摘要请查看[详情](https://www.elastic.co/cn//blog/elasticsearch-6-0-0-released)。\r\n\r\n## Kibana\r\n\r\n支持 “Dashboard Only” 模式，支持 “全屏” 模式，能够将保存的搜索结果导出到 .csv，X-Pack 黄金版及以上版本支持通过 UI 创建告警，X-Pack 基础版提供迁移助手，我们还通过调整对比度、支持快捷键来产品易用性，让用户使用起来更方便。数据交互的未来详见[此贴](https://www.elastic.co/cn/blog/kibana-6-0-0-released)。\r\n\r\n## Logstash\r\n\r\n单一 Logstash 实例中可存在多个自成体系的管道，另有新增 UI 组件 - X-Pack 基础版中的管道查看器，以及 X-Pack 黄金版中的 Logstash 管道管理。了解详情，[点这里](https://www.elastic.co/cn/log/logstash-6-0-0-released)。\r\n\r\n## Beats\r\n\r\nBeats \u0026lt;3 容器以及 Beats \u0026lt;3 模块（并且改进了适用于这些模块的仪表板）。再结合全新命令和配置布局，在 Metricbeat 实现更高效的存储。此外，全新推出 Auditbeat。细节详见[这里](https://www.elastic.co/cn/blog/beats-6-0-0-released)。\r\n\r\n## ES-Hadoop\r\n\r\n对Spark的结构化数据流的一流支持已经降落到了 6.0，并重新编写了连接器映射代码以更好地支持多个映射。支持读写新的连接字段也被添加了。用户现在也可以利用非内联脚本类型的更新操作。[详细信息](https://www.elastic.co/blog/es-hadoop-6-0-0-released)。\r\n\r\n## 立即获取！\r\n\r\n- [Elasticsearch 下载](https://www.elastic.co/cn/downloads/elasticsearch)\r\n- [Kibana 下载](https://www.elastic.co/cn/downloads/kibana)\r\n- [Logstash 下载](https://www.elastic.co/cn/downloads/logstash)\r\n- [Beats 下载](https://www.elastic.co/cn/downloads/beats)\r\n- [ES-Hadoop 下载](https://www.elastic.co/cn/downloads/hadoop)\r\n- [安装 X-Pack](https://www.elastic.co/cn/downloads/x-pack)\r\n- [安装 Elastic Cloud 企业版](https://www.elastic.co/cn/downloads/enterprise)\r\n","title":"Elastic Stack 全新推出 6.0.0","uid":"1","views":"2079","votes":"2"},"_type":"doc"}
{"_id":"381","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510797226","category_id":"2","comments":"1","has_attach":"1","id":"381","message":"本节介绍以下 CRUD API：\n\n\n 单文档  APIs\n\n* [Index API](document-apis/index-api.md)\n* [Get API](document-apis/get-api.md)\n* [Delete API](document-apis/delete-api.md)\n* [Delete By Query API](document-apis/delete-by-query-api.md)\n* [Update API](document-apis/update-api.md)\n\n多文档 APIs\n\n* [Multi Get API](document-apis/multi-get-api.md)\n* [Bulk API](document-apis/bulk-api.md)\n* [Using Bulk Processor](document-apis/using-bulk-processor.md)\n\nMulti Get API\nBulk API\n\n\u0026gt; 注意:所有的单文档的CRUD API，index参数只能接受单一的索引库名称，或者是一个指向单一索引库的alias。\n\n### Index API\nIndex API 允许我们存储一个JSON格式的文档，使数据可以被搜索。文档通过index、type、id唯一确定。我们可以自己提供一个id，或者也使用Index API 为我们自动生成一个。\n\n这里有几种不同的方式来产生JSON格式的文档(document)：\n\n- 手动方式，使用原生的byte[]或者String\n- 使用Map方式，会自动转换成与之等价的JSON\n- 使用第三方库来序列化beans，如Jackson\n- 使用内置的帮助类 XContentFactory.jsonBuilder()\n\n#### 手动方式\n\n[数据格式](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/mapping-date-format.html)\n```\nString json = \u0026quot;{\u0026quot; +\n        \u0026quot;\\\u0026quot;user\\\u0026quot;:\\\u0026quot;kimchy\\\u0026quot;,\u0026quot; +\n        \u0026quot;\\\u0026quot;postDate\\\u0026quot;:\\\u0026quot;2013-01-30\\\u0026quot;,\u0026quot; +\n        \u0026quot;\\\u0026quot;message\\\u0026quot;:\\\u0026quot;trying out Elasticsearch\\\u0026quot;\u0026quot; +\n    \u0026quot;}\u0026quot;;\n```\n##### 实例\n\n```\n/**  \n * 手动生成JSON  \n */  \n@Test  \npublic void CreateJSON(){  \n      \n    String json = \u0026quot;{\u0026quot; +  \n            \u0026quot;\\\u0026quot;user\\\u0026quot;:\\\u0026quot;fendo\\\u0026quot;,\u0026quot; +  \n            \u0026quot;\\\u0026quot;postDate\\\u0026quot;:\\\u0026quot;2013-01-30\\\u0026quot;,\u0026quot; +  \n            \u0026quot;\\\u0026quot;message\\\u0026quot;:\\\u0026quot;Hell word\\\u0026quot;\u0026quot; +  \n        \u0026quot;}\u0026quot;;  \n      \n    IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n            .setSource(json)  \n            .get();  \n    System.out.println(response.getResult());  \n      \n}  \n```\n\n####  Map方式\nMap是key:value数据类型，可以代表json结构.\n\n```\nMap\u0026lt;String, Object\u0026gt; json = new HashMap\u0026lt;String, Object\u0026gt;();\njson.put(\u0026quot;user\u0026quot;,\u0026quot;kimchy\u0026quot;);\njson.put(\u0026quot;postDate\u0026quot;,new Date());\njson.put(\u0026quot;message\u0026quot;,\u0026quot;trying out Elasticsearch\u0026quot;);\n```\n##### 实例\n\n```\n /**  \n * 使用集合  \n */  \n@Test  \npublic void CreateList(){  \n      \n    Map\u0026lt;String, Object\u0026gt; json = new HashMap\u0026lt;String, Object\u0026gt;();  \n    json.put(\u0026quot;user\u0026quot;,\u0026quot;kimchy\u0026quot;);  \n    json.put(\u0026quot;postDate\u0026quot;,\u0026quot;2013-01-30\u0026quot;);  \n    json.put(\u0026quot;message\u0026quot;,\u0026quot;trying out Elasticsearch\u0026quot;);  \n      \n    IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n            .setSource(json)  \n            .get();  \n    System.out.println(response.getResult());  \n      \n}  \n```\n\n####  序列化方式\nElasticSearch已经使用了jackson，可以直接使用它把javabean转为json.\n\n```\nimport com.fasterxml.jackson.databind.*;\n\n// instance a json mapper\nObjectMapper mapper = new ObjectMapper(); // create once, reuse\n\n// generate json\nbyte[] json = mapper.writeValueAsBytes(yourbeaninstance);\n```\n##### 实例\n\n```\n/**  \n * 使用JACKSON序列化  \n * @throws Exception  \n */  \n@Test  \npublic void CreateJACKSON() throws Exception{  \n      \n    CsdnBlog csdn=new CsdnBlog();  \n    csdn.setAuthor(\u0026quot;fendo\u0026quot;);  \n    csdn.setContent(\u0026quot;这是JAVA书籍\u0026quot;);  \n    csdn.setTag(\u0026quot;C\u0026quot;);  \n    csdn.setView(\u0026quot;100\u0026quot;);  \n    csdn.setTitile(\u0026quot;编程\u0026quot;);  \n    csdn.setDate(new Date().toString());  \n      \n    // instance a json mapper  \n    ObjectMapper mapper = new ObjectMapper(); // create once, reuse  \n\n    // generate json  \n    byte[] json = mapper.writeValueAsBytes(csdn);  \n      \n    IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n            .setSource(json)  \n            .get();  \n    System.out.println(response.getResult());  \n}  \n```\n\n####  XContentBuilder帮助类方式\nElasticSearch提供了一个内置的帮助类XContentBuilder来产生JSON文档\n\n```\n// Index name\nString _index = response.getIndex();\n// Type name\nString _type = response.getType();\n// Document ID (generated or not)\nString _id = response.getId();\n// Version (if it's the first time you index this document, you will get: 1)\nlong _version = response.getVersion();\n// status has stored current instance statement.\nRestStatus status = response.status();\n```\n\n##### 实例\n\n```\n/**  \n * 使用ElasticSearch 帮助类  \n * @throws IOException   \n */  \n@Test  \npublic void CreateXContentBuilder() throws IOException{  \n      \n    XContentBuilder builder = XContentFactory.jsonBuilder()  \n            .startObject()  \n                .field(\u0026quot;user\u0026quot;, \u0026quot;ccse\u0026quot;)  \n                .field(\u0026quot;postDate\u0026quot;, new Date())  \n                .field(\u0026quot;message\u0026quot;, \u0026quot;this is Elasticsearch\u0026quot;)  \n            .endObject();  \n      \n    IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodata\u0026quot;).setSource(builder).get();  \n    System.out.println(\u0026quot;创建成功!\u0026quot;);  \n      \n      \n}  \n```\n\n#### 综合实例\n```\n \nimport java.io.IOException;  \nimport java.net.InetAddress;  \nimport java.net.UnknownHostException;  \nimport java.util.Date;  \nimport java.util.HashMap;  \nimport java.util.Map;  \n  \nimport org.elasticsearch.action.index.IndexResponse;  \nimport org.elasticsearch.client.transport.TransportClient;  \nimport org.elasticsearch.common.settings.Settings;  \nimport org.elasticsearch.common.transport.InetSocketTransportAddress;  \nimport org.elasticsearch.common.xcontent.XContentBuilder;  \nimport org.elasticsearch.common.xcontent.XContentFactory;  \nimport org.elasticsearch.transport.client.PreBuiltTransportClient;  \nimport org.junit.Before;  \nimport org.junit.Test;  \n  \nimport com.fasterxml.jackson.core.JsonProcessingException;  \nimport com.fasterxml.jackson.databind.ObjectMapper;  \n  \npublic class CreateIndex {  \n  \n    private TransportClient client;  \n      \n    @Before  \n    public void getClient() throws Exception{  \n        //设置集群名称  \n        Settings settings = Settings.builder().put(\u0026quot;cluster.name\u0026quot;, \u0026quot;my-application\u0026quot;).build();// 集群名  \n        //创建client  \n        client  = new PreBuiltTransportClient(settings)  \n                .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;127.0.0.1\u0026quot;), 9300));  \n    }  \n      \n    /**  \n     * 手动生成JSON  \n     */  \n    @Test  \n    public void CreateJSON(){  \n          \n        String json = \u0026quot;{\u0026quot; +  \n                \u0026quot;\\\u0026quot;user\\\u0026quot;:\\\u0026quot;fendo\\\u0026quot;,\u0026quot; +  \n                \u0026quot;\\\u0026quot;postDate\\\u0026quot;:\\\u0026quot;2013-01-30\\\u0026quot;,\u0026quot; +  \n                \u0026quot;\\\u0026quot;message\\\u0026quot;:\\\u0026quot;Hell word\\\u0026quot;\u0026quot; +  \n            \u0026quot;}\u0026quot;;  \n          \n        IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n                .setSource(json)  \n                .get();  \n        System.out.println(response.getResult());  \n          \n    }  \n      \n      \n    /**  \n     * 使用集合  \n     */  \n    @Test  \n    public void CreateList(){  \n          \n        Map\u0026lt;String, Object\u0026gt; json = new HashMap\u0026lt;String, Object\u0026gt;();  \n        json.put(\u0026quot;user\u0026quot;,\u0026quot;kimchy\u0026quot;);  \n        json.put(\u0026quot;postDate\u0026quot;,\u0026quot;2013-01-30\u0026quot;);  \n        json.put(\u0026quot;message\u0026quot;,\u0026quot;trying out Elasticsearch\u0026quot;);  \n          \n        IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n                .setSource(json)  \n                .get();  \n        System.out.println(response.getResult());  \n          \n    }  \n      \n    /**  \n     * 使用JACKSON序列化  \n     * @throws Exception  \n     */  \n    @Test  \n    public void CreateJACKSON() throws Exception{  \n          \n        CsdnBlog csdn=new CsdnBlog();  \n        csdn.setAuthor(\u0026quot;fendo\u0026quot;);  \n        csdn.setContent(\u0026quot;这是JAVA书籍\u0026quot;);  \n        csdn.setTag(\u0026quot;C\u0026quot;);  \n        csdn.setView(\u0026quot;100\u0026quot;);  \n        csdn.setTitile(\u0026quot;编程\u0026quot;);  \n        csdn.setDate(new Date().toString());  \n          \n        // instance a json mapper  \n        ObjectMapper mapper = new ObjectMapper(); // create once, reuse  \n  \n        // generate json  \n        byte[] json = mapper.writeValueAsBytes(csdn);  \n          \n        IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodate\u0026quot;)  \n                .setSource(json)  \n                .get();  \n        System.out.println(response.getResult());  \n    }  \n      \n    /**  \n     * 使用ElasticSearch 帮助类  \n     * @throws IOException   \n     */  \n    @Test  \n    public void CreateXContentBuilder() throws IOException{  \n          \n        XContentBuilder builder = XContentFactory.jsonBuilder()  \n                .startObject()  \n                    .field(\u0026quot;user\u0026quot;, \u0026quot;ccse\u0026quot;)  \n                    .field(\u0026quot;postDate\u0026quot;, new Date())  \n                    .field(\u0026quot;message\u0026quot;, \u0026quot;this is Elasticsearch\u0026quot;)  \n                .endObject();  \n          \n        IndexResponse response = client.prepareIndex(\u0026quot;fendo\u0026quot;, \u0026quot;fendodata\u0026quot;).setSource(builder).get();  \n        System.out.println(\u0026quot;创建成功!\u0026quot;);  \n          \n          \n    }  \n      \n}  \n```\n\n\n\u0026gt; 你还可以通过startArray(string)和endArray()方法添加数组。.field()方法可以接受多种对象类型。你可以给它传递数字、日期、甚至其他XContentBuilder对象。\n\n\n### Get API\n\n根据id查看文档：\n\n```\nGetResponse response = client.prepareGet(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;).get();\n\n```\n\n更多请查看 [rest get API](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-get.html) 文档\n\n#### 配置线程\n\n`operationThreaded` 设置为 `true` 是在不同的线程里执行此次操作\n\n下面的例子是`operationThreaded` 设置为 `false` ：\n```\nGetResponse response = client.prepareGet(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;)\n        .setOperationThreaded(false)\n        .get();\n```\n\n\n### Delete API\n\n根据ID删除：\n\n```\nDeleteResponse response = client.prepareDelete(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;).get();\n\n```\n\n更多请查看 [delete API](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-delete.html) 文档\n\n#### 配置线程\n\n`operationThreaded` 设置为 `true` 是在不同的线程里执行此次操作\n\n下面的例子是`operationThreaded` 设置为 `false` ：\n```\nGetResponse response = client.prepareGet(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;)\n        .setOperationThreaded(false)\n        .get();\n```\n\n```\nDeleteResponse response = client.prepareDelete(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;)\n        .setOperationThreaded(false)\n        .get();\n```\n\n\n### Delete By Query API\n\n通过查询条件删除\n\n```\nBulkByScrollResponse response =\n    DeleteByQueryAction.INSTANCE.newRequestBuilder(client)\n        .filter(QueryBuilders.matchQuery(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)) //查询条件\n        .source(\u0026quot;persons\u0026quot;) //index(索引名)\n        .get();  //执行\n\nlong deleted = response.getDeleted(); //删除文档的数量\n```\n\n如果需要执行的时间比较长，可以使用异步的方式处理,结果在回调里面获取\n\n\n```\nDeleteByQueryAction.INSTANCE.newRequestBuilder(client)\n    .filter(QueryBuilders.matchQuery(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;))      //查询            \n    .source(\u0026quot;persons\u0026quot;)                //index(索引名)                                    \n    .execute(new ActionListener\u0026lt;BulkByScrollResponse\u0026gt;() {     //回调监听     \n        @Override\n        public void onResponse(BulkByScrollResponse response) {\n            long deleted = response.getDeleted();   //删除文档的数量                 \n        }\n        @Override\n        public void onFailure(Exception e) {\n            // Handle the exception\n        }\n    });\n```\n\n\n### Update API\n\n有两种方式更新索引：\n- 创建 `UpdateRequest`,通过client发送；\n- 使用 `prepareUpdate()` 方法；\n\n#### 使用UpdateRequest\n\n```\nUpdateRequest updateRequest = new UpdateRequest();\nupdateRequest.index(\u0026quot;index\u0026quot;);\nupdateRequest.type(\u0026quot;type\u0026quot;);\nupdateRequest.id(\u0026quot;1\u0026quot;);\nupdateRequest.doc(jsonBuilder()\n        .startObject()\n            .field(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)\n        .endObject());\nclient.update(updateRequest).get();\n```\n\n#### 使用 `prepareUpdate()` 方法\n\n\u0026gt; 这里官方的示例有问题，new Script（）参数错误，所以一下代码是我自己写的（2017/11/10）\n\n```\nclient.prepareUpdate(\u0026quot;ttl\u0026quot;, \u0026quot;doc\u0026quot;, \u0026quot;1\u0026quot;)\n        .setScript(new Script(\u0026quot;ctx._source.gender = \\\u0026quot;male\\\u0026quot;\u0026quot;  ,ScriptService.ScriptType.INLINE, null, null))//脚本可以是本地文件存储的，如果使用文件存储的脚本，需要设置 ScriptService.ScriptType.FILE \n        .get();\n\nclient.prepareUpdate(\u0026quot;ttl\u0026quot;, \u0026quot;doc\u0026quot;, \u0026quot;1\u0026quot;)\n        .setDoc(jsonBuilder()   //合并到现有文档\n            .startObject()\n                .field(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)\n            .endObject())\n        .get();\n```\n\n#### Update by script\n\n使用脚本更新文档 \n\n```\nUpdateRequest updateRequest = new UpdateRequest(\u0026quot;ttl\u0026quot;, \u0026quot;doc\u0026quot;, \u0026quot;1\u0026quot;)\n        .script(new Script(\u0026quot;ctx._source.gender = \\\u0026quot;male\\\u0026quot;\u0026quot;));\nclient.update(updateRequest).get();\n\n```\n\n#### Update by merging documents\n\n合并文档\n\n```\nUpdateRequest updateRequest = new UpdateRequest(\u0026quot;index\u0026quot;, \u0026quot;type\u0026quot;, \u0026quot;1\u0026quot;)\n        .doc(jsonBuilder()\n            .startObject()\n                .field(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)\n            .endObject());\nclient.update(updateRequest).get();\n```\n\n\n#### Upsert\n更新插入,如果存在文档就更新，如果不存在就插入\n\n\n```\nIndexRequest indexRequest = new IndexRequest(\u0026quot;index\u0026quot;, \u0026quot;type\u0026quot;, \u0026quot;1\u0026quot;)\n        .source(jsonBuilder()\n            .startObject()\n                .field(\u0026quot;name\u0026quot;, \u0026quot;Joe Smith\u0026quot;)\n                .field(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)\n            .endObject());\nUpdateRequest updateRequest = new UpdateRequest(\u0026quot;index\u0026quot;, \u0026quot;type\u0026quot;, \u0026quot;1\u0026quot;)\n        .doc(jsonBuilder()\n            .startObject()\n                .field(\u0026quot;gender\u0026quot;, \u0026quot;male\u0026quot;)\n            .endObject())\n        .upsert(indexRequest); //如果不存在此文档 ，就增加 `indexRequest`\nclient.update(updateRequest).get();\n```\n\n如果 `index/type/1` 存在，类似下面的文档：\n\n\n```\n{\n    \u0026quot;name\u0026quot;  : \u0026quot;Joe Dalton\u0026quot;,\n    \u0026quot;gender\u0026quot;: \u0026quot;male\u0026quot;        \n}\n```\n\n如果不存在，会插入新的文档：\n\n\n```\n{\n    \u0026quot;name\u0026quot; : \u0026quot;Joe Smith\u0026quot;,\n    \u0026quot;gender\u0026quot;: \u0026quot;male\u0026quot;\n}\n```\n\n### Multi Get API\n一次获取多个文档\n\n\n```\nMultiGetResponse multiGetItemResponses = client.prepareMultiGet()\n    .add(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;) //一个id的方式\n    .add(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;3\u0026quot;, \u0026quot;4\u0026quot;) //多个id的方式\n    .add(\u0026quot;another\u0026quot;, \u0026quot;type\u0026quot;, \u0026quot;foo\u0026quot;)  //可以从另外一个索引获取\n    .get();\n\nfor (MultiGetItemResponse itemResponse : multiGetItemResponses) { //迭代返回值\n    GetResponse response = itemResponse.getResponse();\n    if (response.isExists()) {      //判断是否存在                \n        String json = response.getSourceAsString(); //_source 字段\n    }\n}\n```\n更多请浏览REST [multi get](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-multi-get.html) 文档\n\n\n\n### Bulk API\n\nBulk API，批量插入：\n\n```\nimport static org.elasticsearch.common.xcontent.XContentFactory.*;\n```\n\n```\nBulkRequestBuilder bulkRequest = client.prepareBulk();\n\n// either use client#prepare, or use Requests# to directly build index/delete requests\nbulkRequest.add(client.prepareIndex(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;)\n        .setSource(jsonBuilder()\n                    .startObject()\n                        .field(\u0026quot;user\u0026quot;, \u0026quot;kimchy\u0026quot;)\n                        .field(\u0026quot;postDate\u0026quot;, new Date())\n                        .field(\u0026quot;message\u0026quot;, \u0026quot;trying out Elasticsearch\u0026quot;)\n                    .endObject()\n                  )\n        );\n\nbulkRequest.add(client.prepareIndex(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;2\u0026quot;)\n        .setSource(jsonBuilder()\n                    .startObject()\n                        .field(\u0026quot;user\u0026quot;, \u0026quot;kimchy\u0026quot;)\n                        .field(\u0026quot;postDate\u0026quot;, new Date())\n                        .field(\u0026quot;message\u0026quot;, \u0026quot;another post\u0026quot;)\n                    .endObject()\n                  )\n        );\n\nBulkResponse bulkResponse = bulkRequest.get();\nif (bulkResponse.hasFailures()) {\n    // process failures by iterating through each bulk response item\n    //处理失败\n}\n```\n\n\n### 使用 Bulk Processor\nBulkProcessor 提供了一个简单的接口，在给定的大小数量上定时批量自动请求\n\n#### 创建`BulkProcessor`实例\n\n首先创建`BulkProcessor`实例\n\n```\nimport org.elasticsearch.action.bulk.BackoffPolicy;\nimport org.elasticsearch.action.bulk.BulkProcessor;\nimport org.elasticsearch.common.unit.ByteSizeUnit;\nimport org.elasticsearch.common.unit.ByteSizeValue;\nimport org.elasticsearch.common.unit.TimeValue;\n```\n\n```\nBulkProcessor bulkProcessor = BulkProcessor.builder(\n        client,  //增加elasticsearch客户端\n        new BulkProcessor.Listener() {\n            @Override\n            public void beforeBulk(long executionId,\n                                   BulkRequest request) { ... } //调用bulk之前执行 ，例如你可以通过request.numberOfActions()方法知道numberOfActions\n\n            @Override\n            public void afterBulk(long executionId,\n                                  BulkRequest request,\n                                  BulkResponse response) { ... } //调用bulk之后执行 ，例如你可以通过request.hasFailures()方法知道是否执行失败\n\n            @Override\n            public void afterBulk(long executionId,\n                                  BulkRequest request,\n                                  Throwable failure) { ... } //调用失败抛 Throwable\n        })\n        .setBulkActions(10000) //每次10000请求\n        .setBulkSize(new ByteSizeValue(5, ByteSizeUnit.MB)) //拆成5mb一块\n        .setFlushInterval(TimeValue.timeValueSeconds(5)) //无论请求数量多少，每5秒钟请求一次。\n        .setConcurrentRequests(1) //设置并发请求的数量。值为0意味着只允许执行一个请求。值为1意味着允许1并发请求。\n        .setBackoffPolicy(\n            BackoffPolicy.exponentialBackoff(TimeValue.timeValueMillis(100), 3))//设置自定义重复请求机制，最开始等待100毫秒，之后成倍更加，重试3次，当一次或多次重复请求失败后因为计算资源不够抛出 EsRejectedExecutionException 异常，可以通过BackoffPolicy.noBackoff()方法关闭重试机制\n        .build();\n```\n#### BulkProcessor 默认设置\n- bulkActions  1000 \n- bulkSize 5mb\n- 不设置flushInterval\n- concurrentRequests 为 1 ，异步执行\n- backoffPolicy 重试 8次，等待50毫秒\n\n#### 增加requests\n然后增加`requests`到`BulkProcessor`\n```\nbulkProcessor.add(new IndexRequest(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;1\u0026quot;).source(/* your doc here */));\nbulkProcessor.add(new DeleteRequest(\u0026quot;twitter\u0026quot;, \u0026quot;tweet\u0026quot;, \u0026quot;2\u0026quot;));\n```\n#### 关闭 Bulk Processor\n当所有文档都处理完成，使用`awaitClose` 或 `close` 方法关闭`BulkProcessor`:\n\n\n```\nbulkProcessor.awaitClose(10, TimeUnit.MINUTES);\n\n```\n或\n\n```\nbulkProcessor.close();\n\n```\n\n#### 在测试中使用Bulk Processor\n\n如果你在测试种使用`Bulk Processor`可以执行同步方法\n```\nBulkProcessor bulkProcessor = BulkProcessor.builder(client, new BulkProcessor.Listener() { /* Listener methods */ })\n        .setBulkActions(10000)\n        .setConcurrentRequests(0)\n        .build();\n\n// Add your requests\nbulkProcessor.add(/* Your requests */);\n\n// Flush any remaining requests\nbulkProcessor.flush();\n\n// Or close the bulkProcessor if you don't need it anymore\nbulkProcessor.close();\n\n// Refresh your indices\nclient.admin().indices().prepareRefresh().get();\n\n// Now you can start searching!\nclient.prepareSearch().get();\n```\n\n[所有实例](https://gitee.com/quanke/elasticsearch-java-study) 已经上传到Git\n\n\n更多请浏览 [spring-boot-starter-es](https://github.com/quanke/spring-boot-starter-es) 开源项目\n\n\n\n\n\u0026gt; 如何有任何问题请关注微信公众号给我留言\n\n\n[attach]1282[/attach]\n\n ","title":"Elasticsearch Java API 索引的增删改查（二）","uid":"6646","views":"3717","votes":"0"},"_type":"doc"}
{"_id":"390","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511315205","category_id":"18","comments":"0","has_attach":"0","id":"390","message":"1.Elasticsearch中文分词插件IK安装、使用\nhttp://t.cn/RYPBZVw \n2.如何使用Elastic APM\nhttp://t.cn/RYPrtHJ\n3.理解Elasticsearch缓存从下面开始\nhttp://t.cn/RYh7cbu\n \n编辑：wt\n归档：https://elasticsearch.cn/article/390\n订阅：https://tinyletter.com/elastic-daily  ","title":"Elastic日报 第108期 (2017-11-22)","uid":"3851","views":"405","votes":"0"},"_type":"doc"}
{"_id":"391","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511404041","category_id":"18","comments":"0","has_attach":"0","id":"391","message":"1.基于word2vec和Elasticsearch实现个性化搜索\nhttp://t.cn/R6SGWTP\n2.一个数据精度引发的血案\nhttp://t.cn/RY75Xu8\n3.关于Elasticsearch部署中的内存注意事项\nhttp://t.cn/RY75Oy6\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/391\n订阅：https://tinyletter.com/elastic-daily  ","title":"Elastic日报 第109期 (2017-11-23)","uid":"668","views":"456","votes":"0"},"_type":"doc"}
{"_id":"392","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511453495","category_id":"18","comments":"1","has_attach":"0","id":"392","message":"1、Elasticsearch要升级到6.0，先滚动升级5.X！\nhttp://t.cn/RYzDIQw\n2、ES冷热数据分离实践\nhttp://t.cn/RjeBOfl\n3、ELK搭建GPE监控预警系统\n[url]http://t.cn/RYzDusL[/url] \n\n编辑：laoyang360\n归档：https://elasticsearch.cn/article/392\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第110期 (2017-11-24)","uid":"1341","views":"534","votes":"1"},"_type":"doc"}
{"_id":"393","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511496097","category_id":"12","comments":"0","has_attach":"0","id":"393","message":"工作地点：北京、杭州\n\n负责蚂蚁中间件搜索产品线的核心研发工作， 能够根据产品的需求， 设计相应的技术方案。参与搜索产品各个功能模块的设计和实现， 构建高可靠性、高可扩展性的体系结构，满足日趋复杂的业务需求；\n \n岗位要求:\n \n1.3年以上搜索平台研发经验，具备扎实的计算机理论基础, 对数据结构及算法有较强的功底，对搜索引擎底层有较为深刻的了解\n2.精通Java语言编程，具备优秀的系统Debug/Profiling能力和经验 \n3.熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力 \n4.熟悉Hadoop/HBase/Spark/Storm/Kafka等开源技术，在开源社区活跃者优先 \n\n ","title":"【北京，杭州】支付宝中间件招ES相关搜索工程师","uid":"4698","views":"1448","votes":"0"},"_type":"doc"}
{"_id":"398","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511766921","category_id":"16","comments":"4","has_attach":"0","id":"398","message":"今天正式启动 **ElasticTalk** 的活动，旨在通过线上直播的方式和大家交流 elastic 产品相关的知识。\n第一期将于**本周四（11月30日）晚8点**在线直播，主题为**使用 ElasticStack 收集和分析 Nginx 日志**。感兴趣的同学可以加群讨论！\n\n![elastic_tips.001.jpeg](http://upload-images.jianshu.io/upload_images/21242-aa80f83f411a5e95.jpeg)\n","title":"ElasticTalk 第一期来袭！使用 ElasticStack 收集分析 Nginx 日志","uid":"86","views":"928","votes":"2"},"_type":"doc"}
{"_id":"399","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511830040","category_id":"18","comments":"0","has_attach":"0","id":"399","message":"1.基于 Kafka 和 ElasticSearch，LinkedIn构建实时日志分析系统。\n[url]http://t.cn/RYffDoE[/url]  \n2.用漫画的形式给你讲搜索的故事，值得一看。\n[url]http://t.cn/RYfIZ0Q[/url]  \n3.使用Spark与Elasticsearch构建一个推荐系统。\n[url]http://t.cn/RYfMJa2[/url] \n \n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/399[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n  \n ","title":"Elastic日报 第114期 (2017-11-28)","uid":"3788","views":"423","votes":"0"},"_type":"doc"}
{"_id":"404","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512263724","category_id":"18","comments":"0","has_attach":"0","id":"404","message":"1.通过suggest API构建自动完成功能。\nhttp://t.cn/RYpIcvs\n2.Elasticsearch字段映射管理。\nhttp://t.cn/RYpSnsu\n3.(自备梯子)AI与区块链的融合：交易是什么？\nhttp://t.cn/RYpoyuK\n4.(日语)Elastic Advent Calendar, Day 2:  如何制作Ingest插件\nhttp://t.cn/RYpobOt\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/404\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第119期 (2017-12-03)","uid":"4460","views":"345","votes":"0"},"_type":"doc"}
{"_id":"410","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512611008","category_id":"18","comments":"3","has_attach":"0","id":"410","message":"1.基于Metricbeat和ELK的Docker性能监控\nhttp://t.cn/RY3lgw1\n2.超级简单的在Kubernetes上构建Elasticsearch集群\nhttp://t.cn/RiuNMXw\n3.一个新的 UI 框架：Elastic UI Framework\nhttps://elasticsearch.cn/article/409\n4.(韩文)Elastic Advent Calendar Day 6,使用cross cluster search进行跨集群搜索\nhttp://t.cn/RY3YPab\n5.Elastic Meetup 深圳交流会\nhttps://elasticsearch.cn/article/406\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/410\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第123期 (2017-12-07)","uid":"668","views":"461","votes":"0"},"_type":"doc"}
{"_id":"414","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512972588","category_id":"18","comments":"0","has_attach":"0","id":"414","message":"1.使用grafana作为数据展示层查看es中的数据。\nhttp://t.cn/RTLuxtG\n2.手把手教你如何使用es来存储java日志。\nhttp://t.cn/RTLr6qQ\n3.使用ansible来管理elasticsearch的指南书。\nhttp://t.cn/RTLgFGv\n4.(德文)Elastic Advent Calendar, Day 10: 使用Elastic Stack来中心化存储日志\n[url]http://t.cn/RTL3N8I[/url]\n \n编辑：cyberdak\n归档：https://elasticsearch.cn/article/414\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第127期 (2017-12-11)","uid":"4063","views":"410","votes":"0"},"_type":"doc"}
{"_id":"416","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513130080","category_id":"18","comments":"0","has_attach":"0","id":"416","message":"1. 聊聊蝇量级搜索平台设计\n[url]http://t.cn/RTIVNkj[/url] \n2. ELK + Filebeat 搭建日志系统\n[url]http://t.cn/RTIVDt1[/url] \n3. 去哪儿客户端全业务线用户行为数据ETL介绍\n[url]http://t.cn/RYsXRym[/url] \n4. (意大利语)Elastic Advent Calendar, Day 12:Elastic Stack监控比特币\n[url]http://t.cn/RTIXXNC[/url]\n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/416[/url]\n订阅： [url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第129期 (2017-12-13)","uid":"3828","views":"353","votes":"0"},"_type":"doc"}
{"_id":"418","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513292834","category_id":"18","comments":"1","has_attach":"0","id":"418","message":"1、尝鲜|Kibana Canvas 新特性体验\nhttp://t.cn/RTXWZeN\n2、kafka导入ElasticSearch实践第二弹\nhttp://t.cn/RT6wGgG\n3、Elasticsearch在云平台使用指南\nhttp://t.cn/RYDVunk\n4、[日文]用Analyze API了解倒排索引和文本分析\nhttp://t.cn/RT6y399\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/418\n订阅： https://tinyletter.com/elastic-daily\n ","title":"  Elastic日报 第131期 (2017-12-15)","uid":"1341","views":"461","votes":"0"},"_type":"doc"}
{"_id":"420","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513435251","category_id":"4","comments":"0","has_attach":"1","id":"420","message":"最近想研究kibana源码，看看他的可视化部分的实现，花了两天才把webpack初始化成功，其中的出现的问题就是在平常看来很正常的一步，导致我卡了很久\r\n\r\n\r\n\r\n\r\n（一）选择master分支 下载到本地 https://github.com/elastic/kibana.git，不过貌似选不选分支都一样，我选了个5.2版本的下到本地还是最新版的7.0alpha版\r\n\r\n（二） 切到kibana目录下 运行npm install.....\r\n\r\n在这里我为了图快。。。用了淘宝镜像cnpm install.....然后坑爹的事情发生了~~~~~安装成功运行下一步 npm run elasticsearch的时候开始无尽的报\r\n\r\n错。。。。都是依赖找不到。。然后安装对应依赖后又出现其他依赖找不到的情况。。。重复几次还是不行。。后来幸亏钉钉群里的大牛们告诉我要严格按照\r\n\r\nCONTRIBUTING.md 这里的步骤来。。然后 我删掉来项目 重新 按照文档步骤来 果然 一步到位~~~~~直接npm install哦\r\n\r\n\r\n\r\n\r\n[attach]1461[/attach]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n（三）然后就可以运行  npm run elasticsearch  是的不用去官网再下elasticsearch的可执行文件了，这时会出现以下cluster的下载信息，这个等待时间会很长。。可以先干点别的事情去：） \r\n\r\n[attach]1460[/attach]\r\n\r\n（四）node scripts/makelogs這步没啥好说的。。。。\r\n\r\n（五）在config/kibana.yml中加上：optimize.enabled：false..加上这句的原因为了时时看到源码修改后页面的结果\r\n\r\n     因为修改之前服务是优先使用bundle.js内容，而不会每次都进到各源码目录执行，这样的话每次该源码是不会看到kibana页面有变化的。。\r\n\r\n（六）运行 npm run start 开始改代码吧","title":"]kibana源码修改（一）webpack初始化爬坑","uid":"7142","views":"1801","votes":"0"},"_type":"doc"}
{"_id":"421","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513439749","category_id":"2","comments":"0","has_attach":"0","id":"421","message":"\n刚刚初始化启动kiabna后是没有索引的，当然，如果elasticsearch中导入过数据那么kibana会自动匹配索引\n现在按照官方例子开始批量给elasticsearch导入数据\n链接如下https://www.elastic.co/guide/en/kibana/6.1/tutorial-load-dataset.html\n我们会依次导入如下 三块数据 \n1.The Shakespeare data 莎士比亚文集的数据结构\n\n\n{\n    \u0026quot;line_id\u0026quot;: INT,\n    \u0026quot;play_name\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;speech_number\u0026quot;: INT,\n    \u0026quot;line_number\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;speaker\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;text_entry\u0026quot;: \u0026quot;String\u0026quot;,\n}\n2.The accounts data  账户数据结构\n\n\n{\n    \u0026quot;account_number\u0026quot;: INT,\n    \u0026quot;balance\u0026quot;: INT,\n    \u0026quot;firstname\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;lastname\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;age\u0026quot;: INT,\n    \u0026quot;gender\u0026quot;: \u0026quot;M or F\u0026quot;,\n    \u0026quot;address\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;employer\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;email\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;city\u0026quot;: \u0026quot;String\u0026quot;,\n    \u0026quot;state\u0026quot;: \u0026quot;String\u0026quot;\n}\n3.The schema for the logs data 日志数据\n\n\n{\n    \u0026quot;memory\u0026quot;: INT,\n    \u0026quot;geo.coordinates\u0026quot;: \u0026quot;geo_point\u0026quot;\n    \u0026quot;@timestamp\u0026quot;: \u0026quot;date\u0026quot;\n}\n然后向elasticsearch设置字段映射\nUse the following command in a terminal (eg bash) to set up a mapping for the Shakespeare data set:\n以下是莎士比亚的字段映射 可以用postman或者curl等发出请求~完整的url应该是localhost:9200/shakespear\nPUT /shakespeare\n{\n \u0026quot;mappings\u0026quot;: {\n  \u0026quot;doc\u0026quot;: {\n   \u0026quot;properties\u0026quot;: {\n    \u0026quot;speaker\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;},\n    \u0026quot;play_name\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;},\n    \u0026quot;line_id\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;},\n    \u0026quot;speech_number\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;}\n   }\n  }\n }\n}\nUse the following commands to establish geo_point mapping for the logs:\n这是 logs的字段映射\nPUT /logstash-2015.05.18\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;log\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;geo\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;coordinates\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n            }\n          }\n        }\n      }\n    }\n  }\n}\n \nPUT /logstash-2015.05.19\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;log\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;geo\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;coordinates\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n            }\n          }\n        }\n      }\n    }\n  }\n}\nCOPY AS CURLVIEW IN CONSOLE \nPUT /logstash-2015.05.20\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;log\u0026quot;: {\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;geo\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;coordinates\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n            }\n          }\n        }\n      }\n    }\n  }\n}\n账户信息没有字段映射。。。\n现在批量导入\ncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json\ncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.json\ncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl\n[b]windows下的curl命令可以到https://curl.haxx.se/download.html#Win64下载，解压后设置环境变量即可\n这里要注意的是 @accounts.json，@shakespeare_6.0.json，@logs.json这些文件的位置应该是你所在的当前目录，\n如果你当前位置是D盘~那么这些文件位置就要放在D盘下，否则读不到\n还有一点~~~windows下要把命令行中的单引号换成双引号，，。。。否则会报\ncurl: (6) Could not resolve host: application这样的错误[/b]\n\n ","title":"elasticsearch批量导入数据注意事项","uid":"7142","views":"3316","votes":"0"},"_type":"doc"}
{"_id":"422","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513476941","category_id":"18","comments":"0","has_attach":"0","id":"422","message":"1.使用ELK监控OpenStack。\nhttp://t.cn/RTpfMIR\n2.(自备梯子)在Kubernetes上使用ELK记录日志。\nhttp://t.cn/RTpMOnw\n3.(自备梯子)算法是新的药物。\nhttp://t.cn/RTpiSiE\n4.(法语)Elastic Advent Calendar, Day 16:  Elasticsearch插件的测试表现\nhttp://t.cn/RTpJjwF\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/422\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第133期 (2017-12-17)","uid":"4460","views":"418","votes":"0"},"_type":"doc"}
{"_id":"424","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513564188","category_id":"3","comments":"2","has_attach":"1","id":"424","message":"\r\n[attach]1462[/attach]\r\n收集网络设备的日志，但是格式不统一，很苦恼，而且仅仅时间戳格式就有快10种不同格式，测试发现date不支持BJT时区","title":"logstash date不支持BJT时区","uid":"6110","views":"890","votes":"0"},"_type":"doc"}
{"_id":"433","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514169463","category_id":"18","comments":"0","has_attach":"0","id":"433","message":"1.XPack 6的改动:移除了默认密码。\nhttp://t.cn/RHAyUPV\n\n2.如何构建一个搜索UI。\nhttp://t.cn/RToO9aU\n\n3.使用ELK监控Spark集群。\nhttp://t.cn/RHAA6Me\n\n4.(德语)Elastic Advent Calendar, Day 24:  用Elasticsearch和Kibana进行数据探索\n[url]http://t.cn/RHAZZbV[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/433\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第141期 (2017-12-25)","uid":"4063","views":"383","votes":"0"},"_type":"doc"}
{"_id":"436","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514335835","category_id":"18","comments":"0","has_attach":"0","id":"436","message":"1. elasticsearch recovery 分析\nhttp://t.cn/RH5T64q\n2. elasticsearch aggregations 聚合分析\nhttp://t.cn/RH5TCdm\n3. logstash-output-jdbc 插件 支持hbase(phoenix)\nhttp://t.cn/RH5HPeD\n \n编辑：江水\n归档：https://elasticsearch.cn/article/436 \n订阅：https://tinyletter.com/elastic-daily  \n","title":"Elastic日报 第143期 (2017-12-27)","uid":"3828","views":"451","votes":"0"},"_type":"doc"}
{"_id":"435","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514252228","category_id":"18","comments":"0","has_attach":"0","id":"435","message":"1.如何使用Grafana从Elasticsearch中拉取数据。\n[url]http://t.cn/RH2FFXU[/url] \n2.基于Elasticsearch的沪江搜索平台。\n[url]http://t.cn/RHLZSEk[/url] \n3.使用Elasticsearch的五个结论。\n[url]http://t.cn/RHLwxM8[/url] \n4.Elastic Advent Calendar, Day 25:Elastic Advent Calendar最后一文，一些众所周知的权威建议。\n[url]http://t.cn/RHLyzo4[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/435[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]  \n ","title":"Elastic日报 第142期 (2017-12-26)","uid":"3788","views":"520","votes":"0"},"_type":"doc"}
{"_id":"444","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515288173","category_id":"18","comments":"0","has_attach":"0","id":"444","message":"1. 如何使用Elasticsearch构建“Did You Mean”。\n[http://t.cn/RHBw74U](http://t.cn/RHBw74U) \n\n2. 使用基于上下文的自动完成功能让Elasticsearch自动完成更强大。\n[http://t.cn/RHB2SEi](http://t.cn/RHB2SEi) \n\n3. (自备梯子)Elasticsearch:构建自动完成功能。\n[http://t.cn/RHBytRS](http://t.cn/RHBytRS) \n\n* 编辑：至尊宝\n\n* 归档：https://elasticsearch.cn/article/444\n\n* 订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第151期 (2018-01-07)","uid":"4460","views":"408","votes":"0"},"_type":"doc"}
{"_id":"447","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515460965","category_id":"18","comments":"0","has_attach":"0","id":"447","message":"1.使用Amazon(AWS) Comprehend自动提取元数据并索引至ES6实现快速搜索。\n[url]http://t.cn/RHDkDuq[/url] \n2.使用ELK分析RunKeeper日志。\n[url]http://t.cn/RHDk1Xa[/url] \n3.Spark与Elasticsearch整合案例详解。\n[url]http://t.cn/RHDs2zw[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/447[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第153期 (2018-01-09)","uid":"3788","views":"353","votes":"0"},"_type":"doc"}
{"_id":"454","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515894890","category_id":"18","comments":"0","has_attach":"0","id":"454","message":"1. 如何使用Elasticsearch下载字段的所有独特术语。\n[http://t.cn/RQGh4wl](http://t.cn/RQGh4wl) \n\n2. 如何在Elasticsearch中找到相似的术语。\n[http://t.cn/RQGz6Pt](http://t.cn/RQGz6Pt) \n\n3. (自备梯子)想成为一名数据科学家？尝试费曼技术。\n[http://t.cn/RQGwPhu](http://t.cn/RQGwPhu) \n\n* 编辑：至尊宝\n\n* 归档：https://elasticsearch.cn/article/454\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第158期 (2018-01-14)","uid":"4460","views":"376","votes":"0"},"_type":"doc"}
{"_id":"455","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515994759","category_id":"18","comments":"0","has_attach":"0","id":"455","message":"1.kibana 6 三个让人喜爱的新特性。\nhttp://t.cn/RQcxAWA\n\n2.使用XPACK来完成基于属性的权限控制。\nhttp://t.cn/RQcJD9h\n\n3.Beats 6.1 新特性。\n[url]http://t.cn/RQc65os[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/455\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第159期 (2018-01-15)","uid":"4063","views":"297","votes":"0"},"_type":"doc"}
{"_id":"456","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516067056","category_id":"18","comments":"0","has_attach":"0","id":"456","message":"1.使用ELK监控Puppet服务器。\n[url]http://t.cn/RQfQf6L[/url] \n2.TableStore+Elasticsearch，海量图书信息全文检索系统实践。\n[url]http://t.cn/RYvNMD3[/url] \n3.社区好文，wood叔原创，ElasticSearch集群故障案例分析之警惕通配符查询。\n[url]https://elasticsearch.cn/article/171[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/456[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":" Elastic日报 第160期 (2018-01-16)","uid":"3788","views":"329","votes":"0"},"_type":"doc"}
{"_id":"462","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516418890","category_id":"18","comments":"0","has_attach":"0","id":"462","message":"几篇旧闻\n1. Elasticsearch 联结查询 joining queries\n[url]http://t.cn/RQNunNP[/url] \n2. Elasticsearch 中的 ignore_above\n[url]http://t.cn/RQNu1fW[/url] \n3. Migration Patterns: Elasticsearch\nhttp://t.cn/RQp8yGC\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/462[/url]\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第164期 (2018-01-20)","uid":"3828","views":"343","votes":"0"},"_type":"doc"}
{"_id":"465","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516606044","category_id":"2","comments":"0","has_attach":"0","id":"465","message":"\u0026gt; Elasticsearch 和大多数的组件是一样，你若想要她全心全意的为你服务，你就必须满足她的需求，毕竟巧妇也难为无米之炊嘛。\n\u0026gt; Elasticsearch 的要求不高，仅仅需要合适的操作系统和JVM版本，这是最基本的要求了，如果无法满足还请放开她。\n\n## 操作系统\n\n![操作系统版本依赖](http://elasticsearch.club/wp-content/uploads/2018/01/os.png)\n\n\n若没有特殊说明，以后文章中ES的操作系统运行环境默认为 :\n\n\t\tCentOS Linux release 7.2.1511 (Core)\n\n## JVM\n\n![JVM版本依赖](http://elasticsearch.club/wp-content/uploads/2018/01/jvm.png)\n\n\n若没有特殊说明，以后文章中运行ES的Java版本默认为 :  \n\n\t\tJava version 1.8.0_102\n\n\n\n## 挑选合适的Elasticsearch版本\n如何选择Elasticsearch 版本与如何选择找女朋友的原理是一样的。\n新的版本、年轻的姑娘相信大家都喜欢.但是新的姑娘大部都分经历少、\n可能家务也不会做，如果这缺点你有接受那没有问题。新的Elasticsearch 版本也是一样，\n新的Elasticsearch 插件的支持可能没有那么好，新特性未被实际的生产环境验证过，如果\n这些都能容忍，那么使用**最新的Elasticsearch版本**是最好的选择。\n\n### 下载Elasticsearch \n\n[Elasticsearch下载](https://www.elastic.co/downloads/elasticsearch)  （ ←  右击在新标签页打开 ^-^）\n\n\n## 解压到指定位置\n```\n1. mkdir -p $ES_HOME_PARENT  //创建用于存放elasticsearch组件的父目录\n2. tar -zxvf elasticsearch-6.1.1.tar.gz  -C $ES_HOME_PARENT \n3. cd  $ES_HOME_PARENT\n4. mv elasticsearch-6.1.1 es-6.1.1_benchmark611 //修改个名称\n5. mkdir -p $ES_DATA_PATH/store/es-6.1.1_benchmark611  //用于存放Elasticsearch 数据\n6. mkdir -p $ES_DATA_PATH/logs/es-6.1.1_benchmark611 //用于存放Elasticsearch 日志 \n```\n\n## 启动前检查\n\n### Linux 系统参数检查\n\u0026gt; 为什么要设置这些系统参数呢？如果不设置会对集群产生哪些影响呢？\n\n\n**文件句柄( File Descriptors)**\n\t如果设置过小的文件句柄，Elasticsearch 将无法与集群进行通信以及创建新的索引。\n\t\n**内存锁定(Memory Lock)**\n\t如果没有锁定内存，操作系统会扫描不使用的内存并把他交换到磁盘上，需要的时候\n\t在加载到内存中。这样的操作会引起磁盘抖动，对于低延时的请求会造成比较大的伤害。\n\t因为JVM已经有垃圾回收器，所以不需要操作系统层面的策略来管理内存，在这里我们\n\t锁定内存来阻止系统层面插手内存管理 。\n\t\n**用户线程限制（User maximum number of threads）**\n\tElasticsearch 中有各种线程池，每种线程池里都会运行着不同的任务，如果操作系统支持的用户线程数据设置的较低，\n\t集群将无法创建更多的线程运行任务，导致集群无法正常工作。\n\t\n**虚拟内存（Virtual Memory）**\n\t操作系统默认virtual memory都是unlimited,如果不是就重新设置，主要与内存映射总数配置同时设置，加速访问索引数据访问。\n\t\n### 设置 文件句柄( File Descriptors) 、 内存锁定(Memory Lock)、用户线程限制（User maximum number of threads）\n\n如下图，我已经修改了操作系统设置,如果你还没设置请用下面的命令设置\n查询命令（**ulimit -a**）\n![操作系统设置](http://elasticsearch.club/wp-content/uploads/2018/01/system.png)\n\n修改命令（执行此命令需要root 权限）\n```\nvim /etc/security/limits.conf \n\tesadmin soft nproc 40000\n\tesadmin hard nproc 40000\n\tesadmin soft nofile 65536\n\tesadmin hard nofile 65536\n\tesadmin soft  memlock -1\n\tesadmin hard memlock -1\n```\n\n\n\n\u0026gt; 内存映射总数(Max Map Count)\n\n\n**内存映射总数(Max Map Count)**\n\tElasticsearch使用mmap把索引映射到虚拟内存空间，Elasticsearch 同样也需求足够的数据来创建内存映射区域。\n\tElasticsearch 要求最大内存映射总数至少设置 262144，过小可能无法完成索引的映射\n\t\n修改命令（执行此命令需要root 权限）\n```\nsysctl -w vm.max_map_count=262144\n```\n\n\n除了以上只是启动前更多需要检查的配置如下\n\n[ES启动前检查](https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html) （ ←  右击在新标签页打开 ^-^）\n\n\n## 集群运行最少的参数配置\n```\n这是Master Node 配置参数\nvim $ES_HOME/config/elasticsearch.yml\n```\n\n```\n# ======================== ES 参数配置 =========================\n#\n#\n# ------------------------ 集群设定 ----------------------------\n#\n# 集群名称 \n cluster.name: benchmark612\n#\n# ------------------------ 节点设定 ----------------------------\n#\n# 节点名称\n node.name: ${HOSTNAME}\n#\n# 节点角色\n node.master: true\n node.data: false\n node.ingest: false\n#\n# ------------------------ 路径设定 ----------------------------\n#\n# 索引、日志存放路径\n path:\n   data: /data/store/es-6.1.2_benchmark612\n   logs: /data/logs/es-6.1.2_benchmark612\n#\n# ------------------------ 内存设定 ----------------------------\n#\n#\n# 锁定内存，阻止操作系统管理内存，可以有效的防止内存数据被交换到磁盘空间，\n#   交换过程中磁盘会抖动，会对性能产生较大的影响。因为ES是基于JAVA开发的\n#   可以能过垃圾回收器来单独管理内存，所以关闭操作系统级别的内存管理可以\n#   提升性能\n bootstrap.memory_lock: true\n#\n# ------------------------ 网络设定 ----------------------------\n#\n# 绑定节点上的所有网络接口，用于接收通过任意网卡传输过来的请求\n network.bind_host: 0.0.0.0\n#\n# 绑定一个网络接口(网卡)，用于集群内部节点通信(一般选择吞吐量大的网卡)\n network.publish_host: _eth0:ipv4_\n#\n# HTTP 通信端口\n http.port: 50000\n#\n# TCP 通信端口\n transport.tcp.port: 50100\n#\n# --------------------------------- 集群发现 模块 ----------------------------------\n#\n# 集群初始化连接列表，节点启动后，首先通过连接初始化列表里的地址去发现集群。\n discovery.zen.ping.unicast.hosts: [\u0026quot;20.120.203.74:50100\u0026quot;,\u0026quot;20.120.203.76:50100\u0026quot;,\u0026quot;20.120.203.81:50100\u0026quot;,\u0026quot;20.120.203.84:50100\u0026quot;,\u0026quot;20.120.203.85:50100\u0026quot;]\n#\n# 为了防止集群脑裂，目前的策略是当且仅当节点有超过半数的master候选者存活时(目前是2台，可以完成选举)，集群才会进行master选举\n discovery.zen.minimum_master_nodes: 2\n#\n# ---------------------------------- 其它 -----------------------------------\n#\n# 关闭操作系统内核验证(我的操作系统没有升级，如果不关闭验证则无法启动)\n bootstrap.system_call_filter: false\n#\n# ------------------------ HTTP ----------------------------\n#\n# 是否支持跨域访问资源\n http.cors.enabled: true\n#\n#\n#允许访问资源的类型\n http.cors.allow-origin: \u0026quot;*\u0026quot;\n#\n#\n# 允许HTTP请求的方法类型 \n http.cors.allow-methods: OPTIONS,HEAD,GET,POST,PUT,DELETE\n#\n# 允许HTTP请求头返回类型\n http.cors.allow-headers: X-Requested-With,Content-Type,Content-Length,Authorization,Content-Encoding,Accept-Encoding\n#\n# 支持HTTP访问API 总开关\n http.enabled: true\n#\n#\n```\n\n\n```\n这是Data Node 配置参数\nvim $ES_HOME/config/elasticsearch.yml\n```\n\n```\n# ======================== ES 参数配置 =========================\n#\n#\n# ------------------------ 集群设定 ----------------------------\n#\n# 集群名称 \n cluster.name: benchmark612\n#\n# ------------------------ 节点设定 ----------------------------\n#\n# 节点名称\n node.name: ${HOSTNAME}\n#\n# 节点角色\n node.master: false\n node.data: true\n node.ingest: false\n#\n# ------------------------ 路径设定 ----------------------------\n#\n# 索引、日志存放路径\n path:\n   data: /data/store/es-6.1.2_benchmark612\n   logs: /data/logs/es-6.1.2_benchmark612\n#\n# ------------------------ 内存设定 ----------------------------\n#\n#\n# 锁定内存，阻止操作系统管理内存，可以有效的防止内存数据被交换到磁盘空间，\n#   交换过程中磁盘会抖动，会对性能产生较大的影响。因为ES是基于JAVA开发的\n#   可以能过垃圾回收器来单独管理内存，所以关闭操作系统级别的内存管理可以\n#   提升性能\n bootstrap.memory_lock: true\n#\n# ------------------------ 网络设定 ----------------------------\n#\n# 绑定节点上的所有网络接口，用于接收通过任意网卡传输过来的请求\n network.bind_host: 0.0.0.0\n#\n# 绑定一个网络接口(网卡)，用于集群内部节点通信(一般选择吞吐量大的网卡)\n network.publish_host: _eth0:ipv4_\n#\n# HTTP 通信端口\n http.port: 50000\n#\n# TCP 通信端口\n transport.tcp.port: 50100\n#\n# --------------------------------- 集群发现 模块 ----------------------------------\n#\n# 集群初始化连接列表，节点启动后，首先通过连接初始化列表里的地址去发现集群。\n discovery.zen.ping.unicast.hosts: [\u0026quot;20.120.203.74:50100\u0026quot;,\u0026quot;20.120.203.76:50100\u0026quot;,\u0026quot;20.120.203.81:50100\u0026quot;,\u0026quot;20.120.203.84:50100\u0026quot;,\u0026quot;20.120.203.85:50100\u0026quot;]\n#\n# 为了防止集群脑裂，目前的策略是当且仅当节点有超过半数的master候选者存活时(目前是2台，可以完成选举)，集群才会进行master选举\n discovery.zen.minimum_master_nodes: 2\n#\n# ---------------------------------- 其它 -----------------------------------\n#\n# 关闭操作系统内核验证(我的操作系统没有升级，如果不关闭验证则无法启动)\n bootstrap.system_call_filter: false\n#\n```\n\n\n相信细心的同学发现了Master和Data 配置的区别\n\n1） 区别一， Master 和 Data 节点角色配置的不同\n```\n# 节点角色  Master\n node.master: true\n node.data: false\n node.ingest: false\n\n# 节点角色  Data\n node.master: false\n node.data: true\n node.ingest: false\n```\n2） 区别二， Master 设置了HTTP 相关参数，如果不设置，将无法通过HEAD能插件来访问集群\n```\n#\n# ------------------------ HTTP ----------------------------\n#\n# 是否支持跨域访问资源\n http.cors.enabled: true\n#\n#\n#允许访问资源的类型\n http.cors.allow-origin: \u0026quot;*\u0026quot;\n#\n#\n# 允许HTTP请求的方法类型 \n http.cors.allow-methods: OPTIONS,HEAD,GET,POST,PUT,DELETE\n#\n# 允许HTTP请求头返回类型\n http.cors.allow-headers: X-Requested-With,Content-Type,Content-Length,Authorization,Content-Encoding,Accept-Encoding\n#\n# 支持HTTP访问API 总开关\n http.enabled: true\n#\n```\n\n不设置HTTP参数\n![插件无法管理ES集群](http://elasticsearch.club/wp-content/uploads/2018/01/head-manager-error.png)\n\n设置HTTP参数后\n![插件管理ES集群](http://elasticsearch.club/wp-content/uploads/2018/01/head-es-success.png)\n\n\n\n\u0026gt; 到这里，一个Elasticsearch 就正常的运行起来了。\n\n转自: http://elasticsearch.club/elasticsearch/es-tutorial/how-to-run-an-elasticsearch-cluster/\n\n\n","title":"如何运行一个elasticsearch集群","uid":"2363","views":"4858","votes":"2"},"_type":"doc"}
{"_id":"466","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516672882","category_id":"18","comments":"0","has_attach":"0","id":"466","message":"1.探讨一下Elasticsearch 6移除Type的前因后果。\n[url]http://t.cn/RQTbVuA[/url] \n2.eBay Elasticsearch 性能优化实战之中文篇。\n[url]http://t.cn/RQTbKQn[/url] \n3.Elastic Filebeat 快速入门。\n[url]http://t.cn/RQTbjQy[/url]\n \n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/466[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第167期 (2018-01-23)","uid":"3788","views":"334","votes":"0"},"_type":"doc"}
{"_id":"477","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517451205","category_id":"18","comments":"0","has_attach":"0","id":"477","message":"1. 卫星系统——酒店后端全链路日志收集工具介绍。\n[http://t.cn/RQxFzOF](http://t.cn/RQxFzOF) \n\n2. 搜索，分析数据库和分布式计算引擎的融合介绍。\n[http://t.cn/R65inbR](http://t.cn/R65inbR) \n\n3. 使用Apache Spark将数据写入ElasticSearch。\n[http://t.cn/R8flF70](http://t.cn/R8flF70) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/477\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第176期 (2018-02-01)","uid":"668","views":"355","votes":"0"},"_type":"doc"}
{"_id":"481","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517620914","category_id":"18","comments":"0","has_attach":"0","id":"481","message":"1. 新手营：es模板的用法\n[https://elasticsearch.cn/article/335](https://elasticsearch.cn/article/335) \n\n2. 关于ELK的由时区引发的问题\n[http://t.cn/R8aSQCS](hhttp://t.cn/R8aSQCS) \n\n3. 一周热点：只用200行Go代码写一个自己的区块链！\n[http://t.cn/R8clX3M](http://t.cn/R8clX3M) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/481\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第178期 (2018-02-03)","uid":"1874","views":"330","votes":"0"},"_type":"doc"}
{"_id":"496","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518246303","category_id":"4","comments":"1","has_attach":"1","id":"496","message":"# indies_view\n\n[https://github.com/TrumanDu/indices_view](https://github.com/TrumanDu/indices_view)\n\u0026gt; An awesome kibana plugin for view indies!\n这个是一个可以查看indices 相关信息的kibana plugin ,欢迎大家使用，或者提出宝贵的经验\n\n---\n\n## Screenshots\n\n[attach]1775[/attach]\n\n## Reg pattern\n\n```\n1. /[^a-z] $/\n2. /[\\d]{4}[-|\\.|/][\\d]{1,2}[-|\\.|/][\\d]{1,2}/\n```\n## Development\n\nSee the [kibana contributing guide](https://github.com/elastic/kibana/blob/master/CONTRIBUTING.md) for instructions setting up your development environment. Once you have completed that, use the following npm tasks.\n\n- `npm start`\n\nStart kibana and have it include this plugin\n\n- `npm start -- --config kibana.yml`\n\nYou can pass any argument that you would normally send to `bin/kibana` by putting them after `--` when running `npm start`\n\n- `npm run build`\n\nBuild a distributable archive\n\n- `npm run test:browser`\n\nRun the browser tests in a real web browser\n\n- `npm run test:server`\n\nRun the server tests using mocha\n\nFor more information about any of these commands run `npm run ${task} -- --help`.\n\n## Deploy\n\n**important** : edit this plugin version and kibana.version to you kibana version in package.json\n\n- `npm install`\n- `npm run build`\n\nBuild a distributable archive\n\n## Install\n\n1. cp to docker container\n\n```$ sudo docker cp ****.zip id:/****.zip```\n\n2. install to kibana\n\n```$bin/kibana-plugin install file:///****.zip```","title":"推荐indies_view 插件","uid":"5051","views":"761","votes":"2"},"_type":"doc"}
{"_id":"500","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518402203","category_id":"15","comments":"6","has_attach":"1","id":"500","message":"代码地址：https://gitee.com/shaojiepeng/wsm-lucene\r\n ### wsm-lucene\r\n一个简单的Lucene工具类，通过注释的方式来配置构建索引的字段。提供新建索引、查找、删除、更新方法，支持分页。\r\n\r\n### 所需jar包\r\n1. lucene-core:2.4.0\r\n2. lucene-analyzers:2.4.1\r\n3. commons-logging:1.2\r\n\r\n### 背景\r\n以前在做某个feature的时候，鉴于存储在DB中的数据量过大，故使用Lucene来优化查找性能。\r\n相信大家在某些场景下会把DB中的数据读出来，建索引来优化查找。那么这个工具类就比较适合这些场景了。\r\n\r\n### 如何使用\r\n **从附件中下载jar包直接导入到项目中，或者下载此Maven项目的源码，使用项目依赖的方式导入你的项目。** \r\n\r\n1. 通过注释的方式配置需要构建索引的model类\r\n\r\n```\r\n **@IndexClass** ：注释，说明此model类需要构建索引\r\n **indexDirPath** ：索引所存放的物理位置，如：\u0026quot;D:/Index\u0026quot;\r\n\r\n **@IndexField** ：注释，说明此字段需要构建索引\r\n **fieldStore** ：Lucene中的Field.Store同义，不懂请自行查询资料\r\n **fieldIndex** ：Lucene中的Field.Index同义，不懂请自行查询资料\r\n```\r\n\r\n[attach]1783[/attach]\r\n\r\n\r\n2. 创建索引\r\n```\r\n\r\nIndexService indexService = new IndexServiceImpl();\r\n/** 构建索引的接口\r\n * List：model的集合\r\n * Class: model的class\r\n *\r\n * return boolean\r\n**/\r\nindexService.buildIndex(List, Class)\r\n```\r\n\r\n[attach]1784[/attach]\r\n\r\n\r\n3.查找\r\n```\r\nArrayList\u0026lt;SearchParamModel\u0026gt; searchParams = new ArrayList\u0026lt;\u0026gt;();\r\n/**添加查询的条件，如果有多个查询条件，则添加SearchParamModel\r\n * fieldName：需要查找的字段，即model中的成员变量\r\n * fieldValue：需要查找字段的值，这个不解释\r\n * BooleanType：Lucene中BooleanClause.Occur值，不懂请自行查询资料\r\n**/\r\nsearchParams.add(new SearchParamModel(fieldName, fieldValue, BooleanType));\r\nIndexService indexService = new IndexServiceImpl();\r\n/** 查询的接口\r\n * searchParams：不解释\r\n * Class: model的class\r\n *\r\n * return model的集合\r\n**/\r\nList objs = indexService.search(searchParams, Class);\r\n```\r\n\r\n[attach]1785[/attach]\r\n\r\n\r\n\r\nIndexService中还支持update, delete和分页查找的方法，请自行查阅代码。\r\n\r\n\r\n觉得不错，请点个赞吧。","title":"一个简单的Lucene工具类，通过注释的方式来配置构建索引的字段。提供新建索引、查找、删除、更新方法，支持分页。","uid":"7807","views":"804","votes":"0"},"_type":"doc"}
{"_id":"503","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518619306","category_id":"18","comments":"0","has_attach":"0","id":"503","message":"1. 日志收集工具fluentd与logstash比较。 \nhttp://t.cn/RR9sgLX\n2. 如何通过logstash将csv数据导入到elasticsearch。\nhttp://t.cn/RCGeeJK\n3. 搜索引擎选择：Elasticsearch与Solr\nhttp://t.cn/RUncwIu\n \n编辑：wt\n归档：https://elasticsearch.cn/article/503\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第189期 (2018-02-14)","uid":"3851","views":"487","votes":"0"},"_type":"doc"}
{"_id":"527","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520731806","category_id":"18","comments":"0","has_attach":"0","id":"527","message":"1.febAzure监控和Azure日志分析：何时使用哪个。 \nhttp://t.cn/REr0nPS \n2.(自备梯子)Sherlock：近实时搜索索引。 \nhttp://t.cn/RErpGvJ \n3.(自备梯子)代码审查最佳实践。 \nhttp://t.cn/RErplG9 \n \n编辑：至尊宝 \n归档：https://elasticsearch.cn/article/527\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第207期 (2018-03-11) ","uid":"4460","views":"497","votes":"0"},"_type":"doc"}
{"_id":"525","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520548164","category_id":"18","comments":"0","has_attach":"0","id":"525","message":"1. Elasticsearch在电商领域的实战应用\nhttp://t.cn/REEzwES\n2.使用Docker和Elasticsearch搭建全文本搜索引擎应用\nhttp://t.cn/REEzUng\n3.剖析Elasticsearch索引原理\n[url]http://t.cn/R8CcO9g[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/525\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第205期 (2018-03-09)","uid":"1341","views":"360","votes":"0"},"_type":"doc"}
{"_id":"509","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519695284","category_id":"18","comments":"0","has_attach":"0","id":"509","message":"1.按月分割nginx访问日志-filebeat配置文件简介。\n[url]http://t.cn/RE5vj5t[/url] \n2.使用Elastic APM监控应用性能及存储应用程序指标。\n[url]http://t.cn/RE5h2w3[/url] \n3.使用Grafana监控Elasticsearch集群。\n[url]http://t.cn/RHcsJYJ[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/509[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第195期 (2018-02-27)","uid":"3788","views":"287","votes":"0"},"_type":"doc"}
{"_id":"511","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519792741","category_id":"5","comments":"1","has_attach":"1","id":"511","message":"[attach]1824[/attach]\n\n#### 下载超过 2.25 亿次，Elastic 公开 X-Pack 源代码\n\n旧金山 (Elastic{ON} 2018) – 2018 年 2 月 27 日 – Elastic，Elasticsearch 和 Elastic Stack背后的公司，今天宣布其产品累计下载次数达到 2.25 亿次的里程牌，去年累计下载次数是 1 亿。除此之外，Elastic 宣布公开其X-Pack 的源代码作为策略的一部分，让用户更容易地下载、检查和与 Elastic 工程团队一起在 X-Pack 特性开发上进行协作。给用户更简单的下载、检查及协助。X-Pack 目前包括了 security、alerting、monitoring、Graph 和machine learning 等众多功能。 \n\n\n“我们的产品被数以百万计的开发人员和成千上万的客户所依赖，他们依靠这些产品来驱动关键型业务，这令我们受宠若惊，” Elastic 创始人兼 CEO Shay Banon 表示， “正如他们与我们开源的产品打交道的一样，公开我们的 X-Pack 源代码能给我们的用户完全的透明度和具备与我们一起协助的能力。这样可以激励每一位开发人员、客户和使用我们软件的合作伙伴，帮助我们创造更好的产品和特性以及允许我们构建一个可持续发展的商业模式。”\n\nElastic 在过去18个月内收购了三家新公司，并在全世界发展了超过 100,000 多位开发者的技术社区。 Elastic{ON} 2018， 是一个最大型的 Elasticsearch 用户聚集的大会。在三天的时间里，超过 2500 名与会者聚在一起学习和分享创意，观看新功能的发布，并获得即将发布的新技术的预览。 \n\n* Elastic APM: 这是 Elastic APM 第一个可被用于生产环境的版本，作为 Elastic 产品栈进入应用性能监控领域的一个延伸。它允许应用程序开发人员和 devops 工程师能够监视和分析特定的代码行对系统和业务性能的影响。这不仅仅是提升速度，同时也能扩展调试流程，将代码性能变化与操作历史有机结合。Elastic APM 将数据存储到 Elasticsearch 的索引里面，允许将 APM 数据与来自 Logstash 或者 Beats 的日志和监控指标进行关联分析，包含针对 Nodejs、Python、Ruby 和 JavaScript 的服务端组件和探针。还提供一个 APM 分析应用来实施典型的 APM 工作流。Elastic APM 已经作为 6.2 发布的一部分可被下载。\n\n* Swiftype App Search: 为开发者构建用以为他们的应用程序提供强大的搜索能力，Swiftype App Search 交付一系列稳健的 API 和额外的搜索相关的特性，如搜索结果重排、同义词和容错等。Swiftype App Search 是一个一站式的 Saas 解决方案，不需要基础设施、管理和维护，提供一个简单上手的用户体验。 Swiftype App Search 现已公测。\n\n* Machine Learning Forecasting: Elastic 机器学习能力的第一个主要扩展，用于预测分析领域。用户可以对时间序列数据进行建模，并使用复杂的、现成的机器学习算法来预测未来可能发生的结果。借助按需预测，用户可以使用现有的机器学习工作，并使用内置的预测模型，来准确预测改模型在预测周期内的增长情况。预测结果被写入到 Elasticsearch 的索引中，用户可用来和实际的数据进行比较。Elastic 的机器预测能力已包含在 6.2 的版本里面。\n\n* GIS App: Elastic 的一个全新研究项目，GIS（地理信息系统）是一个被设计用来捕获、存储、操作、分析、管理和呈现所有地理类型数据的系统。作为 Kibana 的一部分，这个 应用让你以一种全新的方式来执行特定的地理位置分析，在 Dashboard 里面加入内置的增强地图可视化组件。它的核心特性包括，多层地图的支持，映射独立的坐标点和用户端样式自定义。GIS App 目前已提供技术预览版。\n\n* SQL for Elasticsearch: 这个新特性为世界上最成熟的 SQL 数据库开发人员打开了释放 Elastic Stack 强大能力的大门，允许用户用熟悉的 SQL 语法来查询 Elasticsearch 里面的数据。JDBC 协议的支持，大大的简化了将 Elasticsearch 导出到外部 SQL 环境使用的情况。通过允许 Elasticsearch 通过 RESTful 协议理解 SQL，Elasticsearch SQL 允许你使用 SQL 语法来查询 Elasticsearch 里面的数据，以 SQL 引擎一致的表格形式返回那些查询结果，并提供一个用户接口来探索这些数据。Elasticsearch SQL 去年还只是作为一个概念被推出，现在马上将发布 alpha 和 beta 版本。\n\n* Canvas: Canvas 为下一代数据可视化和数据呈现展现了一个全新的篇章。随着 Kibana 越来越受欢迎，Canvas 展现了一种新的方式，可以将数据从 Elasticsearch 中获得的洞察赋予在线的、实时的仪表盘、幻灯片演示和信息图表。Canvas 能让用户能以一种前所未有的方式来表达 Elasticsearch 数据背后的故事，消除将数据导出到 Excel 中的详尽、重复和耗时的过程，来构建 PowerPoint。 Canvas 同样也是可插拔的，允许用户带来新的数据源、可视化类型和 UI 可视化组件。Canvas 去年作为一个概念被提出，目前已提供技术预览版可被下载。\n\n* Rollups: 一般来说，具备关联的指标和日志数据需要长时间保存，rollups 可以让用户存储有限的数据集，减少历史数据的磁盘占用。Elasticsearch 的 rollup 作业可以让用户配置一个定时任务来对数据进行 “rollup” 或预聚合，并保存结果到一个索引。举一个指标监控的例子，如：“web 服务器每小时的平均负载”，也就是说，平均数据被 rollup 起来并存储，但是其它原始数据，如特定用户、页面、IP 信息却不会。该功能将很快在 Elasticsearch 里面提供测试版本并随后在 Kibana 里面提供支持。\n\n* Flexible Deployment Configurations: 随着客户将随着越来越多的数据放进 Elasticsearch 并扩展越来越多的使用场景，Elastic 引入 “sliders” 功能来让用户获得定制他们集群配置的能力。Elastic Cloud 和 Elastic Cloud Enterprise (ECE) 客户将获得这些新能力：支持多种类型的硬件可供选择；支持集群模板和 hot/warm 集群；给现有集群添加机器学习节点、独立 master 节点和 APM 节点的能力。这些新特性很快将能在 Elastic Cloud 和 Elastic Cloud Enterprise 上可用。\n\n* Logstash Azure Monitoring Module: 通过与微软合作，Logstash Azure 监控模块目前是借助 Elastic Stack 监控你的 Azure 基础设施和服务的最简单的方式。新模块集成了 Azure 的集中式日志服务来标准化 Azure 日志和指标，并转换成 JSON 格式。使用 Logstash 来消费这些数据录入到 Elasticsearch。同时借助 Kibana，用户能够分析基础设施的改变和授权信息；识别可疑的行为和潜在的恶意用户；通过调查用户行为来执行根源分析；监控和优化 SQL 数据库的部署。该功能将很快提供 beta 版本。\n\n最后，Elastic 宣布一个新的、官方的 Elastic 认证计划。在用户要求获得专业认证的推动下，Elastic 将为用户提供新的培训课程，让他们成为专家，并通过 Elastic 认证。新课程 Elasticsearch Engineer I 和 Elasticsearch Engineer II 将为用户提供安装、管理和优化 Elasticsearch 集群的第一手知识，也包括，开发新的解决方案来分析他们的数据。这些课程是成为一名 Elastic 认证工程师的基础，包括动手、技术和基于性能的认证考试，通过考试将获得由官方颁发的 Elastic 电子认证徽章。\n\n\n### 了解更多\n\nElastic Opening X-Pack Blog \nOpening X-Pack FAQ \nElastic Certification \nElastic Cause Awards\n\n### 关于 Elastic\n\nElastic 致力于构建大规模实时数据处理软件，场景主要涵盖搜索、日志、安全与数据分析等领域。公司成立于 2012 年，旗下拥有产品包括开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、 X-Pack （商业特性）和 Elastic Cloud （一种托管服务）。迄今为止，这些产品的累积下载次数已超过 2.25 亿。Elastic 由 Benchmark Capital、Index Ventures 及 NEA 投资，投资额超过 1 亿美金。Elastic 拥有超过 800 位员工，分布于世界上 30 多个国家和地区。欲了解详情请访问：elastic.co。\n\n### 媒体联系人：\n\nMichael Lindenberger\n\nReidy Communications for Elastic\n\nMichael@reidycommunications.com\n\n(415) 531-1449\n\n亚太地区\nJeff Yoshimura\n\nCommunications @ Elastic\n\npr@elastic.co","title":"Elastic 在年度用户大会 Elastic{ON} 2018 上发布众多新功能和技术预览","uid":"1","views":"1788","votes":"2"},"_type":"doc"}
{"_id":"516","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520038102","category_id":"18","comments":"0","has_attach":"0","id":"516","message":"1. 将索引更新从6小时降到34分钟的方法(需翻墙）。\n[http://t.cn/REo5HDj](http://t.cn/REo5HDj) \n\n2. 新手营：ES中使用别名的优势。\n[http://t.cn/REo5W9U](http://t.cn/REo5W9U) \n\n3. 渴望成长的工程师-你了解一万小时定律吗？\n[http://t.cn/REo6k76](http://t.cn/REo6k76) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/516\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第199期 (2018-03-03)","uid":"1874","views":"336","votes":"0"},"_type":"doc"}
{"_id":"219","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502245761","category_id":"5","comments":"11","has_attach":"1","id":"219","message":"[b]头条新闻[/b]：Elastic Stack 6.0 发布 beta 版本了。[url]https://www.elastic.co/blog/elastic-stack-6-0-0-beta1-released?blade=cn[/url] \n \n \n注意啦，现在 6.0 还没 GA，不建议直接上生产环境，但是鼓励大家本地测试，和 5.0 一样，我们这次也有一个 Elastic Pioneer 活动，踊跃测试并发现 bug 的同学，可以获得 6.0 特殊纪念礼品一份，欢迎大家一起来捉虫，捉到的 Bug 直接在对应的 GitHub 上提交 issue，打上对应的版本 tag，如6.0.0-beta1 即可参与活动。\n[attach]907[/attach]\n \n\n6.0 beta1 作为一个具备里程碑意义的版本，相比之前的 alpha 版本，又包含了哪些激动人心的新特性呢，下面我们分别来看一下吧。\n \n\n[b]Elasticsearch [url=https://www.elastic.co/downloads/elasticsearch#preview-release][下载][/url] [url=https://www.elastic.co/guide/en/elasticsearch/reference/6.0/breaking-changes-6.0.html][6.0 Breaking Chages][/url][/b]\n[url]https://www.elastic.co/blog/elasticsearch-6-0-0-beta1-released[/url]\n[list]\n[*]Sequence numbers and fast recovery[/*]\n[/list]\n新的序列号机制会为每一个增删改操作分配一个顺序号，可以实现操作层面的细粒度复制，避免低效的基于索引文件的拷贝与 translog 的重做；Translog 使用新的过期机制，默认是 12 小时或者 512MB 大小，方便副本的快速恢复；该特性也为后面的跨数据中心的数据同步铺平了道路。\n[list]\n[*]Search scalability[/*]\n[/list]\n移除 _field_stats 接口，现在每个搜索请求多了一个轻量级的 shard prefiltering phase，提前过滤掉不需要参与实践查询的 shards，并在 shard 级别判断查询是否有效，并重写查询，只在真正有相应数据的 shard 上执行查询；新增参数 max_concurrent_shard_requests 来限制单次请求的并发分片请求数。\n[list]\n[*]Preventing full disks[/*]\n[/list]\n新增参数来控制当磁盘占用达到某个警戒线之后不允许继续写入；限制 Elasticsearch 的日志占用，默认按 128MB 滚动覆盖，限制 ES 总日志文件大小不超过 2GB。\n[list]\n[*]Removal of default passwords[/*]\n[/list]\n为了更加安全，XPack 的默认密码 changeme 去掉了，提供了相应的工具来进行配置。\n[list]\n[*]优化 Profiling 的开销占用，进一步较少针对超时及查询取消的检查开销[/*]\n[*]提升 Percolator 的性能[/*]\n[/list]\n 更多改进：[b][url=https://www.elastic.co/guide/en/elasticsearch/reference/6.0/release-notes-6.0.0-beta1.html][Beta1 Release Notes][/url][/b]\n \n \n[b]Kibana [url=https://www.elastic.co/downloads/kibana][下载][/url] [url=https://www.elastic.co/guide/en/elasticsearch/reference/master/breaking-changes-6.0.html][Breaking Changes][/url][/b]\n[url]https://www.elastic.co/blog/kibana-6-0-0-beta1-released[/url]\n[list]\n[*]Upgrade Assistant and Rolling Upgrade Support[/*]\n[/list]\n \n新增的集群升级助手，属于 X-Pack 的免费功能，自动帮你诊断集群升级要处理的各种问题，支持跨大版本间滚动升级的检测。\n[attach]908[/attach]\n[list]\n[*]Watcher UI for Threshold Based Alerts[/*]\n[/list]\n新增提供基于阈值的快速设置 Watcher 预警规则的 UI 界面。\n\n[attach]914[/attach]\n[list]\n[*]Experimental Kibana Query Language[/*]\n[/list]\n引入新的 Kibana 查询语言：Kuery，支持智能提示和错误失败等丰富的特性。\n[list]\n[*]Refactoring of the Visualizations Code[/*]\n[/list]\n通过此次重构，开发者不再受限于只能使用 Angular 来做渲染了，以及扩展更多的灵活性，方便对 Kibana 的二次开发。\n\n[attach]909[/attach]\n[list]\n[*]X-Pack Monitoring Email Notifications for Cluster Alerts[/*]\n[/list]\n支持设置监控的告警邮件发送。\n\n[attach]910[/attach]\n[list]\n[*]Cluster Alert for X-Pack License Expiration[/*]\n[/list]\n证书过期现在有自动的提示了。\n\n[attach]911[/attach]\n[list]\n[*]New Colors to Improve Accessibility[/*]\n[/list]\n改进Kibana的可用性，如导航的快捷键支持，对色盲色弱用户的友好支持等。\n\n[attach]912[/attach]\n[attach]915[/attach]\n[list]\n[*]Full Screen Mode for Dashboard[/*]\n[/list]\n新增的全屏模式对 Dashboard 的大屏展现更加友好。\n\n[attach]913[/attach]\n更多详情：[url=https://www.elastic.co/guide/en/kibana/6.0/release-notes-6.0.0-beta1.html][6.0 Beta1 Release Notes][/url]  \n\n \n[b]Logstash [url=https://www.elastic.co/downloads/logstash#preview-release][下载][/url] [/b]\n[url]https://www.elastic.co/blog/logstash-6-0-0-beta1-released[/url]\n[list]\n[*]Pipeline Viewer[/*]\n[/list]\nX-Pack Basic 新增的免费功能，用户可以非常直观的了解管道配置，以图形化的方式来展现，从而了解数据流向与处理逻辑，包括管道执行的各项重要指标，从而优化 Logstash 性能。\n\n[attach]916[/attach]\n[list]\n[*]Centrally manage configurations[/*]\n[/list]\n用户可以方便的通过图形化 UI 集中式批量管理所有 Logstash 实例的配置文件，并动态修改生效，不需要重启和单独维护每个 Logstash 的实例。\n\n[attach]917[/attach]\n[list]\n[*]Ingest to Logstash convertor[/*]\n[/list]\n提供一个方便将 Elasticsearch Ingest 脚本转换为 Logstash 配置文件的工具。[code]$LS_HOME/bin/ingest-convert.sh --input file:///tmp/ingest/apache.json --output [url=http://file:///tmp/ingest/apache.conf]file:///tmp/ingest/apache.conf[/url] \n\n[/code]\n \n [b]Beats [url=https://www.elastic.co/downloads/beats][下载][/url] [url=https://www.elastic.co/guide/en/beats/libbeat/6.0/release-notes-6.0.0-beta1.html#_breaking_changes][Breaking Changes][/url][/b]\n[url]https://www.elastic.co/blog/beats-6-0-0-beta1-released[/url]\n[list]\n[*]Auditbeat[/*]\n[/list]\n一个新的 Beat，通过将 Linux Kernel 内的各种事件统统接入到 Elastic Stack 来进行安全审计。\n\n[attach]918[/attach]\n[list]\n[*]New commands and configuration layout[/*]\n[/list]\n一些常见的操作，你现在可以直接通过命令的方式来快速操作了。[code]$ metricbeat modules list\n$ metricbeat modules enable redis\n$ metricbeat modules disable redis[/code]\n[list]\n[*]Add Docker metadata to the Docker logs[/*]\n[/list]\n将 Docker 相关的元数据附加到日志里面，从而丰富上层的分析与应用，详情可见这篇博客：[url]https://www.elastic.co/blog/enrich-docker-logs-with-filebeat[/url]\n[list]\n[*]Internal pipeline refactoring[/*]\n[/list]\nBeats 在管道这一块做了大量的重构，现在不支持 1 个管道 2 个输出了。\n \n更多详情：[url=https://www.elastic.co/guide/en/beats/libbeat/6.0/release-notes-6.0.0-beta1.html][Beta1 Release Notes][/url] \n \n[b]ES-Hadoop [url=https://www.elastic.co/downloads/past-releases/elasticsearch-apache-hadoop-6-0-0-beta1][下载][/url][/b]\n[url]https://www.elastic.co/blog/eshadoop-6-0-0-beta1-released[/url]\n[list]\n[*]Spark 2.2.0 and Stable Support for Spark Structured Streaming[/*]\n[*]Support for new Join Fields[/*]\n[*]Multiple Mappings and Multiple Index Reads[/*]\n[/list]\n \n更多详情：[url=https://www.elastic.co/guide/en/elasticsearch/hadoop/master/eshadoop-6.0.0-beta-1.html][Release Notes][/url]\n \n上面介绍的众多特性，相信总有一个能让你动心，赶紧下载试试吧，记得反馈哦！\n ","title":"Elastic Stack 6.0 发布 beta 版本啦！","uid":"1","views":"3156","votes":"3"},"_type":"doc"}
{"_id":"225","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502759381","category_id":"18","comments":"0","has_attach":"0","id":"225","message":"1.  Hawkular 与 Elasticsearch 集成，实现监控报警：http://t.cn/R9kMKgC 和 http://t.cn/R9kMWIl\n\n2. 借助 Elasticsearch 来实现网站交互的追踪：http://t.cn/R9kMs8G  \n\n3. 微服务监控实战：http://t.cn/R9kxtFF\n\n4. 中国人寿的 Elastic 选择之路： http://t.cn/R9kJ6Wi\n \n\n编辑：Medcl\n归档：https://elasticsearch.cn/article/225\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第17期 (2017-08-15)","uid":"1","views":"745","votes":"2"},"_type":"doc"}
{"_id":"232","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503279079","category_id":"18","comments":"1","has_attach":"0","id":"232","message":"1.Kibana 图表中的 Visual Builder 还没用过？先来看看油管上的官方演示视频(自备梯子) http://t.cn/RCVjwya  http://t.cn/RCVjyNL\n\n2.还是 Visual Builder，再来详细入个门吧！http://t.cn/RCVj5Wm\n\n3.来学习下如何使用 Elastic Stack 来分析 NYC 311 的电话记录！(自备梯子) http://t.cn/RCVjJuc\n\n\n招聘启事：\nElastic日报招聘编辑一名，负责日报相关事宜，机不可失，感兴趣的请加微信 rockybean 私聊！\n编辑要求如下：\n1. 熟悉Elastic相关产品，可以筛选相关高质量文章\n2. 有一定文字组织能力，可以快速提炼文章精华，写出概要推荐语\n3. 轻功要好\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/232\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第23期 (2017-08-21)","uid":"86","views":"721","votes":"1"},"_type":"doc"}
{"_id":"242","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503642707","category_id":"2","comments":"2","has_attach":"0","id":"242","message":"UpdateRequest的upsert方法\n插入10000条数据：处理时间154998ms   处理时间188853ms   处理时间85979ms   处理时间128720ms   处理时间140181ms  \n处理时间156794ms \n去掉一个最大值、最小值后的平均值：145173.25\n\n更新10000条数据：处理时间106973ms    处理时间80587ms   处理时间148659ms  处理时间314724ms   处理时间89156ms  处理时间115655ms 处理时间79783ms  处理时间111543ms  处理时间85369ms  处理时间95792ms  处理时间93313ms 处理时间145522ms\n去掉一个最大值、最小值后的平均值：107257ms\n \nprepareIndex(只能插入新数据，不能用来更新数据，否则会覆盖原有的数据)\n处理时间60551ms\n处理时间45032ms\n处理时间95328ms\n处理时间39207ms\n处理时间75165ms\n ","title":"ElasticSearch的插入新数据和更新指定数据的效率（10000条）","uid":"4654","views":"959","votes":"0"},"_type":"doc"}
{"_id":"249","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504096884","category_id":"2","comments":"1","has_attach":"0","id":"249","message":"一、★★★★★★★单机版安装及环境配置★★★★★★★\n安装环境 CentOS release 6.7 (Final)\n1、因Elasticsearch是基于Java写的，所以它的运行环境中需要java的支持，在Linux下执行命令：\njava -version，检查Jar包是否安装\n安装java版本至少是1.8以上\n\n2、首先准备下载Elasticsearch5.5.0 安装包\nwget https://artifacts.elastic.co/downloads/elasticsearch\n\n3、下载到/usr/openv 目录下，解压\ntar -zxvf  elasticsearch-5.5.0.tar.gz\n\n4、因为Elasticsearch5.0之后,不能使用root账户启动,我们先创建一个esuser组和账户\nuseradd  esuser -g esuser -p esuser\n\n5.更改文件夹权限\nchown -R esuser:esuser /usr/openv/elasticsearch-5.5.0\n\n6、启动elasticsearch：\n/usr/openv/elasticsearch-5.5.0/bin\nsu esuser\n./elasticsearch    (前台启动)\n这时候我们看见下面的提示，说明就成功了：\n    1.    [elasticsearch@vmlnx-sma bin]$ ./elasticsearch  \n2.    [2017-03-02T21:43:21,185][INFO ][o.e.n.Node               ] [] initializing ...  \n3.    [2017-03-02T21:43:21,264][INFO ][o.e.e.NodeEnvironment    ] [uY3prpy] using [1] data paths, mounts [[/ (/dev/mapper/VolGroup-lv_root)]], net usable_space [43.5gb], net total_space [54.6gb], spins? [possibly], types [ext4]  \n4.    [2017-03-02T21:43:21,265][INFO ][o.e.e.NodeEnvironment    ] [uY3prpy] heap size [1.9gb], compressed ordinary object pointers [true]  \n5.    [2017-03-02T21:43:21,268][INFO ][o.e.n.Node               ] node name [uY3prpy] derived from node ID [uY3prpyqTHim5twauiVWhQ]; set [node.name] to override  \n6.    [2017-03-02T21:43:21,271][INFO ][o.e.n.Node               ] version[5.2.2], pid[5602], build[f9d9b74/2017-02-24T17:26:45.835Z], OS[Linux/3.10.5-3.el6.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]  \n7.    [2017-03-02T21:43:22,226][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [aggs-matrix-stats]  \n8.    [2017-03-02T21:43:22,226][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [ingest-common]  \n9.    [2017-03-02T21:43:22,226][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [lang-expression]  \n10.    [2017-03-02T21:43:22,227][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [lang-groovy]  \n11.    [2017-03-02T21:43:22,227][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [lang-mustache]  \n12.    [2017-03-02T21:43:22,227][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [lang-painless]  \n13.    [2017-03-02T21:43:22,228][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [percolator]  \n14.    [2017-03-02T21:43:22,228][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [reindex]  \n15.    [2017-03-02T21:43:22,228][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [transport-netty3]  \n16.    [2017-03-02T21:43:22,229][INFO ][o.e.p.PluginsService     ] [uY3prpy] loaded module [transport-netty4]  \n17.    [2017-03-02T21:43:22,230][INFO ][o.e.p.PluginsService     ] [uY3prpy] no plugins loaded  \n18.    [2017-03-02T21:43:24,689][INFO ][o.e.n.Node               ] initialized  \n19.    [2017-03-02T21:43:24,689][INFO ][o.e.n.Node               ] [uY3prpy] starting ...  \n20.    [2017-03-02T21:43:24,929][INFO ][o.e.t.TransportService   ] [uY3prpy] publish_address {10.245.250.65:9300}, bound_addresses {10.245.250.65:9300}  \n21.    [2017-03-02T21:43:24,948][INFO ][o.e.b.BootstrapChecks    ] [uY3prpy] bound or publishing to a non-loopback or non-link-local address, enforcing bootstrap checks  \n22.    [2017-03-02T21:43:28,010][INFO ][o.e.c.s.ClusterService   ] [uY3prpy] new_master {uY3prpy}{uY3prpyqTHim5twauiVWhQ}{AqALBH68RCucWcPmHCE6dw}{10.245.250.65}{10.245.250.65:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)  \n23.    [2017-03-02T21:43:28,034][INFO ][o.e.h.HttpServer         ] [uY3prpy] publish_address {10.245.250.65:9200}, bound_addresses {10.245.250.65:9200}  \n24.    [2017-03-02T21:43:28,034][INFO ][o.e.n.Node               ] [uY3prpy] started  \n25.    [2017-03-02T21:43:28,061][INFO ][o.e.g.GatewayService     ] [uY3prpy] recovered [0] indices into cluster_state  \n\n./elasticsearch -d (后台启动)\n\n执行 curl http://localhost:9200\n\n打开另一个终端进行测试：\ncurl 'http://localhost:9200/?pretty'\n\n你能看到以下返回信息：\n\n{\n   \u0026quot;status\u0026quot;: 200,\n   \u0026quot;name\u0026quot;: \u0026quot;Shrunken Bones\u0026quot;,\n   \u0026quot;version\u0026quot;: {\n      \u0026quot;number\u0026quot;: \u0026quot;1.4.0\u0026quot;,\n      \u0026quot;lucene_version\u0026quot;: \u0026quot;4.10\u0026quot;\n   },\n   \u0026quot;tagline\u0026quot;: \u0026quot;You Know, for Search\u0026quot;\n}\n\n说明安装成功。\n但是我们希望能够使用ip访问，那么还需要设置相关内容\n跳转到Elasticsearch的config配置文件下，使用vim打开elasticsearch.yml，找到里面的\u0026quot;network.host\u0026quot;,将其改为本机IP,保存。\n\ncd elasticsearch/config/\n\nvim elasticsearch.yml\n\n重启ElasticSearch，然后使用http://192.168.37.137:9200/访问。\n\n二、★★★★★★★常见错误★★★★★★★\n\n问题一：警告提示\n[2016-11-06T16:27:21,712][WARN ][o.e.b.JNANatives ] unable to install syscall filter: \njava.lang.UnsupportedOperationException: seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in\nat org.elasticsearch.bootstrap.Seccomp.linuxImpl(Seccomp.java:349) ~[elasticsearch-5.0.0.jar:5.0.0]\nat org.elasticsearch.bootstrap.Seccomp.init(Seccomp.java:630) ~[elasticsearch-5.0.0.jar:5.0.0]\n报了一大串错误，其实只是一个警告。\n解决：使用心得linux版本，就不会出现此类问题了。\n \n问题二：ERROR: bootstrap checks failed\nmax file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]\nmax number of threads [1024] for user [lishang] likely too low, increase to at least [2048]\n解决：切换到root用户，编辑limits.conf 添加类似如下内容\nvi /etc/security/limits.conf \n添加如下内容:\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 2048\n* hard nproc 4096\n \n问题三：max number of threads [1024] for user [lish] likely too low, increase to at least [2048]\n解决：切换到root用户，进入limits.d目录下修改配置文件。\nvi /etc/security/limits.d/90-nproc.conf \n修改如下内容：\n* soft nproc 1024\n#修改为\n* soft nproc 2048\n \n问题四：max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]\n解决：切换到root用户修改配置sysctl.conf\nvi /etc/sysctl.conf \n添加下面配置：\nvm.max_map_count=655360\n并执行命令：\nsysctl -p\n然后，重新启动elasticsearch，即可启动成功。\n\n三、★★★★★★★★★★★★★★★★★★★\n查看集群健康状态：curl -XGET 'http://localhost:9200/_cluster/health?pretty=true' \n                  \n查看本地节点信息：curl -XGET http://localhost:9200/\n\n其它一些命令：\n\n查看集群状态：curl -XGET http://localhost:9200/_cat/health?v\n              curl -XGET 'http://localhost:9200/_cluster/state?pretty'\n              curl -XGET 'http://localhost:9200/_cluster/stats?human\u0026amp;pretty'\n\n查看集群节点：curl -XGET http://localhost:9200/_cat/nodes?v\n              curl -XGET 'http://localhost:9200/_nodes/stats?pretty'\n              curl -XGET 'http://localhost:9200/_nodes/stats/os,process?pretty'\n\n查询索引列表：curl -XGET http://localhost:9200/_cat/indices?v\n\n创建索引：curl -XPUT http://localhost:9200/customer?pretty\n\n查询索引：curl -XGET http://localhost:9200/customer/external/1?pretty\n\n删除索引：curl -XDELETE http://localhost:9200/customer?pretty\n\n停服与重启\n\n停止ES服务器\n如果是前台启动，直接Ctrl+Z或者直接关掉命令行窗口，则服务器立即停止。\n\n如果是通过后台启动的ES服务，则需要用如下命令停止服务器：\n\n也可以直接在Window系统的服务列表中找到安装的服务，然后右键停止。\n\n另外，还可以通过curl工具来关掉整个集群或者集群中的指定节点，命令如下：\n\n关掉集群：curl -XPOST http://localhost:9200/-cluster/nodes/_shutdown。\n\n关掉指定的节点，节点标识符为jMJhGirhSRa9Iw2fQtjJ5A：curl -XPOST http://localhost:9200/_cluster/nodes/jMJhGirhSRa9Iw2fQtjJ5A/_shutdown。\n\n重启ES服务器\n\n如果是想再次重启已经启动的ES服务，可以在Window系统的服务列表中找到安装的服务，然后右键重新启动即可。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"ElasticSearch5.5.0安装","uid":"4791","views":"2264","votes":"1"},"_type":"doc"}
{"_id":"258","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504675442","category_id":"12","comments":"0","has_attach":"0","id":"258","message":"工作职责： 1、ElasticSearch集群的配置管理和优化； 2、ElasticSearch相关开发。技能及资质要求： 1、本科及以上学历，熟悉Java，Linux； 2、熟悉ElasticSearch，有相关使用或开发经验； 3、熟悉搜索技术、nosql或hadoop等优先。有意向者，请将简历发送至：noh1122@163.com，QQ: 2472659680","title":"【360 - 北京】ES研发工程师","uid":"4944","views":"2102","votes":"0"},"_type":"doc"}
{"_id":"277","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505445861","category_id":"2","comments":"1","has_attach":"1","id":"277","message":"转几篇文章，让大家知晓，当前版本(\u0026lt;=5.x) 为何要避免将稀疏的数据写入ES。 随着ES/Lucene编码的改进，这个问题未来版本可能会得到改善，特别是ES6.0/Lucene7.0优化了doc_values对稀疏数据的编码方式。\n \n[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/general-recommendations.html#sparsity[/url]  \n[quote]\n[b]Avoid sparsityedit[/b]\n\nThe data-structures behind Lucene, which Elasticsearch relies on in order to index and store data, work best with dense data, ie. when all documents have the same fields. This is especially true for fields that have norms enabled (which is the case for text fields by default) or doc values enabled (which is the case for numerics, date, ip and keyword by default).\n\nThe reason is that Lucene internally identifies documents with so-called doc ids, which are integers between 0 and the total number of documents in the index. These doc ids are used for communication between the internal APIs of Lucene: for instance searching on a term with a matchquery produces an iterator of doc ids, and these doc ids are then used to retrieve the value of the norm in order to compute a score for these documents. The way this norm lookup is implemented currently is by reserving one byte for each document. The norm value for a given doc id can then be retrieved by reading the byte at index doc_id. While this is very efficient and helps Lucene quickly have access to the norm values of every document, this has the drawback that documents that do not have a value will also require one byte of storage.\n\nIn practice, this means that if an index has M documents, norms will require M bytes of storage per field, even for fields that only appear in a small fraction of the documents of the index. Although slightly more complex with doc values due to the fact that doc values have multiple ways that they can be encoded depending on the type of field and on the actual data that the field stores, the problem is very similar. In case you wonder: fielddata, which was used in Elasticsearch pre-2.0 before being replaced with doc values, also suffered from this issue, except that the impact was only on the memory footprint since fielddata was not explicitly materialized on disk.\n\nNote that even though the most notable impact of sparsity is on storage requirements, it also has an impact on indexing speed and search speed since these bytes for documents that do not have a field still need to be written at index time and skipped over at search time.\n\nIt is totally fine to have a minority of sparse fields in an index. But beware that if sparsity becomes the rule rather than the exception, then the index will not be as efficient as it could be.\n\nThis section mostly focused on norms and doc values because those are the two features that are most affected by sparsity. Sparsity also affect the efficiency of the inverted index (used to index text/keyword fields) and dimensional points (used to index geo_point and numerics) but to a lesser extent.\n\nHere are some recommendations that can help avoid sparsity:\n[/quote]\n[url]https://www.elastic.co/blog/index-vs-type[/url]\n[quote]\nFields that exist in one type will also consume resources for documents of types where this field does not exist. [b]This is a general issue with Lucene indices: they don’t like sparsity[/b]. Sparse postings lists can’t be compressed efficiently because of high deltas between consecutive matches. And the issue is even worse with doc values: for speed reasons, doc values often reserve a fixed amount of disk space for every document, so that values can be addressed efficiently. This means that if Lucene establishes that it needs one byte to store all value of a given numeric field, it will also consume one byte for documents that don’t have a value for this field. Future versions of Elasticsearch will have improvements in this area but I would still advise you to model your data in a way that will limit sparsity as much as possible.\n[/quote]\n[url]https://www.elastic.co/blog/sparse-versus-dense-document-values-with-apache-lucene[/url]\n[url=https://issues.apache.org/jira/browse/LUCENE-6863]https://issues.apache.org/jira/browse/LUCENE-6863​[/url] \n[url]https://www.elastic.co/blog/elasticsearch-6-0-0-alpha1-released[/url]\n\n[attach]1032[/attach]","title":"为何要避免往ES里写入稀疏数据","uid":"81","views":"1275","votes":"5"},"_type":"doc"}
{"_id":"280","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505598980","category_id":"18","comments":"0","has_attach":"0","id":"280","message":"1.通过Elasticsearch创建阈值警报器。\nhttp://t.cn/RpmnT8C\n2. 使用Elasticsearch和grafana分析github项目。\nhttp://t.cn/R9xXkZE\n3.  第二届GrafanaCon谈话视频整理。\nhttp://t.cn/RpmmMk3\n\n编辑：至尊宝\n归档：https://www.elasticsearch.cn/article/280\n订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第50期 (2017-09-17)","uid":"4460","views":"562","votes":"0"},"_type":"doc"}
{"_id":"286","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505892803","category_id":"2","comments":"0","has_attach":"0","id":"286","message":"利用elk搞了一个日志平台，随着日志越来越多，使用的人反应kibana上查询比较慢。kibana虽然有日志，但记录的信息不全，无法分析到底是什么样的查询比较慢。因此考虑在kibana和elk之间加一个nginx。主要作用有两个：\n1、记录kibana的每个请求日志\n2、kibana通过nginx连到es，可以实现负载均衡的请求es。\n集成方法比较简单，在任意一台机器上安装nginx，nginx里配置es相关信息，kibana配置文件中的elasticsearch.url改成nginx相应的ip和监听端口即可。\nnginx配置文件的主要内容如下：\n    upstream elasticsearch {\n        server 10.10.10.1:9200;\n        server 10.10.10.2:9200;\n        server 10.10.10.3:9200;\n        keepalive 10;\n    }\n\n    server {\n        listen       8888;\n        server_name  hostname;\n\n        location / {\n            proxy_pass http://elasticsearch;\n\n            access_log_bypass_if ($request = 'HEAD / HTTP/1.1');\n            access_log_bypass_if ($request = 'GET /_nodes?filter_path=nodes.*.version%2Cnodes.*.http.publish_address%2Cnodes.*.ip HTTP/1.1');\n            access_log_bypass_if ($request = 'GET /_nodes/_local?filter_path=nodes.*.settings.tribe HTTP/1.1');\n            access_log_bypass_if ($request_body = '{\\\u0026quot;docs\\\u0026quot;:[{\\\u0026quot;_index\\\u0026quot;:\\\u0026quot;.kibana\\\u0026quot;,\\\u0026quot;_type\\\u0026quot;:\\\u0026quot;config\\\u0026quot;,\\\u0026quot;_id\\\u0026quot;:\\\u0026quot;5.5.1\\\u0026quot;}]}');\n            access_log_bypass_if ($request = 'GET /_cluster/health/.kibana?timeout=5s HTTP/1.1');\n            access_log_bypass_if ($request = 'POST /.kibana/config/_search HTTP/1.1');\n            access_log_bypass_if ($request = 'GET /_cluster/settings?include_defaults=true\u0026amp;filter_path=**.script.engine.*.inline HTTP/1.1');\n            access_log_bypass_if ($request = 'GET /_aliases HTTP/1.1');\n            access_log_bypass_if ($request = 'GET /_mapping HTTP/1.1');\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n    }\n \nupstream定义了es有哪些节点。另外，nginx加了日志过滤模块ngx_log_if，用来过滤kibana和es之间的心跳请求日志，这个模块可以在github上下载","title":"nginx和kibana/es集成","uid":"3296","views":"1913","votes":"0"},"_type":"doc"}
{"_id":"293","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506219461","category_id":"18","comments":"0","has_attach":"0","id":"293","message":"1.如何在Node.js应用中集成Elasticsearch。\nhttp://t.cn/R0GmjQC\n2.(自备梯子)不仅仅是一篇Elasticsearch入门级文章！看看别人的团队是怎么选的吧。\nhttp://t.cn/R0GmTgf\n3.Elasticsearch最佳实践，看看大牛在日常工作中都是怎么做的。\nhttp://t.cn/R0Gm8bE\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/293\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第57期 (2017-09-24)","uid":"4460","views":"629","votes":"0"},"_type":"doc"}
{"_id":"299","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506563641","category_id":"18","comments":"0","has_attach":"0","id":"299","message":"1.将elasticsearch的数据自动metric到prometheus http://t.cn/R09JjJh\n2.详解Elasticsearch的nested类型aggregations？ http://t.cn/R0Nk3EA\n3.社区热议：elasticsearch的中文打分到底是怎样的呢？ https://elasticsearch.cn/question/2275\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/299\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第61期 (2017-09-28)","uid":"668","views":"856","votes":"1"},"_type":"doc"}
{"_id":"301","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506587101","category_id":"3","comments":"2","has_attach":"1","id":"301","message":"我新增加了一个字段，对应的值是中文的\r\n\r\n[attach]1095[/attach]\r\n 如上图 我的这个字段类型一直是unknown,下图是配置方式：\r\n\r\n[attach]1096[/attach]\r\n es 是5.4的\r\nlogstash 5.4\r\nkibana 5.4\r\n \r\n \r\n ","title":"中文值的字段是string的类型吗？我有一个字段类型一直显示unknown","uid":"5527","views":"1202","votes":"0"},"_type":"doc"}
{"_id":"2","_index":"forum-mysql","_score":1,"_source":{"addtime":"1439352270","category_id":"1","comments":"3","has_attach":"0","id":"2","message":"第四届Elasticsearch国内开发者大会北京站马上就要开始了,目前已确定分享的主题有6篇了,有来自百度\\新浪\\芒果TV等公司同学们的精彩分享,有国内最大规模elasticsearch集群搭建的经验分享,有ELK的实践应用,有最新的Kibana4的插件开发,有安全领域的分析实战,干货多多,非常值得期待,报名地址(因为meetup不支持国内很多邮箱的注册,请大家使用下面的表单报名,辛苦已经报过名的同学了): [ http://t.cn/Ry2aVzr]( http://t.cn/Ry2aVzr)\n\nESCC#4全称:The 4th Elasticsearch China Conference,是由elasticsearch中文社区每年定期举办的线下交流活动,今年已经是第四届了,会议围绕elasticsearch及周边产品和技术,如:kibana\\logstash\\beats\\logging\\nlp等相关领域及话题都可以进行讨论,只要是你认为可能会感兴趣的话题,都可以提交过来,分享嘉宾来自国内一线互联网公司,倡导干货接地气纯粹的技术交流.​\n\n北京地区:\n地点:中国科学院软件研究所; 时间:2015年10月17日\n\n其它城市正在筹划中,有愿意提供帮助和愿意分享你们和elasticsearch的经验或者故事的同学欢迎和Medcl联系.\n\n关于活动最新动态请访问: http://www.meetup.com/Elasticsearch-China-Users/","title":"10月北京es第4届国内开发者大会现在可以开始报名了.","uid":"1","views":"3084","votes":"3"},"_type":"doc"}
{"_id":"4","_index":"forum-mysql","_score":1,"_source":{"addtime":"1446377146","category_id":"5","comments":"2","has_attach":"0","id":"4","message":"[b]时间[/b]:Sunday, November 22, 2015   1:00 PM\n[b]地点[/b]:四川成都市高新区天府大道中段1366号天府软件园E3-1-11层\n \n[b]报名地址[/b]: [url]http://form.mikecrm.com/f.php?t=mOUa1M [/url]\n\n\n[b]ESCC#4全称:The 4th Elasticsearch China Conference,[/b]\n\n是由elasticsearch中文社区每年定期举办的线下交流活动,今年已经是第四届了,会议围绕elasticsearch及周边产品和技术,如:kibana\\logstash\\beats\\logging\\nlp等相关领域及话题都可以进行讨论,只要是你认为可能会感兴趣的话题,都可以提交过来,分享嘉宾来自国内一线互联网公司,倡导干货接地气纯粹的技术交流.\n\n分享主题\n\n[b]一,《What's New in Elasticsearch2.0?》[/b]\n\n内容介绍:\n\nElasticsearch2.0新特性介绍! \n\n分享者简介：Medcl,Elastic开发工程师及布道师.\n\n[b]二,《基于es构建实时日志检索平台》[/b]\n\n内容介绍:\n\n2011年毕业后加入京东，作为项目技术负责人以及架构师参与了hadoop生态系统建设一期、云存储一期、统一日志、公有PAAS平台和基于容器技术的自动部署等项目。目前在京东成都研究院工具部主要负责工具部各个项目系统架构和产品优化和创新。作为一个技术极客希望组建一支一流的技术团队，同时希望和各位技术爱好者一起交流技术以及技术创新。 提纲：\n\n1.系统整体架构介绍\n2.日志采集方案以及实现原理介绍   \n\n3.日志转发方案以及实现原理介绍\n4.日志搜索实现\n5.es优化简介。\n\n分享者简介：吴友强 京东成都研究院工具部负责人兼系统架构师\n\n[b]三,《ElasticSearch:fast and slow》​[/b]\n\n内容介绍:   \n1,系统整体架构介绍\n2,两个不同场景下的es查询入库优化方案\n3,场景一：毫秒级低延迟入库加查询(fast)\n4,场景二：依赖hadoop做pb级别以上查询(slow)\n    \n分享者简介：查超，瀚思安信基础平台部 研究人员\n\n更多讲师及分享主题介绍陆续添加中...\n\n\n鸣谢:\n\n感谢 货车帮对这次活动的大力支持","title":"Elasticsearch China Conference #4 In Chengdu","uid":"1","views":"4165","votes":"0"},"_type":"doc"}
{"_id":"6","_index":"forum-mysql","_score":1,"_source":{"addtime":"1446907674","category_id":"8","comments":"3","has_attach":"0","id":"6","message":"上海站视频录像照片PPT:\n[url=http://pan.baidu.com/s/1o6iXaqe#path=%252FESCC%25234%252F%25E4%25B8%258A%25E6%25B5%25B7%25E7%25AB%2599]http://pan.baidu.com/s/1boF8Buf#path=%252FESCC%25234%252F%25E4%25B8%258A%25E6%25B5%25B7%25E7%25AB%2599[/url]","title":"ESCC#4上海站视频录像照片PPT","uid":"1","views":"2950","votes":"1"},"_type":"doc"}
{"_id":"15","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449326992","category_id":"14","comments":"0","has_attach":"0","id":"15","message":"前几天，我们已经一步步搞定了一个业务日志从 mapping 设计到异常统计追踪上的用法。作为一个工程师，自评 100 分 —— But，领导找上门来说：你这个结构怎么搞的嘛，在 Kibana 上完全没法搜索！让客服和分析师怎么办？\n\n因为 Kibana 上的输入框，默认使用 querystring 语法。这个里面压根没有对 nested object 的相关语法设计。\n\n不过经过仔细查阅，发现原来 Kibana4 的搜索输入框，其实除了 querystring 以外，还支持 JSON 字符串的方式直接定义 query！其具体处理方式就是：把你输入的字符串判断一下是否是 JSON，如果是 JSON，直接替换进{\u0026quot;query\u0026quot;: 这里}；如果不是，才生成一个 querystring query 放进 {\u0026quot;query\u0026quot;:{\u0026quot;query_string\u0026quot;:\u0026quot;\u0026quot;}}\n\n那我们来尝试一下把第三天写的那个 nested query 贴进搜索框里。内容是：\n[code]{\n  \u0026quot;nested\u0026quot; : {\n    \u0026quot;path\u0026quot; : \u0026quot;video_time_duration\u0026quot;,\n    \u0026quot;query\u0026quot; : {\n      \u0026quot;match\u0026quot; : {\n        \u0026quot;video_time_duration.type\u0026quot; : \u0026quot;1\u0026quot;\n      }\n    }\n  }\n}[/code]意外发生了！Kibana4 竟然在页面上弹出一个错误提示，而且搜索栏的放大镜图标也变成不可以点击的灰色样式，敲回车同样没有反应：\n[img]http://logstash.es/images/elk-advent-2015-05.png[/img]\n当然我很确定我的数据是没问题的。这时候 Kibana4 的另一个特性救了我：[b]它默认会把所有可修改的状态都 rison 序列化了放在 URL 里！[/b]于是我尝试直接在浏览器地址栏里输入下面这段 URL：\n[code]http://kibana:5601/#/discover?_g=()\u0026amp;_a=(columns:!(_source),index:%5Blogstash-mweibo-%5DYYYY.MM.DD,interval:auto,query:(nested:(path:video_time_duration,query:(term:(video_time_duration.type:1)))),sort:!('@timestamp',desc))[/code]地址栏回车之后，页面刷新，看到搜索结果更新(如上图)！虽然搜索栏依然有报错，但实际上 nested query 生效了，我们在下面 search 里看到的都是成功过滤出来的『有过卡顿的视频播放记录』日志。\n\n感谢 Kibana 如此开放的设计原则！\n\nps: 目前 nested aggregation 还没法像这样简单的绕过，不过已经有相关 pull request 在 review 中，或许 Kibana4.3/4.4 的时候就会合并了。有兴趣的同学，也可以跟我一样先睹为快哟：[url]https://github.com/elastic/kibana/pull/5411[/url]\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。\n ","title":"Day5: Kibana4的rison序列化妙用","uid":"7","views":"2724","votes":"0"},"_type":"doc"}
{"_id":"20","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449655032","category_id":"14","comments":"0","has_attach":"0","id":"20","message":"三斗已经写了好多篇了，分享了很多小经验和知识，非常不错，不如我们一起把Advent玩起来吧，这样，我们玩一个接力游戏，每个同学写完之后可以@论坛里面的其它同学，被@的同学需要完成一篇小的Advent，然后写完再继续接着传给下一位，如果不在论坛的同学，就邀请他加入下 ：）\n \n@的操作就是在贴子里@对方的名字，然后你想办法通知到对方就行了，QQ、论坛消息等等反正告诉对方被@和继续就行咯。\n没有找到下一个接班的人就继续写下去。哈哈\n\n写Advent，选择发表类型『文章』，分类选择『advent』，话题添加『advent』+其它的自选\n\n下面是一篇ELK的Advent，顺便分享一下。[url=http://sysadvent.blogspot.com.au/2015/12/day-5-elk-operations-and-administration.html]Day 5 - ELK Operations and Administration[/url]\n \n 欢迎补充完善规则。\n ","title":"大家一起来写Advent吧","uid":"1","views":"2931","votes":"0"},"_type":"doc"}
{"_id":"27","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450278612","category_id":"14","comments":"0","has_attach":"0","id":"27","message":"我们都知道 Elasticsearch 除了普通的 search 接口以外，还有另一个 Percolator 接口，天生用来做实时过滤告警的。但是由于接口比较复杂，在目前的 ELK 体系中不是很容易运用。\n\n而单纯从 Logstash 来做实时过滤报警，规则又不是很灵活。toplog.io 公司开发了一个 logstash-output-percolator插件，在有一定既定条件的情况下，成功运用上了 Percolator 方案。\n\n这个插件的设计逻辑是：\n[list=1]\n[*]通过 logstash-filter-checksum 自主生成 ES 文档的 _id；[/*]\n[*]使用上一步生成的 _id 同时发送 logstash-output-elasticsearch 和 logstash-output-percolator[/*]\n[*]Percolator 接口一旦过滤成功，将 _id 发送给 Redis 服务器[/*]\n[*]其他系统从 Redis 服务器中获取 _id 即可从 ES 里拿到实际数据[/*]\n[/list]\nPercolator 接口的用法简单说是这样：\n\n创建接口：[code]curl -XPUT 'localhost:9200/patterns/.percolator/my-pattern-id' -d '{\u0026quot;query\u0026quot; : {\u0026quot;match\u0026quot; : {\u0026quot;message\u0026quot; : \u0026quot;ERROR\u0026quot;} } }'[/code]过滤测试：[code]curl -XGET 'localhost:9200/my-index/my-type/_percolate' -d '{\u0026quot;doc\u0026quot; : {\u0026quot;message\u0026quot; : \u0026quot;ERROR: Service Apache failed to connect to MySQL\u0026quot;} }'[/code]要点就是把文档放在 doc 属性里发送到 _percolate 里。\n\n对应的 Logstash 配置如下：[code]filter {\n    checksum {\n        algorithm =\u0026gt; \u0026quot;md5\u0026quot;\n        keys =\u0026gt; [\u0026quot;message\u0026quot;]\n    }\n}\noutput {\n    elasticsearch {\n        host =\u0026gt; \u0026quot;localhost\u0026quot;\n        cluster =\u0026gt; \u0026quot;my-cluster\u0026quot;\n        document_id =\u0026gt; \u0026quot;%{logstash_checksum}\u0026quot;\n        index =\u0026gt; \u0026quot;my-index\u0026quot;\n    }\n    percolator {\n        host =\u0026gt; \u0026quot;es-balancer\u0026quot;\n        redis_host =\u0026gt; [\u0026quot;localhost\u0026quot;]\n        document_id =\u0026gt; \u0026quot;%{logstash_checksum}\u0026quot;\n        pattern_index =\u0026gt; \u0026quot;patterns\u0026quot;\n    }\n}[/code]连接上对应的 Redis，就可以看到报警信息了：[code]$ redis-cli\n127.0.0.1:6379\u0026gt; lrange percolator 0 1\n1) \u0026quot;{\\\u0026quot;matches\\\u0026quot;:[\\\u0026quot;2\\\u0026quot;],\\\u0026quot;document_id\\\u0026quot;:\\\u0026quot;a5d5c5f69b26ac0597370c9b1e7a8111\\\u0026quot;}\u0026quot;[/code]想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day14: percolator接口在logstash中的运用","uid":"7","views":"3698","votes":"1"},"_type":"doc"}
{"_id":"35","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450945995","category_id":"14","comments":"6","has_attach":"0","id":"35","message":"我们都知道Kibana4里，所有的aggregation生成的visualize都可以在请求细节查看里选择`Export`成raw或者formatted。其中formatted就是CSV文件。\n但是Discover页上，除了顶部的date_histogram这个visualize，更重要的是下边的search document table的内容。当我们通过搜索发现异常信息，想要长期保存证据，或者分享给其他没有权限的外部人员的时候，单纯保存search到es，或者分享单条日志的link都不顶用，还是需要能导出成一个文件。\n可惜Kibana4没有针对search document table的导出！\n国外一家叫MineWhat的公司，最近公开了一个非常细小的创新方案，意图解决这个问题。他们的方式是：避免修改Kibana源码，而通过chrome浏览器插件完成……\n点击这个地址安装chrome插件：[url]https://chrome.google.com/webstore/detail/elasticsearch-csv-exporte/kjkjddcjojneaeeppobfolgojhohbpjn/related[/url]\n \n然后再访问Kibana的时候，你会发现自己的搜索框最右侧多了一个CSV按钮：\n \n[img]http://minewhat.com/blog/content/images/2015/12/k1.jpg[/img]\n \n然后点击这个『CSV』按钮，会弹出一片提示：\n[img]http://minewhat.com/blog/content/images/2015/12/k2-1.jpg[/img]\n可以点击选择，把search document table内容保存到本机的复制粘贴板，还是Google Drive网盘。\n我们当然选择本机……\n然后打开本地的文本文件，Ctrl+V，就看到编辑器里出现了整个CSV内容。\n实测下来，发现有个小问题，粘贴出来的数据里丢掉了空格~不过聊胜于无吧，还是介绍给大家一试。\n \n[b]注意：这个功能只会导出目前页面上已经展示出来的table内容。并不代表其使用了scroll API去ES拉取全部结果集！[/b]","title":"Day21: 如何快速把Kibana4 Discover页的Document Table导出成CSV","uid":"7","views":"10598","votes":"1"},"_type":"doc"}
{"_id":"36","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451012802","category_id":"14","comments":"1","has_attach":"0","id":"36","message":"网友们多次讨论如何利用 ES 计算用户留存率的问题。这是个比较尴尬的情况，如果多次请求再自己做一下运算，问题很简单。但如果想要一次请求得到最终结果，在没有完整 JOIN 支持的 ES 里又显得比较难以完成。\n\n目前我想到的比较容易达成的做法，是我们在记录用户登录操作日志的时候，把该用户的注册时间也同期输出。也就是说，这个索引的 mapping 是下面这样：[code]curl -XPUT 'http://127.0.0.1:9200/login-2015.12.23/' -d '{\n  \u0026quot;settings\u0026quot; : {\n    \u0026quot;number_of_shards\u0026quot; : 1\n  },\n  \u0026quot;mappings\u0026quot; : {\n    \u0026quot;logs\u0026quot; : {\n      \u0026quot;properties\u0026quot; : {\n        \u0026quot;uid\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; },\n        \u0026quot;register_time\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; },\n        \u0026quot;login_time\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; }\n      }\n    }\n  }\n}'[/code]那么实际记录的日志会类似这样：[code]{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;login-2015.12.23\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;logs\u0026quot;}}\n{\u0026quot;uid\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;register_time\u0026quot;:\u0026quot;2015-12-23T12:00:00Z\u0026quot;,\u0026quot;login_time\u0026quot;:\u0026quot;2015-12-23T12:00:00Z\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;login-2015.12.23\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;logs\u0026quot;}}\n{\u0026quot;uid\u0026quot;:\u0026quot;2\u0026quot;,\u0026quot;register_time\u0026quot;:\u0026quot;2015-12-23T12:00:00Z\u0026quot;,\u0026quot;login_time\u0026quot;:\u0026quot;2015-12-23T12:00:00Z\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;login-2015.12.24\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;logs\u0026quot;}}\n{\u0026quot;uid\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;register_time\u0026quot;:\u0026quot;2015-12-23T12:00:00Z\u0026quot;,\u0026quot;login_time\u0026quot;:\u0026quot;2015-12-24T12:00:00Z\u0026quot;}[/code]这段我虚拟的数据，表示 uid 为 1 的用户，23 号注册并登录，24 号再次登录；uid 为 2 的用户，23 号注册并登录，24 号无登录。\n\n显然以这短短 3 行示例数据，我们口算都知道单日留存率是 50% 了。那么怎么通过一次 ES 请求也算出来呢？下面就要用到 ES 2.0 新增加的 pipeline aggregation 了。[code]curl -XPOST 'http://127.0.0.1:9200/login-2015.12.23,login-2015.12.24/_search' -d'\n{\n  \u0026quot;size\u0026quot; : 0,\n  \u0026quot;aggs\u0026quot; : {\n    \u0026quot;new_users\u0026quot; : {\n\n      \u0026quot;filters\u0026quot; : {\n        \u0026quot;filters\u0026quot; : [\n          {\n            \u0026quot;range\u0026quot; : {\n              \u0026quot;register_time\u0026quot; : {\n                \u0026quot;gte\u0026quot; : \u0026quot;2015-12-23\u0026quot;,\n                \u0026quot;lt\u0026quot; : \u0026quot;2015-12-24\u0026quot;\n              }\n            }\n          }\n        ]\n      },\n      \u0026quot;aggs\u0026quot; : {\n        \u0026quot;register_count\u0026quot; : {\n          \u0026quot;cardinality\u0026quot; : {\n            \u0026quot;field\u0026quot; : \u0026quot;uid\u0026quot;\n          }\n        },\n        \u0026quot;today\u0026quot; : {\n          \u0026quot;filter\u0026quot; : {\n            \u0026quot;range\u0026quot; : {\n              \u0026quot;login_time\u0026quot; : {\n                \u0026quot;gte\u0026quot; : \u0026quot;2015-12-24\u0026quot;,\n                \u0026quot;lt\u0026quot; : \u0026quot;2015-12-25\u0026quot;\n              }\n            }\n          },\n          \u0026quot;aggs\u0026quot; : {\n            \u0026quot;login_count\u0026quot; : {\n              \u0026quot;cardinality\u0026quot; : {\n                \u0026quot;field\u0026quot; : \u0026quot;uid\u0026quot;\n              }\n            }\n          }\n        },\n        \u0026quot;retention\u0026quot; : {\n          \u0026quot;bucket_script\u0026quot; : {\n            \u0026quot;buckets_path\u0026quot; : {\n              \u0026quot;today_count\u0026quot; : \u0026quot;today\u0026gt;login_count\u0026quot;,\n              \u0026quot;yesterday_count\u0026quot; : \u0026quot;register_count\u0026quot;\n            },\n            \u0026quot;script\u0026quot; : {\n              \u0026quot;lang\u0026quot; : \u0026quot;expression\u0026quot;,\n              \u0026quot;inline\u0026quot; : \u0026quot;today_count / yesterday_count\u0026quot;\n            }\n          }\n        }\n      }\n    }\n  }\n}'[/code]这个 pipeline aggregation 在使用上有几个要点：\n[list=1]\n[*]pipeline agg 的 parent agg 必须是返回数组的 buckets agg 类型。我这里曾经打算使用 filter agg 直接请求register_time:[\u0026quot;now-2d\u0026quot; TO \u0026quot;now-1d\u0026quot;]，结果报错说找不到 buckets_path 的 START_OBJECT。所以改用了 filters agg 的数组格式。[/*]\n[*]bucket_script agg 同样受 scripting module 的影响。也就是说，官网示例里的\u0026quot;script\u0026quot;:\u0026quot;today_count / yesterday_count\u0026quot; 这种写法，是采用了 groovy 引擎的 inline 模式。在 ES 2.0 的默认设置下，是被禁止运行的！所以，应该按照 scripting module 的统一要求，改写成 file 形式存放到 config/scripts下；或者改用 Lucene Expression 运行。考虑到 pipeline aggregation 只支持数值运算，这里使用 groovy 价值不大，所以直接指明 lang 参数即可。[/*]\n[/list]\n最终这次请求的响应如下：[code]{\n  \u0026quot;took\u0026quot; : 3,\n  \u0026quot;timed_out\u0026quot; : false,\n  \u0026quot;_shards\u0026quot; : {\n    \u0026quot;total\u0026quot; : 1,\n    \u0026quot;successful\u0026quot; : 1,\n    \u0026quot;failed\u0026quot; : 0\n  },\n  \u0026quot;hits\u0026quot; : {\n    \u0026quot;total\u0026quot; : 3,\n    \u0026quot;max_score\u0026quot; : 0.0,\n    \u0026quot;hits\u0026quot; : [ ]\n  },\n  \u0026quot;aggregations\u0026quot; : {\n    \u0026quot;new_users\u0026quot; : {\n      \u0026quot;buckets\u0026quot; : [ {\n        \u0026quot;doc_count\u0026quot; : 3,\n        \u0026quot;today\u0026quot; : {\n          \u0026quot;doc_count\u0026quot; : 1,\n          \u0026quot;login_count\u0026quot; : {\n            \u0026quot;value\u0026quot; : 1\n          }\n        },\n        \u0026quot;register_count\u0026quot; : {\n          \u0026quot;value\u0026quot; : 2\n        },\n        \u0026quot;retention\u0026quot; : {\n          \u0026quot;value\u0026quot; : 0.5\n        }\n      } ]\n    }\n  }\n}[/code]这个 retention 数据，就是我们要求解的 0.5 了。\n ","title":"Day22：pipeline aggregation计算日留存率示例","uid":"7","views":"7414","votes":"4"},"_type":"doc"}
{"_id":"38","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451033110","category_id":"14","comments":"12","has_attach":"1","id":"38","message":"[b]Note: 本文针对ES2.x[/b]\n Recovery是指将一个索引的未分配shard分配到一个结点的过程。 在快照恢复，更改索引复制片数量，结点故障或者结点启动时发生。由于master持有整个集群的状态信息，因此可以判断出哪些shard需要做再分配，以及分配到哪个结点。例如:\n[list]\n[*]如果某个shard主片在，副片所在结点挂了，那么选择另外一个可用结点，将副片分配(allocate)上去，然后进行主从片的复制。[/*]\n[*]如果某个shard的主片所在结点挂了，副片还在，那么将副片升级为主片，然后做主副复制。[/*]\n[*]如果某个shard的主副片所在结点都挂了，则暂时无法恢复，等待持有相关数据的结点重新加入集群后，从结点上恢复主分片，再选择某个结点分配复制片，并从主分片同步数据。[/*]\n[/list]\n\n通过CAT health API，我们可以查看集群的状态，从而获知数据的完整性情况:\n\n[attach]66[/attach]\n\n\n可能的状态及含义：\n[quote]\nGreen: 所有的shard主副片都完好的\nYellow: 所有shard的主片都完好，部分副片没有了，数据完整性依然完好。\nRed: 某些shard的主副片都没有了，对应的索引数据不完整\n[/quote]\n\nRecovery过程要消耗额外的资源，CPU、内存、结点之间的网络带宽等等。 这些额外的资源消耗，有可能会导致集群的服务能力降级，或者一部分功能暂时不可用。了解一些Recovery的过程和相关的配置参数，对于减小recovery带来的资源消耗，加快集群恢复过程都是很有帮助的。\n\n[b]减少集群Full Restart造成的数据来回拷贝[/b]\n集群可能会有整体重启的需要，比如需要升级硬件、升级操作系统或者升级ES大版本。重启所有结点可能带来的一个问题: 某些结点可能先于其他结点加入集群。 先加入集群的结点可能已经可以选举好master，并立即启动了recovery的过程，由于这个时候整个集群数据还不完整，master会指示一些结点之间相互开始复制数据。 那些晚到的结点，一旦发现本地的数据已经被复制到其他结点，则直接删除掉本地“失效”的数据。 当整个集群恢复完毕后，数据分布不均衡显然是不均衡的，master会触发rebalance过程，将数据在结点之间挪动。整个过程无谓消耗了大量的网络流量。 合理设置recovery相关参数则可以防范这种问题的发生。\n[quote]\ngateway.expected_nodes\ngateway.expected_master_nodes\ngateway.expected_data_nodes\n[/quote]\n以上三个参数是说集群里一旦有多少个结点就立即开始recovery过程。 不同之处在于，第一个参数指的是master或者data都算在内，而后面两个参数则分指master和data node。\n\n在期待的节点数条件满足之前, recovery过程会等待gateway.recover_after_time (默认5分钟) 这么长时间，一旦等待超时，则会根据以下条件判断是否启动:\n[quote]\ngateway.recover_after_nodes\ngateway.recover_after_master_nodes\ngateway.recover_after_data_nodes\n[/quote]\n\n举例来说，对于一个有10个data node的集群，如果有以下的设置:\n[quote]\ngateway.expected_data_nodes: 10\ngateway.recover_after_time: 5m\ngateway.recover_after_data_nodes: 8\n[/quote]\n\n那么集群5分钟以内10个data node都加入了，或者5分钟以后8个以上的data node加入了，都会立即启动recovery过程。\n\n\n[b]减少主副本之间的数据复制[/b]\n如果不是full restart，而是重启单个data node，仍然会造成数据在不同结点之间来回复制。为避免这个问题，可以在重启之前，先关闭集群的shard allocation:\n\n[attach]67[/attach]\n\n\n然后在结点重启完成加入集群后，再重新打开:\n\n[attach]68[/attach]\n\n这样在结点重启完成后，尽量多的从本地直接恢复数据。\n但是在ES1.6版本之前，即使做了以上措施，仍然会发现有大量主副本之间的数据拷贝。从表面去看，这点很让人不能理解。 主副本数据完全一致，ES应该直接从副本本地恢复数据就好了，为什么要重新从主片再复制一遍呢？ 原因在于Recovery是简单对比主副本的segment file来判断哪些数据一致可以本地恢复，哪些不一致需要远端拷贝的。而不同结点的segment merge是完全独立运行的，可能导致主副本merge的深度不完全一样，从而造成即使文档集完全一样，产生的segment file却不完全一样。\n为了解决这个问题，ES1.6版本以后加入了synced flush的新特性。 对于5分钟没有更新过的shard，会自动synced flush一下，实质是为对应的shard加了一个synced flush ID。这样当重启结点的时候，先对比一下shard的synced flush ID，就可以知道两个shard是否完全相同，避免了不必要的segment file拷贝，极大加快了冷索引的恢复速度。\n需要注意的是synced flush只对冷索引有效，对于热索引（5分钟内有更新的索引）没有作用。 如果重启的结点包含有热索引，那么还是免不了大量的文件拷贝。因此在重启一个结点之前，最好按照以下步骤执行，recovery几乎可以瞬间完成:\n[list=1]\n[*]暂停数据写入程序[/*]\n[*]关闭集群shard allocation[/*]\n[*]手动执行POST /_flush/synced[/*]\n[*]重启结点[/*]\n[*]重新开启集群shard allocation [/*]\n[*]等待recovery完成，集群health status变成green[/*]\n[*]重新开启数据写入程序[/*]\n[/list]\n\n[b](特别大的)热索引为何恢复慢[/b]\n对于冷索引，由于数据不再更新，利用synced flush特性，可以快速直接从本地恢复数据。 而对于热索引，特别是shard很大的热索引，除了synced flush派不上用场需要大量跨结点拷贝segment file以外，translog recovery是导致慢的更重要的原因。\n\n从主片恢复数据到副片需要经历3个阶段:\n[list=1]\n[*]对主片上的segment file做一个快照，然后拷贝到复制片分配到的结点。数据拷贝期间，不会阻塞索引请求，新增索引操作记录到translog里。[/*]\n[*]对translog做一个快照，此快照包含第一阶段新增的索引请求，然后重放快照里的索引操作。此阶段仍然不阻塞索引请求，新增索引操作记录到translog里。[/*]\n[*]为了能达到主副片完全同步，阻塞掉新索引请求，然后重放阶段二新增的translog操作。[/*]\n[/list]\n\n可见，在recovery完成之前，translog是不能够被清除掉的（禁用掉正常运作期间后台的flush操作）。如果shard比较大，第一阶段耗时很长，会导致此阶段产生的translog很大。重放translog比起简单的文件拷贝耗时要长得多，因此第二阶段的translog耗时也会显著增加。等到第三阶段，需要重放的translog可能会比第二阶段还要多。 而第三阶段是会阻塞新索引写入的，在对写入实时性要求很高的场合，就会非常影响用户体验。 因此，要加快大的热索引恢复速度，最好的方式是遵从上一节提到的方法: 暂停新数据写入，手动sync flush，等待数据恢复完成后，重新开启数据写入，这样可以将数据延迟影响可以降到最低。\n\n万一遇到Recovery慢，想知道进度怎么办呢？ CAT Recovery API可以显示详细的recovery各个阶段的状态。 这个API怎么用就不在这里赘述了，参考: [url=https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-recovery.html]CAT Recovery[/url]\n\n[b]其他Recovery相关的专家级设置[/b]\n还有其他一些专家级的设置（参见： [url=https://www.elastic.co/guide/en/elasticsearch/reference/current/recovery.html]recovery[/url]）可以影响recovery的速度，但提升速度的代价是更多的资源消耗，因此在生产集群上调整这些参数需要结合实际情况谨慎调整，一旦影响应用要立即调整回来。 对于搜索并发量要求高，延迟要求低的场合，默认设置一般就不要去动了。 对于日志实时分析类对于搜索延迟要求不高，但对于数据写入延迟期望比较低的场合，可以适当调大indices.recovery.max_bytes_per_sec，提升recovery速度，减少数据写入被阻塞的时长。\n \n最后要说的一点是ES的版本迭代很快，对于Recovery的机制也在不断的优化中。 其中有一些版本甚至引入了一些bug，比如在ES1.4.x有严重的translog recovery bug，导致大的索引trans log recovery几乎无法完成 （[url=https://github.com/elastic/elasticsearch/issues/9226]issue #9226[/url]）  。因此实际使用中如果遇到问题，最好在Github的issue list里搜索一下，看是否使用的版本有其他人反映同样的问题。","title":"Day 23 谈谈ES 的Recovery","uid":"81","views":"8204","votes":"19"},"_type":"doc"}
{"_id":"202","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501495882","category_id":"18","comments":"0","has_attach":"0","id":"202","message":"1. Logstash Persistent Queue [url]http://t.cn/R9ctBCQ[/url]\nLogstash 5.x 新加入了持久化队列功能，想要了解的同学不妨看看官网的这篇介绍哦！\n\n2. 在Elasticsearch中应用机器学习排序LTR [url]http://t.cn/RX2AVnS[/url]\n相信不少同学在开发中遇到过修改排序结果的需求，常见的操作是使用function_score 来自定义排序分值，但要做到个性化搜索的话，往往离不开数据挖掘、机器学习的算法，那么如何整合这些算法到Elasticsearch中呢？该文提供了一个思路，推荐阅读，开阔视野！\n\n3.用ElasticSearch搭建自己的搜索和分析引擎  [url]http://t.cn/R9can85[/url]\n来看下腾讯WeTest团队是如何调研和测试 Elasticsearch的，文章中提到的论坛统计分析功能是一个常见的需求，推荐大家阅读并实践！\n\n4.X-Pack Machine Learning Online Training [url]http://t.cn/R9c6vnt[/url]\n价值 $400 的 elastic 机器学习在线教程免费啦！免费啦！免费啦！还不赶紧去注册！\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/202\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第2期 (2017-07-31)","uid":"86","views":"2194","votes":"1"},"_type":"doc"}
{"_id":"203","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501551943","category_id":"18","comments":"3","has_attach":"0","id":"203","message":"1. Elasticsearch 6.0 将严格校验 Content-Type http://t.cn/R9VmPqx\n \n大家知道 Elasticsearch 是 HTTP+Restfu 风格的，在 5.x 及以前的版本，Content-Type 一直是松散不校验的，从而存在跨站脚本攻击的可能，所以从 6.0 开始，所有带请求体的 HTTP 请求都需要带上正确的 Content-type 才能正常执行，同时也意味着你的客户端是不是需要更新或者升级了，另外 6.0 马上就要发布了哦。\n\n2. Elasticsearch: How to avoid index throttling, deep dive in segments merging http://t.cn/R9V1sZH\n\nSegment 的合并会严重影响 Elasticsearch 的性能，但你知道 Elasticsearch 什么时候会进行合并么？这篇文章从源码层面比较详细的介绍了 Elasticsearch 内部的 Segment 合并策略，感兴趣的同学可以仔细读一下。\n\n3. Making your search not suck with Elasticsearch http://t.cn/R9Vg1SO\n\n系列文章，主要介绍文本分析原理以及如何优化 Elasticsearch 的相关性评分，完善搜索结果。\n\n4.极客邦科技发布站内搜索（InfoQ） http://t.cn/R9Vru3R\n\nPowered by Elasticsearch！看起来不错哦，虽然目前功能还比较简单。\n如果您有基于 Elasticsearch 实现的酷站，也欢迎投稿哦。\n \n今天是八一建军节，解放军同志们辛苦了！\n\n\n编辑：Medcl\n归档：https://elasticsearch.cn/article/203​\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第3期 (2017-08-01)","uid":"1","views":"1140","votes":"2"},"_type":"doc"}
{"_id":"207","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501723162","category_id":"18","comments":"4","has_attach":"0","id":"207","message":"1. 安全播报：超过5000个kibana实例裸奔在互联网 http://t.cn/R9JLxE9\n你的kibana也在裸奔吗？戳这里\n \n 2. string类型已死，字符串永生 http://t.cn/R9xxGwq\n还在疑惑ES5为什么移除了string类型？这里有你想要的答案。\n\n3. 机器学习与日志分析 http://t.cn/R9xxJtU\n不要被潮流淘汰：人工分析日志是徒劳的，机器学习是日志分析的趋势，玩转日志分析和机器学习。\n\n4. 另类玩法：用Elasticsearch和Grafana分析你的GitHub项目 http://t.cn/R9xXkZE\n想快速直观炫酷的了解自己的github project，这篇文章教你新姿势。\n\n编辑：金桥\n\n归档：https://elasticsearch.cn/article/207\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第5期 (2017-08-03)","uid":"668","views":"1939","votes":"3"},"_type":"doc"}
{"_id":"210","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501805192","category_id":"18","comments":"3","has_attach":"0","id":"210","message":"1. X-Pack Alternatives http://t.cn/RaFzzv1\n\n如果你看重了 elastic 付费套件 X-Pack 中的某个功能但又囊中羞涩，不妨来看看社区的其他选择方案。当然，还是推荐你去买 X-Pack ，官方出品，质有保障！\n\n2.Elasticsearch as a Graph Database  http://t.cn/R9Xgj2X\n\n\n听说过图数据库吧？你知道 es 也可以在这个领域发挥能力吗？快来看看吧！请自备梯子哦！\n\n3.Scaling Elasticsearch  http://t.cn/R9Xev3r\n\n听说你的es集群频繁GC，压力巨大，要扩容了？来看看这篇文章，科学扩容有保障！请自备梯子哦！\n\n\n招聘：\n\n阿里云近期会推出ES云产品，正在组建ES专家小组，工作地点北京、杭州，薪资待遇优厚。详情请看如下链接：https://elasticsearch.cn/article/209\n\n\n\n\n\n编辑：rockybean\n\n归档：https://elasticsearch.cn/article/210\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第6期 (2017-08-04)","uid":"86","views":"1100","votes":"4"},"_type":"doc"}
{"_id":"211","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501813233","category_id":"2","comments":"0","has_attach":"0","id":"211","message":"BKD Tree \n[url]https://www.elastic.co/blog/lucene-points-6.0[/url]\nBlock k-d trees are a simple yet powerful data structure. At index time, they are built by recursively partitioning the full space of N-dimensional points to be indexed into smaller and smaller rectangular cells, splitting equally along the widest ranging dimension at each step of the recursion. However, unlike an ordinary k-d tree, a block k-d tree stops recursing once there are fewer than a pre-specified (1024 in our case, by default) number of points in the cell.\n\nAt that point, all points within that cell are written into one leaf block on disk and the starting file-pointer for that block is saved into an in-heap binary tree structure. In the 1D case, this is simply a full sort of all values, divided into adjacent leaf blocks. There are k-d tree variants that can support removing values, and rebalancing, but Lucene does not need these operations because of its write-once per-segment design.\n \nAt search time, the same recursion takes place, testing at each level whether the requested query shape intersects the left or right sub-tree of each dimensional split, and recursing if so. In the 1D case, the query shape is simply a numeric range whereas in the 2D and 3D cases, it is a geo-spatial shape (circle, ring, rectangle, polygon, cube, etc.).[code]测试集合：模拟一亿条\n0,\u0026quot; nnrIuS\u0026quot;,\u0026quot;raet\u0026quot;,\u0026quot;lnsr\u0026quot;,\u0026quot;inu \u0026quot;,\u0026quot;saia\u0026quot;,83.405273,73.302012,3991,24,\u0026quot;N\u0026quot;,\u0026quot; usA\u0026quot;,\u0026quot;airport\u0026quot;,\u0026quot;rra i\u0026quot;\n1,\u0026quot;omlritp\u0026quot;,\u0026quot;aaVe\u0026quot;,\u0026quot;y Mu\u0026quot;,\u0026quot;AaVV\u0026quot;,\u0026quot;NMc \u0026quot;,15.459643,-20.826241,2627,54,\u0026quot;a\u0026quot;,\u0026quot;eemo\u0026quot;,\u0026quot;airport\u0026quot;,\u0026quot;MaArp\u0026quot;\n2,\u0026quot;kyaneMr\u0026quot;,\u0026quot;iasm\u0026quot;,\u0026quot;raAA\u0026quot;,\u0026quot; tnt\u0026quot;,\u0026quot;inls\u0026quot;,16.606066,38.663728,2761,53,\u0026quot;o\u0026quot;,\u0026quot;arIi\u0026quot;,\u0026quot;airport\u0026quot;,\u0026quot;uiron\u0026quot;[/code]\n\n\n1. General Multidimensional Space Points\n   Search for points with exact given values. \n  Search for points which has one of the value from a given set of values. \nSearch for points within a given range. \nGet the number of points which has exact point.\nGet the number of points within a given range. (Ranges are multidimensional ranges. In 3D, they are boxes.)\nDivide points into range-buckets and get the count in each buckets. (Range bucket is a range which has a label in it)\n \n2. Locations on the planet surface. (Latitude, Longitude)\n  Find closest set of airports to a given town.  \n  Find the set of airports within a given radius from a particular town.\n  Find the set of airports inside a country. (Country can be given as a polygon) \n  Find the set of airports within a given range of Latitudes and Longitudes. It is a Latitude, Longitude box query. (For a examples: Airports closer to the equatorial) \n  Find the set of airports closer to a given path. (Path can be something like a road. Find the airports which are less than 50km away from a given highway)\n  Count the airports in each country by giving country maps as polygons.\n \n[b]search  result:[/b]\n \nLoading Data is finished ----------------------------------------------------------------------\n建索引花费时间：982ms\nLatLon - Box Query Example------------------------------------------------------------------------------\nsearch_LatLon_Box 花费时间：69ms\n\nLatLon - K Nearest------------------------------------------------------------------------------\nsearch_LatLon_Nearest 花费时间：108ms\n\nDoublePoint 1D Point Exact------------------------------------------------------------------------------\nsearch_Double_1D_Exact 花费时间：10ms\n\nDoublePoint 1D - Range------------------------------------------------------------------------------\nsearch_Double_1D_range 花费时间：8ms\n\nDoublePoint 1D - Range Buckets -----------------------------------------------------------------------------\nsearch_Double_1D_range_bucket 花费时间：58ms\n\nDoublePoint multi dimensional - Range------------------------------------------------------------------------------\nsearch_Double_MiltiDimensional_Range 花费时间：1ms\n \n \n ","title":"Lucene 6 基于BKD Tree Index 的应用","uid":"3880","views":"1546","votes":"1"},"_type":"doc"}
{"_id":"213","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501894061","category_id":"18","comments":"0","has_attach":"0","id":"213","message":"1. 23 Useful Elasticsearch Example Queries  http://t.cn/R9Sjxf5\n\nES作为全文检索引擎，最常用的查询都在这里了\n\n\n\n\n2. All About Analyzers\n\nPart 1: http://t.cn/R9SFtYd\n\nPart 2: http://t.cn/R9SFxPZ\n\n如何利用ES提供的tokenizer filter以及正则等组件定制自己的analyzer，这篇文章给出了方向。\n\n\n\n\n3. Elasticsearch Security: Authentication, Encryption, and Backup http://t.cn/R9SQJlK\n\n安全问题永远不会过时，用这篇文章检查下你的ES集群是否有安全隐患\n\n\n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/213\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第7期 (2017-08-05)","uid":"1874","views":"855","votes":"0"},"_type":"doc"}
{"_id":"532","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520987260","category_id":"18","comments":"0","has_attach":"0","id":"532","message":"1. elastic{on} 2018 新鲜出炉的3个开场视频，快来看看吧！\n[http://t.cn/RnhEkAy](http://t.cn/RnhEkAy)\n\n2. 如果你在使用 Azure，来看看如何使用 ElasticStack 监控它吧！\n[http://t.cn/RnhnA8O](http://t.cn/RnhnA8O)\n\n3. github 上开源的收集 docker 日志到 es 的项目\n[https://github.com/rchicoli/docker-log-elasticsearch](https://github.com/rchicoli/docker-log-elasticsearch)\n\n \n* 编辑：rockybean\n\n* 归档：https://elasticsearch.cn/article/532\n\n* 订阅：https://tinyletter.com/elastic-daily\n\n\n","title":"Elastic日报 第210期 (2018-03-14)","uid":"86","views":"456","votes":"0"},"_type":"doc"}
{"_id":"538","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521248093","category_id":"18","comments":"0","has_attach":"0","id":"538","message":"1. 利用K8S在AWS上部署ES集群\n[http://t.cn/RnLGtw7](http://t.cn/RnLGtw7) \n\n2. Bro与ELK集成之路\npart1:[http://t.cn/RnLI8dW](http://t.cn/RnLI8dW) \npart2:[http://t.cn/RnLInbr](http://t.cn/RnLInbr) \n\n3. 利用ELK自建错误监控工具。\n[http://t.cn/RnLMy5n](http://t.cn/RnLMy5n)  \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/538\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第213期 (2018-03-17)","uid":"1874","views":"561","votes":"0"},"_type":"doc"}
{"_id":"540","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521423151","category_id":"18","comments":"0","has_attach":"0","id":"540","message":"1.温故而知新，es中停用词的应用和优化\nhttp://t.cn/Rn5qP7X\n\n2.使用Hibernate ORM框架来更方便地搜索文档\nhttp://t.cn/RnqNXpc\n\n3. ebay:构建更快的电商搜索\n[url]http://t.cn/RnqW4V2[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/540\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第215期 (2018-03-19)","uid":"4063","views":"542","votes":"0"},"_type":"doc"}
{"_id":"544","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521683233","category_id":"18","comments":"0","has_attach":"0","id":"544","message":"1. Logstash迁移Elasticsearch数据方法解读。\n[http://t.cn/RnJAEhD](http://t.cn/RnJAEhD) \n\n2. 使用Elasticsearch快速搭建食谱搜索系统。\n[http://t.cn/RnJAnKb](http://t.cn/RnJAnKb) \n\n3. 了解如何在es上使用Java High REST客户端。\n[http://t.cn/RnJAu4B](http://t.cn/RnJAu4B) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/544 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第218期 (2018-03-22)","uid":"668","views":"522","votes":"0"},"_type":"doc"}
{"_id":"546","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521853254","category_id":"18","comments":"0","has_attach":"0","id":"546","message":"1.  ES搜索推荐优化的关键点\n\nhttp://t.cn/RnS1XP3\n\n2.  使用Kibana的相关技巧\n\nhttp://t.cn/RnSBs0w\n\n3. 一周热点：Java10来了，来看看它一同发布的全新JIT编译器\n\nhttp://t.cn/RnSdvh6\n\n4.南京meetup的分享报名链接\n\nhttps://elasticsearch.cn/m/question/3781\n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/546\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第220期 (2018-03-24)","uid":"1874","views":"580","votes":"0"},"_type":"doc"}
{"_id":"548","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522025722","category_id":"18","comments":"0","has_attach":"0","id":"548","message":"1.Apache Skywalking : 基于elasticSearch的调用链跟踪系统  \nhttp://t.cn/RTmeqMC\n\n2.  这就是搜索引擎：核心技术详解\nhttp://t.cn/zO4u4yM\n\n3. Twitter实时搜索引擎发展历程:6700亿推文的搜索实现\n[url]http://t.cn/RqZYFcH[/url] \n\n编辑:  cyberdak\n归档：https://elasticsearch.cn/article/548\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第222期 (2018-03-26)","uid":"4063","views":"791","votes":"0"},"_type":"doc"}
{"_id":"549","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522115743","category_id":"18","comments":"0","has_attach":"0","id":"549","message":"1.Elastic在grab的使用案例。\n[url]http://t.cn/Rnj9tdu[/url] \n2.饿了么在ELasticsearch自动化运维平台和监控平台的应用实践。\n[url]https://elasticsearch.cn/slides/109[/url] \n3.基于Elasticsearch的离线搜索平台架构设计。\n[url]https://elasticsearch.cn/slides/110[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/549[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第223期 (2018-03-27)","uid":"3788","views":"336","votes":"0"},"_type":"doc"}
{"_id":"553","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522361426","category_id":"18","comments":"0","has_attach":"0","id":"553","message":"1、Elasitcsearch写入流程解读\nhttp://t.cn/Rn84SeD\n2、ELASTICSEARCH SHRINK 过程原理分析\nhttp://t.cn/Rn849ox\n3、Elasitcsearch源码编译\n[url]http://t.cn/Rn84pUp[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/553\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第226期 (2018-03-30)","uid":"1341","views":"345","votes":"0"},"_type":"doc"}
{"_id":"556","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522635261","category_id":"18","comments":"0","has_attach":"0","id":"556","message":"1.使用新的shrink api来更好管理索引分片。\nhttp://t.cn/Rng7jcU\n\n2.当需要自己手动为文档生成id时的指南，让你挑选到一款高效合理的id生成器\nhttp://t.cn/RLcAIMJ\n\n3.kibana 搜索错误Courier Fetch: shards failed的解决方案\n[url]http://t.cn/RngAsvJ[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/556\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第229期 (2018-04-02)","uid":"4063","views":"320","votes":"0"},"_type":"doc"}
{"_id":"562","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522905776","category_id":"18","comments":"0","has_attach":"0","id":"562","message":"1. 十亿级索引性能优化的一些小经验总结。\n[http://t.cn/RmAME9K](http://t.cn/RmAME9K) \n\n2. ElasticSearch插件开发-Similarity插件。\n[http://t.cn/RmAM3cY](http://t.cn/RmAM3cY) \n\n3. 案例分享：Voxpopme怎么使用elasticsearch获得十倍的性能提升。\n[http://t.cn/RmAMHin](http://t.cn/RmAMHin) \n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/562 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第232期 (2018-04-05)","uid":"668","views":"346","votes":"0"},"_type":"doc"}
{"_id":"561","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522857687","category_id":"2","comments":"0","has_attach":"0","id":"561","message":"### 0、授人以渔，少走半年弯路！\n[死磕 Elasticsearch 方法论：普通程序员高效精进的 10 大狠招！](https://mp.weixin.qq.com/s/stC_xMP1n3aQ-0ZNAc3eQA)\n\n### 一、Elasitcsearch基础篇\n#### _1.1 Elasitcsearch基础认知_\n##### 1、[Elasticsearch学习，请先看这一篇！](https://blog.csdn.net/laoyang360/article/details/52244917)\n##### 2、[Elasticsearch增、删、改、查操作深入详解](https://blog.csdn.net/laoyang360/article/details/51931981)\n##### 3、[Elasticsearch 索引存储深入详解](https://blog.csdn.net/laoyang360/article/details/52166095)\n\n#### _1.2 Elasticsearch集群部署_\n##### 4、[Elasticsearch安装与测试验证详解](https://blog.csdn.net/laoyang360/article/details/5141709)\n##### 5、[Elasticsearch windows下一键安装实现深入详解](https://blog.csdn.net/laoyang360/article/details/5190235)\n##### 6、[Elasticsearch集群部署详解](https://blog.csdn.net/laoyang360/article/details/72850834)\n##### 7、[Elasticsearch5.4.0(head/kibana/logstash)安装部署深入详解](https://blog.csdn.net/laoyang360/article/details/73368740)\n\n#### _1.3 Elasticsearch 插件安装_\n##### 8、[Elasticsearch插件一——-head插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472821)\n##### 9、[Elasticsearch插件二—— kibana插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472888)\n##### 10、[Elasticsearch插件三—— Marvel插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472902)\n##### 11、[Elasticsearch插件四—— logstash插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472914)\n##### 12、[Elasticsearch插件五—— graph插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472931)\n##### 13、[Elasticsearch插件六—— 分词 IK analyzer插件安装详解](https://blog.csdn.net/laoyang360/article/details/51472953)\n##### 14、[Elasticsearch5.4.0 IK分词插件安装详解](https://blog.csdn.net/laoyang360/article/details/74090357)\n\n#### _1.4 Elasticsearch小试牛刀_\n##### 15、[ES技术团队划重点 | ES5.X，你必须知道的API和相关技巧](https://blog.csdn.net/laoyang360/article/details/77412668)\n##### 16、[Elasticsearch检索分类深入详解—基础篇](https://blog.csdn.net/laoyang360/article/details/77623013)\n##### 17、[上线必备 | 高性能ES5.X部署配置清单](https://blog.csdn.net/laoyang360/article/details/77985822)\n##### 18、[ Elasticsearch究竟要设置多少分片数？](https://blog.csdn.net/laoyang360/article/details/78080602)\n##### 19、[深究｜Elasticsearch单字段支持的最大字符数?](https://blog.csdn.net/laoyang360/article/details/78207980)\n##### 20、[Elasticsearch6.X 新类型Join深入详解](https://blog.csdn.net/laoyang360/article/details/79774481)\n\n### 二、Elasticsearch进阶篇\n#### _2.1 Elasitcsearch数据同步_\n\n##### 2.1.1 ES与关系型数据库同步\n###### 21、[logstash-input-jdbc实现mysql 与elasticsearch实时同步深入详解](https://blog.csdn.net/laoyang360/article/details/51747266)\n###### 22、[elasticsearch-jdbc实现MySQL同步到ElasticSearch深入详解](https://blog.csdn.net/laoyang360/article/details/51694519)\n###### 23、[go-mysql-elasticsearch实现mysql 与elasticsearch实时同步深入详解](https://blog.csdn.net/laoyang360/article/details/51771483)\n###### 24、[mysql 与elasticsearch实时同步常用插件及优缺点对比](https://blog.csdn.net/laoyang360/article/details/51771621)\n###### 25、[logstash-input-jdbc 同步原理及相关问题解读](https://blog.csdn.net/laoyang360/article/details/51793301)\n###### 26、[ logstash-input-jdbc实现oracle 与elasticsearch实时同步详解](https://blog.csdn.net/laoyang360/article/details/51824617)\n###### 27、[logstash一次同步Mysql多张表到ES深入详解](https://blog.csdn.net/laoyang360/article/details/75452953)\n\n\n##### 2.1.2 ES与非关系型数据库同步\n###### 28、[ logstash_output_mongodb插件用途及安装详解](https://blog.csdn.net/laoyang360/article/details/65448962)\n###### 29、[ logstash-output-mongodb实现Mysql到Mongodb数据同步](https://blog.csdn.net/laoyang360/article/details/65449127)\n###### 30、[logstash-out-mongodb实现elasticsearch到Mongodb的数据同步](https://blog.csdn.net/laoyang360/article/details/65449239)\n###### 31、[mongo-connector实现MongoDB与elasticsearch实时同步深入详解](https://blog.csdn.net/laoyang360/article/details/51842822)\n\n##### 2.1.3 ES与Kafka同步\n###### 32、[kafka数据同步Elasticsearch深入详解](https://blog.csdn.net/laoyang360/article/details/78868806)\n\n##### 2.1.4 ES文件同步\n###### 33、[ Elasticsearch批量导入本地Json文件Java实现](https://blog.csdn.net/laoyang360/article/details/75911669)\n###### 34、[logstash实现日志文件同步到elasticsearch深入详解](https://blog.csdn.net/laoyang360/article/details/51842744)\n\n##### 2.1.5 ES同步小结\n###### 35、[如何将不同类型数据导入Elaticsearch中？](https://blog.csdn.net/laoyang360/article/details/52304223)\n###### 36、[一张图理清楚关系型/非关系型数据库与Elasticsearch同步](https://blog.csdn.net/laoyang360/article/details/72792865)\n\n#### _2.2 Elasticsearch检索进阶_\n##### 37、[你必须知道的23个最有用的Elasticseaerch检索技巧](https://blog.csdn.net/laoyang360/article/details/76769208)\n##### 38、[Elasticsearch实战 | match_phrase搜不出来，怎么办？](https://blog.csdn.net/laoyang360/article/details/79249823)\n\n#### _2.3 Elasitcsearch聚合进阶_\n##### 39、[ Elasticsearch聚合深入详解——对比Mysql实现](https://blog.csdn.net/laoyang360/article/details/79048455)\n##### 40、[Elasticsearch聚合后分页深入详解](https://blog.csdn.net/laoyang360/article/details/79112946)\n##### 41、[Elasticsearch聚合优化 | 聚合速度提升5倍](https://blog.csdn.net/laoyang360/article/details/79253294)\n\n#### _2.4 Elasticsearch Java API 详解_\n##### 42、[ Elasticsearch Java API深入详解](https://blog.csdn.net/laoyang360/article/details/77146063)\n##### 43、[Elasticsearch Jest实战深入详解](https://blog.csdn.net/laoyang360/article/details/72793210)\n\n#### _2.5 Elasitcsearch数据迁移_\n##### 44、[Elasticsearch索引迁移的四种方式](https://blog.csdn.net/laoyang360/article/details/65449407)\n\n#### _2.6 Elasticsearch性能测试_\n##### 45、[ Elasticsearch自定义脚本完成性能测试](https://blog.csdn.net/laoyang360/article/details/72231924)\n##### 46、[Elasticsearch性能测试工具rally深入详解](https://blog.csdn.net/laoyang360/article/details/52176246)\n##### 47、[esrally性能分析结果图形化展示深入详解](https://blog.csdn.net/laoyang360/article/details/52176045)\n##### 48、[esrally性能测试原理](https://blog.csdn.net/laoyang360/article/details/52155481)\n\n#### _2.7 Elasitcsearch安全监控_\n##### 49、[Elasticsearch6.2.2 X-Pack部署及使用详解](https://blog.csdn.net/laoyang360/article/details/79632579)\n\n### 三、Elasticsearch实战篇\n#### _3.1 Elasticsearch应用场景_\n##### 50、[Elasticsearch的使用场景深入详解](https://blog.csdn.net/laoyang360/article/details/52227541)\n##### 51、[ Elasticsearch全文检索实战小结](https://blog.csdn.net/laoyang360/article/details/77823112)\n#### _3.2 Elasticsearch架构设计_\n##### 52、[ Elasticsearch实战——全文检索架构设计](https://blog.csdn.net/laoyang360/article/details/74090398)\n##### 53、[干货 |《深入理解Elasticsearch》读书笔记](https://blog.csdn.net/laoyang360/article/details/78554610)\n#### _3.3 Elasticsearch项目实战_\n##### 54、[Elasticsearch全文检索系统实现深入详解](https://blog.csdn.net/laoyang360/article/details/75933314)\n##### 55、[ Elasticsearch大文件检索性能提升20倍实践（干货）](https://blog.csdn.net/laoyang360/article/details/78025024)\n##### 56、[刨根问底 | Elasticsearch 5.X集群多节点角色配置深入详解](https://blog.csdn.net/laoyang360/article/details/78290484)\n##### 57、[干货 | Elasticsearch5.X Mapping万能模板](https://blog.csdn.net/laoyang360/article/details/78396928)\n##### 58、[干货 | Elasticsearch 集群健康值红色终极解决方案](https://blog.csdn.net/laoyang360/article/details/78443006)\n##### 59、[ 实战 | Elasticsearch打造知识库检索系统](https://blog.csdn.net/laoyang360/article/details/78703177)\n##### 60、[Elasticsearch实战 | 必要的时候，还得空间换时间!](https://blog.csdn.net/laoyang360/article/details/79515295)\n##### 61、[ Elasticsearch全量数据增量遍历实现原理](https://blog.csdn.net/laoyang360/article/details/79437408)\n##### 62、[ Elasticsearch索引增量统计及定时邮件实现](https://blog.csdn.net/laoyang360/article/details/79427706)\n\n更多干货，持续更新中.....\n更新地址：http://t.cn/Rmwzx9t\n\n![和你一起，死磕ELK Stack！](http://img.blog.csdn.net/20180308060649363?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd29qaXVzaGl3bzk4Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n\n\n\n\n\n\n\n","title":"《死磕 Elasticsearch 方法论》：普通程序员高效精进的 10 大狠招！（完整版）","uid":"1341","views":"6552","votes":"6"},"_type":"doc"}
{"_id":"563","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522967285","category_id":"18","comments":"0","has_attach":"0","id":"563","message":"1、Elasticsearch6.X常见操作清单\nhttp://t.cn/Rm2B2Vz\n2、Elasticsearch在大规模日志系统的使用经验\nhttp://t.cn/Rm2BHud\n3、Elasticsearch分布式一致性原理剖析\n[url]http://t.cn/Rm2BGyO[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/563\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第233期 (2018-04-06)","uid":"1341","views":"338","votes":"0"},"_type":"doc"}
{"_id":"564","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523064184","category_id":"18","comments":"0","has_attach":"0","id":"564","message":"1. es同步分片策略解释\n   http://t.cn/RmUe9yW\n2. es深度分页方案\n   http://t.cn/RmUDSI7\n3. 关于为什么lucene在64位系统上要采用mmap的解释\n   http://t.cn/zj8xz94\n \n编辑: bsll\n归档：https://elasticsearch.cn/article/564\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第234期 (2018-04-06)","uid":"1874","views":"308","votes":"0"},"_type":"doc"}
{"_id":"569","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523413779","category_id":"18","comments":"0","has_attach":"0","id":"569","message":"1. 利用ELK处理Docker日志\n[url]http://t.cn/RmPvOG7[/url] \n2. 使用Elasticsearch的44条建议\n[url]http://t.cn/RmA5FAC[/url] \n3. 在Elasticsearch里面使用深度分页功能\n[url]http://t.cn/RmiNrdY[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/569[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第238期 (2018-04-11)","uid":"3828","views":"308","votes":"0"},"_type":"doc"}
{"_id":"583","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524176339","category_id":"18","comments":"0","has_attach":"0","id":"583","message":"1、上新 | Elastic Podcast——你上班路上的ELK Stack技术学习伴侣\nhttp://t.cn/Rme2GoB\n2、更新认知 | ES分配的内存有一个魔法上限值26GB？\nhttp://t.cn/RpPxEEO\n3、Elasticsearch 源码分析from size, scroll 和 search after\n[url]http://t.cn/RmeUKdE[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/583\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第247期 (2018-04-20)","uid":"1341","views":"422","votes":"0"},"_type":"doc"}
{"_id":"592","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524623354","category_id":"18","comments":"0","has_attach":"0","id":"592","message":"1. 运用打分和Boost优化Elasticsearch搜索结果\n[url]http://t.cn/Rut9qot[/url] \n2. Elasticsearch如何物理删除给定期限的历史数据\n[url]http://t.cn/RutLdaW[/url] \n3. X-Pack 代码已公开并上线\n[url]http://t.cn/RutLF3u[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/592[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第252期 (2018-04-25)","uid":"3828","views":"399","votes":"0"},"_type":"doc"}
{"_id":"598","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525136652","category_id":"18","comments":"0","has_attach":"0","id":"598","message":"1.X-Pack开源计划第一阶段完成。\nhttp://t.cn/RuCHuiK\n\n2.为Apm、日志以及Metrics提供更有深度的操作可视化。\nhttp://t.cn/RuC3zPc\n\n3.使用lucene实现google的”Did you mean”功能。\n[url]http://t.cn/RuCDeO0[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/598\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第258期 (2018-05-01)","uid":"4063","views":"341","votes":"0"},"_type":"doc"}
{"_id":"602","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525386269","category_id":"18","comments":"0","has_attach":"0","id":"602","message":"1、Elasticsearch 移除 type 之后的新姿势\nhttps://elasticsearch.cn/article/601\n2、Elasticsearch比Mysql快的原因\nhttp://t.cn/RqTdHRR\n3、ELK + Filebeat 搭建日志系统\n[url]http://t.cn/RuOc1XR[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/602\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第261期 (2018-05-04)","uid":"1341","views":"383","votes":"0"},"_type":"doc"}
{"_id":"609","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525834835","category_id":"18","comments":"0","has_attach":"0","id":"609","message":"1. Elastic Stack 监控 Kafka 和 Zookeeper\n[url]http://t.cn/R3zwwGX[/url] \n2. Elasticsearch 使用 rescore 重打分机制\n[url]http://t.cn/R3zwIQf[/url] \n3. Elasticsearch 优化系列\n（一）[url]http://t.cn/R3zAzaC[/url] \n（二）[url]http://t.cn/R3zAL2D[/url] \n（三）[url]http://t.cn/R3zA4RG[/url] \n（四）[url]http://t.cn/R3zA5Tw[/url] \n（五）[url]http://t.cn/R3zAMK8[/url] \n（六）[url]http://t.cn/R3zAXT5[/url] \n（七）[url]http://t.cn/R3zA9Zg[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/609[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第266期 (2018-05-09)","uid":"3828","views":"464","votes":"1"},"_type":"doc"}
{"_id":"682","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529889765","category_id":"18","comments":"0","has_attach":"0","id":"682","message":"1.kibana在搜索上面的改进和提升。\nhttp://t.cn/Rrq9Hh5\n\n2.ES集群服务器CPU负载瞬间飚高分析。\nhttps://elasticsearch.cn/article/348\n\n3.SSD硬盘寿命对于ES的性能影响？\n[url]https://elasticsearch.cn/question/1932[/url] \n\n活动预告\n\n1. 6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647\n\n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/682\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第313期 (2018-06-25)","uid":"4063","views":"309","votes":"0"},"_type":"doc"}
{"_id":"677","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529462126","category_id":"18","comments":"0","has_attach":"0","id":"677","message":"1. 从ELK到EFK\n[url]http://t.cn/ROrGdqr[/url] \n2.两个Elaticsearch查询问题分析\n[url]http://t.cn/RBI7tSI[/url] \n3.Elasticsearch filter和query的不同\n[url]http://t.cn/R1Gs2NG[/url] \n \n活动预告\n1. 6月30日南京meetup参会报名中\n[url]https://elasticsearch.cn/m/article/647[/url] \n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/677[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第308期 (2018-06-20)","uid":"3828","views":"297","votes":"0"},"_type":"doc"}
{"_id":"678","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529561043","category_id":"18","comments":"0","has_attach":"0","id":"678","message":"1.一个在kibana页面进行计算的插件\nhttp://t.cn/Rrvs0I0\n2.Elasticsearch:跨集群数据迁移之离线迁移\nhttp://t.cn/RrvsYkX\n3.如何使用LogStash将SQL Server数据复制到Elasticsearch\nhttp://t.cn/RrvsR1m\n\n活动预告：\n1.6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647 \n2.7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655 \n\n编辑：金桥\n归档：https://elasticsearch.cn/article/678\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第309期 (2018-06-21)","uid":"668","views":"278","votes":"0"},"_type":"doc"}
{"_id":"674","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529293248","category_id":"18","comments":"0","has_attach":"0","id":"674","message":"1、慎用TTL功能，可能导致节点OOM\nhttp://t.cn/RB8Lbud\n\n2、ElasticSearch 全文搜索精确匹配中文短语\nhttp://t.cn/RB8I1h1\n\n3、elasticsearch 倒排索引原理\n[url]http://t.cn/RB8xZq9[/url] \n\n活动预告\n1. 6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647\n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/674\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第306期 (2018-06-18)","uid":"4063","views":"312","votes":"0"},"_type":"doc"}
{"_id":"616","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526034939","category_id":"4","comments":"5","has_attach":"0","id":"616","message":"","title":"ELK中的host字段可以根据  如：如果是1我显示A，如果是2我显示B","uid":"8576","views":"431","votes":"0"},"_type":"doc"}
{"_id":"627","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526690550","category_id":"18","comments":"0","has_attach":"0","id":"627","message":"1. es主节点的垃圾回收配置经验分享\n[http://t.cn/R3YGdzY](http://t.cn/R3YGdzY) \n\n2. ES工程师使用Elastic Stack记录弟弟的旅行轨迹\n[http://t.cn/R3YGdzl](http://t.cn/R3YGdzl) \n\n3. 一周热点：技术人最重要的能力是什么？\n[http://t.cn/RuPYCdR](http://t.cn/RuPYCdR) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/627\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第276期 (2018-05-19)","uid":"1874","views":"360","votes":"0"},"_type":"doc"}
{"_id":"620","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526350693","category_id":"18","comments":"0","has_attach":"0","id":"620","message":"1.如何使用Elasticsearch加速WordPress搜索。\n[url]http://t.cn/R3JSZyv[/url] \n2.使用Node、vue和Elasticsearch构建一个实时搜索引擎。\n[url]http://t.cn/R3JS4Tu[/url] \n3.使用Active Directory认证和授权保护您的Amazon Elasticsearch Service。\n[url]http://t.cn/R3JSqDI[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/620[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第272期 (2018-05-15)","uid":"3788","views":"359","votes":"0"},"_type":"doc"}
{"_id":"625","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526545463","category_id":"9","comments":"1","has_attach":"0","id":"625","message":"感谢社区同学小莫（@msx）的贡献，Elasticsearch 的 PHP 客户端的中文手册上线了。\n为什么是 PHP，因为 PHP 是最好的语言（不服来辩啊）。\n \n地址：[url]https://www.elastic.co/guide/cn/elasticsearch/php/current/index.html[/url]\n \n ","title":"Elasticsearch-PHP 中文手册上线了","uid":"1","views":"463","votes":"1"},"_type":"doc"}
{"_id":"638","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527201139","category_id":"18","comments":"0","has_attach":"0","id":"638","message":"1、利用HDFS备份实现Elasticsearch容灾\nhttp://t.cn/R17PZJv\n2、Elasticsearch 架构以及源码概览\nhttp://t.cn/R17PGhf\n3、Elasticsearch图像检索实践\nhttp://t.cn/R17PVoX\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/638\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第282期 (2018-05-25)","uid":"1341","views":"560","votes":"0"},"_type":"doc"}
{"_id":"648","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527780216","category_id":"2","comments":"1","has_attach":"0","id":"648","message":"常见的数据库都会提供备份的机制，以解决在数据库无法使用的情况下，可以开启新的实例，然后通过备份来恢复数据减少损失。虽然 Elasticsearch 有良好的容灾性，但由于以下原因，其依然需要备份机制。\n\n1. 数据灾备。在整个集群无法正常工作时，可以及时从备份中恢复数据。\n2. 归档数据。随着数据的积累，比如日志类的数据，集群的存储压力会越来越大，不管是内存还是磁盘都要承担数据增多带来的压力，此时我们往往会选择只保留最近一段时间的数据，比如1个月，而将1个月之前的数据删除。如果你不想删除这些数据，以备后续有查看的需求，那么你就可以将这些数据以备份的形式归档。\n3. 迁移数据。当你需要将数据从一个集群迁移到另一个集群时，也可以用备份的方式来实现。\n\nElasticsearch 做备份有两种方式，一是将数据导出成文本文件，比如通过 [*elasticdump*](https://github.com/taskrabbit/elasticsearch-dump)、[*esm*](https://github.com/medcl/esm) 等工具将存储在 Elasticsearch 中的数据导出到文件中。二是以备份 elasticsearch data 目录中文件的形式来做快照，也就是 Elasticsearch 中 *snapshot* 接口实现的功能。第一种方式相对简单，在数据量小的时候比较实用，当应对大数据量场景效率就大打折扣。我们今天就着重讲解下第二种备份的方式，即 *snapshot* api 的使用。\n\n备份要解决备份到哪里、如何备份、何时备份和如何恢复的问题，那么我们接下来一个个解决。\n\n\n\n# 1. 备份到哪里\n\n\n在 Elasticsearch 中通过 repository 定义备份存储类型和位置，存储类型有共享文件系统、AWS 的 S3存储、HDFS、微软 Azure的存储、Google Cloud 的存储等，当然你也可以自己写代码实现国内阿里云的存储。我们这里以最简单的共享文件系统为例，你也可以在本地做实验。\n\n首先，你要在 *elasticsearch.yml* 的配置文件中注明可以用作备份路径 *path.repo* ，如下所示：\n\n```yaml\npath.repo: [\u0026quot;/mount/backups\u0026quot;, \u0026quot;/mount/longterm_backups\u0026quot;]\n```\n\n配置好后，就可以使用 *snapshot* api 来创建一个 repository 了，如下我们创建一个名为 my_backup 的 repository。\n\n```json\nPUT /_snapshot/my_backup\n{\n  \u0026quot;type\u0026quot;: \u0026quot;fs\u0026quot;,\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;location\u0026quot;: \u0026quot;/mount/backups/my_backup\u0026quot;\n  }\n}\n```\n\n之后我们就可以在这个 repository 中来备份数据了。\n\n# 2. 如何备份\n\n有了 repostiroy 后，我们就可以做备份了，也叫快照，也就是记录当下数据的状态。如下所示我们创建一个名为 snapshot_1 的快照。\n\n```json\nPUT /_snapshot/my_backup/snapshot_1?wait_for_completion=true\n```\n\n*wait_for_completion* 为 true 是指该 api 在备份执行完毕后再返回结果，否则默认是异步执行的，我们这里为了立刻看到效果，所以设置了该参数，线上执行时不用设置该参数，让其在后台异步执行即可。\n\n执行成功后会返回如下结果，用于说明备份的情况：\n\n```json\n{\n  \u0026quot;snapshots\u0026quot;: [\n    {\n      \u0026quot;snapshot\u0026quot;: \u0026quot;snapshot_1\u0026quot;,\n      \u0026quot;uuid\u0026quot;: \u0026quot;52Lr4aFuQYGjMEv5ZFeFEg\u0026quot;,\n      \u0026quot;version_id\u0026quot;: 6030099,\n      \u0026quot;version\u0026quot;: \u0026quot;6.3.0\u0026quot;,\n      \u0026quot;indices\u0026quot;: [\n        \u0026quot;.monitoring-kibana-6-2018.05.30\u0026quot;,\n        \u0026quot;.monitoring-es-6-2018.05.28\u0026quot;,\n        \u0026quot;.watcher-history-7-2018.05.30\u0026quot;,\n        \u0026quot;.monitoring-beats-6-2018.05.29\u0026quot;,\n        \u0026quot;metricbeat-6.2.4-2018.05.28\u0026quot;,\n        \u0026quot;.monitoring-alerts-6\u0026quot;,\n        \u0026quot;metricbeat-6.2.4-2018.05.30\u0026quot;\n      ],\n      \u0026quot;include_global_state\u0026quot;: true,\n      \u0026quot;state\u0026quot;: \u0026quot;SUCCESS\u0026quot;,\n      \u0026quot;start_time\u0026quot;: \u0026quot;2018-05-31T12:45:57.492Z\u0026quot;,\n      \u0026quot;start_time_in_millis\u0026quot;: 1527770757492,\n      \u0026quot;end_time\u0026quot;: \u0026quot;2018-05-31T12:46:15.214Z\u0026quot;,\n      \u0026quot;end_time_in_millis\u0026quot;: 1527770775214,\n      \u0026quot;duration_in_millis\u0026quot;: 17722,\n      \u0026quot;failures\u0026quot;: [],\n      \u0026quot;shards\u0026quot;: {\n        \u0026quot;total\u0026quot;: 28,\n        \u0026quot;failed\u0026quot;: 0,\n        \u0026quot;successful\u0026quot;: 28\n      }\n    }\n  ]\n}\n```\n\n返回结果的参数意义都是比较直观的，比如 *indices* 指明此次备份涉及到的索引名称，由于我们没有指定需要备份的索引，这里备份了所有索引；*state* 指明状态；*duration_in_millis* 指明备份任务执行时长等。\n\n我们可以通过 `GET _snapshot/my_backup/snapshot_1`获取 snapshot_1 的执行状态。\n\n此时如果去 */mount/backups/my_backup* 查看，会发现里面多了很多文件，这些文件其实都是基于 elasticsearch data 目录中的文件生成的压缩存储的备份文件。大家可以通过 *du -sh .* 命令看一下该目录的大小，方便后续做对比。\n\n# 3. 何时备份\n\n通过上面的步骤我们成功创建了一个备份，但随着数据的新增，我们需要对新增的数据也做备份，那么我们如何做呢？方法很简单，只要再创建一个快照 *snapshot_2* 就可以了。\n\n```json\nPUT /_snapshot/my_backup/snapshot_2?wait_for_completion=true\n```\n\n当执行完毕后，你会发现 */mount/backups/my_backup* 体积变大了。这说明新数据备份进来了。要说明的一点是，当你在同一个 repository 中做多次 snapshot 时，elasticsearch 会检查要备份的数据 segment 文件是否有变化，如果没有变化则不处理，否则只会把发生变化的 segment file 备份下来。这其实就实现了增量备份。\n\nelasticsearch 的资深用户应该了解 *force merge* 功能，即可以强行将一个索引的 segment file 合并成指定数目，这里要注意的是如果你主动调用 force merge api，那么 snapshot 功能的增量备份功能就失效了，因为 api 调用完毕后，数据目录中的所有 segment file 都发生变化了。\n\n另一个就是备份时机的问题，虽然 snapshot 不会占用太多的 cpu、磁盘和网络资源，但还是建议大家尽量在闲时做备份。\n\n# 4. 如何恢复\n\n所谓“养兵千日，用兵一时”，我们该演练下备份的成果，将其恢复出来。通过调用如下 api 即可快速实现恢复功能。\n\n```json\nPOST /_snapshot/my_backup/snapshot_1/_restore?wait_for_completion=true\n{\n  \u0026quot;indices\u0026quot;: \u0026quot;index_1\u0026quot;,\n  \u0026quot;rename_replacement\u0026quot;: \u0026quot;restored_index_1\u0026quot;\n}\n```\n\n通过上面的 api，我们可以将 *index_1* 索引恢复到 *restored_index_1* 中。这个恢复过程完全是基于文件的，因此效率会比较高。\n\n虽然我们这里演示的是在同一个集群做备份与恢复，你也可以在另一个集群上连接该 repository 做恢复。我们这里就不做说明了。\n\n# 5. 其他\n\n由于 Elasticsearch 版本更新比较快，因此大家在做备份与恢复的时候，要注意版本问题，同一个大版本之间的备份与恢复是没有问题的，比如都是 5.1 和 5.6 之间可以互相备份恢复。但你不能把一个高版本的备份在低版本恢复，比如将 6.x 的备份在 5.x 中恢复。而低版本备份在高版本恢复有一定要求：\n\n1) 5.x 可以在 6.x 恢复\n\n2) 2.x 可以在 5.x 恢复\n\n3) 1.x 可以在 2.x 恢复\n\n其他跨大版本的升级都是不可用的，比如1.x 的无法在 5.x 恢复。这里主要原因还是 Lucene 版本问题导致的，每一次 ES 的大版本升级都会伴随 Lucene 的大版本，而 Lucene 的版本是尽量保证向前兼容，即新版可以读旧版的文件，但版本跨越太多，无法实现兼容的情况也在所难免了。\n\n# 6. 继续学习\n\n本文只是简单对 snapshot 功能做了一个演示，希望这足够引起你的兴趣。如果你想进一步深入的了解该功能，比如备份的时候如何指定部分索引、如何查询备份和还原的进度、如何跨集群恢复数据、如何备份到 HDFS 等，可以详细阅读官方手册[https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html)，如果在使用的过程中遇到了问题，欢迎留言讨论。","title":"Elasticsearch snapshot 备份的使用方法","uid":"86","views":"1394","votes":"6"},"_type":"doc"}
{"_id":"649","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527805995","category_id":"2","comments":"0","has_attach":"0","id":"649","message":"1、Elasticsearch snapshot 备份的使用方法\nhttps://elasticsearch.cn/article/648\n2、ElasticSearch + Canal 开发千万级的实时搜索系统\nhttp://t.cn/R8vjBwD\n3、【线下活动】2018-06-30 南京Elastic Meetup日程安排\nhttps://elasticsearch.cn/article/647\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/649\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第289期 (2018-06-01)","uid":"1341","views":"263","votes":"0"},"_type":"doc"}
{"_id":"654","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528160339","category_id":"18","comments":"0","has_attach":"0","id":"654","message":"1.在 docker 容器和 kubernetes 上使用 elastic栈监控应用。\n[url]http://t.cn/R1ERKJB[/url] \n2.大众点评业务高可用对 Elasticsearch 的使用。\n[url]http://t.cn/R1ERTAF[/url] \n3.Elasticsearch NettyTransport 通信机制详解。\n[url]http://t.cn/R1ERRrA[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/654[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第293期 (2018-06-05)","uid":"3788","views":"287","votes":"0"},"_type":"doc"}
{"_id":"655","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528177078","category_id":"16","comments":"34","has_attach":"1","id":"655","message":"当当当！\n上海的小伙伴们注意啦！\n今年的 Elastic 上海 Meetup 活动初步定于 7 月 21 日在 eBay 上海研发中心举行，现在开始征集分享嘉宾，欢迎大家自告奋勇！\n活动日程信息：[url]http://meetup.elasticsearch.cn/2018/shanghai.html[/url] \n分享报名链接：[url]http://elasticsearch.mikecrm.com/A6QbFvU[/url]\n参会报名链接：[url]http://elasticsearch.mikecrm.com/fUqiv0T[/url] \n \nPPT 查看地址：\n[list]\n[*][url=https://elasticsearch.cn/slides/122]EYou—阿里云Elasticsearch智能优化运维工具分享[/url][/*]\n[*][url=https://elasticsearch.cn/slides/121]Elasticsearch 在企业协作服务中的应用实践[/url][/*]\n[*][url=https://elasticsearch.cn/slides/120]Elasticsearch 集群诊断和索引生命周期[/url][/*]\n[*][url=https://elasticsearch.cn/slides/119]ES Cross Cluster Search 生产实践[/url][/*]\n[*][url=https://elasticsearch.cn/slides/118]B站日志系统的演进之路[/url][/*]\n[*][url=https://elasticsearch.cn/slides/117]利用Elastic Stack快速搭建SIEM系统[/url][/*]\n[*][url=https://elasticsearch.cn/slides/116]基于 Elasticsearch 电商搜索[/url] [/*]\n[/list]\n \n\n场地大小有限，大家尽量观看直播，\n\n线上直播注册和【回看】观看入口：\n[list]\n[*][url=http://www.itdks.com/dakashuo/playback/2393?userId=45158]IT 大咖说直播[/url][/*]\n[*][url=https://yq.aliyun.com/webinar/play/465]阿里云栖直播[/url][/*]\n[/list]\n [attach]2686[/attach]\n \n\n社区活动，重在参与，欢迎大家报名，一起分享交流！","title":"7月21日，周六，Elastic 上海 线下 Meetup   [活动结束, PPT已上传]","uid":"1","views":"3888","votes":"12"},"_type":"doc"}
{"_id":"662","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528634654","category_id":"18","comments":"0","has_attach":"0","id":"662","message":"1.Elasticsearch + Hadoop：实时数据搜索和分析的两个最佳选择。\nhttp://t.cn/RBzx228\n2.Elasticsearch的SQL解决方案。\nhttp://t.cn/RBzx4sr\n3.(自备梯子)优步和Lyft会变得不同吗？\nhttp://t.cn/RBzxty1\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/662\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第298期 (2018-06-10)","uid":"4460","views":"368","votes":"0"},"_type":"doc"}
{"_id":"663","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528695481","category_id":"18","comments":"1","has_attach":"0","id":"663","message":"1.Elasticsearch 通信模块的分析\nhttp://t.cn/RB4hMr7\n2.Elasticsearch的慢查询日志配置。\nhttp://t.cn/RB47F0O\n3.使用路由来进一步提高Elasticsearch的检索效率\nhttp://t.cn/RB4zeRZ\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/663\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第299期 (2018-06-11)","uid":"4063","views":"306","votes":"0"},"_type":"doc"}
{"_id":"667","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528894139","category_id":"2","comments":"1","has_attach":"0","id":"667","message":"有以下DSL\n```json\n{\n  \u0026quot;size\u0026quot; : 0,\n  \u0026quot;query\u0026quot; : { },\n  \u0026quot;_source\u0026quot; : false,\n  \u0026quot;aggregations\u0026quot; : {\n    \u0026quot;aggData\u0026quot; : {\n      \u0026quot;terms\u0026quot; : {\n        \u0026quot;field\u0026quot; : \u0026quot;url\u0026quot;,\n        \u0026quot;size\u0026quot; : 200,\n        \u0026quot;min_doc_count\u0026quot; : 1,\n        \u0026quot;shard_min_doc_count\u0026quot; : 0,\n        \u0026quot;show_term_doc_count_error\u0026quot; : false,\n        \u0026quot;order\u0026quot; : [\n          {\n            \u0026quot;PV\u0026quot; : \u0026quot;desc\u0026quot;\n          }\n        ]\n      },\n      \u0026quot;aggregations\u0026quot; : {\n        \u0026quot;PV\u0026quot; : {\n          \u0026quot;cardinality\u0026quot; : {\n            \u0026quot;field\u0026quot; : \u0026quot;userssid\u0026quot;\n          }\n        }\n      }\n    }\n  }\n}\n```  \n目的是对用户访问的URL进行分组统计，按独立用户数来排序。\n执行后，data节点频繁FGC，内存无法回收，随即OOM，然后data节点脱离，集群变为red。\n最初以为是cardinality精度问题导致内存使用过多，随即将precision_threshold设置为100，再次执行，内存使用量确实少了很多，但是还是用到GB级别。为了确认是否是cardinality问题，去掉外层聚合，直接执行\n```json\n\u0026quot;aggregations\u0026quot; : {\n        \u0026quot;PV\u0026quot; : {\n          \u0026quot;cardinality\u0026quot; : {\n            \u0026quot;field\u0026quot; : \u0026quot;userssid\u0026quot;\n          }\n        }\n      }\n```  \n发现响应非常快，而且内存占用只有KB级别。\n再次单独执行外部聚合，发现也非常快，于是猜测是order导致，将order去掉，果然，如丝般顺滑，再也没有OOM。\n为了解决这种OOM，首先想到的是熔断器。默认indices.breaker.request.limit配置是60%。改成10%后，触发熔断，集群正常，但是多点几次之后，data还是出现OOM了。\n于是逐步调试，发现每执行1次，内存就增加一点，熔断返回后并没有被回收，直到OOM。基本确定是这里的order导致内存泄露了。\n就在此时，同事反馈在5.6不会有这个问题，于是去查release note，果然在[5.5的版本](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/release-notes-5.5.0.html)发现fix了这个问题。[问题描述](https://github.com/elastic/elasticsearch/pull/24941)。\n这个bug的根本原因是：\n```\nterms aggregations at the root level use the global_ordinals execution hint by default.\nWhen all sub-aggregators can be run in breadth_first mode the collected buckets for these sub-aggs are dense (remapped after the initial pruning).\nBut if a sub-aggregator is not deferrable and needs to collect all buckets before pruning we don't remap global ords and the aggregator needs to deal with sparse buckets.\nMost (if not all) aggregators expect dense buckets and uses this information to allocate memories.\nThis change forces the remap of the global ordinals but only when there is at least one sub-aggregator that cannot be deferred.\n```  \n解决方案：\n1，升级到5.5以上版本；\n\n2，DSL增加\u0026quot;execution_hint\u0026quot;:\u0026quot;map\u0026quot;,属性。\n```json\n{\n  \u0026quot;size\u0026quot; : 0,\n  \u0026quot;query\u0026quot; : { },\n  \u0026quot;_source\u0026quot; : false,\n  \u0026quot;aggregations\u0026quot; : {\n    \u0026quot;aggData\u0026quot; : {\n      \u0026quot;terms\u0026quot; : {\n        \u0026quot;field\u0026quot; : \u0026quot;url\u0026quot;,\n        \u0026quot;size\u0026quot; : 200,\n\u0026quot;execution_hint\u0026quot;:\u0026quot;map\u0026quot;，\n        \u0026quot;min_doc_count\u0026quot; : 1,\n        \u0026quot;shard_min_doc_count\u0026quot; : 0,\n        \u0026quot;show_term_doc_count_error\u0026quot; : false,\n        \u0026quot;order\u0026quot; : [\n          {\n            \u0026quot;PV\u0026quot; : \u0026quot;desc\u0026quot;\n          }\n        ]\n      },\n      \u0026quot;aggregations\u0026quot; : {\n        \u0026quot;PV\u0026quot; : {\n          \u0026quot;cardinality\u0026quot; : {\n            \u0026quot;field\u0026quot; : \u0026quot;userssid\u0026quot;\n          }\n        }\n      }\n    }\n  }\n}\n```  ","title":"ES5.3聚合内存溢出bug","uid":"1629","views":"986","votes":"5"},"_type":"doc"}
{"_id":"668","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528942756","category_id":"18","comments":"0","has_attach":"0","id":"668","message":"1. Elastic Stack 6.3重磅发布。\n[http://t.cn/RBXttvr](http://t.cn/RBXttvr) \n\n2. Kubernetes EFK 实战。\n[http://t.cn/RBiiwHR](http://t.cn/RBiiwHR)\n[http://t.cn/RBiiGFp](http://t.cn/RBiiGFp) \n\n3. 译文：kafka学习之路。\n[http://t.cn/RXGeTLz](http://t.cn/RXGeTLz) \n\n4. Google Pub / Sub与ELK Stack集成\n[http://t.cn/RBii6rQ](http://t.cn/RBii6rQ) \n\n#### 活动预告\n1. 6月30日南京meetup参会报名中\n[https://elasticsearch.cn/m/article/647](https://elasticsearch.cn/m/article/647) \n\n2. 7月21日上海meetup演讲申请中\n[https://elasticsearch.cn/m/article/655](https://elasticsearch.cn/m/article/655) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/668\n\n*  订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第302期 (2018-06-14)","uid":"668","views":"399","votes":"0"},"_type":"doc"}
{"_id":"685","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529984955","category_id":"12","comments":"0","has_attach":"0","id":"685","message":"PingPong 金融是家极其低调又极具实力的独角兽公司，作为中国第一家获得欧洲支付牌照的民营公司，目前在跨境收款这个风口处于领先地位，公司继去年的 B 轮之后，现在又敲定 C 轮融资了。\n\n我司已经自建 IDC 搭建大数据中心，微服务上线如火如荼，Spark, Hadoop, HBase, MongoDB, Dubbo, RocketMQ, Elasticsearch 等大公司用的技术，我们全部都有用，我们完全拥抱开源，18 年我们已经准备自研一些开源的 framework，也愿意为开源贡献力量。\n\n我们招聘技术大牛了，先贴下公司福利：\n\n最新版 MacBook Pro 或 Surface 随你挑\n\n每天下午水果 + 晚上免费晚餐\n\n每年 15 天年假 + 每月 2k 加班费 + 3 个月以上的年终\n\n生日礼品 + 每月团建费 + 节日聚餐 + 买书报销\n\n继续贴 JD:\n\n============================================================\n\n高级 Java 工程师职位描述(薪资 25-40K):\n\n岗位职责\n\n1.带领团队完成产品开发，承担技术 leader 和项目经理角色;\n\n2.负责系统后端核心 API 的编写;\n\n3.负责公司各平台的对接工作;\n\n4.根据业务需求合理设计和扩展;\n\n岗位要求\n\n1.Java 基础扎实,精通多线程、并发、集合、网络、IO 等基础知识,熟悉 Http、TCP/IP 等协议;\n\n2.熟练使用 SpringBoot、Mybatis 等常用的框架并了解其工作原理;\n\n3.熟悉 RocketMQ、Dubbo、Zookeeper 等开源技术的使用以及工作原理;\n\n4.熟悉 MySql、HBase、Elasticsearch、Redis 等的运用以及原理,优秀的 SQL 编写能力以及调优能力;\n\n5.思维清晰,能独立分析并解决遇到的问题,丰富的系统设计能力以及服务化设计能力;\n\n6.具备良好的表达能力,善于团队合作、具备非常良好的责任心以及 Owner 意识,具备独立解决问题能力;\n\n有意向的请发简历到邮箱: jiwg#pingpongx.com, 最后感谢各位的阅读.","title":"[杭州滨江] [PingPong 金融] 招聘 Java 高级工程师","uid":"9014","views":"696","votes":"1"},"_type":"doc"}
{"_id":"689","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530150966","category_id":"18","comments":"0","has_attach":"0","id":"689","message":"1. 利用metricbeat和jolokia监控java应用。\n[http://t.cn/Rr9N1fw](http://t.cn/Rr9N1fw) \n\n2. es2.3.5修改源代码获取dismax每个字段的得分。\n[http://t.cn/Rr9NdSb](http://t.cn/Rr9NdSb) \n\n3. 你真的会打 Log 吗？\n[http://t.cn/Rr9NFh8](http://t.cn/Rr9NFh8) \n\n\n#### 活动预告：\n1. 6月30日南京meetup参会报名中\n[https://elasticsearch.cn/m/article/647](https://elasticsearch.cn/m/article/647)\n\n2. 7月21日上海meetup演讲申请中\n[https://elasticsearch.cn/m/article/655](https://elasticsearch.cn/m/article/655)\n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/689\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第316期 (2018-06-28)","uid":"668","views":"301","votes":"0"},"_type":"doc"}
{"_id":"690","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530225727","category_id":"18","comments":"0","has_attach":"0","id":"690","message":"1、玩转 Elasticsearch 的 SQL 功能\nhttps://elasticsearch.cn/article/687\n2、重写Elasticsearch Ik插件\nhttp://t.cn/RrWjbWU\n3、Elasticsearch script的高级使用方式\n[url]http://t.cn/RrWjJQd[/url] \n\n活动预告：\n1.6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647 \n2.7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655 \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/690\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第317期 (2018-06-29)","uid":"1341","views":"277","votes":"0"},"_type":"doc"}
{"_id":"695","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530604568","category_id":"18","comments":"0","has_attach":"0","id":"695","message":"1.提升Elasticsearch查询性能的七个小贴士。\n[url]http://t.cn/RrkMzQn[/url] \n2.使用ELK分析Nginx日志实战。\n[url]http://t.cn/RBTxsci[/url] \n3.使用Kafka Streams和Elasticsearch 构建home feed。\n[url]http://t.cn/Rrk4z0S[/url] \n\n活动预告\n1. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/695[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第321期 (2018-07-03)","uid":"3788","views":"309","votes":"0"},"_type":"doc"}
{"_id":"707","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531190212","category_id":"18","comments":"0","has_attach":"0","id":"707","message":"1.Elasticsearch 6.3.0对Java 10的支持。\nhttp://t.cn/RdYmTE3\n2.如何监控Elasticsearch。\n​http://t.cn/RdT4xjw\n3.（自备翻墙）使用React与Elasticsearch构建电影搜索APP。\nhttp://t.cn/RdYmJ8R\n\n活动预告\n1. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n2. Elastic 中国开发者大会 2018 已悄然上线！ 时间 2018年11月10日，地点深圳 JW 万豪酒店，现已开始正式对外接收演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/707\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第328期 (2018-07-10)","uid":"3788","views":"364","votes":"0"},"_type":"doc"}
{"_id":"719","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531915548","category_id":"2","comments":"7","has_attach":"0","id":"719","message":"我曲解了Elasticsearch，我以为是每个节点可以存放不同的数据，哈哈哈?。既然不是这样，引发了我另一个思考，说是Elasticsearch能处理TB以及PB的数据，这样的话，一台存放PB级数据的机器该是个多“可怕”的配置。每个节点的数据都一样，这是真正意义的分布式吗？我觉得按Elasticsearch的概念只是利用了节点的硬件资源。我真心希望我的理解是错的，这样我将欢欣鼓舞。","title":"我曲解Elasticsearch了吗？","uid":"6529","views":"427","votes":"0"},"_type":"doc"}
{"_id":"711","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531406950","category_id":"2","comments":"2","has_attach":"0","id":"711","message":"**注意** 本文参考的ES 5.0.1的源码\n\n### 1. 查看集群状态\n可以通过API查看集群状态\n```\nGET /_cluster/state\n```\n大致可以得到如下内容\n![cluster_state](https://ut-bucket01.sh1a.qingstor.com/blog/WechatIMG67.jpeg)\n`version` 集群状态数字版本号\n每次更新version + 1\n集群重启version不会置0(只会单调增)\n\n`state_uuid` 是集群状态字符串版本号(UUID)\n\n`master_node` master节点\n\n`nodes` 该版本中的所有节点信息\n\n`routing_table` 和 `routing_nodes` 都是描述不同index上的shard在node上的分布关系\n\n\n### 2. 集群状态的维护\n可以阅读\n.//core/src/main/java/org/elasticsearch/cluster/ClusterState.java\n\n* 2.1 ClusterState是不可变对象，每次状态变更都会产生新的ClusterState，它们拥有不同的版本号\n* 2.2 在ES中, 集群状态由Master维护，并且只能由master节点更新集群状态\n* 2.3 更新完成后，Master会把新版本的集群状态推送给集群的其它所有节点\n对于publish,Master节点会根据它已知其它节点所拥有的集群状态版本，决定是执行\n`sendFullClusterState()`还是`sendClusterStateDiff()`,  前者是全量推送，后者增量推送。\n\n* 2.4 对于使用Zen Discovery的情况，只要有minimumMasterNodes响应了Master节点的`publish`消息, 那么这次的`commit`就算成功\n\n\n\u0026gt;  The cluster state can be updated only on the master node. All updates are performed by on a single thread and controlled by the {@link ClusterService}. After every update the\n{@link Discovery#publish} method publishes new version of the cluster state to all other nodes in the cluster.  \n\u0026gt;In the Zen Discovery it is handled in the {@link PublishClusterStateAction#publish} method\n\n* 2.5 另外需要补充的是Elasticsearch使用Gossip + Bully算法进行选主。Bully算法在具体实现中，不是简单选取节点ID小的节点, 首先要先比较ClusterState的版本。版本高的优先当选。（各个版本实现有不同，但都需要考虑候选节点的集群状态版本）\n```\n    /**\n     * Elects a new master out of the possible nodes, returning it. Returns \u0026lt;tt\u0026gt;null\u0026lt;/tt\u0026gt;\n     * if no master has been elected.\n     */\n    public MasterCandidate electMaster(Collection\u0026lt;MasterCandidate\u0026gt; candidates) {\n        assert hasEnoughCandidates(candidates);\n        List\u0026lt;MasterCandidate\u0026gt; sortedCandidates = new ArrayList\u0026lt;\u0026gt;(candidates);\n        sortedCandidates.sort(MasterCandidate::compare);\n        return sortedCandidates.get(0);\n    }\n```\n```\n        /**\n         * compares two candidates to indicate which the a better master.\n         * A higher cluster state version is better\n         *\n         * @return -1 if c1 is a batter candidate, 1 if c2.\n         */\n        public static int compare(MasterCandidate c1, MasterCandidate c2) {\n            // we explicitly swap c1 and c2 here. the code expects \u0026quot;better\u0026quot; is lower in a sorted\n            // list, so if c2 has a higher cluster state version, it needs to come first.\n            int ret = Long.compare(c2.clusterStateVersion, c1.clusterStateVersion);\n            if (ret == 0) {\n                ret = compareNodes(c1.getNode(), c2.getNode());\n            }\n            return ret;\n        }\n    }\n```\n\n### 参考资料\n1. [cluster-state](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html)\n\n\n\n欢迎光临我的个人博客 萌叔 | http://vearne.cc\n","title":"聊聊ELASTICSEARCH的集群状态的管理和维护","uid":"8713","views":"843","votes":"1"},"_type":"doc"}
{"_id":"714","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531539457","category_id":"18","comments":"2","has_attach":"0","id":"714","message":"1. ES使用SQL示例\n[http://t.cn/RgvTQ3C](http://t.cn/RgvTQ3C) \n\n2. ES6.3新功能:使用Rollup来合并旧日志。\n[http://t.cn/Rdr8LIZ](http://t.cn/Rdr8LIZ) \n\n3. pyspark操作ES实例。\n[http://t.cn/RgzHJm0](http://t.cn/RgzHJm0) \n\n活动预告\n1. 7月21日上海meetup倒计时（更大场地，等您来！）\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/714\n\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第332期 (2018-07-14)","uid":"1874","views":"334","votes":"0"},"_type":"doc"}
{"_id":"718","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531886851","category_id":"18","comments":"0","has_attach":"0","id":"718","message":"1. 来自腾讯的 elasticsearch 调优实践\nhttps://0x7.me/Rzl6U\n2. 基于 ElasticStack 实现 Kubernetes 的全方位监控\nhttps://0x7.me/7U3gW\n3. 想知道 Kibana 最近在研发哪些功能，来看看这个\nhttps://0x7.me/31pGr\n\n\n活动预告\n1. 7月21日上海meetup倒计时\nhttps://elasticsearch.cn/m/article/655\n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/718\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第336期 (2018-07-18)","uid":"86","views":"380","votes":"0"},"_type":"doc"}
{"_id":"720","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531980116","category_id":"18","comments":"2","has_attach":"0","id":"720","message":"1.JavaWeb项目架构之Elasticsearch日志处理系统\nhttp://t.cn/RgKPKeO\n2.基于快速GeoHash，如何实现海量商品与商圈的高效匹配？\nhttp://t.cn/RgKP3qE\n3.kafka的内部通信和可靠性\nhttp://t.cn/RgKPFrW\n\n活动预告\n1. 7月21日上海meetup倒计时\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/720\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第337期 (2018-07-19)","uid":"668","views":"246","votes":"0"},"_type":"doc"}
{"_id":"723","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532087377","category_id":"8","comments":"0","has_attach":"0","id":"723","message":" \nElasticTalk 第2期 直播的内容是 Elasticsearch 压测实战之 esrally 入门和实战。希望这次直播可以帮助大家快速掌握 esrally 这款优秀的 es 压测工具。\n \n视频地址如下：\nhttps://www.bilibili.com/video/av27114309/","title":"ElasticTalk #2 Elasticsearch压测实战 I esrally 入门与实战","uid":"86","views":"297","votes":"0"},"_type":"doc"}
{"_id":"724","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532087462","category_id":"8","comments":"0","has_attach":"0","id":"724","message":"ElasticTalk 第3期 直播的内容是 Elasticsearch 压测实战之 esrally 进阶实战。\n\n本次我们主要讲解了 esrally 如何自定义测试集群、自定义数据集和报告，最后还讲了三步上手 esrally 的方法。\n \n视频地址如下：\nhttp://www.bilibili.com/video/av27117279/","title":"ElasticTalk #3 Elasticsearch压测实战 II esrally 进阶实战","uid":"86","views":"266","votes":"0"},"_type":"doc"}
{"_id":"725","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532139915","category_id":"18","comments":"0","has_attach":"0","id":"725","message":"1. 使用Elasticsearch和Azure Active Directory实现基于SAML的单点登录。\n[http://t.cn/RgTH5sa](http://t.cn/RgTH5sa) \n\n2. 使用 Apache Spark 和 Elasticsearch 构建推荐系统。\n[http://t.cn/Rj8rNDe](http://t.cn/Rj8rNDe) \n\n3.  一周热点：WebIDE：在浏览器中写代码的时代即将来临？\n[http://t.cn/RgH4hqq](http://t.cn/RgH4hqq) \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n* 编辑：叮咚光军\n\n* 归档：https://elasticsearch.cn/article/725\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第339期 (2018-07-21)","uid":"1874","views":"328","votes":"0"},"_type":"doc"}
{"_id":"727","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532222025","category_id":"18","comments":"0","has_attach":"0","id":"727","message":"1.Elasticsearch性能测试技巧。\nhttp://t.cn/RgR1dcw\n2.ELK Stack 在商业上的应用。\nhttp://t.cn/RgR16cA\n3.(自备梯子)数据驱动决策？再想想。\n[url]http://t.cn/RgRJFRz[/url] \n\n活动预告：\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/publish/article/727\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第340 (2018-07-22)","uid":"4460","views":"283","votes":"0"},"_type":"doc"}
{"_id":"740","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533181376","category_id":"18","comments":"0","has_attach":"0","id":"740","message":"1.如何优化beats性能\nhttp://t.cn/Re8KXlI\n2.logstash input插件开发\nhttp://t.cn/Re8KCox\n3.容器监控方案 cAdvisor + Elasticsearch\nhttp://t.cn/RS7tLSW\n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/740\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第351期 (2018-08-02)","uid":"668","views":"257","votes":"0"},"_type":"doc"}
{"_id":"744","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533434235","category_id":"18","comments":"0","has_attach":"0","id":"744","message":"1.Kubernetes使用Fluentd和Logz.io记录日志。\nhttp://t.cn/RDPaFVJ\n2.Docker使用EFK记录日志。\nhttp://t.cn/RDPNDt3\n3.(自备梯子)如何像数据科学家一样思考的12个步骤。\nhttp://t.cn/RDP9e3d\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/744\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第354 (2018-08-05)","uid":"4460","views":"222","votes":"0"},"_type":"doc"}
{"_id":"747","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533740593","category_id":"18","comments":"0","has_attach":"0","id":"747","message":"1.kibana插件Logtrail终端式体验。\nhttp://t.cn/RDMgCLh\n2.es集群启动流程。\nhttp://t.cn/RDMkAsX\n3.es搜索优化。\nhttp://t.cn/RDMkDSv\n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：wt\n归档：https://elasticsearch.cn/article/747\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第357期 (2018-08-08)","uid":"3851","views":"359","votes":"1"},"_type":"doc"}
{"_id":"748","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533819500","category_id":"18","comments":"0","has_attach":"0","id":"748","message":"1.探讨ES的long_range,date_range类型，可能不仅只是语法糖\nhttp://t.cn/RDXKwq7\n2.Elasticsearch 6.3 X-PACK SQL 简述\nhttp://t.cn/RDXKUPs\n3.如何建设高吞吐量的日志平台\nhttp://t.cn/RDXK5On\n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/748\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第358期 (2018-08-09)","uid":"668","views":"201","votes":"0"},"_type":"doc"}
{"_id":"750","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533869947","category_id":"2","comments":"0","has_attach":"0","id":"750","message":"_nodes/stats thread_pool   中的bulk 在版本6.3.0中没有了，是哪个版本中取消了吗？","title":"_nodes/stats thread_pool   中的bulk 在版本6.3.0中没有了，是哪个版本中取消了吗？","uid":"9164","views":"152","votes":"0"},"_type":"doc"}
{"_id":"756","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534232863","category_id":"2","comments":"12","has_attach":"0","id":"756","message":"把Mysql的数据同步到Elasticsearch是个很常见的需求，但在Github里找到的同步工具用起来或多或少都有些别扭。\n例如：某记录内容为\u0026quot;aaa|bbb|ccc\u0026quot;，将其按|分割成数组同步到es，这样的简单任务都难以实现，再加上配置繁琐，文档语焉不详...\n所以我写了个同步工具MysqlsMom：力求用最简单的配置完成复杂的同步任务。目前除了我所在的部门，也有越来越多的互联网公司在生产环境中使用该工具了。\n欢迎各位大佬进行试用并提出意见，任何建议、鼓励、批评都受到欢迎。\ngithub: https://github.com/m358807551/mysqlsmom\n![Alt text](https://github.com/m358807551/images/blob/master/images/MysqlsMom.jpeg?raw=true)\n\n简介：同步 *Mysql* 数据到 *elasticsearch* 的工具；\nQQ、微信：358807551\n\n## 特点\n\n1. 纯 *Python* 编写；\n2. 支持基于 *sql* 语句的全量同步，基于 *binlog* 的增量同步，基于更新字段的增量同步三种同步方式；\n3. 全量更新只占用少量内存；支持通过sql语句同步数据；\n4. 增量更新自动断点续传；\n5. 取自 *Mysql* 的数据可经过一系列自定义函数的处理后再同步至 *Elasticsearch*；\n6. 能用非常简单的配置完成复杂的同步任务；\n\n## 环境\n\n- *python*2.7；\n- 增量同步需开启 *redis*；\n- 分析 *binlog* 的增量同步需要 *Mysql* 开启 *binlog*（*binlog-format=row*）；\n\n## 快速开始\n\n### 全量同步MySql数据到es\n\n1. clone 项目到本地；\n\n2. 安装依赖；\n\n   ```\n   cd mysqlsmom\n   pip install -r requirements.txt\n   ```\n\n   默认支持 elasticsearch-2.4版本，支持其它版本请运行（将5.4换成需要的elasticsearch版本）\n\n   ```\n   pip install --upgrade elasticsearch==5.4\n   ```\n\n3. 编辑 ./config/example_init.py，按注释提示修改配置；\n\n   ```python\n   # coding=utf-8\n   \n   STREAM = \u0026quot;INIT\u0026quot;\n   \n   # 修改数据库连接\n   CONNECTION = {\n       'host': '127.0.0.1',\n       'port': 3306,\n       'user': 'root',\n       'passwd': ''\n   }\n   \n   # 修改elasticsearch节点\n   NODES = [{\u0026quot;host\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;port\u0026quot;: 9200}]\n   \n   TASKS = [\n       {\n           \u0026quot;stream\u0026quot;: {\n               \u0026quot;database\u0026quot;: \u0026quot;test_db\u0026quot;,  # 在此数据库执行sql语句\n               \u0026quot;sql\u0026quot;: \u0026quot;select * from person\u0026quot;  # 将该sql语句选中的数据同步到 elasticsearch\n           },\n           \u0026quot;jobs\u0026quot;: [\n               {\n                   \u0026quot;actions\u0026quot;: [\u0026quot;insert\u0026quot;, \u0026quot;update\u0026quot;],\n                   \u0026quot;pipeline\u0026quot;: [\n                       {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}  # 默认设置 id字段的值 为elasticsearch中的文档id\n                   ],\n                   \u0026quot;dest\u0026quot;: {\n                       \u0026quot;es\u0026quot;: {\n                           \u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;,\n                           \u0026quot;index\u0026quot;: \u0026quot;test_index\u0026quot;,   # 设置 index\n                           \u0026quot;type\u0026quot;: \u0026quot;test\u0026quot;,          # 设置 type\n                           \u0026quot;nodes\u0026quot;: NODES\n                       }\n                   }\n               }\n           ]\n       }\n   ]\n   ```\n\n4. 运行\n\n   ```\n   cd mysqlsmom\n   python mysqlsmom.py ./config/example_init.py\n   ```\n\n   等待同步完成即可；\n\n### 分析 *binlog* 的增量同步\n\n1. 确保要增量同步的MySql数据库开启binlog，且开启redis(为了存储最后一次读到的binlog文件名及读到的位置。未来可能支持本地文件存储该信息。)\n\n2. 下载项目到本地，且安装好依赖后，编辑 ./config/example_init.py，按**注释**提示修改配置；\n\n   ```python\n   # coding=utf-8\n   \n   STREAM = \u0026quot;BINLOG\u0026quot;\n   SERVER_ID = 99  # 确保每个用于binlog同步的配置文件的SERVER_ID不同；\n   SLAVE_UUID = __name__\n   \n   # 配置开启binlog权限的MySql连接\n   BINLOG_CONNECTION = {\n       'host': '127.0.0.1',\n       'port': 3306,\n       'user': 'root',\n       'passwd': ''\n   }\n   \n   # 配置es节点\n   NODES = [{\u0026quot;host\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;port\u0026quot;: 9200}]\n   \n   TASKS = [\n       {\n           \u0026quot;stream\u0026quot;: {\n               \u0026quot;database\u0026quot;: \u0026quot;test_db\u0026quot;,  # [table]所在的数据库\n               \u0026quot;table\u0026quot;: \u0026quot;person\u0026quot;  # 监控该表的binlog\n           },\n           \u0026quot;jobs\u0026quot;: [\n               {\n                   \u0026quot;actions\u0026quot;: [\u0026quot;insert\u0026quot;, \u0026quot;update\u0026quot;],\n                   \u0026quot;pipeline\u0026quot;: [\n                       {\u0026quot;only_fields\u0026quot;: {\u0026quot;fields\u0026quot;: [\u0026quot;id\u0026quot;, \u0026quot;name\u0026quot;, \u0026quot;age\u0026quot;]}},  # 只同步这些字段到es，注释掉该行则同步全部字段的值到es\n                       {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}  # 设置es中文档_id的值取自 id(或根据需要更改)字段\n                   ],\n                   \u0026quot;dest\u0026quot;: {\n                       \u0026quot;es\u0026quot;: {\n                           \u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;,\n                           \u0026quot;index\u0026quot;: \u0026quot;test_index\u0026quot;,  # 设置 index\n                           \u0026quot;type\u0026quot;: \u0026quot;test\u0026quot;,         # 设置 type\n                           \u0026quot;nodes\u0026quot;: NODES\n                       }\n                   }\n               }\n           ]\n       }\n   ]\n   ```\n\n3. 运行\n\n   ```shell\n   cd mysqlsmom\n   python mysqlsmom.py ./config/example_binlog.py\n   ```\n\n   该进程会一直运行，实时同步新增和更改后的数据到elasticsearch；\n\n   注意：第一次运行该进程时不会同步MySql中已存在的数据，从第二次运行开始，将接着上次同步停止时的位置继续同步；\n\n   同步旧数据请看*全量同步MySql数据到es*；\n\n### 基于更新时间的增量同步\n\n若 *Mysql* 表中有类似 `update_time` 的时间字段，且在每次插入、更新数据后将该字段的值设置为操作时间，则可在不用开启 *binlog* 的情况下进行增量同步。\n\n1. 下载项目到本地，且安装好依赖后，编辑 ./config/example_cron.py，按**注释**提示修改配置；\n\n   ```python\n   # coding=utf-8\n   \n   STREAM = \u0026quot;CRON\u0026quot;\n   \n   # 修改数据库连接\n   CONNECTION = {\n       'host': '127.0.0.1',\n       'port': 3306,\n       'user': 'root',\n       'passwd': ''\n   }\n   \n   # redis存储上次同步时间等信息\n   REDIS = {\n       \u0026quot;host\u0026quot;: \u0026quot;127.0.0.1\u0026quot;,\n       \u0026quot;port\u0026quot;: 6379,\n       \u0026quot;db\u0026quot;: 0,\n       \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot;,  # 不需要密码则注释或删掉该行\n   }\n   \n   # 一次同步 BULK_SIZE 条数据到elasticsearch，不设置该配置项默认为1\n   BULK_SIZE = 1\n   \n   # 修改elasticsearch节点\n   NODES = [{\u0026quot;host\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;port\u0026quot;: 9200}]\n   \n   TASKS = [\n       {\n           \u0026quot;stream\u0026quot;: {\n               \u0026quot;database\u0026quot;: \u0026quot;test_db\u0026quot;,  # 在此数据库执行sql语句\n               \u0026quot;sql\u0026quot;: \u0026quot;select id, name from person where update_time \u0026gt;= ?\u0026quot;,  # 将该sql语句选中的数据同步到 elasticsearch\n               \u0026quot;seconds\u0026quot;: 10,  # 每隔 seconds 秒同步一次,\n               \u0026quot;init_time\u0026quot;: \u0026quot;2018-08-15 18:05:47\u0026quot;  # 只有第一次同步会加载\n           },\n           \u0026quot;jobs\u0026quot;: [\n               {\n                   \u0026quot;pipeline\u0026quot;: [\n                       {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}  # 默认设置 id字段的值 为 es 中的文档id\n                   ],\n                   \u0026quot;dest\u0026quot;: {\n                       \u0026quot;es\u0026quot;: {\n                           \u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;,\n                           \u0026quot;index\u0026quot;: \u0026quot;test_index\u0026quot;,   # 设置 index\n                           \u0026quot;type\u0026quot;: \u0026quot;test\u0026quot;          # 设置 type\n                       }\n                   }\n               }\n           ]\n       }\n   ]\n   ```\n\n2. 运行\n\n   ```shell\n   cd mysqlsmom\n   python mysqlsmom.py ./config/example_cron.py\n   ```\n\n## 组织架构\n![Alt text](https://github.com/m358807551/images/blob/master/images/mysqlsmom/all.png?raw=true)\n\n## *Mysqlsmom* 使用实战\n\n*Mysqlsmom* 的灵活性依赖于：\n\n* 在 *row_handlers.py* 中添加自定义函数对取自Mysql的数据进行二次加工。\n* 在 *row_filters.py* 中添加自定义函数决定是否要同步某一条数据。\n* 在 *config/* 目录下的任意配置文件应用上面的函数。\n\n如果不了解 Python 也没关系，上述两个文件中自带的函数足以应付大多数种情况，遇到特殊的同步需求可以在 Github 发起 issue 或通过微信、QQ联系作者。\n\n### 同步多张表\n\n在一个配置文件中即可完成：\n\n```python\n...\nTASKS = [\n    # 同步表1\n    {\n        \u0026quot;stream\u0026quot;: {\n            \u0026quot;database\u0026quot;: \u0026quot;数据库名1\u0026quot;,\n            \u0026quot;table\u0026quot;: \u0026quot;表名1\u0026quot;\n        },\n        \u0026quot;jobs\u0026quot;: [...]\n    }\n    # 同步表2\n    {\n        \u0026quot;stream\u0026quot;: {\n            \u0026quot;database\u0026quot;: \u0026quot;数据库名2\u0026quot;,\n            \u0026quot;table\u0026quot;: \u0026quot;表名2\u0026quot;\n        },\n        \u0026quot;jobs\u0026quot;: [...]\n    }\n]\n```\n\n一个 *Mysql Connection* 对应**一个**配置文件。\n\n### 一张表同步到多个索引\n\n分为两种情况。\n\n一种是把相同的数据同步到不同的索引，配置如下：\n\n```python\n...\nTASKS = [\n    {\n        \u0026quot;stream\u0026quot;: {...},\n        \u0026quot;jobs\u0026quot;: [\n            {\n                \u0026quot;actions\u0026quot;: [...],\n                \u0026quot;pipeline\u0026quot;: [...],\n                \u0026quot;dest\u0026quot;: [\n                    # 同步到索引1\n                    {\n                        \u0026quot;es\u0026quot;: {\u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;, \u0026quot;index\u0026quot;: \u0026quot;索引1\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;类型1\u0026quot;, \u0026quot;nodes\u0026quot;: NODES},\n                    },\n                    # 同步到索引2\n                    {\n                        \u0026quot;es\u0026quot;: {\u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;, \u0026quot;index\u0026quot;: \u0026quot;索引2\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;类型2\u0026quot;, \u0026quot;nodes\u0026quot;: NODES},\n                    }\n                ]\n            }\n        ]\n    },\n    ...\n]\n```\n\n另一种是把同一个表产生的数据经过不同的 *pipeline* 同步到不同的索引：\n\n```python\n...\nTASKS = [\n    {\n        \u0026quot;stream\u0026quot;: {...},\n        \u0026quot;jobs\u0026quot;: [\n            {\n                \u0026quot;actions\u0026quot;: {...},\n                \u0026quot;pipeline\u0026quot;: [...],  # 对数据经过一系列处理\n                \u0026quot;dest\u0026quot;: {\u0026quot;es\u0026quot;: {\u0026quot;index\u0026quot;: \u0026quot;索引1\u0026quot;, ...}}  # 同步到索引1\n            },\n            {\n                \u0026quot;actions\u0026quot;: {...},\n                \u0026quot;pipeline\u0026quot;: [...],  # 与上面的pipeline不同\n                \u0026quot;dest\u0026quot;: {\u0026quot;es\u0026quot;: {\u0026quot;index\u0026quot;: \u0026quot;索引2\u0026quot;, ...}}  # 同步到索引2\n            }\n        ]\n    }\n]\n```\n\n* *TASKS* 中的每一项对应一张要同步的表。\n* *jobs* 中的每一项对应对一条记录的一种处理方式。\n* *dest* 中的每一项对应一个es索引类型。\n\n### 只同步某些字段\n\n对每条来自 *Mysql* 的 记录的处理都在 **pipeline** 中进行处理。\n\n```python\n\u0026quot;pipeline\u0026quot;: [\n\t{\u0026quot;only_fields\u0026quot;: {\u0026quot;fields\u0026quot;: [\u0026quot;id\u0026quot;, \u0026quot;name\u0026quot;]}},  # 只同步 id 和 name字段\n    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}  # 然后设置 id 字段为es中文档的_id\n]\n```\n\n### 字段重命名\n\n对于 *Mysql* 中的字段名和 *elasticsearch* 中的域名不一致的情况：\n\n```python\n\u0026quot;pipeline\u0026quot;: [\n    # 将name重命名为name1，age 重命名为age1\n\t{\u0026quot;replace_fields\u0026quot;: {\u0026quot;name\u0026quot;: [\u0026quot;name1\u0026quot;], \u0026quot;age\u0026quot;: [\u0026quot;age1\u0026quot;]}},\n    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}\n]\n```\n\n*pipeline* 会依次执行处理函数，上面的例子等价于：\n\n```python\n\u0026quot;pipeline\u0026quot;: [\n    # 先重命名 name 为 name1\n\t{\u0026quot;replace_fields\u0026quot;: {\u0026quot;name\u0026quot;: [\u0026quot;name1\u0026quot;]}},\n    # 再重命名 age 为 age1\n    {\u0026quot;replace_fields\u0026quot;: {\u0026quot;age\u0026quot;: [\u0026quot;age1\u0026quot;]}},\n    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}\n]\n```\n\n还有一种特殊情形，es 中两个字段存相同的数据，但是分词方式不同。\n\n例如 *name_default* 的分析器为 *default*，*name_raw* 设置为不分词，需要将 *name* 的值同时同步到这两个域：\n\n```python\n\u0026quot;pipeline\u0026quot;: [\n\t{\u0026quot;replace_fields\u0026quot;: {\u0026quot;name\u0026quot;: [\u0026quot;name_default\u0026quot;, \u0026quot;name_raw\u0026quot;]}},\n    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}\n]\n```\n\n当然上述问题有一个更好的解决方案，在 *es* 的 *mappings* 中配置 *name* 字段的 *fields* 属性即可，这超出了本文档的内容。\n\n### 切分字符串为数组\n\n有时 Mysql 存储字符串类似：\u0026quot;aaa|bbb|ccc\u0026quot;，希望转化成数组: [\u0026quot;aaa\u0026quot;, \u0026quot;bbb\u0026quot;, \u0026quot;ccc\u0026quot;] 再进行同步\n\n```python\n\u0026quot;pipeline\u0026quot;: [\n\t# tags 存储类似\u0026quot;aaa|bbb|ccc\u0026quot;的字符串，将 tags 字段的值按符号 `|` 切分成数组\n\t{\u0026quot;split\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;tags\u0026quot;, \u0026quot;flag\u0026quot;: \u0026quot;|\u0026quot;}},\n    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}\n] \n```\n\n### 同步删除文档\n\n只有 ***binlog* 同步** 能实现删除 *elasticsearch* 中的文档，配置如下：\n\n```python\nTASKS = [\n    {\n        \u0026quot;stream\u0026quot;: {\n            \u0026quot;database\u0026quot;: \u0026quot;test_db\u0026quot;,\n            \u0026quot;table\u0026quot;: \u0026quot;person\u0026quot;\n        },\n        \u0026quot;jobs\u0026quot;: [\n            # 插入、更新\n            {\n                \u0026quot;actions\u0026quot;: [\u0026quot;insert\u0026quot;, \u0026quot;update\u0026quot;],\n                \u0026quot;pipeline\u0026quot;: [\n                    {\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}  # 设置 id 字段的值为 es 中文档 _id\n                ],\n                \u0026quot;dest\u0026quot;: {\n                    \u0026quot;es\u0026quot;: {\n                        \u0026quot;action\u0026quot;: \u0026quot;upsert\u0026quot;,\n                        ...\n                    }\n                }\n            },\n            # 重点在这里，配置删除\n            {\n                \u0026quot;actions\u0026quot;: [\u0026quot;delete\u0026quot;],  # 当读取到 binlog 中该表的删除操作时\n                \u0026quot;pipeline\u0026quot;: [{\u0026quot;set_id\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;id\u0026quot;}}],  # 要删除的文档 _id\n                \u0026quot;dest\u0026quot;: {\n                    \u0026quot;es\u0026quot;: {\n                        \u0026quot;action\u0026quot;: \u0026quot;delete\u0026quot;,  # 在 es 中执行删除操作\n                        ...  # 与上面的 index 和 type 相同\n                    }\n                }\n            }\n        ]\n    },\n    ...\n]\n```\n\n\n\n### 更多示例正在更新\n\n## 常见问题\n\n#### 为什么我的增量同步不及时？\n\n1. 连接本地数据库增量同步不及时\n\n   该情况暂未收到过反馈，如能复现请联系作者。\n\n2. 连接线上数据库发现增量同步不及时\n\n   2.1 推荐使用内网IP连接数据库。连接线上数据库（如开启在阿里、腾讯服务器上的Mysql）时，推荐使用内网IP地址，因为外网IP会受到带宽等限制导致获取binlog数据速度受限，最终可能造成同步延时。\n\n## 待改进\n\n1. 据部分用户反馈，全量同步百万级以上的数据性能不佳。\n\n## 未完待续\n\n文档近期会较频繁更新，任何问题、建议都收到欢迎，请在issues留言，会在24小时内回复；或联系QQ、微信: 358807551；","title":"推荐一个同步Mysql数据到Elasticsearch的工具","uid":"6688","views":"2778","votes":"2"},"_type":"doc"}
{"_id":"757","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534303329","category_id":"18","comments":"0","has_attach":"0","id":"757","message":"1. 微服务架构实践（日志收集）\nhttp://t.cn/Rd3QEfE\n2. Elasticsearch SQL\nhttp://t.cn/RDgJ9HQ\n3. 日志汇集系统搭建\n[url]http://t.cn/RDg9wU2[/url] \n \n活动预告：\nElastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/757[/url]\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第364期 (2018-08-15)","uid":"3828","views":"259","votes":"0"},"_type":"doc"}
{"_id":"762","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534558446","category_id":"18","comments":"0","has_attach":"0","id":"762","message":"1. 支持弹性化部署的Elastic  Cloud。\n[http://t.cn/Rk2LTeO](http://t.cn/Rk2LTeO) \n\n2. 使用ES处理数据的经验分享(需翻墙）。\n[http://t.cn/Rk2L13a](http://t.cn/Rk2L13a) \n\n3. Elassandra:将es和Apache Cassandra结合的工具。\n[http://t.cn/Rk2DOuf](http://t.cn/Rk2DOuf) \n\n活动预告\n1. 活动预告：Elastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/762\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第367期 (2018-08-18)","uid":"1874","views":"229","votes":"0"},"_type":"doc"}
{"_id":"768","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535062292","category_id":"18","comments":"0","has_attach":"0","id":"768","message":"1、一行命令：从 ELK 迁移日志服务\nhttp://t.cn/RklH6TU\n2、搜索之路：Elasticsearch的诞生\nhttp://t.cn/Rk6ZPYq\n3、教你编译调试Elasticsearch 6.3.2源码\nhttp://t.cn/RklHW8y\n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/768\n订阅：https://tinyletter.com/elastic-daily\n\n ","title":" Elastic日报 第373期 (2018-08-24)","uid":"1341","views":"260","votes":"1"},"_type":"doc"}
{"_id":"779","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535637905","category_id":"2","comments":"2","has_attach":"0","id":"779","message":"[Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/index.html) 是elasticsearch 官方的一个索引管理工具，可以通过配置文件的方式帮助我们对指定的一批索引进行创建/删除、打开/关闭、快照/恢复等管理操作。\n\n\n\n# 场景\n\n比如，出于读写性能的考虑，我们通常会把基于时间的数据按时间来创建索引。\n\n![indices](https://ws3.sinaimg.cn/large/0069RVTdgy1fur095ze6uj31240by0te.jpg)当数据量到达一定量级时，为了节省内存或者磁盘空间，我们往往会根据实际情况选择关闭或者删除一定时间之前的索引。通常我们会写一段脚本调用elasticsearch的api，放到crontab中定期执行。这样虽然可以达到目的，但是脚本多了之后会变得难以维护。\n\nCurator是如何解决这类问题的呢？我们一步一步来：\n\n \n\n# 安装\n\n首先，Curator是基于python实现的，我们可以直接通过pip来安装，这种方式最简单。\n\n```bash\npip install elasticsearch-curator\n```\n\n \n\n# 基本配置\n\n接下来，需要为 Curator 配置es连接: \n\n```yaml\n# ~/.curator/curator.yml\n\nclient:\n  hosts:\n    - 127.0.0.1\n  port: 9200\n\nlogging:\n  loglevel: INFO\n```\n\n其中hosts 允许配置多个地址，但是只能属于同一个集群。\n\n这边只列举了最基本的配置，[官方文档](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html)中包含了更详细的配置。\n\n \n\n# 动作配置\n\n然后需要配置我们需要执行的动作，每个动作会按顺序执行：\n\n```yaml\n# /etc/curator/actions/maintain_log.yml\n\nactions:\n  1:\n    #创建第二天的索引\n    action: create_index\n    description: \u0026quot;create new time-based index for log-*\u0026quot;\n    options:\n      name: '\u0026lt;log-{now/d+1d}\u0026gt;'\n  2:\n    #删除3天前的索引\n    action: delete_indices\n    description: \u0026quot;delete outdated indices for log-*\u0026quot;\n    filters:\n    - filtertype: pattern\n      kind: prefix\n      value: log\n    - filtertype: age\n      source: name\n      direction: older\n      timestring: '%Y.%m.%d'\n      unit: days\n      unit_count: 3\n```\n\n**action** 定义了需要执行的动作，curator支持十多种动作，可以在[官方文档](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html)查看完整的动作列表。\n\n**options** 定义了执行动作所需的参数，不同动作的参数也不尽相同，具体文档中都有写明。\n\n**filters** 定义了动作的执行对象，通过设置filter，可以过滤出我们需要操作的索引。同一个action下的filter之间是**且**的关系。比如在上面的定义中，delete_indices下定义了两个filters：\n\n- 模式匹配：匹配前缀为log的索引\n- “年龄”匹配：根据索引名中“%Y.%m.%d”时间格式，过滤出3天以前的索引\n\ncurator支持十多种filter，可以在[官方文档](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/filters.html)查看完整列表。\n\n \n\n# 执行\n\n最后，我们通过curator命令行工具来执行：\n\n```\ncurator --config /etc/curator/curator.yml /etc/curator/actions/maintain_log.yml\n```\n\n得到命令行输出：\n\n```\n2018-08-30 12:31:26,829 INFO      Preparing Action ID: 1, \u0026quot;create_index\u0026quot;\n2018-08-30 12:31:26,841 INFO      Trying Action ID: 1, \u0026quot;create_index\u0026quot;: create new time-based index for log-*\n2018-08-30 12:31:26,841 INFO      \u0026quot;\u0026lt;log-{now/d+1d}\u0026gt;\u0026quot; is using Elasticsearch date math.\n2018-08-30 12:31:26,841 INFO      Creating index \u0026quot;\u0026lt;log-{now/d+1d}\u0026gt;\u0026quot; with settings: {}\n2018-08-30 12:31:27,049 INFO      Action ID: 1, \u0026quot;create_index\u0026quot; completed.\n2018-08-30 12:31:27,050 INFO      Preparing Action ID: 2, \u0026quot;delete_indices\u0026quot;\n2018-08-30 12:31:27,058 INFO      Trying Action ID: 2, \u0026quot;delete_indices\u0026quot;: delete outdated indices for log-*\n2018-08-30 12:31:27,119 INFO      Deleting selected indices: ['log-2018.08.24', 'log-2018.08.25', 'log-2018.08.27', 'log-2018.08.26', 'log-2018.08.23']\n2018-08-30 12:31:27,119 INFO      ---deleting index log-2018.08.24\n2018-08-30 12:31:27,120 INFO      ---deleting index log-2018.08.25\n2018-08-30 12:31:27,120 INFO      ---deleting index log-2018.08.27\n2018-08-30 12:31:27,120 INFO      ---deleting index log-2018.08.26\n2018-08-30 12:31:27,120 INFO      ---deleting index log-2018.08.23\n2018-08-30 12:31:27,282 INFO      Action ID: 2, \u0026quot;delete_indices\u0026quot; completed.\n2018-08-30 12:31:27,283 INFO      Job completed.\n```\n\n从日志中可以看到，我们已经成功创建了隔天的索引，并删除了28号以前的索引。\n\n \n\n# 定时执行\n\n配置好curator后，还需要配置定时任务\n\n使用`crontab -e`编辑crontab，\n\n添加一行：\n\n```bash\n0 23 * * * /usr/local/bin/curator --config /root/.curator/curator.yml /etc/curator/actions/maintain_log.yml \u0026gt;\u0026gt; /var/curator.log 2\u0026gt;\u0026amp;1\n```\n\ncrontab配置中的第一段是执行的周期，6个值分别是“分 时 日 月 周”，*表示全部。所以这段配置的含义是在每天23点执行我们的这段脚本。\n\n \n\n# 单个执行\n\n除了定时任务，我们也可以在不依赖action配置文件的情况下用curator执行一些临时的批量操作。curator提供了`curator_cli`的命令来执行单个action，比如我们想对所有log开头的索引做快照，使用一条命令即可完成：\n\n```bash\ncurator_cli snapshot --repository repo_name --filter_list {\u0026quot;filtertype\u0026quot;: \u0026quot;pattern\u0026quot;,\u0026quot;kind\u0026quot;: \u0026quot;prefix\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;log\u0026quot;}\n```\n\n是不是特别方便？\n\n \n\n# 执行流程\n\n# ![image-20180830200126973](https://ws2.sinaimg.cn/large/0069RVTdgy1furz9yfos8j30v40my760.jpg)\n\n在命令执行过程中，Curator 会进行以下几步操作：\n\n1. 从ES拉取所有的索引信息\n2. 根据设置的过滤条件过滤出需要操作的索引\n3. 对过滤后的索引执行指定的动作\n\n\n\n# 复杂需求\n\n实际生产中，会有一些更复杂的需求，简单的action和filter组合并不能满足我们的业务。Curator还提供了[python包](https://curator.readthedocs.io/en/latest/)，方便我们自己写脚本时调用它提供的actions和filters，减少我们的开发工作量。\n\n\n\n以上通过一个实际的场景向大家介绍了Curator的使用方式，但是只用到了它一小部分的功能。大家可以通过文中的链接查看官方文档，发掘出更多的使用姿势。希望对大家有所帮助！\n\n![elasticTalk,qrcode](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)","title":"Curator从入门到实战","uid":"9765","views":"1458","votes":"2"},"_type":"doc"}
{"_id":"788","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536116469","category_id":"18","comments":"0","has_attach":"0","id":"788","message":"1.Curator 从入门到实战\nhttp://t.cn/RFX0HoV\n2.论 Elasticsearch 数据建模的重要性\nhttp://t.cn/RFOdWke\n3.Elasticsearch 原理分析\nhttp://t.cn/ReCN93k\n \n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/788[/url]\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第385期 (2018-09-05)","uid":"3828","views":"281","votes":"0"},"_type":"doc"}
{"_id":"791","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536272569","category_id":"18","comments":"0","has_attach":"0","id":"791","message":"1、如何使用Elasticsearch进行智能运维?\nhttp://t.cn/RQVKwkg\n2、用kerberos保证ES集群安全\nhttp://t.cn/RsG9ud2\n3、百亿级日志系统架构设计及优化\nhttp://t.cn/RsGCUGs\n\n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/791\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第387期 (2018-09-07)","uid":"1341","views":"300","votes":"0"},"_type":"doc"}
{"_id":"793","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536463516","category_id":"18","comments":"0","has_attach":"0","id":"793","message":"1.ELK Stack完整指南 - 2018年。\nhttp://t.cn/R9RHO6l\n2.安全最佳实践：高增长初创企业的经验教训。\nhttp://t.cn/RsoQXK2\n3.(自备梯子)再见，面向对象编程。\nhttp://t.cn/Rt4icdt\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/793\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第389期 (2018-09-09)","uid":"4460","views":"300","votes":"0"},"_type":"doc"}
{"_id":"801","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537056050","category_id":"18","comments":"0","has_attach":"0","id":"801","message":"1.(自备梯子)Kibana的第三方地图和平铺服务。\nhttp://t.cn/EvfhXE9\n2.Logstash教程：快速入门指南。\nhttp://t.cn/Evf7oTo\n3.(自备梯子)苹果想要挽救你的生命。\nhttp://t.cn/Evfzk6z\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/801\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第396期 (2018-09-16)","uid":"4460","views":"269","votes":"0"},"_type":"doc"}
{"_id":"809","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537425439","category_id":"18","comments":"0","has_attach":"0","id":"809","message":"1.有赞搜索系统的技术内幕\nhttp://t.cn/EvCIAYs\n2.生产环境怎么监控kafka\nhttp://t.cn/Ev8mGTp\n3.使用nprobe和ELK构建netflow分析平台\nhttp://t.cn/Ev8mMw6\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：金桥\n归档：https://elasticsearch.cn/article/809\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第400期 (2018-09-20)","uid":"668","views":"237","votes":"0"},"_type":"doc"}
{"_id":"811","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537587955","category_id":"18","comments":"0","has_attach":"0","id":"811","message":"1. 使用tophits显示聚合结果中的原始文档内容。\n[http://t.cn/R5UV8Fc](http://t.cn/R5UV8Fc) \n\n2. 官方公布的ES相关安全问题。\n[http://t.cn/RUoSc1G](http://t.cn/RUoSc1G) \n\n3. es只删除数据不删除type的tip。\n[http://t.cn/EPPDfQI](http://t.cn/EPPDfQI) \n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/811 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第402期 (2018-09-22）","uid":"1874","views":"186","votes":"0"},"_type":"doc"}
{"_id":"817","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537929913","category_id":"18","comments":"0","has_attach":"0","id":"817","message":"1. ELK日志系统之使用Rsyslog快速方便的收集Nginx日志\nhttp://t.cn/EPSMYc3\n2. 使用ELK构建微服务的日志平台\nhttp://t.cn/Rkb1wdM\n3. Elasticsearch通用优化建议\nhttp://t.cn/RkjzIL2\n \n​活动预告\n1. Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/817[/url]\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第406期 (2018-09-26)","uid":"3828","views":"300","votes":"0"},"_type":"doc"}
{"_id":"821","_index":"forum-mysql","_score":1,"_source":{"addtime":"1538289924","category_id":"18","comments":"0","has_attach":"0","id":"821","message":"1.将Apache Pig和Hadoop与Elasticsearch及Elasticsearch-Hadoop Connector一起使用。\nhttp://t.cn/EPkOKwG\n2.(自备梯子)日志管理：Graylog vs ELK\nhttp://t.cn/EPkpnzZ\n3.(自备梯子)如何学习数据科学。\nhttp://t.cn/Ev0BfUZ\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/821\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第410期 (2018-09-30)","uid":"4460","views":"317","votes":"0"},"_type":"doc"}
{"_id":"824","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539137403","category_id":"2","comments":"2","has_attach":"0","id":"824","message":"elk6.4.2版本自带的x-pack插件怎么启动与使用,主要是想给kibana设置登录验证.","title":"elk6.4.2版本自带的x-pack","uid":"7866","views":"382","votes":"0"},"_type":"doc"}
{"_id":"831","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539569408","category_id":"18","comments":"0","has_attach":"0","id":"831","message":"1、kibana canvas 初步入门指南。\nhttp://t.cn/E78MvKs\n\n2.图数据库的发展\nhttp://t.cn/E78097R\n\n3. Elasticsearch和MongoDB分片及高可用对比\nhttp://t.cn/E78johf\n\n活动预告\n1、Elastic 中国开发者大会门票发售中,庆祝上市，抢半价门票\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/{}\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第418期 (2018-10-15)","uid":"4063","views":"208","votes":"0"},"_type":"doc"}
{"_id":"990","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539762478","category_id":"44","comments":"0","has_attach":"1","id":"990","message":"[attach]3040[/attach]\n 欢迎来到 Elastic 社区电台的第五期节目，本期分享嘉宾邀请来自位于南京的趋势科技中国研发中心。趋势科技是网络安全软件及服务领域的全球领导者。趋势科技深度的使用了 Elastic Stack 来解决多个业务场景下的多种需求，目前部署共超过 8 个集群，单个最大集群承载了上百个 TB 的业务数据。比如在病毒样本的分析场景，通过使用 Elasticsearch 来构建的病毒特征库，比之前的方案更快更高效。另外移动端手机 APP 行为数据的安全分析以及趋势内部应用的日志分析也都是使用的 Elasticsearch 来完成的。想要了解更多详情，快来收听本期节目来吧。\n\n\n[b]嘉宾：[/b]\n李啸(white), 目前就职于趋势科技中国研发中心，担任 staff software engineer一职，2012 年接触 elk 技术，7 年分布式系统开发，devops 经验，目前主要从事移动病毒大数据分析平台系统研发工作。\n\n张振风(houper), 趋势高级研发工程师，从事 big data 相关工作，自 2015 年起接触和关注 elastic 技术。\n\n[b]主持人：[/b]\nElastic 技术布道师，曾勇（Medcl）。\n\n\n可以点击下面的任意链接来收听（时长约 50 分钟）：\n\nApple iTunes: https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/id1415654232?mt=2\n喜马拉雅：https://www.ximalaya.com/keji/14965410/124736791\n蜻蜓 FM：https://www.qingting.fm/channels/244978/programs/9817402\n\n[b]关于趋势科技[/b]\n\n趋势科技——网络安全软件及服务领域的全球领导者，以卓越的前瞻和技术革新能力引领了从桌面防毒到网络服务器和网关防毒的潮流，以独特的服务理念向业界证明了趋势科技的前瞻性和领导地位。总部位于日本东京和美国硅谷，在38个国家和地区设有分公司，拥有7 个全球研发中心，员工总数超过4000人。\n\n\n[b]关于 Elastic 社区电台[/b]\n\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\n\n[attach]3041[/attach]\n ","title":"Elastic 社区电台 第五期，嘉宾：李啸、张振风@趋势科技","uid":"1","views":"215","votes":"0"},"_type":"doc"}
{"_id":"1005","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540607996","category_id":"18","comments":"0","has_attach":"0","id":"1005","message":"1. 索引时排序的优势之一：节省空间。\n[http://t.cn/EZpy0Pm](http://t.cn/EZpy0Pm) \n\n2. Wordpress利用ElasticPress插件使用es的实例。\n[http://t.cn/EZp5JZJ](http://t.cn/EZp5JZJ) \n\n3. 一款支持英语、俄语的词法分析插件。\n[http://t.cn/EZpKfK4](http://t.cn/EZpKfK4) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/1005 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第430期 (2018-10-27）","uid":"1874","views":"184","votes":"0"},"_type":"doc"}
{"_id":"1021","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540895137","category_id":"18","comments":"0","has_attach":"0","id":"1021","message":"1、Elasticsearch官方Node.js客户端。\nhttp://t.cn/EwvuIHq\n2、Elasticsearch文档和映射。\nhttp://t.cn/EwvkYbt\n3、Elasticsearch快速指南。\n​http://t.cn/Ewvk8JY\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/1021\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第433期 (2018-10-30)","uid":"3788","views":"176","votes":"0"},"_type":"doc"}
{"_id":"6347","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548469159","category_id":"18","comments":"0","has_attach":"0","id":"6347","message":"1. ES使用中遇到的多种坑，以及解决方案。\n[http://t.cn/Etzlrca](http://t.cn/Etzlrca) \n\n2.使用Python ES Kibana构建的实时异常检测开源框架。\n[http://t.cn/R8Vu2q3](http://t.cn/R8Vu2q3) \n\n3. Golang操作elasticsearch。\n[http://t.cn/EtzjhkJ](http://t.cn/EtzjhkJ) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6347 \n\n* 订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第521期 (2019-01-26）","uid":"1874","views":"49","votes":"0"},"_type":"doc"}
{"_id":"6349","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548571979","category_id":"2","comments":"0","has_attach":"0","id":"6349","message":"本文将详细介绍利用 ES 与 Hive 直接的数据交互；通过 Hive 外部表的方式，可以快速将 ES 索引数据映射到 Hive 中，使用易于上手的 Hive SQL 实现对数据的进一步加工。\n\n## 一、开发环境\n### 1、组件版本\n- CDH 集群版本：6.0.1\n- ES 版本：6.5.1\n- Hive 版本：2.1.1\n- ES-Hadoop 版本：6.5.1\n\n### 2、Hive 简介\nHive 在 Hadoop 生态系统中扮演着数据仓库的角色，借助 Hive 可以方便地进行数据汇总、即席查询以及分析存储在 Hadoop 文件系统中的大型数据集。\n\nHive 通过类 SQL 语言（HSQL）对 Hadoop 上的数据进行抽象，这样用户可以通过 SQL 语句对数据进行定义、组织、操作和分析；在 Hive 中，数据集是通过表（定义了数据类型相关信息）进行定义的，用户可以通过内置运算符或用户自定义函数（UDF）对数据进行加载、查询和转换。\n\n### 3、Hive 安装 ES-Hadoop\n官方推荐的安装方式：\n#### 使用 `add jar`\n```\nadd jar /path/elasticsearch-hadoop.jar\n```\n#### 使用 `hive.aux.jars.path`\n```\n$ bin/hive --auxpath=/path/elasticsearch-hadoop.jar\n```\n#### 修改配置(`hive-site.xml`)\n```\n\u0026lt;property\u0026gt;\n  \u0026lt;name\u0026gt;hive.aux.jars.path\u0026lt;/name\u0026gt;\n  \u0026lt;value\u0026gt;/path/elasticsearch-hadoop.jar\u0026lt;/value\u0026gt;\n  \u0026lt;description\u0026gt;A comma separated list (with no spaces) of the jar files\u0026lt;/description\u0026gt;\n\u0026lt;/property\u0026gt;\n```\n\n#### CDH6.X 推荐的安装方法\n将 `elasticsearch-hadoop.jar` 复制到 Hive 的 auxlib 目录中，然后重启 Hive 即可。\n\n```\ncp elasticsearch-hadoop.jar /opt/cloudera/parcels/CDH/lib/hive/auxlib/\n```\n\n## 二、Hive 与 ElasticSearch 的数据交互\n### 1、数据类型对照表\n\u0026gt; 请务必注意，ES 中的类型是 `index/_mapping` 中对应的数据类型，非 `_source` 里面数据的类型。\n\nHive type | Elasticsearch type\n---|---\nvoid | null\nboolean | boolean\ntinyint | byte\nsmallint | short\nint | int\nbigint | long\ndouble | double\nfloat | float\nstring | string\nbinary | binary\n**timestamp** | date\nstruct | map\nmap | map\narray | array\nunion | not supported (yet)\ndecimal | string\n**date** | date\nvarchar | string\nchar | string\n\n### 2、建立 Hive 外部表\n```\nCREATE EXTERNAL TABLE default.surface(\n    water_type STRING,\n    water_level STRING,\n    monitor_time TIMESTAMP,\n    sitecode STRING,\n    p492 DOUBLE,\n    p311 DOUBLE,\n    status STRING\n)\nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'\nTBLPROPERTIES(\n    'es.resource'='ods_data_day_surface*/doc',\n    'es.query'='?q=status:001'\n    'es.nodes'='sky-01','es.port'='9200',\n    'es.net.http.auth.user'='sky',\n    'es.net.http.auth.pass'='jointsky',\n    'es.date.format'='yyyy-MM-dd HH:mm:ss',\n    'es.ser.reader.value.class'='com.jointsky.bigdata.hive.EsValueReader'\n    'es.mapping.names'='waterType:water_type,monitortime:monitor_time'\n);\n```\n\n### 3、配置项说明\n#### es.resource\n`es.resource` 用于设置 ES 资源的位置，默认该配置项同时设置了读和写的索引，当然也可以分别设置读写索引名称：\n- `es.resource.read`：设置读取位置；\n- `es.resource.write`：设置写入位置。\n\n#### es.query\n`es.query` 设置查询过滤条件，目前支持 `uri query`、`query dsl`、`external resource` 三种设置方式。\n```\n# uri (or parameter) query\nes.query = ?q=costinl\n\n# query dsl\nes.query = { \u0026quot;query\u0026quot; : { \u0026quot;term\u0026quot; : { \u0026quot;user\u0026quot; : \u0026quot;costinl\u0026quot; } } }\n\n# external resource\nes.query = org/mypackage/myquery.json\n```\n\n#### es.mapping.names\n`es.mapping.names` 用于设置 Hive 与 ES 的字段映射关系，如果不设置，则默认字段名不发生变化（即为 data type 区域定义的字段名）；此外该部分还用于定义 Hive 到 ES 的数据映射类型。\n```\n'es.mapping.names' = 'date:@timestamp , url:url_123 ')\n```\n\n\u0026gt; 其他通用字段的说明请参考文章：[使用 ES-Hadoop 将 Spark Streaming 流数据写入 ES](https://juejin.im/post/5c30dfbf6fb9a049ae080b37)\n\n\n### 4、自定义日期类型解析\n目前将 ES 的 date 类型映射到 Hive 的 TIMESTAMP 类型时，ES-Hadoop 组件只能识别时间戳格式或者标准的 XSD 格式的日期字符串：\n```\n@Override\nprotected Object parseDate(Long value, boolean richDate) {\n    return (richDate ? new TimestampWritable(new Timestamp(value)) : processLong(value));\n}\n\n@Override\nprotected Object parseDate(String value, boolean richDate) {\n    return (richDate ? new TimestampWritable(new Timestamp(DatatypeConverter.parseDateTime(value).getTimeInMillis())) : parseString(value));\n}\n```\n\n\u0026gt; 关于 XSD（XML Schema Date/Time Datatypes）可用参考文章：[https://www.w3schools.com/xml/schema_dtypes_date.asp](https://www.w3schools.com/xml/schema_dtypes_date.asp)\n\n为了兼容自定义的日期格式，需要编写自定义的日期读取类：\n```\n\nimport org.apache.hadoop.hive.serde2.io.TimestampWritable;\nimport org.elasticsearch.hadoop.cfg.Settings;\nimport org.elasticsearch.hadoop.hive.HiveValueReader;\n\nimport java.sql.Timestamp;\nimport java.text.ParseException;\nimport java.text.ParsePosition;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\npublic class EsValueReader extends HiveValueReader {\n    private String dateFormat;\n    private static final String DEFAULT_DATE_FORMAT = \u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;;\n    private static final String DEFAULT_DATE_FORMAT_MIN = \u0026quot;yyyy-MM-dd HH:mm\u0026quot;;\n    private static final String DEFAULT_DATE_FORMAT_HOUR = \u0026quot;yyyy-MM-dd HH\u0026quot;;\n    private static final String DEFAULT_DATE_FORMAT_DAY = \u0026quot;yyyy-MM-dd\u0026quot;;\n\n    @Override\n    public void setSettings(Settings settings) {\n        super.setSettings(settings);\n        dateFormat = settings.getProperty(\u0026quot;es.date.format\u0026quot;);\n    }\n\n    @Override\n    protected Object parseDate(String value, boolean richDate) {\n        if (value != null \u0026amp;\u0026amp; value.trim().length() \u0026gt; 0 \u0026amp;\u0026amp; DEFAULT_DATE_FORMAT.equalsIgnoreCase(dateFormat)) {\n            if (richDate){\n                if (value.length() == 16){\n                    return new TimestampWritable(new Timestamp(parseDate(value, DEFAULT_DATE_FORMAT_MIN).getTime()));\n                }\n                if (value.length() == 13){\n                    return new TimestampWritable(new Timestamp(parseDate(value, DEFAULT_DATE_FORMAT_HOUR).getTime()));\n                }\n                if (value.length() == 10){\n                    return new TimestampWritable(new Timestamp(parseDate(value, DEFAULT_DATE_FORMAT_DAY).getTime()));\n                }\n                return new TimestampWritable(new Timestamp(parseDate(value, DEFAULT_DATE_FORMAT).getTime()));\n            }\n            return parseString(value);\n        }\n        return super.parseDate(value, richDate);\n    }\n\n    /**\n     * 解析日期,根據指定的格式進行解析.\u0026lt;br\u0026gt;\n     * 如果解析錯誤,則返回null\n     * @param stringDate 日期字串\n     * @param format 日期格式\n     * @return 日期型別\n     */\n    private static Date parseDate(String stringDate, String format) {\n        if (stringDate == null) {\n            return null;\n        }\n        try {\n            return parseDate(stringDate, new String[] { format });\n        } catch (ParseException e) {\n            return null;\n        }\n    }\n\n    public static Date parseDate(String str, String... parsePatterns) throws ParseException {\n        return parseDateWithLeniency(str, parsePatterns, true);\n    }\n\n    private static Date parseDateWithLeniency(\n            String str, String[] parsePatterns, boolean lenient) throws ParseException {\n        if (str == null || parsePatterns == null) {\n            throw new IllegalArgumentException(\u0026quot;Date and Patterns must not be null\u0026quot;);\n        }\n\n        SimpleDateFormat parser = new SimpleDateFormat();\n        parser.setLenient(lenient);\n        ParsePosition pos = new ParsePosition(0);\n        for (String parsePattern : parsePatterns) {\n            String pattern = parsePattern;\n            if (parsePattern.endsWith(\u0026quot;ZZ\u0026quot;)) {\n                pattern = pattern.substring(0, pattern.length() - 1);\n            }\n            parser.applyPattern(pattern);\n            pos.setIndex(0);\n            String str2 = str;\n            if (parsePattern.endsWith(\u0026quot;ZZ\u0026quot;)) {\n                str2 = str.replaceAll(\u0026quot;([-+][0-9][0-9]):([0-9][0-9])$\u0026quot;, \u0026quot;$1$2\u0026quot;);\n            }\n            Date date = parser.parse(str2, pos);\n            if (date != null \u0026amp;\u0026amp; pos.getIndex() == str2.length()) {\n                return date;\n            }\n        }\n        throw new ParseException(\u0026quot;Unable to parse the date: \u0026quot; + str, -1);\n    }\n}\n```\n\n#### 上述代码的 Maven 依赖\n```\n\u0026lt;dependencies\u0026gt;\n    \u0026lt;dependency\u0026gt;\n        \u0026lt;groupId\u0026gt;org.apache.hive\u0026lt;/groupId\u0026gt;\n        \u0026lt;artifactId\u0026gt;hive-exec\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt;\n        \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n\n    \u0026lt;dependency\u0026gt;\n        \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt;\n        \u0026lt;artifactId\u0026gt;elasticsearch-hadoop\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;6.5.4\u0026lt;/version\u0026gt;\n        \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n\u0026lt;/dependencies\u0026gt;\n```\n\n#### 自定义日期解析包的部署\n代码编写完成后，将代码进行打包，然后将打包好的 jar 包放置到 Hive 的 auxlib 目录中，然后重启 Hive 即可；该步骤与 ES-Hadoop 的安装步骤一样。\n\n\u0026gt; 在编写 Spark 程序从 Hive 中读取数据的时候，需要添加对该包的依赖以及对 ES-Hadoop 的依赖。\n\n## 三、总结\n经过上述的步骤，Hive 与 ES 的映射已经不成问题，如果想从 ES 中导出数据，可用借助 HSQL `insert into table XXX select * from XXXXX;` 的方式从 ES 中读取数据写入到 HDFS；当然通过更为复杂的 HSQL 可以将数据进行处理，并将数据重新写入到 ES 或者存储到 HDFS。\n\n充分利用 ES 的查询、过滤和聚合，可以很好的去服务数据标准化、数据清洗、数据分布情况等 ETL 流程。\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](http://img.luooqi.com/FoE5jYLo6p4UVmGN8GPjCZz8Xete)\n","title":"Hive 与 ElasticSearch 的数据交互","uid":"8031","views":"23","votes":"1"},"_type":"doc"}
{"_id":"6341","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548156757","category_id":"2","comments":"5","has_attach":"0","id":"6341","message":"# 为ES构建Stanford NLP分词插件\n\n## Stanford NLP？\n\nStanford分词器是斯坦福大学NLP团队维护的一个开源分词器，支持了包括中文、英文…的语言，而且除了分词之外，它还支持了包括词性分析、情感分析…的各种功能。\\\n这俩是这个project的项目主页\n * [Home page](https://stanfordnlp.github.io/CoreNLP/index.html)\n * [GitHub page](https://github.com/stanfordnlp/CoreNLP)\n\n## Why Stanford core NLP？\n \n市面上确实会有很多很有名的开源分词器，比如IK、Jieba，还有一些其他团队和公司提供的开源/商用的分词器，他们各有优劣。但是在各种分词器上比较了一大堆的分词case之后，我们发现Stanford NLP似乎是最适合我们当前需求的一个，因为我们不仅仅需要分词，还需要一些包括情感分析之类在内的更多的一些功能。\n\n我们公司是做金融数据的搜索推荐的，在对比了各家分词器之后我们老板觉得Stanford NLP的效果最好，但是作为算法出身的人，他实现了一套非常重的分词、排序、搜索的服务。\n\n在对比如研报、财报之类的信息进行搜索的时候确实会比较有效，但是在对经济类的新闻进行搜索的时候就会显得十分的笨重。\n\n基于这个背景，我开始试图在ES里面引入老板推崇的Stanford 分词器来适应他的搜索、分词的需要，同时也能够不通过他那个笨重的分词排序服务来对我们系统中大量的经济、金融类的新闻进行分词、索引，并提供和他自己分词效果类似的分词和检索服务。\n\n## Why this project\n\n我在包括百度、某谷姓404网站、GitHub以及国内的中文社区（[Elastic中文社区](https://elasticsearch.cn/))在内的各种地方搜过也问过了，但是似乎没有一个直接开箱可用的分词插件。所以，我只剩一条路了，就是搭建一个自己的插件来引用这个分词器。\n\n## How\n\n对ES来说，插件主要分为两个部分：\n1. 让ES可以看到的部分（class extends Plugin）\n2. 自己行使职能的部分（functional part）\n\n### plugin\n\n1. 为了让ES可以加载我们的plugin，我们需要先继承Plugin类，然后我们这个是个分词器插件，所以还要实现AnalysisPlugin类\n2. 看过ES源码或者其他分词器源码的同学应该会知道，分词器插件需要实现两个方法，一个用来提供tokenizer，一个是analyzer分别对应分词器中的这俩。\n\t* 重写`Map\u0026lt;String, AnalysisModule.AnalysisProvider\u0026lt;TokenizerFactory\u0026gt;\u0026gt;`是为了可以提供搜索用分词器\n\t* 重写`Map\u0026lt;String, AnalysisModule.AnalysisProvider\u0026lt;AnalyzerProvider\u0026lt;? extends Analyzer\u0026gt;\u0026gt;\u0026gt;`是为了可以提供索引用分词器\n3. 在这个分词器里面我们主要是依靠Tokenizer来实现分词的\n\n### functional class\n\n分词器，特别是Tokenizer主要是靠重写三个方法来实现分词的\n1.\tincrementToken：用来确定每一个词元，输出每一个单词（字）以及它的位置、长度等\n2.\treset：用来重制分词结果\n3.\tend：用来告诉ES，这段文本的分词已经结束了\n\n所以我们主要需要重写的就是这仨方法，当然了，为了能让分词器正确的使用，我们还需要添加一些分词器的配置和初始化的内容，具体代码不写了可以参考我的git，主要讲两个坑：\n1.\tES是通过配置文件里的路径来寻找对应的插件类\n2.\t然后通过配置文件里的key和刚才提到的代码里的key来寻找对应的分词器，所以这俩地方不要写错了\n`#plugin-descriptor.properties: classname=org.elasticsearch.plugin.analysis.AnalysisSDPlugin`\n`#plugin-descriptor.properties: name=stanford-core-nlp`\n3. 在开发过程中由于有java-security的存在，所以需要通过AccessController来调用和加载我们需要的外部jar包\n\n### odds and ends\n\n1. Stanford分词器里面包含了很多功能，目前我使用了分词的部分\n2. 分词器自带词典文件，不过如果要做词典的修改可能需要解包，修改，再重新打包\n3. 我现在hardcode了一大堆的标点符号在里面，后面可能会去优化一下部分逻辑\n4. 待完成的功能还有其他功能包括情感分析之类的\n\n### also see\n[GitHub 地址](https://github.com/godlockin/esStanfordNLPAnalyzer)","title":"自研基于StanfordNLP的ES分词插件","uid":"8330","views":"116","votes":"2"},"_type":"doc"}
{"_id":"6333","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547690729","category_id":"18","comments":"0","has_attach":"0","id":"6333","message":"1.使用Logstash拆分数据并将其发送到多个输出\nhttp://t.cn/EquNcDU\n2.Logan：美团点评的开源移动端基础日志库\nhttp://t.cn/EquNpVL\n3.praeco：Elasticsearch报警工具\nhttp://t.cn/EAgg8WQ\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6333\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第512期 (2019-01-17)","uid":"668","views":"163","votes":"0"},"_type":"doc"}
{"_id":"6327","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547181896","category_id":"18","comments":"0","has_attach":"0","id":"6327","message":"1、在Spring Boot 2.0中使用ElasticSearch\nhttp://t.cn/EqLtnXp\n2、Elasticsearch索引管理利器——Curator深入详解\nhttp://t.cn/EqL9Tdq\n3、ES分片分配策略\nhttp://t.cn/EqLc7XK\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6327\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第506期（2019-1-11）","uid":"1341","views":"168","votes":"0"},"_type":"doc"}
{"_id":"6322","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546865034","category_id":"2","comments":"6","has_attach":"0","id":"6322","message":"\u0026gt; ELK Tips 主要介绍一些 ELK 使用过程中的小技巧，内容主要来源为 Elastic 中文社区。\n\n## 一、Logstash\n### 1、Logstash 性能调优主要参数\n- `pipeline.workers`：设置启动多少个线程执行 fliter 和 output；当 input 的内容出现堆积而 CPU 使用率还比较充足时，可以考虑增加该参数的大小；\n- `pipeline.batch.size`：设置单个工作线程在执行过滤器和输出之前收集的最大事件数，较大的批量大小通常更高效，但会增加内存开销。输出插件会将每个批处理作为一个输出单元。；例如，ES 输出会为收到的每个批次发出批量请求；调整 `pipeline.batch.size` 可调整发送到 ES 的批量请求（Bulk）的大小；\n- `pipeline.batch.delay`：设置 Logstash 管道的延迟时间， 管道批处理延迟是 Logstash 在当前管道工作线程中接收事件后等待新消息的最长时间（以毫秒为单位）；简单来说，当 `pipeline.batch.size` 不满足时，会等待 `pipeline.batch.delay` 设置的时间，超时后便开始执行 filter 和 output 操作。\n\n### 2、使用 Ruby Filter 根据现有字段计算一个新字段\n```\nfilter {\n    ruby {\n           code =\u0026gt; \u0026quot;event.set('kpi', ((event.get('a') + event.get('b'))/(event.get('c')+event.get('d'))).round(2))\u0026quot;\n     }\n}\n```\n\n### 3、logstash filter 如何判断字段是够为空或者 null\n```\nif ![updateTime]\n```\n\n### 4、Date Filter 设置多种日期格式\n```\ndate {\n  match =\u0026gt; [\u0026quot;logtime\u0026quot;, \u0026quot;yyyy-MM-dd HH:mm:ss.SSS\u0026quot;,\u0026quot;yyyy-MM-dd HH:mm:ss,SSS\u0026quot;]\n  target =\u0026gt; \u0026quot;logtime_utc\u0026quot;\n}\n```\n\n## 二、Elasticsearch\n### 1、高效翻页 Search After\n通常情况下我们会使用 from 和 size 的方式实现查询结果的翻页，但是当达到深度分页时，成本变得过高（堆内存占用和时间耗费与 from+size 的大小成正比），因此 ES 设置了限制（`index.max_result_window`），默认值为 10000，防止用户进行过于深入的翻页。\n\n推荐使用 Scroll api 进行高效深度滚动，但滚动上下文代价很高，因此不要将 Scroll 用于实时用户请求。search_after 参数通过**提供实时游标**来解决深度滚动的问题，其主要思路是使用上一页的结果来帮助检索下一页。\n\n```\nGET twitter/_search\n{\n    \u0026quot;size\u0026quot;: 10,\n    \u0026quot;query\u0026quot;: {\n        \u0026quot;match\u0026quot; : {\n            \u0026quot;title\u0026quot; : \u0026quot;elasticsearch\u0026quot;\n        }\n    },\n    \u0026quot;search_after\u0026quot;: [1463538857, \u0026quot;654323\u0026quot;],\n    \u0026quot;sort\u0026quot;: [\n        {\u0026quot;date\u0026quot;: \u0026quot;asc\u0026quot;},\n        {\u0026quot;tie_breaker_id\u0026quot;: \u0026quot;asc\u0026quot;}\n    ]\n}\n```\n\n### 2、ES 文档相似度 BM25 参数设置\nES2.X 默认是以 TF/IDF 算法计算文档相似度，从 ES5.X 开始，BM25 作为默认的相似度计算算法。\n```\nPUT /index\n{\n    \u0026quot;settings\u0026quot; : {\n        \u0026quot;index\u0026quot; : {\n            \u0026quot;similarity\u0026quot; : {\n              \u0026quot;my_similarity\u0026quot; : {\n                \u0026quot;type\u0026quot; : \u0026quot;DFR\u0026quot;,\n                \u0026quot;basic_model\u0026quot; : \u0026quot;g\u0026quot;,\n                \u0026quot;after_effect\u0026quot; : \u0026quot;l\u0026quot;,\n                \u0026quot;normalization\u0026quot; : \u0026quot;h2\u0026quot;,\n                \u0026quot;normalization.h2.c\u0026quot; : \u0026quot;3.0\u0026quot;\n              }\n            }\n        }\n    }\n}\n\nPUT /index/_mapping/_doc\n{\n  \u0026quot;properties\u0026quot; : {\n    \u0026quot;title\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;text\u0026quot;, \u0026quot;similarity\u0026quot; : \u0026quot;my_similarity\u0026quot; }\n  }\n}\n```\n\n### 3、ES2.X 得分计算\n得分计算脚本：\n```\ndouble tf = Math.sqrt(doc.freq); \ndouble idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; \ndouble norm = 1/Math.sqrt(doc.length); \nreturn query.boost * tf * idf * norm;\n```\n\n- 忽略词频统计及词频位置：将字段的 `index_options` 设置为 `docs`;\n- 忽略字段长度：设置字段的 `\u0026quot;norms\u0026quot;: { \u0026quot;enabled\u0026quot;: false }`；\n\n### 4、CircuitBreakingException: [parent] Data too large\n报错信息：\n```\n[WARN ][r.suppressed             ] path: /, params: {}\norg.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [\u0026lt;http_request\u0026gt;] would be [1454565650/1.3gb], which is larger than the limit of [1454427340/1.3gb], usages [request=0/0b, fielddata=568/568b, in_flight_requests=0/0b, accounting=1454565082/1.3gb]\n```\njvm 堆内存不够当前查询加载数据所以会报 data too large, 请求被熔断，`indices.breaker.request.limit`默认为 jvm heap 的 60%，因此可以通过调整 ES 的 Heap Size 来解决该问题。\n\n### 5、ES 免费的自动化运维工具推荐\n- Ansible: https://github.com/elastic/ansible-elasticsearch\n- Puppet: https://github.com/elastic/puppet-elasticsearch\n- Cookbook: https://github.com/elastic/cookbook-elasticsearch\n- **Curator**：https://www.elastic.co/guide/en/elasticsearch/client/curator/current/about.html\n\n### 6、elasticsearch-hanlp 分词插件包\n核心功能：\n- 内置多种分词模式，适合不同场景；\n- 内置词典，无需额外配置即可使用；\n- 支持外置词典，用户可自定义分词算法，基于词典或是模型；\n- 支持分词器级别的自定义词典，便于用于多租户场景；\n- 支持远程词典热更新（待开发）；\n- 拼音过滤器、繁简体过滤器（待开发）；\n- 基于词语或单字的 ngram 切分分词（待开发）。\n\n\u0026gt; https://github.com/AnyListen/elasticsearch-analysis-hanlp\n\n### 7、节点重启时延迟索引分片重分配\n当某个节点短时间离开集群时，一般是不会影响整体系统运行的，可以通过下面的请求延迟索引分片的再分配。\n```\nPUT _all/_settings\n{\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;index.unassigned.node_left.delayed_timeout\u0026quot;: \u0026quot;5m\u0026quot;\n  }\n}\n```\n\n### 8、ES 数据修改后，查询还是未修改前的数据\n默认是 1 秒可见，如果你的需求一定要写完就可见，那在写的时候增加 refresh 参数，强制刷新即可，但强烈建议不这么干，因为这样会把整个集群拖垮。\n\n### 9、Terms Query 从另一个索引获取 terms\n当 Terms Query 需要指定很多 terms 的时候，如果手动设置还是相当麻烦的，可以通过 terms-lookup 的方式从另外一个索引加载需要匹配的 terms。\n```\nPUT /users/_doc/2\n{\n    \u0026quot;followers\u0026quot; : [\u0026quot;1\u0026quot;, \u0026quot;3\u0026quot;]\n}\n\nPUT /tweets/_doc/1\n{\n    \u0026quot;user\u0026quot; : \u0026quot;1\u0026quot;\n}\n\nGET /tweets/_search\n{\n    \u0026quot;query\u0026quot; : {\n        \u0026quot;terms\u0026quot; : {\n            \u0026quot;user\u0026quot; : {\n                \u0026quot;index\u0026quot; : \u0026quot;users\u0026quot;,\n                \u0026quot;type\u0026quot; : \u0026quot;_doc\u0026quot;,\n                \u0026quot;id\u0026quot; : \u0026quot;2\u0026quot;,\n                \u0026quot;path\u0026quot; : \u0026quot;followers\u0026quot;\n            }\n        }\n    }\n}\n\n-----------等效下面的语句--------------\n\nPUT /users/_doc/2\n{\n \u0026quot;followers\u0026quot; : [\n   {\n     \u0026quot;id\u0026quot; : \u0026quot;1\u0026quot;\n   },\n   {\n     \u0026quot;id\u0026quot; : \u0026quot;2\u0026quot;\n   }\n ]\n}\n```\n\n### 10、ES 备份路径设置\n报错信息：\n```\ndoesn't match any of the locations specified by path.repo because this setting is empty\n```\n结局方案，修改 ES 的配置文件：\n```\n# 在 elasticsearch.yml 中添加下面配置来设置备份仓库路径 \npath.repo: [\u0026quot;/home/test/backup/zty_logstash\u0026quot;]\n```\n\n### 11、Query cache 和 Filter cache 的区别\nFilter cache 被重命名为 Node Query Cache，也就是说 Query cache 等同于 Filter cache；Query Cache 采用了 LRU 的缓存方式（当缓存满的时候，淘汰旧的不用的缓存数据），Query Cache 只缓存被用于 filter 上下文的内容。\n\n### 12、Shard 大小需要考虑的因素有哪些？\nLucene 底层没有这个大小的限制，20-40GB 的这个区间范围本身就比较大，经验值有时候就是拍脑袋，不一定都好使。\n- Elasticsearch 对数据的隔离和迁移是以分片为单位进行的，分片太大，会加大迁移成本；\n- 一个分片就是一个 Lucene 的库，一个 Lucene 目录里面包含很多 Segment，每个 Segment 有文档数的上限，Segment 内部的文档 ID 目前使用的是 Java 的整型，也就是 2 的 31 次方，所以能够表示的总的文档数为 Integer.MAX_VALUE - 128 = 2^31 - 128 = 2147483647 - 1 = 2,147,483,519，也就是21.4亿条；\n- 同样，如果你不 force merge 成一个 Segment，单个 shard 的文档数能超过这个数；\n- 单个 Lucene 越大，索引会越大，查询的操作成本自然要越高，IO 压力越大，自然会影响查询体验；\n- 具体一个分片多少数据合适，还是需要结合实际的业务数据和实际的查询来进行测试以进行评估。\n\n### 13、ES 索引更新时通过 mapping 限制指定字段更新\nElasticsearch 默认是 Dynamic Mapping，新字段会自动猜测数据类型，并自动 merge 到之前的 Mapping，你可以在 Mapping 里面可以配置字段是否支持动态加入，设置参数dynamic即可：true，默认，表示支持动态加入新字段；false，表示忽略该字段的后续索引等操作，但是索引还是成功的；strict支持不支持未知字段，直接抛错。\n\n### 14、ES 数据快照到 HDFS\nES 做快照和使用 ES-Hadoop 导数据是完全的两种不同的方式，使用 ES-Hadoopp 后期导入的成本可能也不小。\n- 如果要恢复快，当然是做快照和还原的方式最快，速度完全取决于网络和磁盘的速度；\n- 如果为了节省磁盘，快照的时候，可以选 6.5 最新支持的 `source_only` 模式，导出的快照要小很多，不过恢复的时候要进行重建，速度慢。\n\n### 15、segment.memory 简介\nsegment 的大小，和 indexing buffer 有关，有三种方式会生成 segment：\n- 一种是 indexing buffer 写满了会生成 segment 文件，默认是堆内存的10%，是节点共享的；\n- 一种是 index buffer 有文档，但是还没满，但是 refresh 时间到了，这个时候就会把 buffer 里面的生成 segment 文件；\n- 还有最后一种就是 es 自动的会将小的 segment 文件定期合并产生新的 segment 文件。\n\n\n## 三、社区文章精选\n- [2018 年 Elastic Advent Calendar 分享活动](https://elasticsearch.cn/article/6149)\n- [使用 ES-Hadoop 将 Spark Streaming 流数据写入 ES](https://elasticsearch.cn/article/6318)\n- [Elastic Stack 6.5 最新功能](https://elasticsearch.cn/article/6209)\n- [让Elasticsearch飞起来!——性能优化实践干货](https://mp.weixin.qq.com/s/GQfEMb2jMvm9PEANkLl3Tg)\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](https://user-gold-cdn.xitu.io/2019/1/6/168231e1663bec4a?w=258\u0026amp;h=258\u0026amp;f=png\u0026amp;s=45449)","title":"ELK 使用小技巧（第 4 期）","uid":"8031","views":"281","votes":"2"},"_type":"doc"}
{"_id":"6320","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546844259","category_id":"18","comments":"0","has_attach":"0","id":"6320","message":"1. 苏宁大企业级立体式监控的构建\nhttp://t.cn/EG0z5BG\n\n2. Kibana 6.6 中的插件相关api更新\nhttp://t.cn/EG0ZPRA\n\n3.贝聊ELK实战\nhttp://t.cn/EG0Z8xN\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/publish/article/6320\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第502期 (2019-01-07)","uid":"4063","views":"223","votes":"0"},"_type":"doc"}
{"_id":"6315","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546481023","category_id":"18","comments":"0","has_attach":"0","id":"6315","message":"1.HotThreads源码分析\nhttp://t.cn/EbF0saD\n2.kubernetes 日志架构\nhttp://t.cn/EbFOLtD\n3.ee-outliers：用于检测Elasticsearch事件中的异常值的开源框架\nhttp://t.cn/EbxWUsD\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6315\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第498期 (2019-01-03)","uid":"668","views":"205","votes":"0"},"_type":"doc"}
{"_id":"6316","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546575873","category_id":"18","comments":"0","has_attach":"0","id":"6316","message":"1、Elasticsearch、MongoDB和Hadoop选型指南\nhttp://t.cn/EG7Knck\n2、使用ee-outliers和Elasticsearch检测可疑子进程\nhttp://t.cn/E4Q1lLF\n3、curator工具使用解读\nhttp://t.cn/EG79Pug\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6316\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第499期（2019-1-4）","uid":"1341","views":"214","votes":"0"},"_type":"doc"}
{"_id":"6312","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546135085","category_id":"18","comments":"0","has_attach":"0","id":"6312","message":"1.使用ElasticSearch进行全文检索。\nhttp://t.cn/Eb9Ahhr\n2.使用Flink和Kafka构建数据管道。\nhttp://t.cn/Eb92onY\n3.(自备梯子)Jupyter Notebook 扩展。\nhttp://t.cn/EyD8Ao5\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6312\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第494期 (2018-12-30)","uid":"4460","views":"190","votes":"0"},"_type":"doc"}
{"_id":"6220","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545628472","category_id":"18","comments":"1","has_attach":"0","id":"6220","message":"1.聊聊 ElasticSearch 使用场景\nhttp://t.cn/E4QEI6q\n2.让 Elasticsearch 飞起来：性能优化实践干货\nhttp://t.cn/E4Q3cbj\n3.Filebeat issue 排查  ： i/o timeout\nhttp://t.cn/E4Q3Bhz\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6220\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第488期 (2018-12-24)","uid":"4063","views":"172","votes":"0"},"_type":"doc"}
{"_id":"6209","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545194476","category_id":"5","comments":"0","has_attach":"1","id":"6209","message":"中文字幕视频介绍，不用翻墙：https://jwp.io/s/mm39Gki9\n\n[attach]3330[/attach]\n \n这里也有一个围绕这些特性的电台访谈节目：\nhttps://www.ximalaya.com/keji/14965410/139462151\n \n下载地址：\nhttps://www.elastic.co/downloads","title":"Elastic Stack 6.5 最新功能","uid":"1","views":"264","votes":"3"},"_type":"doc"}
{"_id":"6196","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544757126","category_id":"18","comments":"0","has_attach":"0","id":"6196","message":"1、Elasticsearch日志系统搭建\nhttp://t.cn/EyOugcQ\n2、Elasticsearch最佳实践之核心概念与原理\nhttp://t.cn/EUJa22D\n3、Elasticsearch和Hive比较\nhttp://t.cn/EUJaPGa\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6196\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第478期 (2018-12-14)","uid":"1341","views":"197","votes":"0"},"_type":"doc"}
{"_id":"6207","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545110841","category_id":"18","comments":"0","has_attach":"0","id":"6207","message":"1、Elasticsearch常用操作之集群管理篇。\nhttp://t.cn/EUFd8Yd\n​2、ElasticsearchSQL用法详解。\nhttp://t.cn/EUFdu9z\n​3、在滴滴云DC2云服务器上搭建ELK。\nhttp://t.cn/EUFdrKb\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6207\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第482期 (2018-12-18)","uid":"3788","views":"208","votes":"0"},"_type":"doc"}
{"_id":"6187","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544509370","category_id":"18","comments":"0","has_attach":"0","id":"6187","message":"1、当Elasticsearch遇见Kafka\nhttp://t.cn/EUwFsy6\n2、Elasticsearch检索 — 聚合和LBS\nhttp://t.cn/EU7qsRb\n3、有赞订单管理的三生三世与 “十面埋伏”\nhttp://t.cn/EU75ZTF\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6187\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第475期 (2018-12-11)","uid":"3788","views":"217","votes":"0"},"_type":"doc"}
{"_id":"6183","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544407387","category_id":"18","comments":"0","has_attach":"0","id":"6183","message":"1. 如何设置kibana的堆大小避免oom\nhttp://t.cn/Ey1omYc\n\n2. Es 另外一款web管理UI，包含导入，查看，编辑等功能\nhttp://t.cn/Ey1dKAj\n\n3. 使用elasticseach 搜索emoji表情\nhttp://t.cn/Rf5r848\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6183\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第474期 (2018-12-10)","uid":"4063","views":"190","votes":"0"},"_type":"doc"}
{"_id":"6156","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543152194","category_id":"44","comments":"0","has_attach":"1","id":"6156","message":"[attach]3187[/attach]\n\n欢迎来到 Elastic 社区电台的第八期节目，我们本期节目的嘉宾是来自于Elastic 在中国的首席架构师吴斌， Elastic 在本月11月14日发布了一个全新的版本 6.5，放出了一系列精彩的特性，本次节目我们就这些最近发布的新特性做一个简单的解读。\n\n## 收听地址\n[https://www.ximalaya.com/keji/14965410/139462151](https://www.ximalaya.com/keji/14965410/139462151)\n\n## 嘉宾\n\n吴斌，十年 IT 行业经验，经历了软件工程师到架构师的全方位磨练。专注于海量数据处理、挖掘、分析和企业级搜索等领域。 现任 Elastic 架构师，负责公司亚太地区事务。致力于应用 Elastic 的先进技术产品解决企业数据应用问题。\n\n\n## 主持人\n\nElastic 技术布道师，曾勇（Medcl）。\n\n\n## 关于 Elastic 社区电台\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。","title":"访谈：Elastic Stack v6.5 新特性解读","uid":"1","views":"462","votes":"4"},"_type":"doc"}
{"_id":"6167","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543754400","category_id":"2","comments":"1","has_attach":"0","id":"6167","message":"互联网时代，十亿、百亿、千亿的数据日志呈井喷式增长，基于日志搜索分析的需求也越来越强烈。Elasticsearch 作为一个分布式、可扩展、实时的搜索与数据分析引擎， 在大体量的数据处理上，无论实在全文搜索，还是在结构化数据统计中，都有非常大的优势。然而在真正实践过程中海量数据如何高效采集，如何合理优化分配索引，如何规划集群，如何满足业务分析需求都是我们可能会面临的问题。\n\n本次袋鼠云联合阿里云、Elastic 中文社区，共同邀请滴滴、有赞等行业技术专家一同分享和探讨各自领域Elastic的实践。\n \n本次活动[b]时间[/b]为[b]12月15日 周六[/b]，[b]人数限制100人[/b]，大家抓紧报名哈，报名链接https://meetup.elasticsearch.cn/event/hangzhou/1001.html。\n\n参与线下互动还有机会获得技术书籍与精美礼品哦！！！\n不出意外，这应该是2018年Elastic在杭州的最后一次沙龙，小伙伴们抓紧今年的尾巴，不放过任何学习的机会哦！！！","title":"【 报名开启】2018 Elastic \u0026amp; 袋鼠云 \u0026amp; 阿里云技术沙龙（杭州）","uid":"10533","views":"764","votes":"6"},"_type":"doc"}
{"_id":"6168","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543799502","category_id":"14","comments":"1","has_attach":"0","id":"6168","message":"## 介绍\n\n大家好，我是vvv，这个名字和王者荣耀AG超玩会中的vv没有一毛钱关系，随意取的一个的名字，后来发现貌似不能改了。做过一些数据产品，正是这段时间里开始接触elasticstack，对kibana做过一些二次开发。今天主要想写一些开发过程中的一些tips，希望可以给大家带来一些帮助。\n\n\n## 技术栈分析\n\n既然我们的主题是kibana，我们先来看下kibana的主要技术栈。很早开始kibana就开始基于nodejs （hapi框架） + angular（1.x）来进行开发，后来引入了react。kibana本身的代码也经过了多次重构剥离。现在的kibana的代码结构更加清晰\n\n\n## 前提\nelasticstack发展迅速，现在已经是6.5版本了。我们今天要介绍的是6.x系列的版本，6.x各个版本会有一些细微差异，但大致一样\n\n\n## tips\n\n官方提供kibana下载版本主要是编译后的release版本。如果要基于kibana做二次开发，我们需要去https://github.com/elastic/kibana 上面下载对应的分支。官方有相应的文档去说明如何安装开发环境。我这里有一些tips：\n\n\u0026gt; 设置国内yarn源\n\n```\nyarn config --global set 'registry https://registry.npm.taobao.org'\n```\n\n\u0026gt; 一些耗时需要编译的包可以全局安装\n\n```\nyarn global add  node-sass\n```\n\n\u0026gt; 多环境nodejs版本\n\n```\n不同kibana版本对nodejs版本要求也不一样，为了减少坑我们通常和官方要求的保持一致，如果你的电脑上需要运行多套不同版本的nodejs，那么你可能需要zsh + nvs, 会根据根目录的.node-version版本自动切换当前使用的node版本\n```\n\n\u0026gt; IDE推荐\n\n```\n推荐使用vscode，轻量免费，支持很多插件。可以安装个prettier插件，帮助对代码做更好的格式化\n```\n\n\u0026gt; debug\n\n如果你用的不是上面我推荐的vscode的话，请忽略这一条。对于使用vscode的同学，首先在vsocde的设置里面开启:\n\n```\n\u0026quot;autoAttach\u0026quot;: \u0026quot;on\u0026quot;\n```\n\n然后在vsocode里面打开一个终端，输入:\n\n```\nnode --inspect-brk scripts/kibana.js --dev --oss --no-base-path\n```\n这个时候vscode就会在启动kibana dev模式的同时attach一个进程进去用于断点调试，对于调试node层非常方便。也能帮助你更好的阅读kibana源码\n\n\u0026gt; 本地es\n\n我们知道kibana是长在es之上，想要运行kibana怎么少得了es。kibana又一些命令命令可以快速的启动一个es环境：\n\n下载并启动一个当前kibana需要的es版本\n```\nyarn es snapshot\n```\n\n灌入一些测试数据(如果需要定制灌入的数据可以看下这个脚本的帮助内容,加-h参数即可)\n```\nnode scripts/makelogs\n```\n\n\u0026gt; 编译\n\nkibana代码在release之前是要进行编译的。kibana提供了方便的命令行进行编译，甚至跨平台的交叉编译（生成不同平台的kibana release版本）。但是呢，有几个问题：\n\n1. kibana在编译的时候需要去aws上下载一些安装包，会导致正常情况下国内访问十分缓慢。（编译命令提供了几个参数可以关掉下载一些如nodejs等，但是还是很慢）\n2. build十分消耗cpu/gpu (mac的iterm2启动会做gpu优化)\n\n解决办法：\n\n1. 如果你能解决网络问题，而且有性能不错的编译机器。这都不是问题\n2. 如果你对kibana的代码更改都是无侵入的（比如只是写了一些插件扩展），那么你可以去官方下载他们的snapshot版本\n3. 当然，如果你用的kibana版本就是release版本并且你的扩展都是插件，那么你直接用官方的release版本就好了\n\n\u0026gt; 库的选型\n\n1. server端：\nnodejs具有十分丰富的生态，你可以找到很多nodejs相关的库。kibana本身的后端web框架是基于node的hapi的。hapi是一个沃尔玛团队维护的企业级框架，其本身也有很多扩展。当你需要对web框架做一些扩展的时候，可以优先想到去hapi官方看下\n\n2. ui端:\nkibana有一套漂亮的ui，其本身也是单独剥离成了一个库，方便引入使用。当然你也可以引入一些其他的前端库来满足你的具体业务需求。推荐尽量使用原生的eui和kibana源码里面的一些封装。这样让你的引入更少，更容易维护。\n\n\n\u0026gt; 国际化\n\n国际化是kibana很早就开始立的一个项。这块的进度也是越来越快。新版的kibana里面用@kbn/i18n这个package来统一javascript，html, nodejs做国际化的事情（具体大家可以看下这个package的readme）。国际化这块有一些建议:\n1. 扩展插件的时候养成国际化的习惯\n2. 默认的语系不建议再次设置成一个json文件。因为最新的@kbn/i18n会提供一个默认的文本，用于默认情况下展示。所以我们是没必要重复去维护一个默认的语言翻译json\n3. 假设你的默认语言是英文（和kibana一致），只有当你想要替换kibana默认翻译的时候，才去覆写en.json\n4. 当你对原生kibana有国际化这种需求的时候，建议独立出一个i18n翻译的插件去维护各个语言翻译相关的东西\n5. 目前kibana的国际化还未100%，如果你想知道目前哪些文本内容是支持国际化的。可以尝试如下脚本:\n\n```\nnode scripts/extract_default_translations \\\n --path src/core_plugins/kibana \\\n --output /tmp\n```\n6. 各个插件的之间的翻译文件独立，即使是相同的翻译内容。插件文本内容养成预留国际化的习惯\n\n\n\n## 总结\n\n上面列举了一些我平时的一些经验。时间篇幅有限，未能一一列举。希望可以帮到大家吧。也希望可以和大家多多交流","title":"Day 3 - kibana二次开发tips","uid":"1270","views":"670","votes":"2"},"_type":"doc"}
{"_id":"6173","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543981114","category_id":"18","comments":"0","has_attach":"0","id":"6173","message":"1. Elasticsearch写入原理深入详解\nhttp://t.cn/EyI2jxr\n2.Lucene倒排索引简述 细说倒排索引构建\nhttp://t.cn/EyI2eMN\n3. 知乎如何基于开源Druid打造下一代数据平台\nhttp://t.cn/E2Kmzj0\n \n编辑：江水\n归档：https://elasticsearch.cn/article/6173\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第469期 (2018-12-05)","uid":"3828","views":"247","votes":"0"},"_type":"doc"}
{"_id":"6150","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542769961","category_id":"18","comments":"0","has_attach":"0","id":"6150","message":"1. 海量数据搜索 搜索引擎\nhttp://t.cn/E2HKuxt\n2. Elasticsearch常见的5个错误及解决策略\nhttp://t.cn/E2H9bKw\n3. Elasticsearch 原理分析\nhttp://t.cn/ReCN93k\n \n编辑：江水\n归档：https://elasticsearch.cn/article/6150\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第455期 (2018-11-21)","uid":"3828","views":"206","votes":"0"},"_type":"doc"}
{"_id":"6143","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542510437","category_id":"18","comments":"0","has_attach":"0","id":"6143","message":"1.ElasticSearch嵌套搜索：如何搜索嵌入的文档。\nhttp://t.cn/E2tAGhG\n2.Spark ElasticSearch Hadoop更新和Upsert示例和说明。\nhttp://t.cn/E2t2yg2\n3.(自备梯子)我的数据科学恐怖故事。\nhttp://t.cn/E2t2FrI\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6143\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第452期 (2018-11-18)","uid":"4460","views":"190","votes":"0"},"_type":"doc"}
{"_id":"6138","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542346062","category_id":"18","comments":"0","has_attach":"0","id":"6138","message":"1、喜大普奔！Elastic6.5发布\nhttp://t.cn/E2PPJH2\n2、Elastic开启了大数据应用新时代\nhttp://t.cn/E2PPCmn\n3、图解elasticsearch原理\nhttp://t.cn/E2PPThd\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6138\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第450期 (2018-11-16)","uid":"1341","views":"192","votes":"0"},"_type":"doc"}
{"_id":"6124","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541683512","category_id":"18","comments":"0","has_attach":"0","id":"6124","message":"1、Elasticsearch运维宝典——监控实战篇\nhttp://t.cn/EAwlTOI\n2、mysql同步elasticsearch调研对比\nhttp://t.cn/EAwlE6w\n3、Elastic 搜索奖，表彰那些将 Elasticsearch 用于改造业务\nhttp://t.cn/EZFFN7C\n\n编辑：铭毅天下\n归档: https://elasticsearch.cn/article/6124\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第442期 (2018-11-08)","uid":"1341","views":"234","votes":"0"},"_type":"doc"}
{"_id":"6121","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541409891","category_id":"18","comments":"0","has_attach":"0","id":"6121","message":"1.elasticsearch 从 5.5.0升级到6.1版本的经历\nhttp://t.cn/Ew8p7PD\n2.你应该了解的5个logstash插件\nhttp://t.cn/RrEiE3j\n3.高效管理基于时间的索引\nhttp://t.cn/REFMMZM\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6121\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第439期 (2018-11-05)","uid":"4063","views":"224","votes":"0"},"_type":"doc"}
{"_id":"66","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459332454","category_id":"2","comments":"0","has_attach":"0","id":"66","message":"[b]ElasticSearch的很多功能都是官方或第三方基于ElasticSearch的AbstractPlugin类实现的插件来提供的，所以，在里里记录下一些常用的及实用的插件地址，以备不时之需[/b]\n\n分词插件\n\nCombo Analysis Plugin (作者 Olivier Favre, Yakaz)\n\n简介：组合分词器，可以把多个分词器的结果组合在一起。\n\nSmart Chinese Analysis Plugin (作者 elasticsearch 团队)\n\n简介：lucene默认的中文分词器\n\nICU Analysis plugin (作者 elasticsearch 团队)\n\n简介：lucene自带的ICU分词，ICU是一套稳定、成熟、功能强大、轻便易用和跨平台支持Unicode 的开发包。\n\nStempel (Polish) Analysis plugin (作者 elasticsearch 团队)\n\n简介：法文分词器\n\nIK Analysis Plugin (作者 Medcl)\n\n简介：大名鼎鼎的ik分词，都懂的！\n\nMmseg Analysis Plugin (作者 Medcl)\n\n简介：mmseg中文分词\n\nHunspell Analysis Plugin (作者 Jörg Prante)\n\n简介：lucene自带的Hunspell模块\n\nJapanese (Kuromoji) Analysis plugin (作者 elasticsearch 团队).\n\n简介：日文分词器\n\nJapanese Analysis plugin (作者 suguru).\n\n简介：日文分词器\n\nRussian and English Morphological Analysis Plugin (作者 Igor Motov)\n\n简介：俄文英文分词器\n\nPinyin Analysis Plugin (作者 Medcl)\n\n简介：拼音分词器\n\nString2Integer Analysis Plugin (作者 Medcl)\n\n简介：字符串转整型工具。主要用在facet这个功能上，如果facet的field的值是字符串的话，计算起来比较耗资源。可以把字符串映射成整型，对整型进行facet操作要比对字符串的快很多。\n\n同步插件\n\nCouchDB River Plugin (作者 elasticsearch 团队)\n\n简介：CouchDB和elasticsearch的同步插件\n\nWikipedia River Plugin (作者 elasticsearch 团队)\n\n简介：wikipedia文件读取插件。wikipedia是维基百科的一个离线库，不定期发布最新数据，是以xml形式发布的。这个river读取这个文件来建索引。\n\nTwitter River Plugin (作者 elasticsearch 团队)\n\n简介：twitter的同步插件，可以同步你twitter上的微博。\n\nRabbitMQ River Plugin (作者 elasticsearch 团队)\n\n简介：rabbitmq同步插件，读取rabbitmq上的队列信息并索引。\n\nRSS River Plugin (作者 David Pilato)\n\n简介：定期索引指定一个或多个RSS源的数据。\n\nMongoDB River Plugin (作者 Richard Louapre)\n\n简介：mongodb同步插件，mongodb必须搭成副本集的模式，因为这个插件的原理是通过定期读取mongodb中的oplog来同步数据。\n\nOpen Archives Initiative (OAI) River Plugin (作者 Jörg Prante)\n\n简介：可以索引oai数据提供者提供的数据。\n\nSofa River Plugin (作者 adamlofts)\n\n简介：这个插件可以把多个CouchDB的数据库同步到同一个es索引中。\n\nJDBC River Plugin (作者 Jörg Prante)\n\n简介：关系型数据库的同步插件\n\nFileSystem River Plugin (作者 David Pilato)\n\n简介：本地文件系统文件同步插件，使用方法是指定一个本地目录路径，es会定期扫描索引该目录下的文件。\n\nLDAP River Plugin (作者 Tanguy Leroux)\n\n简介：索引LDAP目录下的文件数据。\n\nDropbox River Plugin (作者 David Pilato)\n\n简介：索引dropbox网盘上的文件。通过oauth协议来调用dropbox上的api建索引。\n\nActiveMQ River Plugin (作者 Dominik Dorn)\n\n简介：activemq队列的同步插件，和之前rabbitmq的类似\n\nSolr River Plugin (作者 Luca Cavanna)\n\n简介：solr同步插件，可以把solr里面的索引同步到es\n\nCSV River Plugin (作者 Martin Bednar)\n\n简介：通过指定目录地址来索引csv文件。\n\n数据传输插件\n\nServlet transport (作者 elasticsearch 团队)\n\n简介：Servlet rest插件，通过servlet来封装rest接口。\n\nMemcached transport plugin (作者 elasticsearch 团队)\n\n简介：本插件可以通过memcached协议进行rest接口的调用。注意：这里不是使用memcache作为es的缓存。\n\nThrift Transport (作者 elasticsearch 团队)\n\n简介：使用thrift进行数据传输。\n\nZeroMQ transport layer plugin (作者 Tanguy Leroux)\n\n简介：使用zeromq进rest接口的调用。\n\nJetty HTTP transport plugin (作者 Sonian Inc.)\n\n简介：使用jetty来提供http rest接口。默认是使用netty。这个插件的好处是可以对http接口进行一些权限的设置。\n\n脚本插件\n\nPython language Plugin (作者 elasticsearch 团队)\n\n简介：python脚本支持\n\nJavaScript language Plugin (作者 elasticsearch 团队)\n\n简介：javascript脚本支持\n\nGroovy lang Plugin (作者 elasticsearch 团队)\n\n简介：groovy脚本支持\n\nClojure Language Plugin (作者 Kevin Downey)\n\n简介：clojure脚本支持\n\n站点插件（以网页形式展现）\n\nBigDesk Plugin (作者 Lukáš Vlček)\n\n简介：监控es状态的插件，推荐！\n\nElasticsearch Head Plugin (作者 Ben Birch)\n\n简介：很方便对es进行各种操作的客户端。\n\nParamedic Plugin (作者 Karel Minařík)\n\n简介：es监控插件\n\nSegmentSpy Plugin (作者 Zachary Tong)\n\n简介：查看es索引segment状态的插件\n\nInquisitor Plugin (作者 Zachary Tong)\n\n简介：这个插件主要用来调试你的查询。\n\n其它插件\n\nMapper Attachments Type plugin (作者 elasticsearch 团队)\n\n简介：附件类型插件，通过tika库把各种类型的文件格式解析成字符串。\n\nHadoop Plugin (作者 elasticsearch team)\n\n简介：hadoop和elasticsearch的集成插件，可以通过hadoop的mapreduce算法来并行建立索引，同时支持cascading，hive和pig等框架。\n\nAWS Cloud Plugin (作者 elasticsearch 团队)\n\n简介：elasticsearch与amazon web services的集成。\n\nElasticSearch Mock Solr Plugin (作者 Matt Weber)\n\n简介：elasticsearch的solr api接口。用了这个插件可以使用solr的api来调用es，直接用solrj就可以调用es。比较适用于从solr转es时暂时过度。\n\nSuggester Plugin (作者 Alexander Reelsen)\n\n简介：es 搜索提示功能插件，不过es0.9版本后自带了这个功能，\n\nElasticSearch PartialUpdate Plugin (作者 Medcl)\n\n简介：elasticsearch的部分更新插件。\n\nZooKeeper Discovery Plugin (作者 Sonian Inc.)\n\n简介：通过zookeeper管理集群的插件。通过这个插件，es的分布式架构和solrcloud相似。\n\nElasticSearch Changes Plugin (作者 Thomas Peuss)\n\n简介：elasticsearch索引操作记录插件。通过这个插件可以查看用户对索引的增删改操作。\n\nElasticSearch View Plugin (作者 Tanguy Leroux)\n\n简介：这个插件可以把es的文档以html，xml或text的方式显示出来，它也可以通过查询生成web页面。\n\nElasticSearch New Relic Plugin (作者 Vinicius Carvalho)\n\n简介：elasticsearch和newrelic的集成插件。newrelica是一个性能监控工具。这个插件会把节点的状态数据传到newrelic的账号上。\n[b]社区的编辑器好像不支持复制富文本信息，所以插件都没有链接，插件太多懒得一个个打链接了，想点地址的可以移步寒舍[url]http://www.kailing.pub/article/index/arcid/87.html[/url][/b]\n ","title":"ElasticSearch插件集","uid":"1032","views":"6333","votes":"1"},"_type":"doc"}
{"_id":"71","_index":"forum-mysql","_score":1,"_source":{"addtime":"1460950960","category_id":"2","comments":"3","has_attach":"1","id":"71","message":"从2015年后，大数据被认为是驱动企业变革的推动剂，为经济创新带来新的增量。ElasticSearch（下文简称ES）是当前流行的企业级搜索引擎，它提供了一个分布式多用户能力的全文搜索引擎。简言之，大数据时代ES能够提供简单易用的方式帮助企业从大型数据库中快速提取有效信息进行分析。\n\n2016年首届ES中文社区全国巡回技术沙龙在北京、上海、广州三地召开。ES中文社区携手数说故事共同主办 ElasticSearch技术沙龙-广州站，诚邀您参加交流。\n\n4月23日14:00 - 17:30，广州筑梦咖啡，我们不见不散。\n\n\n[b]沙龙详情：[/b]\n\n1、主办方：\n    \n ElasticSearch中文社区    数说故事\n\n[attach]150[/attach]\n\n2、时间与地点：\n\n\n4月23日14:00 - 17:30（周六）\n\n广州筑梦咖啡（广州天河区黄埔大道中309号羊城创意产业园(近骏景花园)\n\n[attach]154[/attach]\n\n\n[b]沙龙主题：[/b]\n\nElasticSearch技术沙龙—企业级搜索引擎实战与案例分享\n\n \n[b]分享一：你不得不知道的ES的使用经验及优化技巧[/b]\n\n\n[attach]153[/attach]\n\n赖鸿智\n\n欢聚时代搜索工程师，负责欢聚时代搜索服务\n\n主题简介：\n\nES使用中掉过的坑以及优化技巧，主要包括：搜索平台的架构，实时大数据分析平台的架构。\n\n \n\n[b]分享二： 基于父子文档实现的ES关联查询[/b]\n\n\n[attach]151[/attach]\n\n\n黄耀鸿\n\n数说故事技术总监，多年大数据开发经验\n\n主题简介：\n\n为你解答在千万级用户和发布的亿级文章内容中，如何利用父子文档，通过一对多的关联查询，实现对内容搜索，对用户分析的场景。\n\n[b] \n\n分享三：ES实战现场:亿级规模的ES查询优化实战[/b]\n\n\n[attach]152[/attach]\n\n                                                                                              何金城\n\n塔布高级数据项目经理\n\n主题简介：\n\n在传统家电企业的DMP系统实施实战中ES的一些使用情况及查询优化实践。\n\n\n[b]活动流程：[/b]\n\n14:00-14:30  签到及入场\n14:30-14:40  主持人介绍活动\n14:40-15:20  赖鸿智    Elasticsearch的一些使用经验及优化技巧\n15:20-16:00  黄耀鸿    基于父子文档实现的ES关联查询\n16:00-16:40  何金城    亿级规模的ES查询优化实战\n16:40-17:10  提问交流   可获精美礼品\n17:10-17:30  自由沟通\n\n\n[b]哪些惊喜：[/b]\n\n企业级搜索引擎全程干货的分享\n\n免费领取由ElasticSearch中文社区提供的限量版礼品\n\n有机会参观大数据公司【数说故事】，近距离了解大数据工作流程\n\n\n[b]报名方式：[/b]\n\n[b]本次活动全程免费，欢迎报名[/b]\n \n[b][url=http://t.cn/RqX5yll]报名入口：活动行[/url][/b]\n\n活动联系：\n联系人：陈小姐\n手机：13660037521\n邮箱：625802461@qq.com\n\n\n更多活动详情扫描二维码关注数说故事\n\n[attach]155[/attach]\n\n（公众号：datastory2015）      ","title":"首届ES中文社区技术沙龙【广州站】—企业级搜索引擎与大数据实战分享","uid":"1103","views":"4054","votes":"7"},"_type":"doc"}
{"_id":"72","_index":"forum-mysql","_score":1,"_source":{"addtime":"1461051910","category_id":"2","comments":"0","has_attach":"0","id":"72","message":"input{\n    redis{\n        host =\u0026gt; \u0026quot;192.168.80.50\u0026quot;\n        port =\u0026gt; 6379\n        password =\u0026gt; \u0026quot;xxx\u0026quot;\n        data_type =\u0026gt; \u0026quot;list\u0026quot;\n        key =\u0026gt; \u0026quot;logstash-ljk-screen\u0026quot;\n        codec =\u0026gt; json\n        type=\u0026gt;\u0026quot;ljkscreen\u0026quot;\n    }\n    redis{\n        host =\u0026gt; \u0026quot;192.168.80.50\u0026quot;\n        port =\u0026gt; 6379\n        password =\u0026gt; \u0026quot;xxx\u0026quot;\n        data_type =\u0026gt; \u0026quot;list\u0026quot;\n        key =\u0026gt; \u0026quot;logstash-kg-media\u0026quot;\n        codec =\u0026gt; json\n                type=\u0026gt;\u0026quot;kgmedia\u0026quot;\n                \n    }\n}","title":"elasticsearch读取多个redis值","uid":"1087","views":"2797","votes":"0"},"_type":"doc"}
{"_id":"77","_index":"forum-mysql","_score":1,"_source":{"addtime":"1462936127","category_id":"1","comments":"0","has_attach":"1","id":"77","message":"1、主办方：\n    \n\n      ElasticSearch中文社区    奇点机智\n\n[attach]165[/attach]\n\n\n\n2、时间与地点：\n\n\n      5月15日14:00 - 17:30（周日）\n\n     北京海淀区中关村鼎好电子大厦太库孵化器路演厅\n\n\n[attach]171[/attach]\n\n \n\n沙龙主题：\n\n\n分享一：5miles基于es的对外搜索业务实践 \n\n[attach]166[/attach]\n\n王浩宇\n\n5miles搜索工程师\n\n主题简介：\n\n和大家交流一些5miles对外搜索业务中的工作，例如基于es function_score 的rerank的实现，通过geohash减少请求，通过多个data center来实现请求异步，风险控制等\n\n \n\n分享二： Elasticsearch与Spark的整合\n\n[attach]168[/attach]\n\n\n祝威廉\n\n多年大数据经验，现专注于Spark/ES 相关领域\n\n主题简介：\n\n个人对ElasticSearch 和 Spark的整合一些看法，简要介绍通过对elasticsearch-hadoop项目的改进，以Spark 和 ElasticSearch 为依托，构建一个Ad-Hoc 查询引擎。\n\n \n\n分享三：ElasticStack 5.0 介绍\n\n\n[attach]167[/attach]\n\n\nmedcl\n\nDeveloper@Elastic\n\n主题简介：\n\nElasticStack 5.0的新特性介绍\n\n\n \n\n活动流程：\n\n\n13:00-13:45  签到及入场\n\n13:45-14:00  主持人介绍活动\n\n14:00-15:00  王浩宇    5miles基于es的对外搜索业务实践\n\n15:00-16:00  祝威廉    ElasticSearch 与 Spark 的整合 \n\n16:00-16:30  茶歇与自由沟通\n\n16:30-17:30  medcl   ElasticStack 5.0 介绍\n\n\n[attach]169[/attach]\n\n\n\n报名方式：\n\n本次活动全程免费，欢迎报名\n[url]http://www.huodongxing.com/event/6334153926600#rd[/url]\n\n\n活动联系：\n联系人：凌霄\n手机：18600209779\n邮箱：hellolingxiao@gmail.com\n\n\n\n[attach]172[/attach]\n想要加入Elastic北京微信群，扫描上方二维码加小助手拉你进群\n\n[attach]170[/attach]\n\n\n\n\n\n ","title":"北京 Elastic社区第一次线下活动","uid":"1035","views":"2837","votes":"0"},"_type":"doc"}
{"_id":"81","_index":"forum-mysql","_score":1,"_source":{"addtime":"1464266716","category_id":"1","comments":"0","has_attach":"1","id":"81","message":"1. 主办方\nElastic中文社区  趋势科技\n[attach]225[/attach]\n\n2. 时间地点\n 活动时间：2016年6月25日 14:00 - 17:30 \n 活动地点：雨花区软件大道48号苏豪国际广场B座（靠花神庙地铁站）\n[attach]202[/attach]\n\n3. 主题 \n[b]分享一：ES和Kibana在实时流量分析中的应用[/b]\n演讲者简介：\n杨润达​ 南京云利来软件科技有限公司研发部\n \n主题简介：\n流量的抓取和存储，流量的可视化，有关流量异常的案例分析，在线的kibana功能展示。\n \n[b]分享二：ELK平台SaaS化的问题和解决方案[/b]\n演讲者简介：\n[attach]211[/attach] \n王晓亮（Tomo Wang） 瀚思安信高级研发工程师\n毕业于南京大学，曾就职于趋势科技、Opera，现任瀚思安信高级研发工程师，负责瀚思在线安全分析平台“安全易”的研发工作。\n \n主题简介：\nELK（ElasticSearch，Logstash，Kibana）是一套有效的开源日志分析平台，它们作为工具使用非常便利，但是如果要围绕它们搭建在线服务，却有诸多问题。这次的分享主要介绍“安全易”在SaaS化ELK平台的过程中遇到的问题以及对应的技术方案。\n \n[b]分享三：ES在苏宁海量日志平台的实践[/b]\n演讲者简介：\n[attach]212[/attach]\n彭燕卿 苏宁云商IT总部监控研发中心技术副总监\n9年软件研发经验，09年加入苏宁,先后从事了SOA系统开发、苏宁易购等大型网站的性能分析调优、监控平台等系统研发和架构工作，目前主要从事苏宁监控系统架构及技术管理工作，专注于APM以及Elasticsearch等实时计算领域。\n \n主题简介：\n实时日志平台ES架构演变，ES使用过程中遇到的坑及调优，Kibana二次开发等。\n \n[b]分享四：甲方安全看日志消息在ELK中的流转​[/b]\n演讲者简介：\n李天爽 闻心科技上海研发中心总监\n毕业于南京大学，曾担任趋势科技高级工程师，携程信息安全部资深安全研发工程师。\n \n主题简介：\n分享携程的日志平台架构、安全事件在ELK中的生命周期、ES的权限方案等。\n \n[b]分享五：ES在移动病毒分析和检测中的应用[/b]\n演讲者简介：\n[attach]213[/attach]\n李啸（White Li） 趋势科技中国研发中心资深工程师\n毕业于南京邮电大学，曾就职于小米、百度，专注于大规模分布式系统的架构和运维，现负责趋势科技移动安全专家系统的开发工作。\n \n主题简介：\n介绍ES在样本分析、检测系统中的应用和逐步演变，重点探讨碰到的问题和解决方案。\n \n4. 主题slides\n\n[url=http://yun.baidu.com/s/1boARr6R#dir/path=/ES南京meetup/slides]ES南京meetup资料[/url]\n\n\n ","title":"南京Elastic社区第一次线下活动","uid":"1264","views":"6086","votes":"2"},"_type":"doc"}
{"_id":"86","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466737921","category_id":"15","comments":"0","has_attach":"0","id":"86","message":"[code]Lucene的索引结构是有层次结构的，主要分以下几个层次：\n\n\n\n索引(Index)：\n在Lucene中一个索引是放在一个文件夹中的。\n如上图，同一文件夹中的所有的文件构成一个Lucene索引。\n段(Segment)：\n一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并。\n如上图，具有相同前缀文件的属同一个段，图中共三个段 \u0026quot;_0\u0026quot; 和 \u0026quot;_1\u0026quot;和“_2”。\nsegments.gen和segments_X是段的元数据文件，也即它们保存了段的属性信息。\n文档(Document)：\n文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档。\n新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中。\n域(Field)：\n一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里。\n不同域的索引方式可以不同，在真正解析域的存储的时候，我们会详细解读。\n词(Term)：\n词是索引的最小单位，是经过词法分析和语言处理后的字符串。\n 更多对应的文件后缀\n\n名称\n文件拓展名\n描述\n段文件\nsegments_N\t保存了索引包含的多少段，每个段包含多少文档。\n段元数据\n.si\t保存了索引段的元数据信息\n锁文件 \nwrite.lock\t防止多个IndexWriter同时写到一份索引文件中。\n复合索引文件\n.cfs, .cfe\t把所有索引信息都存储到复合索引文件中。\n索引段的域信息\n.fnm\n保存此段包含的域，以及域的名称和域的索引类型。\n索引段的文档信息\n.fdx, .fdt\n保存此段包含的文档，每篇文档中包含的域以及每个域的信息。\n\n索引段Term信息\n.tim, .tip\n.tim文件中存储着每个域中Term的统计信息且保存着指向.doc, .pos, and .pay 索引文件的指针。\n\n.tip文件保存着Term 字典的索引信息，可支持随机访问。\n\n文档中Term词频和跳表信息\n.doc\n保存此段中每个文档对应的Term频率信息。\n文档中Term的位置信息\n.pos\n保存此段中每个文档对应的Term位置信息。\n文档的有效载荷和部分位置信息\n.pay\n保存此段中每个文档的有效载体(payload) 和 Term的位置信息(offsets)。 其中有一部分的Term位置信息存储在.pos文件中。\n索引字段加权因子\n.nvd, .nvm\t\n.nvm 文件保存索引字段加权因子的元数据\n\n.nvd 文件保存索引字段加权数据\n\n索引文档加权因子\n.dvd, .dvm\n.dvm 文件保存索引文档加权因子的元数据\n\n.dvd 文件保存索引文档加权数据\n\n索引矢量数据\n.tvx, .tvd, .tvf\n.tvd 存储此段文档的Term、Term频率、位置信息、有效载荷等信息。\n\n.tvx 索引文件，用于把特定的文档加载到内存。\n\n.tvf 保存索引字段的矢量信息。\n\n有效文档\n.liv\n保存有效文档的索引文件信息\nLucene的索引结构中，即保存了正向信息，也保存了反向信息。\n\n所谓正向信息：\n\n按层次保存了从索引，一直到词的包含关系：索引(Index) –\u0026gt; 段(segment) –\u0026gt; 文档(Document) –\u0026gt; 域(Field) –\u0026gt; 词(Term)\n也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词。\n既然是层次结构，则每个层次都保存了本层次的信息以及下一层次的元信息，也即属性信息，比如一本介绍中国地理的书，应该首先介绍中国地理的概况， 以及中国包含多少个省，每个省介绍本省的基本概况及包含多少个市，每个市介绍本市的基本概况及包含多少个县，每个县具体介绍每个县的具体情况。\n如上图，包含正向信息的文件有：\nsegments_N保存了此索引包含多少个段，每个段包含多少篇文档。\nXXX.fnm保存了此段包含了多少个域，每个域的名称及索引方式。\nXXX.fdx，XXX.fdt保存了此段包含的所有文档，每篇文档包含了多少域，每个域保存了那些信息。\nXXX.tvx，XXX.tvd，XXX.tvf保存了此段包含多少文档，每篇文档包含了多少域，每个域包含了多少词，每个词的字符串，位置等信息。\n所谓反向信息：\n\n保存了词典到倒排表的映射：词(Term) –\u0026gt; 文档(Document)\n如上图，包含反向信息的文件有：\nXXX.tis，XXX.tii保存了词典(Term Dictionary)，也即此段包含的所有的词按字典顺序的排序。\nXXX.frq保存了倒排表，也即包含每个词的文档ID列表。\nXXX.prx保存了倒排表中每个词在包含此词的文档中的位置。\n在了解Lucene索引的详细结构之前，先看看Lucene索引中的基本数据类型。\n\n\n二、基本类型\n\nLucene索引文件中，用以下基本类型来保存信息：\n\nByte：是最基本的类型，长8位(bit)。\nUInt32：由4个Byte组成。\nUInt64：由8个Byte组成。\nVInt：\n变长的整数类型，它可能包含多个Byte，对于每个Byte的8位，其中后7位表示数值，最高1位表示是否还有另一个Byte，0表示没有，1表示有。\n越前面的Byte表示数值的低位，越后面的Byte表示数值的高位。\n例如130化为二进制为 1000, 0010，总共需要8位，一个Byte表示不了，因而需要两个Byte来表示，第一个Byte表示后7位，并且在最高位置1来表示后面还有一个Byte， 所以为(1) 0000010，第二个Byte表示第8位，并且最高位置0来表示后面没有其他的Byte了，所以为(0) 0000001。\n\n\n\n\nChars：是UTF-8编码的一系列Byte。\nString：一个字符串首先是一个VInt来表示此字符串包含的字符的个数，接着便是UTF-8编码的字符序列Chars。\n\n三、基本规则\n\nLucene为了使的信息的存储占用的空间更小，访问速度更快，采取了一些特殊的技巧，然而在看Lucene文件格式的时候，这些技巧却容易使我们感到困惑，所以有必要把这些特殊的技巧规则提取出来介绍一下。\n\n在下不才，胡乱给这些规则起了一些名字，是为了方便后面应用这些规则的时候能够简单，不妥之处请大家谅解。\n\n1. 前缀后缀规则(PREFIX+SUFFIX)\n\nLucene在反向索引中，要保存词典(Term Dictionary)的信息，所有的词(Term)在词典中是按照字典顺序进行排列的，然而词典中包含了文档中的几乎所有的词，并且有的词还是非常的长 的，这样索引文件会非常的大，所谓前缀后缀规则，即当某个词和前一个词有共同的前缀的时候，后面的词仅仅保存前缀在词中的偏移(offset)，以及除前 缀以外的字符串(称为后缀)。\n\n[图]前缀后缀规则\n\n\n\n比如要存储如下词:term，termagancy，termagant，terminal，\n\n如果按照正常方式来存储，需要的空间如下：\n\n[VInt = 4] [t][e][r][m]，[VInt = 10][t][e][r][m][a][g][a][n][c][y]，[VInt = 9][t][e][r][m][a][g][a][n][t]，[VInt = 8][t][e][r][m][i][n][a][l]\n\n共需要35个Byte.\n\n如果应用前缀后缀规则，需要的空间如下：\n\n[VInt = 4] [t][e][r][m]，[VInt = 4 (offset)][VInt = 6][a][g][a][n][c][y]，[VInt = 8 (offset)][VInt = 1][t]，[VInt = 4(offset)][VInt = 4][i][n][a][l]\n\n共需要22个Byte。\n\n大大缩小了存储空间，尤其是在按字典顺序排序的情况下，前缀的重合率大大提高。\n\n2. 差值规则(DELTA)\n\n在Lucene的反向索引中，需要保存很多整型数字的信息，比如文档ID号，比如词(Term)在文档中的位置等等。\n\n由上面介绍，我们知道，整型数字是以VInt的格式存储的。随着数值的增大，每个数字占用的Byte的个数也逐渐的增多。所谓差值规则(Delta)就是先后保存两个整数的时候，后面的整数仅仅保存和前面整数的差即可。\n\n[图]差值规则\n\n\n\n比如要存储如下整数：16386，16387，16388，16389\n\n如果按照正常方式来存储，需要的空间如下：\n\n[(1) 000, 0010][(1) 000, 0000][(0) 000, 0001]，[(1) 000, 0011][(1) 000, 0000][(0) 000, 0001]，[(1) 000, 0100][(1) 000, 0000][(0) 000, 0001]，[(1) 000, 0101][(1) 000, 0000][(0) 000, 0001]\n\n供需12个Byte。\n\n如果应用差值规则来存储，需要的空间如下：\n\n[(1) 000, 0010][(1) 000, 0000][(0) 000, 0001]，[(0) 000, 0001]，[(0) 000, 0001]，[(0) 000, 0001]\n\n共需6个Byte。\n\n大大缩小了存储空间，而且无论是文档ID，还是词在文档中的位置，都是按从小到大的顺序，逐渐增大的。\n\n3. 或然跟随规则(A, B?)\n\nLucene的索引结构中存在这样的情况，某个值A后面可能存在某个值B，也可能不存在，需要一个标志来表示后面是否跟随着B。\n\n一般的情况下，在A后面放置一个Byte，为0则后面不存在B，为1则后面存在B，或者0则后面存在B，1则后面不存在B。\n\n但这样要浪费一个Byte的空间，其实一个Bit就可以了。\n\n在Lucene中，采取以下的方式：A的值左移一位，空出最后一位，作为标志位，来表示后面是否跟随B，所以在这种情况下，A/2是真正的A原来的值。\n\n\n\n\n\n如果去读Apache Lucene - Index File Formats这篇文章，会发现很多符合这种规则的：\n\n.frq文件中的DocDelta[, Freq?]，DocSkip,PayloadLength?\n.prx文件中的PositionDelta,Payload? (但不完全是，如下表分析)\n当然还有一些带?的但不属于此规则的：\n\n.frq文件中的SkipChildLevelPointer?，是多层跳跃表中，指向下一层表的指针，当然如果是最后一层，此值就不存在，也不需要标志。\n.tvf文件中的Positions?, Offsets?。\n在此类情况下，带?的值是否存在，并不取决于前面的值的最后一位。\n而是取决于Lucene的某项配置，当然这些配置也是保存在Lucene索引文件中的。\n如Position和Offset是否存储，取决于.fnm文件中对于每个域的配置(TermVector.WITH_POSITIONS和TermVector.WITH_OFFSETS)\n为什么会存在以上两种情况，其实是可以理解的：\n\n对于符合或然跟随规则的，是因为对于每一个A，B是否存在都不相同，当这种情况大量存在的时候，从一个Byte到一个Bit如此8倍的空间节约还是很值得的。\n对于不符合或然跟随规则的，是因为某个值的是否存在的配置对于整个域(Field)甚至整个索引都是有效的，而非每次的情况都不相同，因而可以统一存放一个标志。\n文章中对如下格式的描述令人困惑：\nPositions --\u0026gt;  Freq\nPayload --\u0026gt;\nPositionDelta和Payload是否适用或然跟随规则呢？如何标识PayloadLength是否存在呢？\n其实PositionDelta和Payload并不符合或然跟随规则，Payload是否存在，是由.fnm文件中对于每个域的配置中有关Payload的配置决定的(FieldOption.STORES_PAYLOADS) 。\n当Payload不存在时，PayloadDelta本身不遵从或然跟随原则。\n当Payload存在时，格式应该变成如下：Positions --\u0026gt;  Freq\n从而PositionDelta和PayloadLength一起适用或然跟随规则。\n\n4. 跳跃表规则(SKIP LIST)  \n\n为了提高查找的性能，Lucene在很多地方采取的跳跃表的数据结构。\n\n跳跃表(Skip List)是如图的一种数据结构，有以下几个基本特征：\n\n元素是按顺序排列的，在Lucene中，或是按字典顺序排列，或是按从小到大顺序排列。\n跳跃是有间隔的(Interval)，也即每次跳跃的元素数，间隔是事先配置好的，如图跳跃表的间隔为3。\n跳跃表是由层次的(level)，每一层的每隔指定间隔的元素构成上一层，如图跳跃表共有2层。\n\n\n\n\n需要注意一点的是，在很多数据结构或算法书中都会有跳跃表的描述，原理都是大致相同的，但是定义稍有差别：\n\n对间隔(Interval)的定义： 如图中，有的认为间隔为2，即两个上层元素之间的元素数，不包括两个上层元素；有的认为是3，即两个上层元素之间的差，包括后面上层元素，不包括前面的上 层元素；有的认为是4，即除两个上层元素之间的元素外，既包括前面，也包括后面的上层元素。Lucene是采取的第二种定义。\n对层次(Level)的定义：如图中，有的认为应该包括原链表层，并从1开始计数，则总层次为3，为1，2，3层；有的认为应该包括原链表层，并 从0计数，为0，1，2层；有的认为不应该包括原链表层，且从1开始计数，则为1，2层；有的认为不应该包括链表层，且从0开始计数，则为0，1层。 Lucene采取的是最后一种定义。\n跳跃表比顺序查找，大大提高了查找速度，如查找元素72，原来要访问2，3，7，12，23，37，39，44，50，72总共10个元素，应用跳 跃表后，只要首先访问第1层的50，发现72大于50，而第1层无下一个节点，然后访问第2层的94，发现94大于72，然后访问原链表的72，找到元 素，共需要访问3个元素即可。\n\n然而Lucene在具体实现上，与理论又有所不同，在具体的格式中，会详细说明。\n[/code][code]\n原文地址：[url]http://www.kailing.pub/article/index/arcid/73.html[/url][/code]","title":"Lucene5.5入门第三篇——Lucene索引文件结构","uid":"1032","views":"7695","votes":"0"},"_type":"doc"}
{"_id":"95","_index":"forum-mysql","_score":1,"_source":{"addtime":"1467944023","category_id":"2","comments":"9","has_attach":"0","id":"95","message":"最近有翻译官网文档的念头，从上周开始陆陆续续的抽时间翻译，因为工作比较忙，都是晚上熬夜开始翻译的。想要翻译官方文档的原因主要有这几点：\n[list=1]\n[*]官方文档写的比较好，例子多，容易理解；[/*]\n[*]已有的翻译资料感觉并不是很完善，要么只翻译了一部分，要么版本很旧，很久没人维护（有人翻译 ElasticSearch 权威指南，这个还是不错）；[/*]\n[*]自己在工作中经常用到 ElasticSearch，感觉 ElasticSearch 非常强大，帮助我们解决了很多问题，让我有激情去更深入的探索；[/*]\n[*]希望可以帮助到别人；[/*]\n[/list]\n \ngithub:  [url]https://github.com/liuzxc/Elasticsearch_reference_cn[/url]\n \nread online :   [url]https://liuzxc.gitbooks.io/elasticsearch_reference_cn/content/[/url]\n \n我现在基本上每天翻译 1- 2 节的样子，会持续更新下去，有兴趣的伙伴可以加入进来一起搞！","title":"尝试翻译 ElasticSearch 官方文档","uid":"1406","views":"4392","votes":"6"},"_type":"doc"}
{"_id":"97","_index":"forum-mysql","_score":1,"_source":{"addtime":"1469068543","category_id":"2","comments":"3","has_attach":"0","id":"97","message":"我们现在Elasticsearch的版本较老，然后数据量比较大，我不知道有平滑升级的方案不？如果有，该怎么做？如果没有，我是否可以把新版本的节点加入到老版本的集群中使用，两个版本共存，然后最后老数据删除，老版本的数据节点也就删除了，想问一下我想的方案是否可行？\n \n两个版本共存在一个集群中，会出现哪些可预知的问题？还希望了解的同学回答一下？谢谢！","title":"在一个Elasticsearch集群中可以使用过个版本数据节点共存吗？","uid":"694","views":"1624","votes":"1"},"_type":"doc"}
{"_id":"107","_index":"forum-mysql","_score":1,"_source":{"addtime":"1478238388","category_id":"14","comments":"11","has_attach":"0","id":"107","message":"时间一转又到了年末，去年的 Advent 在三斗的发起下，进行的很不错，今年的 Advent 活动继续办下去吧，借鉴日本（[url]http://qiita.com/advent-calendar/2016/elastic[/url]）的做法，我们今年可以先报名占坑，预定一个日子和你打算写的文章的标题，尽量错开时间。\n\n今年的Advent文章也会同步发布到社区公众号。\n\n去年 Advent 活动回顾 [url]http://elasticsearch.cn/topic/advent[/url]\n \n由于本站没有日历的功能，大家留言评论报名预定就好了。\n \n格式（仅12月）：日期，标题\n如：12月x日 , xxx 小技巧一则\n \n已发布：\n[url=http://elasticsearch.cn/article/110]《大规模Elasticsearch集群管理心得》[/url]\n[url=http://elasticsearch.cn/article/111]《Kibana 系漫游指南》[/url] \n[url=http://elasticsearch.cn/article/113]《创建一个你自己的 Beat》[/url]\n[url=http://elasticsearch.cn/article/114]《将sql转换为es的DSL》[/url]\n[url=http://elasticsearch.cn/article/126]《Elasticsearch 2.x mapping tips》[/url]\n[url=http://elasticsearch.cn/article/121]《无外网环境10分钟快速集成 elasticsearch-head》[/url]\n[url=http://elasticsearch.cn/article/120]《Elasticsearch 5 入坑指南》[/url]\n[url=http://elasticsearch.cn/article/119]《可定制的 elasticsearch 数据导入工具 ——mysql_2_elasticsearch》[/url]\n[url=http://elasticsearch.cn/article/118]《记一次es性能调优》[/url]\n[url=http://elasticsearch.cn/article/116]《PacketBeat奇妙的OOM小记》[/url]\n[url=http://elasticsearch.cn/article/115]《ES5.0.0 安装记录》[/url]","title":"Elastic Advent Calendar 活动启动咯！","uid":"1","views":"3522","votes":"4"},"_type":"doc"}
{"_id":"111","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480690083","category_id":"14","comments":"6","has_attach":"0","id":"111","message":"大家好，欢迎你们来到 ELK 三体星系的第二天。昨天，wood 送给大家一本脚踏实地的生存指南，今天让我们仰望星空，由我给大家介绍一下围绕在 Kibana 身边的诸多行星们~\n\n[b]Kibana Plugin 类型简介[/b]\n\n我们最熟悉的 Kibana Plugin，其实就是 Kibana 本身~ Kibana 提供了一整套框架，我们可以在此基础上，开发诸多不同类型的插件，包括：\n[list]\n[*]app[/*]\n[*]visTypes[/*]\n[*]spyModes[/*]\n[*]fieldFormatter[/*]\n[/list]\n\n列这么几个源码里的名词出来可能大家觉得比较晦涩。其实呢，app 就是同时具有前后端实现的应用，在 Kibana 5 里，默认分发的 app 有四个：实现日志查询和可视化的 kibana app、实现时序指标统计和可视化的 timelion app、实现和 ES 接口交互命令的 console app、在有异常的时候才看得到的状态页面 status_page app。\n\n而 visTypes 则是在 kibana 中具体可用的可视化效果。默认分发的有：kbn_vislib_vis_types、metric、table、markdown。我们常用的那些由 D3.js 完成的饼图线图地图，都是在 kbn_vislib_vis_types 中完成的。\n\nfieldFormatter 则用来定义在 ES 中相同类型的数据，根据其实际含义，可以有不同的展示方式。比如说：URL 肯定是一个字符串，但是可以用 fieldFormatter 把它在页面展示的时候，加上 `\u0026lt;a href\u0026gt;\u0026lt;/a\u0026gt;` 的样式，让人一键点击；同理，还可以过滤判断一下图片类 URL，加上 `\u0026lt;img src\u0026gt;\u0026lt;/img\u0026gt;` 的样式，直接在 Kibana 界面上就看图片内容~~\n\n[b]官方的我们会看手册啦~[/b]\n\n好啦好啦，我也不会真的去抄一把官方手册假冒《Kibana 系漫游指南》来骗你们流量的。下面给大家介绍一些社区开源的，让你绝对眼前一亮的各种新奇扩展：\n\n1. [url=https://github.com/sivasamyk/logtrail]logtrail[/url]\n    这是一个 app 插件，创意来自 papertrail 公司的产品。完全的满足了 Geeker 们喜欢黑底白字终端的癖好~不过其实实现非常简单：每隔 10 秒请求一次最近 500 条日志就是啦！\n[img]https://raw.githubusercontent.com/sivasamyk/logtrail/master/screenshot.png[/img]\n2. [url=https://github.com/stormpython/vectormap]vectormap[/url]\n    这是一个 visType 插件，也就是我们在 Kibana3 里曾经用过的 map panel 效果。这个插件不被官方直接采用的一个原因是版权许可问题。不做商用的情况下，这个插件还是可以极大方便我们做行政区域的访问情况统计和展示的。\n    [img]https://github.com/stormpython/vectormap/raw/master/vectormap.png[/img]\n3. [url=https://github.com/dlumbrer/kbn_network]kbn_network[/url]\n    这也是一个 visType 插件，酷毙了的网状图效果！通过不同的 aggs 数据展示 node 和 relational。\n    注意这个跟 Elastic 的 graph 并不是完全一致的东西。该插件要求你本身的数据已经有直接的关联可用。\n    [img]https://github.com/dlumbrer/kbn_network/raw/master/images/sizes.png[/img]\n4. [url=https://github.com/sirensolutions/sentinl]sentinl[/url]\n    这是一个同时带有 spyMode 和 app 双插件的项目。其基础思路是参照 Elastic 的 Watcher 接口，但是将监控告警的进程从 ES 挪到 Kibana 里。同时还可以通过 phantomjs 做到截图报表。\n    [img]https://camo.githubusercontent.com/4d0ae59cb6ca1efc1d768abb048a3a1f947b3fe1/687474703a2f2f692e696d6775722e636f6d2f506a317573696e2e676966[/img]\n    这个项目最大的特点，是通过 spyMode 插件，大大降低了配置告警规则的复杂度。这个扩展让你可以在 Kibana 上配置任意聚合效果之后，就地点击定义当前聚合语句为告警规则！\n    [img]https://camo.githubusercontent.com/4660f4a85cbd4725eaea0bbbdc215227a3fb0976/687474703a2f2f692e696d6775722e636f6d2f346c44544f56522e706e67[/img]\n5. [url=https://github.com/rashidkpc/kibana-keynote]kibana-keynote[/url]\n    这是另一个剑走偏锋的 app 插件，出自 Kibana 作者本人之手。它的作用是：播放 keynote 演讲稿！事实上项目里放的演讲稿就是作者本人在 ELastic{ON} 2016 上用的。让我们猜一猜下周的大会上，他会不会就用这个插件给我们分享呢？\n\n今天就先讲这几颗最闪亮的星了~有兴趣了解更多 Kibana 行星的游客，欢迎阅读全本[url=https://github.com/elastic/kibana/wiki/Known-Plugins]《Kibana系漫游指南》[/url]。\n\n也欢迎观看 Kibana 行星的[url=http://www.linkedin.com/groups/12019407]《探索·发现》[/url]节目哟~","title":"Day2:《Kibana 系漫游指南》","uid":"7","views":"7188","votes":"9"},"_type":"doc"}
{"_id":"112","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480727408","category_id":"2","comments":"6","has_attach":"0","id":"112","message":"[url]https://github.com/DataSays/wES/[/url] \n\nwES 是一组开源的Java ElasticSearch客户端和工具; 简洁但是很勥 :)\nwES = Java Retrofit2/OkHttp版本的客户端(不依赖Json类库,高度可定制) + 工具包 + spring-boot demo + 常用的ElasticSearch环境Dockerfile\n\n[b]wES 模块[/b]\nwES 分割成许多模块, 可以按需选择.\nwUtil: 一些有用的帮助类和工具类.\nwES-client: 一个基于Retrofit2/OkHttp的Java客户端, 她是基于官方的ElasticSearch Rest API规范生成的. 她包含两种访问ElasticSearch的实现: OkHttp3版本的和Retrofit2版本. 而且她只依赖okhttp3/retrofit2,并且可以通过实现org.datasays.wes.core.IConvert接口支持任意一种Java Json类库. 你可以按照你的想法使用她.\nwES-toolkit: 一些使用wES-client和ElasticSearch的工具包. 她包含了一套基于Gson的标准IConvert实现及封装代码库.\nwES-demo: 一个Spring-boot + Vue.js的web应用, 用于展示一些通用的ElasticSearch使用场景.\nwES-docker: 一些构建ElasticSearch开发/生产环境的常用Dockerfiles和shell脚本.\n\n ","title":"开源一组ES工具包,请大家帮忙宣传下,谢谢","uid":"2021","views":"2785","votes":"0"},"_type":"doc"}
{"_id":"115","_index":"forum-mysql","_score":1,"_source":{"addtime":"1480902120","category_id":"2","comments":"1","has_attach":"0","id":"115","message":"\n[b]创建用户：adduser elasticsearch[/b]\n可查看创建结果：\n##########/etc/passwd\n##########/etc/shadow\n##########/etc/group\n[b]配置环境变量[/b]\n修改文件：/home/elasticsearch/.profile\n追加内容：\nexport JAVA_HOME=/home/elasticsearch/java/jdk1.8.0_73\nexport PATH=$JAVA_HOME/bin:$PATH\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATH\nexport PATH\n[b]配置elasticsearch5.0.0[/b]\ntar -xf elasticsearch-5.0.0.tar.gz -C /home/elasticsearch/\ncd /home/elasticsearch/\nln -sv elasticsearch-5.0.0 elasticsearch\nmkdir -pv /esdata/elasticsearch/{data,logs}\nchown -R elasticsearch.elasticsearch /esdata/elasticsearch\n[b]修改ES配置文件[/b]\n/home/elasticsearch/elasticsearch-5.0.0/config/elasticsearch.yml\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \u0026quot;*\u0026quot;\npath.data: /esdata/elasticsearch/data\npath.logs: /esdata/elasticsearch/logs\nnetwork.host: 192.168.25.57\nhttp.port: 8201\ntransport.tcp.port: 8301\nbootstrap.memory_lock: true\n/home/elasticsearch/elasticsearch-5.0.0/config/jvm.options\n-Xms8g\n-Xmx8g\n[b]修改系统参数[/b]\n/etc/security/limits.conf\nelasticsearch soft nproc 65536\nelasticsearch hard nproc 65536\nelasticsearch soft nofile 65536\nelasticsearch hard nofile 65536\nelasticsearch - memlock unlimited\n/etc/sysctl.conf\nvm.max_map_count = 262144\n[b]加载更新[/b]：sysctl -p\n[b]启动ES服务[/b]\nsu - elasticsearch -c \u0026quot;/home/elasticsearch/elasticsearch/bin/elasticsearch \u0026amp;\u0026quot;\n ","title":"ES5.0.0 安装记录","uid":"1411","views":"2595","votes":"1"},"_type":"doc"}
{"_id":"121","_index":"forum-mysql","_score":1,"_source":{"addtime":"1481786987","category_id":"2","comments":"1","has_attach":"0","id":"121","message":"一台连上外网的机器\n1.下载对应的 [url=https://nodejs.org/en/download/]node[/url] 安装包\n\n2.下载 [url=https://github.com/mobz/elasticsearch-head]Elasticsearch-head[/url] 安装包（顺便解压）\n\n3.cmd 输入下面命令安装taobao提供的镜像（原因你懂的）[code]$ npm install -g cnpm --registry=https://registry.npm.taobao.org[/code] \n4.cmd cd 到你解压的 elasticsearch-head 目录下[code]$ cnpm install[/code]这时你会发现多了一个 node_modules 目录\n\n5.install 后，head 目录下会自动生成一个 node_modules 目录，里面为相关的依赖\n\n到此，本地的准备工作都已完成。\n可以把两个安装包上传到服务器。\n建议：elasticsearch-head 重新压缩后上传\n \n/etc/profile 添加（改成你的路径）[code]export NODE_HOME=/usr/local/elastic/node/node-v6.9.2-linux-x64\nexport PATH=$NODE_HOME/bin:$PATH[/code]记得[code]$ source /etc/profile[/code]\n在 elastic/config/elasticsearch.yml 添加（否则完成后网页中会显示未连接）[code]http.cors.enabled: true\nhttp.cors.allow-origin: \u0026quot;*\u0026quot;[/code]\n之后（后台启动加 \u0026amp;）[code]./grunt server [/code]\n在网页中输入你的http://localhost:9100","title":"无外网环境10分钟快速集成 elasticsearch-head","uid":"1974","views":"2629","votes":"2"},"_type":"doc"}
{"_id":"124","_index":"forum-mysql","_score":1,"_source":{"addtime":"1483950541","category_id":"5","comments":"3","has_attach":"1","id":"124","message":"[attach]386[/attach]\n 在几十位社区同学的共同努力下，《Elasticsearch 权威指南》的翻译工作接近尾声，\n在线访问链接如下：\n[url]http://es-guide-preview.elasticsearch.cn[/url]\n \n晚点会放到 elastic.co 官网上，大家学习 Elasticsearch 又多了一份好的资料，大家在访问的过程，如果发现有问题（翻译的各种 bug，翻译有误，不合理，不通顺，标点，格式等等），欢迎前往  [url]https://github.com/elasticsearch-cn/elasticsearch-definitive-guide[/url] 提交 Issue，同时也欢迎直接提交 pull request 来改进本书。\n \n同时也希望更多的志愿者加入我们一起进行翻译，后续我们会继续翻译其他的手册，另外有很多同学自己已经在翻译部分内容，也欢迎加入我们一起，有兴趣的同学加入我们翻译的QQ群：109764489 ，一起为 Elastic 的中文资料贡献力量。\n\n最后，再次感谢以下本书的志愿者：\n薛杰，骆朗，彭秋源，魏喆，饶琛琳， 风虎，路小磊，michealzh，nodexy，sdlyjzh，落英流离， sunyonggang，Singham，烧碱，龙翔，陈思，陈华， 追风侃侃，Geolem，卷发，kfypmqqw，袁伟强，yichao， 小彬，leo，tangmisi，Alex，baifan，Evan，fanyer， wwb，瑞星，刘碧琴，walker，songgl， 吕兵，东，杜宁，秦东亮，biyuhao，刘刚， yumo，王秀文，zcola，gitqh，blackoon，David，韩炳辰， 韩陆，echolihao，Xargin，abel-sun，卞顺强， bsll，冬狼，王琦。\n ","title":"《Elasticsearch 权威指南》中文版","uid":"1","views":"14029","votes":"6"},"_type":"doc"}
{"_id":"128","_index":"forum-mysql","_score":1,"_source":{"addtime":"1484122298","category_id":"1","comments":"0","has_attach":"0","id":"128","message":"招聘需求：\n \n技术总监1名：\n1、 日志分析产品研发经验优先，8年以上工作经验\n2、 精通elasticsearch、Redis、MongoDB、Neo4J等NoSQL系统，熟悉elasticsearch集群管理和性能调优，有在实际项目中使用搜索引擎工具、内存数据库、文档数据库、图数据库的经验\n3、 熟悉Hadoop、Spark、Spark Streaming、Storm、HBase、ZooKeeper等大数据生态系统组件;熟悉Kafka、ZeroMQ等消息系统组件\n4、 精通日志处理工具集ELK，flume，heka等\n5、 熟悉Linux环境，熟练使用Python和Shell进行脚本编程\n6、 精通JAVA语言，熟悉主流开源框架Struts2、Spring、Hibernate，SpringMVC的运行机制及使用。熟练掌握和使用J2EE开发中常见面向对象设计模式(Singleton，Proxy，Factory等)\n7、 有系统运维管理平台项目开发及管理经验优先\n8、 提供优厚待遇及期权，薪水50万以上\n9、 金融行业背景优先考虑\n \n \n技术专家2名：\n1、熟悉Hadoop生态圈相关技术，如Hbase，Hive，Zookeeper，flume，kafka，storm\n2、了解spark运行机制，研读spark部分内核源码；了解ELK日志分析平台（elasticsearch、logstash、kibana）使用\n3、 熟悉Linux系统的基本操作和集群环境的搭建和部署\n4、 熟悉JavaEE的开发，掌握JavaEE流行框架的使用，如：Struts2、Spring、Hibernate、SpringMVC等\n5、熟悉主流数据库Oracle、DB2、MySQL、Mariadb的使用及性能优化；会使用NoSql数据库（如redis）解决开发过程中遇到的业务问题\n6、提供优厚待遇和期权，薪水30万以上\n7、金融行业优先考虑\n如有意向请联系郝女士   联系电话：13520834022      邮箱：haojinjin16@163.com\n招聘单位：洋大数据信息技术（北京）有限公司","title":"招聘","uid":"2226","views":"2065","votes":"0"},"_type":"doc"}
{"_id":"138","_index":"forum-mysql","_score":1,"_source":{"addtime":"1488511011","category_id":"13","comments":"0","has_attach":"1","id":"138","message":"Golang 因为其语法简单，上手快且方便部署正被越来越多的开发者所青睐，一个 Golang 程序开发好了之后，势必要关心其运行情况，今天在这里就给大家介绍一下如果使用 Elastic Stack 来分析 Golang 程序的内存使用情况，方便对 Golang 程序做长期监控进而调优和诊断，甚至发现一些潜在的内存泄露等问题。\n \nElastic Stack 其实是一个集合，包含 Elasticsearch、Logstash 和 Beats 这几个开源软件，而 Beats 又包含 Filebeat、Packetbeat、Winlogbeat、Metricbeat 和新出的 Heartbeat，呵呵，有点多吧，恩，每个 beat 做的事情不一样，没关系，今天主要用到 Elasticsearch、Metricbeat 和 Kibana 就行了。\n \nMetricbeat 是一个专门用来获取服务器或应用服务内部运行指标数据的收集程序，也是 Golang 写的，部署包比较小才10M 左右，对目标服务器的部署环境也没有依赖，内存资源占用和 CPU 开销也较小，目前除了可以监控服务器本身的资源使用情况外，还支持常见的应用服务器和服务，目前支持列表如下：\n[list]\n[*]Apache Module[/*]\n[*]Couchbase Module[/*]\n[*]Docker Module[/*]\n[*]HAProxy Module[/*]\n[*]kafka Module[/*]\n[*]MongoDB Module[/*]\n[*]MySQL Module[/*]\n[*]Nginx Module[/*]\n[*]PostgreSQL Module[/*]\n[*]Prometheus Module[/*]\n[*]Redis Module[/*]\n[*]System Module[/*]\n[*]ZooKeeper Module[/*]\n[/list]\n当然，也有可能你的应用不在上述列表，没关系，Metricbeat 是可以扩展的，你可以很方便的实现一个模块，而本文接下来所用的 Golang Module 也就是我刚刚为 Metricbeat 添加的扩展模块，目前已经 merge 进入 Metricbeat 的 master 分支，预计会在 6.0 版本发布，想了解是如何扩展这个模块的可以查看 [url=https://github.com/elastic/beats/tree/master/metricbeat/module/golang]代码路径[/url] 和 [url=https://github.com/elastic/beats/pull/3536]PR地址[/url]。\n \n上面的这些可能还不够吸引人，我们来看一下 Kibana 对 Metricbeat 使用 Golang 模块收集的数据进行的可视化分析吧：\n\n[attach]422[/attach]\n \n上面的图简单解读一下:\n最上面一栏是 Golang Heap 的摘要信息，可以大致了解 Golang 的内存使用和 GC 情况，System 表示 Golang 程序从操作系统申请的内存，可以理解为进程所占的内存（注意不是进程对应的虚拟内存），Bytes allocated 表示 Heap 目前分配的内存，也就是 Golang 里面直接可使用的内存，GC limit 表示当 Golang 的 Heap 内存分配达到这个 limit 值之后就会开始执行 GC，这个值会随着每次 GC 而变化， GC cycles 则代表监控周期内的 GC 次数；\n \n中间的三列分别是堆内存、进程内存和对象的统计情况；Heap Allocated 表示正在用和没有用但还未被回收的对象的大小；Heap Inuse 显然就是活跃的对象大小了；Heap Idle 表示已分配但空闲的内存；\n\n底下两列是 GC 时间和 GC 次数的监控统计，CPUFraction 这个代表该进程 CPU 占用时间花在 GC 上面的百分比，值越大说明 GC 越频繁，浪费更多的时间在 GC 上面，上图虽然趋势陡峭，但是看范围在0.41%~0.52%之间，看起来还算可以，如果GC 比率占到个位数甚至更多比例，那肯定需要进一步优化程序了。\n \n有了这些信息我们就能够知道该 Golang 的内存使用和分配情况和 GC 的执行情况，假如要分析是否有内存泄露，看内存使用和堆内存分配的趋势是否平稳就可以了，另外 GC_Limit 和 Byte Allocation 一直上升，那肯定就是有内存泄露了，结合历史信息还能对不同版本/提交对 Golang 的内存使用和 GC 影响进行分析。\n\n接下来就要给大家介绍如何具体使用了，首先需要启用 Golang 的 expvar 服务，expvar（[url]https://golang.org/pkg/expvar/[/url]） 是 Golang 提供的一个暴露内部变量或统计信息的标准包。\n使用的方法很简单，只需要在 Golang 的程序引入该包即可，它会自动注册现有的 http 服务上，如下：[code]import _ \u0026quot;expvar\u0026quot;[/code]如果 Golang 没有启动 http 服务，使用下面的方式启动一个即可，这里端口是 6060，如下：[code]func metricsHandler(w http.ResponseWriter, r *http.Request) {\n\tw.Header().Set(\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json; charset=utf-8\u0026quot;)\n\n\tfirst := true\n\treport := func(key string, value interface{}) {\n\t\tif !first {\n\t\t\tfmt.Fprintf(w, \u0026quot;,\\n\u0026quot;)\n\t\t}\n\t\tfirst = false\n\t\tif str, ok := value.(string); ok {\n\t\t\tfmt.Fprintf(w, \u0026quot;%q: %q\u0026quot;, key, str)\n\t\t} else {\n\t\t\tfmt.Fprintf(w, \u0026quot;%q: %v\u0026quot;, key, value)\n\t\t}\n\t}\n\n\tfmt.Fprintf(w, \u0026quot;{\\n\u0026quot;)\n\texpvar.Do(func(kv expvar.KeyValue) {\n\t\treport(kv.Key, kv.Value)\n\t})\n\tfmt.Fprintf(w, \u0026quot;\\n}\\n\u0026quot;)\n}\n\nfunc main() {\n   mux := http.NewServeMux()\n   mux.HandleFunc(\u0026quot;/debug/vars\u0026quot;, metricsHandler)\n   endpoint := http.ListenAndServe(\u0026quot;localhost:6060\u0026quot;, mux)\n}[/code]默认注册的访问路径是/debug/vars， 编译启动之后，就可以通过 [url]http://localhost:6060/debug/vars[/url]  来访问 expvar 以 JSON 格式暴露出来的这些内部变量，默认提供了 Golang 的 runtime.Memstats 信息，也就是上面分析的数据源，当然你还可以注册自己的变量，这里暂时不提。\n \nOK，现在我们的 Golang 程序已经启动了，并且通过 expvar 暴露出了运行时的内存使用情况，现在我们需要使用 Metricbeat 来获取这些信息并存进 Elasticsearch。\n \n关于 Metricbeat 的安装其实很简单，下载对应平台的包解压（下载地址：[url]https://www.elastic.co/downloads/beats/metricbeat[/url] ），启动 Metricbeat 前，修改配置文件：metricbeat.yml[code]metricbeat.modules:\n  - module: golang\n     metricsets: [\u0026quot;heap\u0026quot;]\n     enabled: true\n     period: 10s\n     hosts: [\u0026quot;localhost:6060\u0026quot;]\n     heap.path: \u0026quot;/debug/vars\u0026quot;[/code]上面的参数启用了 Golang 监控模块，并且会10秒获取一次配置路径的返回内存数据，我们同样配置该配置文件，设置数据输出到本机的 Elasticsearch：[code]output.elasticsearch:\n  hosts: [\u0026quot;localhost:9200\u0026quot;][/code]\n现在启动 Metricbeat：[code]./metricbeat -e -v[/code]现在在 Elasticsearch 应该就有数据了，当然记得确保 Elasticsearch 和 Kibana 是可用状态，你可以在 Kibana 根据数据灵活自定义可视化，推荐使用 Timelion 来进行分析，当然为了方便也可以直接导入提供的样例仪表板，就是上面第一个图的效果。\n关于如何导入样例仪表板请参照这个文档：[url]https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-sample-dashboards.html[/url] \n \n除了监控已经有的内存信息之外，如果你还有一些内部的业务指标想要暴露出来，也是可以的，通过 expvar 来做同样可以。一个简单的例子如下：[code]var inerInt int64 = 1024\npubInt := expvar.NewInt(\u0026quot;your_metric_key\u0026quot;)\npubInt.Set(inerInt)\npubInt.Add(2)[/code]在 Metricbeat 内部也同样暴露了很多内部运行的信息，所以 Metricbeat 可以自己监控自己了。。。\n首先，启动的时候带上参数设置pprof监控的地址，如下：[code]./metricbeat -httpprof=\u0026quot;127.0.0.1:6060\u0026quot; -e -v[/code]这样我们就能够通过 [url=http://127.0.0.1:6060/debug/vars访问到内部运行情况了，如下：]http://127.0.0.1:6060/debug/vars[/url] 访问到内部运行情况了，如下：[code]{\n\u0026quot;output.events.acked\u0026quot;: 1088,\n\u0026quot;output.write.bytes\u0026quot;: 1027455,\n\u0026quot;output.write.errors\u0026quot;: 0,\n\u0026quot;output.messages.dropped\u0026quot;: 0,\n\u0026quot;output.elasticsearch.publishEvents.call.count\u0026quot;: 24,\n\u0026quot;output.elasticsearch.read.bytes\u0026quot;: 12215,\n\u0026quot;output.elasticsearch.read.errors\u0026quot;: 0,\n\u0026quot;output.elasticsearch.write.bytes\u0026quot;: 1027455,\n\u0026quot;output.elasticsearch.write.errors\u0026quot;: 0,\n\u0026quot;output.elasticsearch.events.acked\u0026quot;: 1088,\n\u0026quot;output.elasticsearch.events.not_acked\u0026quot;: 0,\n\u0026quot;output.kafka.events.acked\u0026quot;: 0,\n\u0026quot;output.kafka.events.not_acked\u0026quot;: 0,\n\u0026quot;output.kafka.publishEvents.call.count\u0026quot;: 0,\n\u0026quot;output.logstash.write.errors\u0026quot;: 0,\n\u0026quot;output.logstash.write.bytes\u0026quot;: 0,\n\u0026quot;output.logstash.events.acked\u0026quot;: 0,\n\u0026quot;output.logstash.events.not_acked\u0026quot;: 0,\n\u0026quot;output.logstash.publishEvents.call.count\u0026quot;: 0,\n\u0026quot;output.logstash.read.bytes\u0026quot;: 0,\n\u0026quot;output.logstash.read.errors\u0026quot;: 0,\n\u0026quot;output.redis.events.acked\u0026quot;: 0,\n\u0026quot;output.redis.events.not_acked\u0026quot;: 0,\n\u0026quot;output.redis.read.bytes\u0026quot;: 0,\n\u0026quot;output.redis.read.errors\u0026quot;: 0,\n\u0026quot;output.redis.write.bytes\u0026quot;: 0,\n\u0026quot;output.redis.write.errors\u0026quot;: 0,\n\u0026quot;beat.memstats.memory_total\u0026quot;: 155721720,\n\u0026quot;beat.memstats.memory_alloc\u0026quot;: 3632728,\n\u0026quot;beat.memstats.gc_next\u0026quot;: 6052800,\n\u0026quot;cmdline\u0026quot;: [\u0026quot;./metricbeat\u0026quot;,\u0026quot;-httpprof=127.0.0.1:6060\u0026quot;,\u0026quot;-e\u0026quot;,\u0026quot;-v\u0026quot;],\n\u0026quot;fetches\u0026quot;: {\u0026quot;system-cpu\u0026quot;: {\u0026quot;events\u0026quot;: 4, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-filesystem\u0026quot;: {\u0026quot;events\u0026quot;: 20, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-fsstat\u0026quot;: {\u0026quot;events\u0026quot;: 4, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-load\u0026quot;: {\u0026quot;events\u0026quot;: 4, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-memory\u0026quot;: {\u0026quot;events\u0026quot;: 4, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-network\u0026quot;: {\u0026quot;events\u0026quot;: 44, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}, \u0026quot;system-process\u0026quot;: {\u0026quot;events\u0026quot;: 1008, \u0026quot;failures\u0026quot;: 0, \u0026quot;success\u0026quot;: 4}},\n\u0026quot;libbeat.config.module.running\u0026quot;: 0,\n\u0026quot;libbeat.config.module.starts\u0026quot;: 0,\n\u0026quot;libbeat.config.module.stops\u0026quot;: 0,\n\u0026quot;libbeat.config.reloads\u0026quot;: 0,\n\u0026quot;memstats\u0026quot;: {\u0026quot;Alloc\u0026quot;:3637704,\u0026quot;TotalAlloc\u0026quot;:155\n... ...[/code]比如，上面就能看到output模块Elasticsearch的处理情况，如 output.elasticsearch.events.acked 参数表示发送到 Elasticsearch Ack返回之后的消息。\n \n现在我们要修改 Metricbeat 的配置文件，Golang 模块有两个 metricset，可以理解为两个监控的指标类型，我们现在需要加入一个新的 expvar 类型，这个即自定义的其他指标，相应配置文件修改如下：[code]- module: golang\n  metricsets: [\u0026quot;heap\u0026quot;,\u0026quot;expvar\u0026quot;]\n  enabled: true\n  period: 1s\n  hosts: [\u0026quot;localhost:6060\u0026quot;]\n  heap.path: \u0026quot;/debug/vars\u0026quot;\n  expvar:\n    namespace: \u0026quot;metricbeat\u0026quot;\n    path: \u0026quot;/debug/vars\u0026quot;[/code]上面的一个参数 namespace 表示自定义指标的一个命令空间，主要是为了方便管理，这里是 Metricbeat 自身的信息，所以 namespace 就是 metricbeat。\n \n重启 Metricbeat 应该就能收到新的数据了，我们前往 Kibana。\n \n这里假设关注 output.elasticsearch.events.acked和\noutput.elasticsearch.events.not_acked这两个指标，我们在Kibana里面简单定义一个曲线图就能看到 Metricbeat 发往 Elasticsearch 消息的成功和失败趋势。\nTimelion 表达式：[code].es(\u0026quot;metricbeat*\u0026quot;,metric=\u0026quot;max:golang.metricbeat.output.elasticsearch.events.acked\u0026quot;).derivative().label(\u0026quot;Elasticsearch Success\u0026quot;),.es(\u0026quot;metricbeat*\u0026quot;,metric=\u0026quot;max:golang.metricbeat.output.elasticsearch.events.not_acked\u0026quot;).derivative().label(\u0026quot;Elasticsearch Failed\u0026quot;)[/code]效果如下：\n\n[attach]423[/attach]\n从上图可以看到，发往 Elasticsearch 的消息很稳定，没有出现丢消息的情况，同时关于 Metricbeat 的内存情况，我们打开导入的 Dashboard 查看:\n\n[attach]424[/attach]\n\n关于如何使用 Metricbeat 来监控 Golang 应用程序的内容基本上就差不多到这里了，上面介绍了如何基于 expvar 来监控 Golang 的内存情况和自定义业务监控指标，在结合 Elastic Stack 可以快速的进行分析，希望对大家有用。\n\n最后，这个 Golang 模块目前还没 release，估计在 beats 6.0 发布，有兴趣尝鲜的可以自己下载源码打包。","title":"使用 Elastic Stack 来监控和调优 Golang 应用程序","uid":"1","views":"7072","votes":"6"},"_type":"doc"}
{"_id":"139","_index":"forum-mysql","_score":1,"_source":{"addtime":"1488996397","category_id":"5","comments":"2","has_attach":"1","id":"139","message":"Elastic 一年一度的用户大会 Elasitc{ON}17 昨日在旧金山举行了，与参人员达到了 2000 多位，这是第三届 Elastic{ON} 了，让我们一起来看看这次大会都要哪些亮点吧。\n\n在进入主题之前，我们先参观看看会场及周边情况吧，这次会场是在旧金山的 48 号码头，和去年的场地很近，不过今年的场地为了容纳的更多的人数，比去年的场地要大很多，码头对面就是著名的AT\u0026amp;T棒球场，看图。\n\n[attach]453[/attach]\n\n[attach]454[/attach]\n\n[attach]455[/attach]\n\n今年多了一个开场的舞蹈，跟别人不一样的事，芭蕾舞蹈演员身上佩戴着若干闪光的传感器，在大背景墙上面可以看到随着演员的舞蹈，有不断变化的各种传感器实时分析的 Kibana 界面，这一切都是实时的哦。\n\n[attach]456[/attach]\n\n[attach]457[/attach]\n\n然后就进入 Keynote 了，Elastic 公司 CEO Shay Banon 宣布 Elastic 的产品下载次数达到小目标，已经累计一个亿了。\n\n[attach]458[/attach]\n\nElastic 的产品的一个重要原则就是简单，为了让简单的事情变简单，比如采集日志文件，现在的 Filebeat 引入了模块的概念，相应模块直接提供对应成套的配置文件，包括 Mapping、Ingest pipeline、Kibana Dashboard， 启动 filebeat 收集数据进入 es 之后，直接就能可视化分析了。\n\n[attach]459[/attach]\n\n现在使用 elasticsearch 来做 metric 分析的场景和用户越来越多，而 Kibana 的 Timeseries visual builder 就是为了 metric 场景而产生的一个新的特性，支持非常灵活的自定义可视化，还支持 elasticsearch 的 pipeline aggregation。\n\n[attach]460[/attach]\n\n[attach]461[/attach]\n\n接下来就是，Elasticsearch 机器学习了，去年收购的 Perlert，目前已经和 Elasticsearch 无缝集成，现场 demo 演示了通过机器学习模块来分析日志的完整过程，实时的进行异常预测，从众多 service 的日志中找到 root cause。\n\n[attach]462[/attach]\n\n[attach]463[/attach]\n\n[attach]465[/attach]\n\n[attach]464[/attach]\n\n\n然后就是 ECE，即 ElasticCloud 的私有云，企业可以很方便的借助它来实现搭建 Elastic 的私有云，集群管理，集群升级都很简单。\n\n[attach]466[/attach]\n\n[attach]467[/attach]\n\n然后前 CEO Steven Schuurman 为大家揭晓了今年的第一届 Elastic Cause Awards 获奖的结果，你知道吗，Elasticsearch 正被用于预防埃博拉病毒、拯救人口贩卖以及防止校园暴力等很多有意义的项目中。\n\n[attach]471[/attach]\n\n[attach]468[/attach]\n\n[attach]470[/attach]\n\n[attach]469[/attach]\n\n然后 Costin Leau 为大家演示了 Elasticsearch-sql，新的和 Elasticsearch 交互的方式，jdbc 兼容，大家期盼已久的功能终于来了，你可以使用现有的支持 jdbc 协议的各种工具来使用 elasticsearch 了，当然不会是完整的 SQL 标准协议，但满足大部分常见的简单的场景。\n\n[attach]475[/attach]\n[attach]472[/attach]\n[attach]473[/attach]\n[attach]474[/attach]\n \n接下来，Rashid Khan 为大家介绍了与社区相关的一些统计，到最后才跳出来，这些炫酷的 infographic 和 presentation 居然就是在 Kibana 上面，并且这些数据是实时变化的，从而引入了 Kibana 新的功能：Kibana Canvas，借助它，你可以灵活布局设计报表或是 presentation，与后端Elasticsearch数据实时连接，另外与大家通常熟知的静态的 infographic 不同，所有的这些可视化图形都是可以交互操作的，比如过滤与搜索，从此，数据的探索与分析又有了一种新的方式了。\n\n[attach]479[/attach]\n\n[attach]477[/attach]\n\n[attach]481[/attach]\n\n[attach]480[/attach]\n\n[attach]476[/attach]\n\nKeynote 的内容主要就到这里了，下午还有很多其他的具体的演讲，都是各个产品的具体的新的特性，回头再补充。\n \n现场还有很多各种类型的 Demo。\n\n[attach]487[/attach]\n\n[attach]489[/attach]\n\n[attach]485[/attach]\n\n[attach]486[/attach]\n\n[attach]484[/attach]\n\n[attach]482[/attach]\n\n[attach]483[/attach]\n\n[attach]488[/attach]\n\n\n想知道 Elastic{ON}17 后续几天还有什么新鲜事么，欢迎关注我的微博：[url=http://weibo.com/medcl]@medcl[/url] 和 Elastic 中文社区公众号。\n ","title":"Elastic{ON}17 见闻","uid":"1","views":"1814","votes":"6"},"_type":"doc"}
{"_id":"140","_index":"forum-mysql","_score":1,"_source":{"addtime":"1489310337","category_id":"2","comments":"0","has_attach":"0","id":"140","message":"刚发在了github,给个链接就好了:\nhttps://vastxiao.github.io/article/2017/03/26/curator_running/","title":"用es的官方工具curator4来配置和管理和优化es索引","uid":"739","views":"3049","votes":"0"},"_type":"doc"}
{"_id":"312","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507876745","category_id":"5","comments":"4","has_attach":"1","id":"312","message":"[i][url=https://www.elastic.co/cn/about/press/elastic-partners-with-alibaba-cloud-to-deliver-elasticsearch-on-alibaba-cloud]新服务发布 －阿里云 Elasticsearch 将包含 Elasticsearch、Kibana 及 Elastic 的 X-Pack 功能[/url][/i]\n\nElastic - 旗下拥有 Elasticsearch，以及使用最广泛的开源产品集合 Elastic Stack，用于解决搜索、日志和数据分析等关键任务型用例 - 今天宣布与阿里巴巴集团（纽约证券交易所代码：BABA，「阿里巴巴」）旗下云计算平台阿里云达成新的合作伙伴关系，旨在共同研发及发布于阿里云上提供托管的 Elasticsearch，为中国市场提供崭新的用户体验。\n\n这项名为 “ 阿里云 Elasticsearch ” 的新服务能让阿里巴巴的客户随心所欲地运用 Elasticsearch 强大的实时搜索、采集及数据分析功能，是一站式而且主导性的解决方案。\n\n阿里云总裁胡晓明先生表示：“作为全球领先的云计算服务提供商，阿里云内致力于通过我们的平台向客户提供最先进的产品，使其保持竞争优势并促进创新。” 他指出：“阿里云 Elasticsearch 将会成为一项高度差异化的服务，因为它运用了 Elastic 先进的搜索产品及强大的 X-Pack 功能，不论在服务的任何层面上，均容易上手使用以及方便管理。”\n\n阿里云 Elasticsearch 现已正式上线，简单配置即可添加到客户的云计算服务之上。通过 Elasticsearch 实时搜索的能力与客户应用相结合，以 Logstash 或 Beats 将数据导入阿里云 Elasticsearch 里，使用 Kibana 仪表板把实时及历史数据可视化，加上 X-Pack 的一系列功能如 security、alerting、monitoring、reporting、Graph 分析及 machine learning，为开发人员提供一站式产品的体验。\n\n此外，阿里云和 Elastic 会着力于技术提升，确保阿里云 Elasticsearch 与时并进，拥有最新的功能。在未来，日志导入功能及其他服务也将相继可用。\n\nElastic 创始人兼首席执行官 Shay Banon 先生表示：“中国对我们来说是一个不断增长的市场，过去几年间，我们看到 Elasticsearch 的社区版图扩展至超过 5000 多位开发人员。 通过与亚洲最大的云端供应商阿里云合作，并配合 Elasticsearch 的实时处理能力、强大的 X-Pack 功能，如 security，alerting和 machine learning，我们能够一同加快中国广大开发者生态的创新步伐，构建、托管及管理更多不同的应用。”\n\n\n\n[attach]1135[/attach]\n\n阿里云总裁胡晓明与 Elastic 创始人兼首席执行官 Shay Banon\n\n\n\n[b]了解更多[/b]\n\n[url=https://data.aliyun.com/product/elasticsearch]阿里云 Elasticsearch[/url]\n[url=https://www.elastic.co/cn/blog/alibaba-cloud-to-offer-elasticsearch-kibana-and-x-pack-in-china]Elastic \u0026amp; Alibaba Blog[/url]\n\n[b]关于阿里云[/b]\n\n阿里云创立于 2009 年， 为阿里巴巴集团旗下云计算业务。现时被 Gartner 评为全球 3 大基础设施即服务 (IaaS) 供货商之一。根据 IDC 2016年调研显示，阿里云为中国最大的公共云端服务供货商，基础设施即服务 (IaaS) 收入全球排行第四。阿里云提供全面的云计算服务，支持世界各地的企业，包括在阿里巴巴集团市场上做生意的商家、初创公司、企业级客户及政府机构等。阿里云现时为国际奥林匹克委员会官方云服务官方合作伙伴。有关更多信息，请访问 https://www.aliyun.com。\n\n[b]关于 Elastic[/b]\n\nElastic 通过构建软件，让用户能够实时地、大规模地将数据用于搜索、日志和分析场景。Elastic 创立于 2012 年，相继开发了开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、X-Pack（商业功能）和 Elastic Cloud（托管服务）。截至目前，累计下载量超过 1.5 亿。Benchmark Capital、Index Ventures 和 NEA 为 Elastic 提供了超过 1 亿美元资金作为支持，Elastic 共有 600 多名员工，分布在 30 个国家/地区。有关更多信息，请访问 elastic.co/cn。\n\nhttps://www.elastic.co/cn/about/press/elastic-partners-with-alibaba-cloud-to-deliver-elasticsearch-on-alibaba-cloud","title":"Elastic与阿里云达成合作伙伴关系 提供 ” 阿里云 Elasticsearch ” 的新服务","uid":"1","views":"1229","votes":"9"},"_type":"doc"}
{"_id":"315","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508046085","category_id":"2","comments":"0","has_attach":"0","id":"315","message":"[quote]\n本文翻译自QBox官方博客的“Elasticsearch索引性能优化”系列文章中的第二篇，版权归原作者 Adam Vanderbush所有。该系列文章共有三篇，其中第一篇已有同行翻译，参考链接http://www.zcfy.cc/article/how-to-maximize-elasticsearch-indexing-performance-part-1-3624.html   后续还会有第三篇的推送，敬请关注。\n[/quote]\n \n[b]作者：[/b]Adam Vanderbush\n[b]译者：[/b]杨振涛@vivo\n \n本系列文章重点关注如何最大化地提升elasticsearch的索引吞吐量和降低监控与管理负荷。\n\nElasticsearch是准实时的，这表示当索引一个文档后，需要等待下一次刷新后就可以搜索到该文档了。\n\n刷新是一个开销较大的操作，这就是为什么默认要设置一个特定的间隔，而不是每索引一个文档就刷新一次。如果想索引大批量的文档，并不需要立刻就搜索到新的索引信息，为了优化索引性能甚至搜索性能，可以临时降低刷新的频率，直到索引操作完成。\n\n一个索引库的分片由多个段组成。Lucene的核心数据结构中，一个段本质上是索引库的一个变更集。这些段是在每次刷新时所创建，随后会在后台合并到一起，以保证资源的高效使用；每个段都会消耗文件句柄、内存和CPU。工作在该场景背后的Lucene负责段的合并，一旦处理不当，可能会消耗昂贵的计算资源并导致Elasticsearch自动降级索引请求到一个单一线程上。\n\n本文将继续关注Elasticsearch的索引性能调优，重点聚焦在集群和索引级别的各种索引配置项设置。\n\n \n[size=16][b]1 关注refresh_interval参数[/b][/size]\n\n这个间隔通过参数index.refresh_interval设置，既可以在Elasticsearch配置文件里全局设置，也可以针对每一个索引库单独设置。如果同时设置，索引库设置会覆盖全局配置。默认值是1s，因此最新索引的文档最多不超过1s后即可搜索到。\n\n因为刷新是非常昂贵的操作，提升索引吞吐量的方式之一就是增大refresh_interval；更少的刷新意味着更低的负载，并且更多的资源可以向索引线程倾斜。因此，根据搜索需求，可以考虑设置刷新间隔为大于1秒的值；甚至可以考虑在某些时候，比如执行批量索引时，临时关闭索引库的刷新操作，执行结束后再手动打开。\n\n更新设置API可以在批量索引时动态改变索引以便更加高效，然后再修改为更加实时的索引状态。在批量索引开始前，设置：[code]curl -XPUT 'localhost:9200/test/_settings' -d '{\n   \u0026quot;index\u0026quot; : {\n       \u0026quot;refresh_interval\u0026quot; : \u0026quot;-1\u0026quot;\n   }\n}'[/code]\n如果要做一次较大的批量导入，可以考虑设置index.number_of_replicas: 0来禁止副本。当设置了副本后，整个文档会被发送到副本节点，并重复索引过程；这意味着每个副本都会执行分析、索引及可能的合并操作。反之，如果索引时设置0副本，完成后再打开副本支持，恢复过程实质上只是一个网络字节流传输的过程，这比重复索引过程要高效得多了。[code]curl -XPUT 'localhost:9200/my_index/_settings' -d ' {\n   \u0026quot;index\u0026quot; : {\n       \u0026quot;number_of_replicas\u0026quot; : 0\n   }\n}'[/code]\n然后一旦批量索引完成，即可更新设置（比如恢复成默认设置）：[code]curl -XPUT 'localhost:9200/my_index/_settings' -d '{\n   \u0026quot;index\u0026quot; : {\n       \u0026quot;refresh_interval\u0026quot; : \u0026quot;1s\u0026quot;\n   } \n}'[/code]\n并且可以强制触发一次合并：[code]curl -XPOST 'localhost:9200/my_index/_forcemerge?max_num_segments=5'[/code]\n刷新API支持显式地刷新一个或多个索引库，以便让上次刷新后的所有操作完成并可被搜索感知。实时或近实时能力取决于所使用的索引引擎。比如，内置引擎要求显式调用刷新，而默认地刷新是周期性执行的。[code]curl -XPOST 'localhost:9200/my_index/_refresh'[/code]\n\n[size=16][b] 2 段与合并[/b][/size]\n\n段合并是一个计算开销较大的操作，而且会消耗大量的磁盘I/O。由于合并操作比较耗时，尤其是较大的段，所以一般设定为后台执行；这也没什么太大问题，因为大段的合并相对还是比较少的。\n\n但也有时候，合并速率会低于生产速率；一旦如此，Elasticsearch将会自动地限流索引请求到一个单一线程。这能阻止段爆发问题，否则在合并前可能会生成数百个段。\n\nElasticsearch在这里默认是比较保守的：不希望搜索性能受到后台合并操作的挤兑；但有时（尤其是使用SSD，或写日志的场景）节流限制会过低。\n\n默认的20 MB/s对于传统机械磁盘是一个挺不错的设置；如果使用SSD，可能要考虑加大该设置到100–200 MB/s。[code]curl -XPUT 'localhost:9200/test/_settings' -d '{\n   \u0026quot;index\u0026quot; : {\n       \u0026quot;refresh_interval\u0026quot; : \u0026quot;-1\u0026quot;\n   }\n}'[/code]\n如果正在做批量导入，且根本不介意搜索，就可以彻底关闭合并限流；这样索引操作就会根据磁盘的速率尽可能快地执行：[code]curl -XPUT 'localhost:9200/_cluster/settings' -d '{\n   \u0026quot;transient\u0026quot; : {\n       \u0026quot;indices.store.throttle.type\u0026quot; : \u0026quot;none\u0026quot; \n   }\n}'[/code]\n设置限流类型为none就可以完全关闭合并限流；等批量导入完成后再恢复该配置项为merge。[code]curl -XPUT 'localhost:9200/_cluster/settings' -d '{\n   \u0026quot;transient\u0026quot; : {\n       \u0026quot;indices.store.throttle.type\u0026quot; : \u0026quot;merge\u0026quot; \n   }\n}'[/code]\n注意：上面的设置只适用于Elasticsearch 1.X版本，Elasticsearch 2.X移除了索引级别的速率限制（indices.store.throttle.type、 indices.store.throttle.max_bytes_per_sec、index.store.throttle.type、 index.store.throttle.max_bytes_per_sec），下沉到Lucene的ConcurrentMergeScheduler，以自动管理限流。\n\n合并调度器（ConcurrentMergeScheduler）在需要时会控制合并操作的执行。合并操作运行在独立的线程池中，一旦达到最大线程数，更多的合并请求将会阻塞等待，直到有可用的合并线程。\n\n合并调度器支持下列动态设置： \nindex.merge.scheduler.max_thread_count\n\n最大线程数默认为 Math.max(1,Math.min(4,Runtime.getRuntime().availableProcessors() / 2))，对于固态硬盘（SSD）工作得很好；如果使用传统机械硬盘，则降低到1。\n\n机械介质在并发I/O方面有较大的时间开销，因此需要减少线程数，以便能按索引并发访问磁盘。该设置允许每次有max_thread_count + 2个线程操作磁盘，所以设置为1表示支持3个线程。\n\n如果使用机械硬盘而不是SSD，就要在elasticsearch配置文件中加入以下配置： \nindex.merge.scheduler.max_thread_count: 1\n\n当然也可以为单个索引库设置：[code]curl -XPUT 'localhost:9200/my_index/_settings' -d '{ \n   \u0026quot;index.merge.scheduler.max_thread_count\u0026quot; : 1\n}'[/code]\n为所有已创建的索引库设置：[code]curl -XPUT 'localhost:9200/_settings' -d '{ \n    \u0026quot;index.merge.scheduler.max_thread_count\u0026quot; : 1\n}'\n\n[/code]\n[size=16][b] 3 事务日志的清理[/b][/size]\n\n在节点挂掉时事务日志可以防止数据丢失，设计初衷是帮助在flush时原本丢失的分片恢复运行。该日志每5秒，或者在每个索引、删除、更新或批量请求（不管先后顺序）完成时，会提交到磁盘一次。\n\n对Lucene的变更仅会在一次Lucene提交后持久化到磁盘，Lucene提交是比较重量级的操作，索引不能再每个索引或删除操作后就执行。当进程退出或硬件故障时，一次提交后或另一次提交前的变更将会丢失。\n\n为防止这些数据丢失，每个分片有一个事务日志，或者与之关联的预写日志。任何索引或删除操作，在内置的Lucene索引处理完成后都是写到事务日志中。崩溃发生后，就可以从事务日志回放最近的事务来恢复分片。\n\nElasticsearch的flush操作，本质上是执行了一次Lucene提交并启动了一个新的事务日志；这些都是在后台自动完成的，目的是确保事务日志不会变得过大，否则恢复数据期间的回放操作可能需要消耗相当长的时间。这个功能同样暴露了一个API供调用，虽然很少需要手动触发。\n\n与刷新（refresh）一个索引分片相比，真正昂贵的操作是flush其事务日志（这涉及到Lucene提交）。Elasticsearch基于许多随时可变的定时器来执行flush。通过延迟flush或者彻底关闭flush可以提升索引吞吐量。不过并没有免费的午餐，延迟flush最终实际执行时显然会消耗更长的时间。\n\n下列可动态更新的配置控制着内存缓存刷新到磁盘的频率：\n\nindex.translog.flush_threshold_size - 一旦事务日志达到这个值，就会发生一次flush；默认值为512mb。\n\nindex.translog.flush_threshold_ops - 在多少操作后执行flush，默认无限制。\n\nindex.translog.flush_threshold_period - 触发一次flush前的等待时间，不管日志大小，默认值为30分钟。\n\nindex.translog.interval - 检查是否需要flush的时间间隔，随机在该时间到2倍之间取值，默认为5秒。\n\n可以把index.translog.flush_threshold_size的值从默认值的512MB调大比如到1GB，这样在一次flush发生前就可以在日志中积累更大的段。通过构建更大的段，就可以减少flush的次数以及大段的合并次数。所有这些措施加起来就会减少磁盘I/O并获得更好的索引效率。\n\n当然，这需要一定数量的可用堆内存，用于额外的缓存空间，所以调整此类配置时请注意这一点。\n\n\n[size=16][b] 4 索引缓冲区的容量规划[/b][/size]\n\n索引缓冲区用于存储新的索引文档，如果满了，缓冲区的文档就会写到磁盘上的一个段。节点上所有分片的缓冲区都是独立的。\n\n下列配置项是静态的，并且必须在集群的每个数据节点上都配置：\n\nindices.memory.index_buffer_size - 可设置为百分比或者字节数大小，默认是10%，表示总内存的10%分配给该节点，作为索引缓冲区大小，全局共享。\n\nindices.memory.min_index_buffer_size - 如果index_buffer_size设置为百分比，那么这项配置用于指定一个绝对下限，默认是48MB。\n\nindices.memory.max_index_buffer_size - 如果index_buffer_size设置为百分比，那么这项配置用于指定一个绝对上限，默认是无限制。\n\n配置项indices.memory.index_buffer_size定义了可供索引操作使用的堆内存百分比（剩余堆内存将主要用于检索操作）。如果要索引很多数据，默认的10%可能会太小，有必要调大该值。\n\n\n[size=16][b]5 索引和批量操作的线程池大小[/b][/size]\n\n接下来试试在节点级别调大索引和批量操作的线程池大小，看看否带来性能提升。\n\nindex - 用于索引和删除操作。线程类型是固定大小的（fixed)，默认大小是可用处理器核数，队列大小queue_size是200，该线程池最大为1+可用处理器核数。\n\nbulk - 用于批量操作。线程类型是固定大小的，默认大小是可用处理器核数，队列大小是50，线程池最大为1+可用处理器核数。\n\n单个分片与独立的Lucene是一个层次，因此同时执行索引的并发线程数是有上限的，在Lucene中默认是8，而在ES中可以通过index.index_concurrency配置项来设置。\n\n在为该参数设置默认值时应当多想一想，特别是对于往一个索引库索引数据时，一个节点只有一个分片的情况。\n\n由于索引/批量线程池可以保护和控制并发，所以大部分时候都可以考虑调大默认值；尤其是对于节点上没有其他分片的情况（评估是否值得），可以考虑调大该值。\n\n\n[size=14][b]关于译者[/b][/size]\n[quote]\n杨振涛\n\nvivo互联网搜索引擎团队负责人，开发经理。10年数据和软件领域经验，先后从事基因测序、电商、IM及厂商互联网领域的系统架构设计和实现。专注于实时分布式系统和大数据的存储、检索和可视化，尤其是搜索引擎及深度学习在NLP方向的应用。技术翻译爱好者，TED Translator，InfoQ中文社区编辑。\n[/quote]\n \n \n未经授权，禁止转载。\n \n英文原文地址：[url]https://qbox.io/blog/maximize-guide-elasticsearch-indexing-performance-part-2[/url] ","title":"【翻译】Elasticsearch索引性能优化（2）","uid":"54","views":"1695","votes":"6"},"_type":"doc"}
{"_id":"316","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508118177","category_id":"18","comments":"0","has_attach":"0","id":"316","message":"1.老文新发，讲述百度搜索架构的优化历程，其中很多经验值得在使用es中注意。\nhttp://t.cn/R4wpIvT\n2.logTrail，一款kibana 日志可视化展插件。\nhttp://t.cn/RcXglR2\n3.斗鱼的elk实践发展史。\nhttp://t.cn/ROHWPdu\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/316\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第71期 (2017-10-16)","uid":"4063","views":"459","votes":"0"},"_type":"doc"}
{"_id":"319","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508287543","category_id":"18","comments":"0","has_attach":"0","id":"319","message":"1. 基于 ELKB 搭建实时日志分析平台\n[url]http://t.cn/RCeSfaP[/url] \n2. 通过 Nginx 给 ES 加一个安全的外衣\n[url]http://t.cn/ROB4eiQ[/url] \n3. 来自 db-engines 的 ES 与 Redis对比\n[url]http://t.cn/ROBqcYF[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/319[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第73期 (2017-10-18)","uid":"3828","views":"543","votes":"0"},"_type":"doc"}
{"_id":"323","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508434725","category_id":"2","comments":"5","has_attach":"1","id":"323","message":"为了KPI、为了集群的稳定性，为了集群出问题后进行回溯追踪，为了能够更早的发现集群的瓶颈，\n答案就在。。。\n \n [url]http://rickywag.com/archives/506[/url]\n \n\n[attach]1162[/attach]\n ","title":"Elasticsearch监控（理论篇）","uid":"2363","views":"1069","votes":"2"},"_type":"doc"}
{"_id":"327","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508627826","category_id":"18","comments":"0","has_attach":"0","id":"327","message":"1.从Solr迁移到Elasticsearch，常用Solr查询翻译成Elasticsearch示例。\nhttp://t.cn/RWLyKiM\n2.Postgres扩展，使用Elasticsearch创建索引。\nhttp://t.cn/RWLypo7\n3.如何将数据从Splunk迁移至ELK Stack。\nhttp://t.cn/RWLylxJ\n活动预告：Elastic 长沙交流会 \nhttps://elasticsearch.cn/article/320\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/327\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第77期 (2017-10-22)","uid":"4460","views":"428","votes":"0"},"_type":"doc"}
{"_id":"328","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508726931","category_id":"18","comments":"0","has_attach":"0","id":"328","message":"1.每个工程师都应该知道的搜索细节。(自备梯子)\nhttp://t.cn/RWbkpJT\n\n2.使用Rsyslog配置logstash收集日志。\nhttp://t.cn/RtlA8gh\n\n3.使用ELK Stack收集jenkins构建日志。\n[url]http://t.cn/RWGhqav[/url] \n\n活动预告：Elastic 长沙交流会\n[url]https://elasticsearch.cn/article/320[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/328\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第78期 (2017-10-23)","uid":"4063","views":"441","votes":"0"},"_type":"doc"}
{"_id":"337","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509018418","category_id":"2","comments":"0","has_attach":"1","id":"337","message":"[b]一，单index,单type[/b]\r\n未来发布的elasticsearch 6.0.0版本为保持兼容，仍然会支持单index，多type结构，但是作者已不推荐这么设置。在elasticsearch 7.0.0版本必须使用单index,单type，多type结构则会完全移除。\r\n针对这一问题，elasticsearch 作者的讨论：\r\nhttps://github.com/elastic/elasticsearch/pull/24317\r\n[url]https://www.elastic.co/guide/en/elasticsearch/reference/5.6/removal-of-types.html[/url]\r\n \r\n[b]二，单index，多type结构弊端[/b]\r\n人们经常会谈到index类似传统sql数据库的“database”,而type类似于\u0026quot;table\u0026quot;。现在想想，这是一个非常糟糕的比喻，而这个比喻会造成很多错误的假设。\r\n在传统的sql数据库中，各个\u0026quot;table\u0026quot;之间是互相独立的，在一个表中的列都与另一个表相同名称的列无关。\r\n①，而在我们elasticsearch中同一 Index 下，同名 Field 类型必须相同，即使不同的 Type；\r\n②， 同一 Index 下，TypeA 的 Field 会占用 TypeB 的资源（互相消耗资源），会形成一种稀疏存储的情况。尤其是 doc value ，为什么这么说呢？doc value为了性能考虑会保留一部分的磁盘空间，这意味着 TypeB 可能不需要这个字段的 doc_value 而 TypeA 需要，那么 TypeB 就被白白占用了一部分没有半点用处的资源；\r\n③，Score 评分机制是 index-wide 的，不同的type之间评分也会造成干扰。\r\n④，索引元数据本身是放在主节点中维护的，CP 设计。意味着涉及到大量字段变更及元数据变更的操作，都会导致该 Index 被堵塞或假死。我们应该对这样的 Index 做隔离，避免影响到其他 Index 正常的增删改查。甚至当涉及到字段变更十分频繁且无法预定义 schema 的场景时，是否要使用 ES 都应该慎思熟虑了！\r\n \r\n[b]三，doc value 扩展介绍[/b]\r\n \r\n参见官方文档[url=https://www.elastic.co/guide/en/elasticsearch/guide/current/docvalues-intro.html]docvalues[/url]\r\n先看倒排索引组织结构大致如下：\r\n\r\n[attach]1178[/attach]\r\n \r\n如果我要查询包含 brown 的文档有哪些？这个就是全文检索了，也相当好办，先从词典里遍历到 brown 这个单词，然后根据倒排索引查得 Doc_1 和 Doc_2 包含这个单词。\r\n如果我要查 Doc_1 和 Doc_2 包含的单词分别有什么？这个用倒排索引的话开销会非常大，至少是要将整张表关于 Doc_1 和 Doc_2 的列数据遍历一遍才行。这时候我们将数据换一种组织形式，将会起到非常好的效果。\r\n\r\n[b][attach]1179[/attach][/b]\r\n\r\nDoc_1 和 Doc_2 存了什么单词，一目了然。我们把这种数据的组织方式叫做doc_value。\r\n倒排索引的特点很明显，就是为了全文检索而生的，但是对于一些聚合查询（排序、求平均值等等）的场景来说，显然不适用。那么这样一来我们为了应对一些聚合场景就需要结构化数据来应付，这里说的结构化数据就是『列存储』，也就是上面说的doc_value。\r\ndoc_value在 ES 中有几个应用场景：\r\n \r\n对某个字段排序；\r\n某个字段聚合查询（ max/min/count ）；\r\n部分过滤器 （ 地理位置过滤器 ）；\r\n某个字段的脚本执行。等等。\r\n \r\ndoc_value是顺序存储到磁盘的，因此访问是很快的。当我们所处理的集合小于所给的 JVM 堆内存，那么整个数据集合是会被加载到内存里的；如果数据集合大于所给的堆内存，那么就会分页加载到内存之中，而不会报出『OutOfMemory Error』。\r\n \r\n值得一提的是，doc_value的字段使用极其频繁，因此在5.x 版本后强化成为两个字段，分别是 text 和 keyword。\r\ntext：string 类型，支持倒排索引，不支持 doc_value；\r\nkeyword：string 类型，不支持倒排索引，支持doc_value。\r\n \r\n四：参考\r\n①：[url=https://leonlibraries.github.io/2017/04/27/ElasticSearch%E5%86%85%E9%83%A8%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90%E4%B8%89/]ElasticSearch 内部机制浅析[/url]\r\n \r\n \r\n ","title":"【拓展篇】Elasticsearch 6.0 一个索引只允许有一个type","uid":"6245","views":"3744","votes":"3"},"_type":"doc"}
{"_id":"346","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509430237","category_id":"8","comments":"3","has_attach":"1","id":"346","message":"[attach]1200[/attach]\n[attach]1201[/attach]\n ","title":"[分享]Kibana，Elasticsearch 指令速查","uid":"1","views":"2765","votes":"2"},"_type":"doc"}
{"_id":"353","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509843611","category_id":"18","comments":"1","has_attach":"0","id":"353","message":"1.(自备梯子)让你成为优秀数据科学家的45种方法。\nhttp://t.cn/RWeyM6d\n2.(自备梯子)非常全面的介绍ElasticSearch的特点，使用案例和推荐书籍。\nhttp://t.cn/RlfRbkm\n3.使用Kubernetes管理日志记录。\nhttp://t.cn/RlfRcwf\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/353\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第91期 (2017-11-05)","uid":"4460","views":"412","votes":"0"},"_type":"doc"}
{"_id":"354","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509933535","category_id":"18","comments":"0","has_attach":"0","id":"354","message":"1.基于es数据使用tableu。\nhttp://t.cn/Rl6ZoRX\n\n2.在vscode中调试es查询语句。\n[url]http://t.cn/Rlio50B[/url] \n\n3.全面介绍韩语分词器。\n[url]http://t.cn/Rli9inA[/url] \n\n编辑：cybredak\n归档：https://elasticsearch.cn/article/354\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第92期 (2017-11-06)","uid":"4063","views":"378","votes":"0"},"_type":"doc"}
{"_id":"358","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510033998","category_id":"12","comments":"2","has_attach":"0","id":"358","message":"工作地点：北京\n薪资待遇：25k ~ 40k\n工作内容：\n1、开发、维护ES及相应管理后台\n2、ElasticSearch集群的配置管理及优化\n3、个性化功能及插件开发。\n\n职位要求：\n1、本科以上学历，4年以上工作经验。\n2、精通Java，熟悉各种中间件技术及常用框架。\n3、熟悉Elasticsearch，有相应开发维护经验者优先。\n\n京东正大力推进Elasticsearch的使用场景，目前已有数千个实例，每日新增数据百T，日查询量千亿级别，技术氛围好,发展潜力大。欢迎您的加入~\n\n欢迎投递简历至：wanghanghang@jd.com\n ","title":"【京东商城】ES高级工程师","uid":"4890","views":"1587","votes":"3"},"_type":"doc"}
{"_id":"359","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510049394","category_id":"5","comments":"1","has_attach":"0","id":"359","message":"好消息来啦！好消息来啦！好消息来啦！\n \n如果你是创业公司的员工，并且你们在使用 elastic 的产品解决自己的业务问题，比如 elasticsearch、kibana、logstash 等，又对 X-Pack 很感兴趣，现在可以申请初创公司优惠价格了，真的很优惠，走过路过不要错过！\n \n初创公司定义为：\n1. 公司人数50人以内\n2. 年销售额500万以内\n3. 注册资金2500万以内。\n \n申请方式为：\n \n访问 [url]http://elastictech.cn[/url] ，点击右上角的【创业公司优惠申请】链接填写相关信息即可！","title":"Elastic XPack 对初创公司开放优惠申请啦！","uid":"6028","views":"1219","votes":"0"},"_type":"doc"}
{"_id":"360","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510107883","category_id":"18","comments":"0","has_attach":"0","id":"360","message":"1. 剖析 Elasticsearch 集群系列\nPart1 [url]http://t.cn/R5eAIJz[/url] \nPart2 [url]http://t.cn/RtCo3Sw[/url] \nPart3 [url]http://t.cn/Rt0avHj[/url] \n2. Siddontang 大神的 Elasticsearch学习笔记（在 github 上，版本不是很新，仅供参考）\n[url]http://t.cn/Rl0kKfd[/url] \n3. Elasticsearch 数据备份，恢复，及迁移（2015年文章）\n[url]http://t.cn/RL3YX6g[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/360[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第94期 (2017-11-08)","uid":"3828","views":"417","votes":"1"},"_type":"doc"}
{"_id":"364","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510207073","category_id":"16","comments":"1","has_attach":"1","id":"364","message":"Elastic Meetup 线下交流活动再次来到羊城广州，算是社区在广州的第二次线下聚会了，广州的小伙伴们，快快报名吧！\n回顾去年的线下活动，可以点击这里：https://elasticsearch.cn/article/71​\n \n[attach]1245[/attach]\n\n## 主办：\n本次活动由 `Elastic` 与 `网易游戏运维与基础架构部` 联合举办。\n \n## 媒体：\n本次活动由 `IT大咖说` 独家提供现场直播。\n \n## 时间：\n2017.11.25​  下午2:00-5:00（1点半开始签到）\n \n## 地点：\n广州市天河区科韵路16号广州信息港E栋网易大厦 一楼博学堂\n \n## 主题：\n\n1. 网易 - 杜鑫 - ELK在藏宝阁中的应用\n1. 酷狗 - 钟旺 - 基于ES的音乐搜索引擎 \n1. 阿里云 - 赵弘扬 - Elasticsearch在阿里云的实践分享\n1. 网易 - 林邦骏 - 网易ELK 系统综述\n1. 数说故事 - 吴文杰 - Data Warehouse with ElasticSearch in Datastory\n1. 闪电分享（5-10分钟，可现场报名） \n\n\n## 参会报名：\nhttp://elasticsearch.mikecrm.com/O6o0yq3\n \n## 现场直播：\n\n直播连接：http://www.itdks.com/eventlist/detail/1673\n[attach]1284[/attach]\n\n\n## 主题介绍：\n\n### ELK在藏宝阁中的应用 \n\n#### 内容介绍：\n 1. 藏宝阁项目介绍\n 主要介绍一下藏宝阁项目，让不熟悉藏宝阁的听众有一个基本的了解，熟悉应用的背景。\n\n2. ELK在藏宝阁中的应用（概述）\n 大致简要的阐述一下ELK在藏宝阁中哪些地方发挥了什么样的作用。\n\n3. ELK在藏宝阁推荐系统中的应用（重点）\n 较为详细的剖析一下ELK在推荐系统中的发挥的作用，具备的优势。\n\n#### 分享嘉宾：\n\n[attach]1285[/attach]\n\n杜鑫，网易藏宝阁工作室资深开发工程师，目前主要从事藏宝阁推荐业务相关的研发工作。\n \n\n### 网易ELK 系统综述\n\n#### 内容介绍：\n \n从架构以及功能两个角度去阐述网易的 ELK 平台，介绍系统内部各个组件及其管理方式。进而以用户的视角介绍平台中包含的自动化服务等功能，从管理员的视角去讨论组件的配置管理、资源调度回收等问题。\n\n#### 分享嘉宾：\n\n[attach]1269[/attach]\n\n\n林邦骏，网易 GDC产品组资深运维工程师，主要负责内部 ELK 产品的运维、功能开发等工作。\n \n### 基于ES的音乐搜索引擎\n\n#### 内容介绍：\n\n1、酷狗音乐搜索引擎架构变迁\n\n2、构建音乐搜索引擎经验之谈 \n\n#### 分享嘉宾：\n\n[attach]1274[/attach]\n\n钟旺，酷狗后台开发工程师，从事JAVA、ES相关的开发工作。\n \n\n### Data Warehouse with ElasticSearch in Datastory\n\n#### 内容介绍：\n\nES最多使用的场景是搜索和日志分析，然而ES强大的实时索引查询、全文检索和聚合能力也能成为数据仓库与OLAP场景的强力支持。\n\n本次分享将为大家带来数说故事如何借助ES和Hadoop生态在不同的数据场景下构建起数据仓库能力。\n\n#### 分享嘉宾：\n\n[attach]1270[/attach]\n\n吴文杰 ，数说故事平台架构团队 高级工程师，负责数说故事百亿级数据的存储查询及内部基础平台建设。\n \n\n### Elasticsearch在阿里云的实践分享\n#### 内容介绍\n\n介绍阿里云Elastiserach服务的技术架构和Xpack相关功能，并分享在云上环境搭建ELK的实践案例。\n\n#### 分享嘉宾\n\n[attach]1271[/attach]\n\n赵弘扬，阿里巴巴搜索产品专家，负责阿里云搜索产品规划和开发。\n\n-----\n \n深圳也在筹备中，可以提前报名！：https://elasticsearch.cn/article/261\n \n\n---\n\n## 关于 Elastic Meetup\n\nElastic Meetup 由 Elastic 中文社区定期举办的线下交流活动，主要围绕 Elastic 的开源产品（Elasticsearch、Logstash、Kibana 和 Beats）及周边技术，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。\n\n \n## 关于 Elastic\n\n[attach]1243[/attach]\n\nElastic 通过构建软件，让用户能够实时地、大规模地将数据用于搜索、日志和分析场景。Elastic 创立于 2012 年，相继开发了开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、X-Pack（商业功能）和 Elastic Cloud（托管服务）。截至目前，累计下载量超过 1.5 亿。Benchmark Capital、Index Ventures 和 NEA 为 Elastic 提供了超过 1 亿美元资金作为支持，Elastic 共有 600 多名员工，分布在 30 个国家/地区。有关更多信息，请访问 http://elastic.co/cn 。\n \n## 关于网易游戏运维与基础架构部\n\n[attach]1244[/attach]\n\n网易游戏运维与基础架构部， 主要负责网易游戏产品的可靠性保障以及基础设施的开发和部署，旨在：\n\n1. 专注为产品全生命周期提供可靠性保障服务，依托于大数据为运维提供决策\n2. 通过智能监控提高问题发现和解决能力，以自动化驱动低成本的业务管理\n3. 打造混合云方案，站在游戏业务角度驱动的TCO优化和运维智能化\n\n\n\n## 关于IT大咖说\n \n[attach]1242[/attach]\n\nIT大咖说，IT垂直领域的大咖知识分享平台，践行“开源是一种态度”，通过线上线下开放模式分享行业TOP大咖干货，技术大会在线直播点播，在线活动直播平台。http://www.itdks.com 。\n \n \n_ 再次感谢网易游戏运维与基础架构部和IT大咖说的大力支持! _","title":"Elastic Meetup 广州交流会","uid":"1","views":"3676","votes":"10"},"_type":"doc"}
{"_id":"492","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518162421","category_id":"2","comments":"0","has_attach":"0","id":"492","message":"\n[b][size=18]配置详解[/size][/b]\n文件中\u0026quot;mapping\u0026quot;:{}中的内容,即为创建索引的mappingsource 如：\n[code]\u0026quot;mappings\u0026quot;: {\n    \u0026quot;_default_\u0026quot; : {    //@1\n        \u0026quot;_all\u0026quot; : {\u0026quot;enabled\u0026quot; : true},    //@2\n        \u0026quot;properties\u0026quot; : {    //@3\n            \u0026quot;tableType\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},    //@4\n            \u0026quot;caption\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n            \u0026quot;code\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n            \u0026quot;description\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n            \u0026quot;perm\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;, \u0026quot;include_in_all\u0026quot; : false}\n\t\t}\n\t},\n\t\u0026quot;ec02_goodsinfo\u0026quot; : {    //@5\n\t    \u0026quot;_all\u0026quot; : {\u0026quot;enabled\u0026quot; : true},    //@6\n\t\t\u0026quot;properties\u0026quot; : {    //@7\n\t\t\t\u0026quot;tableType\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n\t\t\t\u0026quot;caption\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n\t\t\t\u0026quot;code\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n\t\t\t\u0026quot;description\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;no\u0026quot;, \u0026quot;include_in_all\u0026quot; : false, \u0026quot;store\u0026quot;: true},\n\t\t\t\u0026quot;perm\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;, \u0026quot;include_in_all\u0026quot; : false},\n\t\t\t\u0026quot;bill\u0026quot;:{    //@8\n\t\t\t\tproperties\u0026quot; : {\n\t\t                       \u0026quot;CreateYear\u0026quot; : {\u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;, \u0026quot;include_in_all\u0026quot; : true}    //@9\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}[/code]\n[list]\n[*]@1 _default_所有单据默认的创建索引的配置[/*]\n[*]@2 _all{} 每个单据下所有的字段配置，\u0026quot;enabled\u0026quot; : true 所有字段创建索引,false 所有字段禁止创建索引,[*注意]除非properties指定的字段,默认字段类型将自动匹配[/*]\n[*]@3 properties {},每个单据下字段或者properties的指定配置[/*]\n[*]@4 properties {}中指定了属性(properties):\u0026quot;tableType\u0026quot;的检索配置,type:string \u0026gt; 类型字符串,include_in_all:false \u0026gt; 改字段或者属性不包含在单据的所有字段中，\u0026quot;store\u0026quot;: true \u0026gt; 储存在数据库中[/*]\n[*]@5 ec02_goodsinfo 表示对单据 \u0026quot;ec02_goodsinfo\u0026quot; 的特定检索配置[/*]\n[*]@6 _all{} 只对\u0026quot;ec02_goodsinfo\u0026quot;单据下所有的字段配置[/*]\n[*]@7 properties {},只对\u0026quot;ec02_goodsinfo\u0026quot;单据下字段或者properties的指定配置[/*]\n[*][*注意]@8,@9 bill在单据中额字段都会包括一层bill,所以如果要对单据中某个字段指定需要套一层bill{}[/*]\n[/list]\n-----------------------------------------------------------------------------------------------------------------------------------------\n[b][size=18]属性解说[/size][/b]\n[size=14][i]版本5.X以前[/i][/size]\n[list]\n[*]index 可选值为analyzed(默认)和not_analyzed，如果是字段是字符串类型的，则可以是not_analyzed[/*]\n[*]store 可选值为yes或no，指定该字段的原始值是否被写入索引中，默认为no，即结果中不能返回该字段。[/*]\n[*]boost默认为1，定义了文档中该字段的重要性，越高越重要[/*]\n[*]null_value 如果一个字段为null值(空数组或者数组都是null值)的话不会被索引及搜索到，null_value参数可以显示替代null values为指定值，这样使得字段可以被搜索到。[/*]\n[*]include_in_all 指定该字段是否应该包括在_all字段里头，默认情况下都会包含。[/*]\n[*]type 可以指定String,long,int,doulbe,floot,boolean,等[/*]\n[/list]\n[size=14][i]版本5.X以后[/i][/size]\n[list]\n[*]原本type string,其index 可选值为analyzed(默认)和not_analyzed,现在直接拆违type text( index analyzed)，type keyword(index not_analyzed)[/*]\n[*]store 可选值为enable或false，指定该字段的原始值是否被写入索引中，默认为enable，即结果中不能返回该字段。[/*]\n[*]index 表示是否用于检索默认enable,可选false[/*]\n[/list]\n-------------------------------------------------------------------------------------------------------------------------------\n[size=18][b]字段的数据类型[/b][/size]\n[list]\n[*]简单类型string(指定分词器)[/*]\n[*]date(默认使用UTC保持,也可以使用format指定格式)[/*]\n[*]数值类型(byte,short,integer,long,float,double)[/*]\n[*]boolean[/*]\n[*]binary(存储在索引中的二进制数据的base64表示，比如图像，只存储不索引)[/*]\n[*]ip(以数字形式简化IPV4地址的使用，可以被索引、排序并使用IP值做范围查询)注意string是5.x以前的,5.x之后被分裂为text,keyword[/*]\n[/list]\n\n有层级结构的类型,比如object 或者 nested.\n特殊类型\n[list]\n[*]geo_point[/*]\n[*]geo_shape[/*]\n[*]completion[/*]\n[/list]\n ","title":"Elasticsearch mapping 配置个人解读","uid":"5030","views":"1850","votes":"4"},"_type":"doc"}
{"_id":"373","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510552713","category_id":"2","comments":"0","has_attach":"0","id":"373","message":"config/elasticsearch.yml\n\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please consult the documentation for further information on configuration options:\n# https://www.elastic.co/guide/en/elasticsearch/reference/index.html\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\n#cluster.name: my-application\ncluster.name: es5_dev\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\n#node.name: node-1\nnode.name: es5-node03\n#\n# Add custom attributes to the node:\n#\n#node.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\n#path.data: /path/to/data\n#\n# Path to log files:\n#\n#path.logs: /path/to/logs\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\n#bootstrap.memory_lock: true\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\n#network.host: 192.168.0.1\nnetwork.host: [\u0026quot;127.0.0.1\u0026quot;,\u0026quot;10.204.12.33\u0026quot;]\nhttp.port: 9201\ntransport.tcp.port: 9301\n#http.host: 127.0.0.1\n#http.enabled: false\n#\n# Set a custom port for HTTP:\n#\n#http.port: 9200\n#\n# For more information, consult the network module documentation.\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n# The default list of hosts is [\u0026quot;127.0.0.1\u0026quot;, \u0026quot;[::1]\u0026quot;]\n#\n#discovery.zen.ping.unicast.hosts: [\u0026quot;host1\u0026quot;, \u0026quot;host2\u0026quot;]\nnode.master: true\nnode.data: true\ndiscovery.zen.minimum_master_nodes: 1\ndiscovery.zen.ping.unicast.hosts:\n   - 10.204.12.31:9301\n   - 10.204.12.32:9301\n   - 10.204.12.33:9301\n#\n# Prevent the \u0026quot;split brain\u0026quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):\n#\n#discovery.zen.minimum_master_nodes: 3\n#\n# For more information, consult the zen discovery module documentation.\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\n#gateway.recover_after_nodes: 3\n#\n# For more information, consult the gateway module documentation.\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Require explicit names when deleting indices:\n#\n#action.destructive_requires_name: true\nindices.requests.cache.size: 5%\nconfig/jvm.options\n\n## JVM configuration\n################################################################\n## IMPORTANT: JVM heap size\n################################################################\n##\n## You should always set the min and max JVM heap\n## size to the same value. For example, to set\n## the heap to 4 GB, set:\n##\n## -Xms4g\n## -Xmx4g\n##\n## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html\n## for more information\n##\n################################################################\n# Xms represents the initial size of total heap space\n# Xmx represents the maximum size of total heap space\n-Xms2g\n-Xmx2g\n################################################################\n## Expert settings\n################################################################\n##\n## All settings below this section are considered\n## expert settings. Don't tamper with them unless\n## you understand what you are doing\n##\n################################################################\n## GC configuration\n-XX:+UseConcMarkSweepGC\n-XX:CMSInitiatingOccupancyFraction=75\n-XX:+UseCMSInitiatingOccupancyOnly\n## optimizations\n# pre-touch memory pages used by the JVM during initialization\n-XX:+AlwaysPreTouch\n## basic\n# force the server VM (remove on 32-bit client JVMs)\n-server\n# explicitly set the stack size (reduce to 320k on 32-bit client JVMs)\n-Xss1m\n# set to headless, just in case\n-Djava.awt.headless=true\n# ensure UTF-8 encoding by default (e.g. filenames)\n-Dfile.encoding=UTF-8\n# use our provided JNA always versus the system one\n-Djna.nosys=true\n# use old-style file permissions on JDK9\n-Djdk.io.permissionsUseCanonicalPath=true\n# flags to configure Netty\n-Dio.netty.noUnsafe=true\n-Dio.netty.noKeySetOptimization=true\n-Dio.netty.recycler.maxCapacityPerThread=0\n# log4j 2\n-Dlog4j.shutdownHookEnabled=false\n-Dlog4j2.disable.jmx=true\n-Dlog4j.skipJansi=true\n## heap dumps\n# generate a heap dump when an allocation from the Java heap fails\n# heap dumps are created in the working directory of the JVM\n-XX:+HeapDumpOnOutOfMemoryError\n# specify an alternative path for heap dumps\n# ensure the directory exists and has sufficient space\n#-XX:HeapDumpPath=${heap.dump.path}\n## GC logging\n#-XX:+PrintGCDetails\n#-XX:+PrintGCTimeStamps\n#-XX:+PrintGCDateStamps\n#-XX:+PrintClassHistogram\n#-XX:+PrintTenuringDistribution\n#-XX:+PrintGCApplicationStoppedTime\n# log GC status to a file with time stamps\n# ensure the directory exists\n#-Xloggc:${loggc}\n# By default, the GC log file will not rotate.\n# By uncommenting the lines below, the GC log file\n# will be rotated every 128MB at most 32 times.\n#-XX:+UseGCLogFileRotation\n#-XX:NumberOfGCLogFiles=32\n#-XX:GCLogFileSize=128M\n# Elasticsearch 5.0.0 will throw an exception on unquoted field names in JSON.\n# If documents were already indexed with unquoted fields in a previous version\n# of Elasticsearch, some operations may throw errors.\n#\n# WARNING: This option will be removed in Elasticsearch 6.0.0 and is provided\n# only for migration purposes.\n#-Delasticsearch.json.allow_unquoted_field_names=true\n\n\n\n安装ik分词器\n\n\nbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.5.1/elasticsearch-analysis-ik-5.5.1.zip\n\n\n\n\n./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.6.3/elasticsearch-analysis-ik-5.6.3.zip\n\n\n\n配置ik远程扩展词典用于热词更新　elasticsearch-5.6.3/config/analysis-ik/IKAnalyzer.cfg.xml\n\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\n\u0026lt;!DOCTYPE properties SYSTEM \u0026quot;http://java.sun.com/dtd/properties.dtd\u0026quot;\u0026gt;\n\u0026lt;properties\u0026gt;\n       \u0026lt;comment\u0026gt;IK Analyzer 扩展配置\u0026lt;/comment\u0026gt;\n       \u0026lt;!--用户可以在这里配置自己的扩展字典 --\u0026gt;\n       \u0026lt;entry key=\u0026quot;ext_dict\u0026quot;\u0026gt;\u0026lt;/entry\u0026gt;\n        \u0026lt;!--用户可以在这里配置自己的扩展停止词字典--\u0026gt;\n       \u0026lt;entry key=\u0026quot;ext_stopwords\u0026quot;\u0026gt;\u0026lt;/entry\u0026gt;\n       \u0026lt;!--用户可以在这里配置远程扩展字典 --\u0026gt;\n       \u0026lt;entry key=\u0026quot;remote_ext_dict\u0026quot;\u0026gt;http://distribute.search.leju.com:8888/remotedic/ik_remote_ext.dic\u0026lt;/entry\u0026gt;\n       \u0026lt;!--用户可以在这里配置远程扩展停止词字典--\u0026gt;\n       \u0026lt;!-- \u0026lt;entry key=\u0026quot;remote_ext_stopwords\u0026quot;\u0026gt;words_location\u0026lt;/entry\u0026gt; --\u0026gt;\n\u0026lt;/properties\u0026gt;\n安装拼音分词器\n\ncd elasticsearch-5.5.1/plugins\nwget https://github.com/medcl/elasticsearch-analysis-pinyin/releases/tag/v5.5.1\nunzip v5.5.1\n\n\n\n\n打包部署其他节点时，先清理data目录\n\n\n\n\n集群监控可以利用head的chrome插件\n\n\n\n\n数据迁移\n\n迁移工具是自己写的elasticbak，目前更新了5.6.3驱动。github链接：https://github.com/jiashiwen/elasticbak。\n\n数据备份\n\njava -jar elasticbak-2.3.3.jar \\\n--exp \\\n--cluster lejuesdev \\\n--host 10.204.12.31 \\\n--filesize 1000 \\\n--backupdir ./esbackupset \\\n--backupindexes \u0026quot;*\u0026quot; \\\n--threads 4\n由于版本field的变化需要手工重建索引，这里举个例子，主要是2.x版本的string需要改为text。2.x版本我们通过index参数指定该字段是否被索引(\u0026quot;index\u0026quot;: \u0026quot;no\u0026quot;)以及是否通过分词器分词(\u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;)。在5.X版本里index只用来制定是否创建索引，如果需要整个字段不过分词器创建索引，需要通过keyword字段完成。  \n\n \n\ncurl -XPUT \u0026quot;http://10.204.12.31:9201/house_geo\u0026quot; -H 'Content-Type: application/json' -d'\n{\n \u0026quot;mappings\u0026quot;: {\n   \u0026quot;house\u0026quot;: {\n     \u0026quot;dynamic\u0026quot;: \u0026quot;strict\u0026quot;,\n     \u0026quot;_all\u0026quot;: {\n       \u0026quot;enabled\u0026quot;: false\n     },\n     \u0026quot;properties\u0026quot;: {\n       \u0026quot;_category\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n                 \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;_content\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n         \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n       },\n       \u0026quot;_deleted\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;boolean\u0026quot;,\n         \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;_doccreatetime\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;format\u0026quot;: \u0026quot;strict_date_optional_time||epoch_millis||yyyy/MM/dd HH:mm:ss||yyyy/MM/dd\u0026quot;\n       },\n       \u0026quot;_docupdatetime\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;format\u0026quot;: \u0026quot;strict_date_optional_time||epoch_millis||yyyy/MM/dd HH:mm:ss||yyyy/MM/dd\u0026quot;\n       },\n       \u0026quot;_flags\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;analyzer\u0026quot;: \u0026quot;whitespace\u0026quot;\n       },\n       \u0026quot;_hits\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;\n       },\n       \u0026quot;_location\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n       },\n       \u0026quot;_multi\u0026quot;: {\n         \u0026quot;properties\u0026quot;: {\n           \u0026quot;_location\u0026quot;: {\n             \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n           }\n         }\n       },\n       \u0026quot;_origin\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n         \u0026quot;enabled\u0026quot;: false\n       },\n       \u0026quot;_scope\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n         \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;_tags\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n         \u0026quot;boost\u0026quot;: 10,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n         \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n         \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n       },\n       \u0026quot;_title\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n         \u0026quot;store\u0026quot;: true,\n         \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n         \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n       },\n       \u0026quot;_uniqid\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n         \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;_uniqsign\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;,\n         \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;_url\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n         \u0026quot;index\u0026quot;: false,\n         \u0026quot;store\u0026quot;: true\n       },\n       \u0026quot;location\u0026quot;: {\n         \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\n       }\n     }\n   }\n },\n \u0026quot;settings\u0026quot;: {\n   \u0026quot;index\u0026quot;: {\n     \u0026quot;number_of_shards\u0026quot;: \u0026quot;3\u0026quot;,\n     \u0026quot;requests\u0026quot;: {\n       \u0026quot;cache\u0026quot;: {\n         \u0026quot;enable\u0026quot;: \u0026quot;true\u0026quot;\n       }\n     },\n     \u0026quot;analysis\u0026quot;: {\n       \u0026quot;filter\u0026quot;: {\n         \u0026quot;my_synonym\u0026quot;: {\n           \u0026quot;type\u0026quot;: \u0026quot;synonym\u0026quot;,\n           \u0026quot;synonyms_path\u0026quot;: \u0026quot;analysis-ik/custom/synonym.dic\u0026quot;\n         }\n       },\n       \u0026quot;analyzer\u0026quot;: {\n         \u0026quot;searchanalyzer\u0026quot;: {\n           \u0026quot;filter\u0026quot;: \u0026quot;my_synonym\u0026quot;,\n           \u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\n           \u0026quot;tokenizer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n         },\n         \u0026quot;indexanalyzer\u0026quot;: {\n           \u0026quot;filter\u0026quot;: \u0026quot;my_synonym\u0026quot;,\n           \u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\n           \u0026quot;tokenizer\u0026quot;: \u0026quot;ik_max_word\u0026quot;\n         }\n       }\n     },\n     \u0026quot;number_of_replicas\u0026quot;: \u0026quot;1\u0026quot;\n   }\n }\n}'\n利用新版elasticbak导入索引数据\n\n\njava -jar elasticbak-5.6.3.jar \\\n--imp \\\n--cluster es5_dev \\\n--host 10.204.12.31 \\\n--port 9301 \\\n--restoreindex house_geo \\\n--restoretype dataonly \\\n--backupset esbackupset/house_geo \\\n--threads 4\n ","title":"从es2.3到5.6的迁移实践","uid":"6713","views":"1725","votes":"1"},"_type":"doc"}
{"_id":"384","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510876489","category_id":"18","comments":"0","has_attach":"0","id":"384","message":"1、揭秘 | 影响Elasticsearch存储的关键因素\nhttp://t.cn/RS2kgfB\n2、索引膨胀的原因大讨论\nhttp://t.cn/RjxtXPs\n3、旧闻新读 | IK分词作者林良益访谈实录\nhttp://t.cn/RjomL5I\n4、只等你来 | Elastic Meetup 广州交流会\nhttps://elasticsearch.cn/article/364\n\n编辑：laoyang360\n归档：https://elasticsearch.cn/article/384\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第103期 (2017-11-17)","uid":"1341","views":"455","votes":"0"},"_type":"doc"}
{"_id":"1","_index":"forum-mysql","_score":1,"_source":{"addtime":"1425951139","category_id":"9","comments":"17","has_attach":"0","id":"1","message":"![cover](https://raw.githubusercontent.com/looly/elasticsearch-definitive-guide-cn/master/cover_small.jpg)\n\n本来想自己翻译这本书的，但是发现章节的数量已经超出能力范围，每天时间也有限，在不断的努力以及几个热心人的参与下，完成了6章的翻译。如果你对Elasticsearch感兴趣或者在工作中有用，那就关注我们的翻译。有兴趣的也可以fork后提交Pull Request。当然，我觉得前6章入门已经够用，如果你想学习也可以关注我们的翻译。\n\nGithub地址： https://github.com/looly/elasticsearch-definitive-guide-cn\n\nGit@OSC地址： http://git.oschina.net/loolly/elasticsearch-definitive-guide-cn\n\nGitBook阅读地址： http://es.xiaoleilu.com/\n\n### PS：封面是我自己设计的哦~~","title":"《Elasticsearch权威指南》中文版开始翻译","uid":"183","views":"16201","votes":"9"},"_type":"doc"}
{"_id":"7","_index":"forum-mysql","_score":1,"_source":{"addtime":"1447807698","category_id":"5","comments":"1","has_attach":"1","id":"7","message":"时间:\n\n2015年11月22日 周日 下午1点开始\n\n地点:\n\n四川成都市高新区天府大道中段1366号天府软件园E3-1-11层   (感谢货车帮提供场地支持)\n\n会议日程:\n\n[attach]46[/attach]\n\n\n请您提前到场,安排好时间,如因故不能参加,请提前发邮件告知: medcl*elastic.co ,谢谢合作.","title":"11.22 ESCC#4成都站马上开始了","uid":"1","views":"2585","votes":"0"},"_type":"doc"}
{"_id":"13","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449288260","category_id":"14","comments":"0","has_attach":"0","id":"13","message":"话接上回，我们只是解决了写数据的问题，这种格式不太符合常规的数据怎么读，也需要我们相应的做出点改变。\n\n今天以一个实际的例子来讲。我曾经处理过一份数据，记录的是视频播放的卡顿情况。其中有一个数组，每次卡顿就新增一个对象元素。所以设计的 mapping 如下：\n[code]         \u0026quot;video_time_duration\u0026quot; : {\n           \u0026quot;type\u0026quot;: \u0026quot;nested\u0026quot;,\n           \u0026quot;properties\u0026quot; : {\n             \u0026quot;duration\u0026quot; : {\n               \u0026quot;type\u0026quot; : \u0026quot;long\u0026quot;,\n               \u0026quot;doc_values\u0026quot; : true\n             },\n             \u0026quot;type\u0026quot; : {\n               \u0026quot;type\u0026quot; : \u0026quot;long\u0026quot;,\n               \u0026quot;doc_values\u0026quot; : true\n             }\n           }\n         },[/code]其中 type 只有 0 或 1 两个可能，0 表示播放正常，1 表示卡顿。所以下面我们发一个请求，要求是计算这样的结果：\n\n[b]出现了播放卡顿的用户，单次卡顿时长在10到200ms的，最常见于哪些城市？[/b]\n\n下面是我们最终的查询请求 JSON：\n[code]{\n  \u0026quot;size\u0026quot; : 0,\n  \u0026quot;query\u0026quot; : {\n    \u0026quot;nested\u0026quot; : {\n      \u0026quot;path\u0026quot; : \u0026quot;video_time_duration\u0026quot;,\n      \u0026quot;query\u0026quot; : {\n        \u0026quot;match\u0026quot; : {\n          \u0026quot;video_time_duration.type\u0026quot; : \u0026quot;1\u0026quot;\n        }\n      }\n    }\n  },\n  \u0026quot;aggs\u0026quot; : {\n    \u0026quot;video\u0026quot; : {\n      \u0026quot;nested\u0026quot; : {\n        \u0026quot;path\u0026quot; : \u0026quot;video_time_duration\u0026quot;\n      },\n      \u0026quot;aggs\u0026quot; : {\n        \u0026quot;filter_type\u0026quot; : {\n          \u0026quot;filter\u0026quot; : {\n            \u0026quot;term\u0026quot; : {\n              \u0026quot;video_time_duration.type\u0026quot; : \u0026quot;1\u0026quot;\n            }\n          },\n          \u0026quot;aggs\u0026quot; : {\n            \u0026quot;duration_ranges\u0026quot; : {\n              \u0026quot;range\u0026quot; : {\n                \u0026quot;field\u0026quot; : \u0026quot;video_time_duration.duration\u0026quot;,\n                \u0026quot;ranges\u0026quot; : [\n                  { \u0026quot;from\u0026quot; : 10, \u0026quot;to\u0026quot; : 200 }\n                ]\n              },\n              \u0026quot;aggs\u0026quot; : {\n                \u0026quot;city\u0026quot; : {\n                  \u0026quot;reverse_nested\u0026quot;: {},\n                  \u0026quot;aggs\u0026quot; : {\n                    \u0026quot;city_terms\u0026quot; : {\n                      \u0026quot;terms\u0026quot; : {\n                        \u0026quot;field\u0026quot; : \u0026quot;geoip.city\u0026quot;\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}[/code]很明显的可以看到对 nested object 里存的数据，不管是做 query 还是 agg，都需要显式的加上[i]\u0026quot;nested\u0026quot;: {\u0026quot;path\u0026quot; : \u0026quot;video_time_duration\u0026quot; [/i]的声明。这样，才能保证我们取到的 duration 数值是对应 type 为卡顿的，而不是流畅播放的。\n\n大家可能注意到，我同时在 query 和 aggFilter 中重复了一场 term 过滤。其中这次 nested query 是不必要的，除了作为语法展示以外，也有一个减少 hits 数的作用。但是和一般的请求不同的是，这里不可以去掉 nested agg 里的 term filter，因为 nested query 只是拿到『有过卡顿』的数据 id。不加 filter，聚合 duration 的时候，会把卡过但也流畅过的那部分都计算在内。\n\n另一个要点：当我们过滤好 nested 数据的时候，要取顶层其他字段的内容，在 sub agg 里是无法直接获取的，需要额外使用一次[b] reverse_nested [/b]来跳出这个 nested path，才可以恢复正常的 agg 路径。\n\n最终得到的响应如下：\n[code]{\n  \u0026quot;took\u0026quot; : 4672,\n  \u0026quot;timed_out\u0026quot; : false,\n  \u0026quot;_shards\u0026quot; : {\n    \u0026quot;total\u0026quot; : 100,\n    \u0026quot;successful\u0026quot; : 100,\n    \u0026quot;failed\u0026quot; : 0\n  },\n  \u0026quot;hits\u0026quot; : {\n    \u0026quot;total\u0026quot; : 9560309,\n    \u0026quot;max_score\u0026quot; : 0.0,\n    \u0026quot;hits\u0026quot; : [ ]\n  },\n  \u0026quot;aggregations\u0026quot; : {\n    \u0026quot;video\u0026quot; : {\n      \u0026quot;doc_count\u0026quot; : 33713503,\n      \u0026quot;filter_type\u0026quot; : {\n        \u0026quot;doc_count\u0026quot; : 25441559,\n        \u0026quot;duration_ranges\u0026quot; : {\n          \u0026quot;buckets\u0026quot; : [ {\n            \u0026quot;key\u0026quot; : \u0026quot;10.0-200.0\u0026quot;,\n            \u0026quot;from\u0026quot; : 10.0,\n            \u0026quot;from_as_string\u0026quot; : \u0026quot;10.0\u0026quot;,\n            \u0026quot;to\u0026quot; : 200.0,\n            \u0026quot;to_as_string\u0026quot; : \u0026quot;200.0\u0026quot;,\n            \u0026quot;doc_count\u0026quot; : 2521720,\n            \u0026quot;city\u0026quot; : {\n              \u0026quot;doc_count\u0026quot; : 2521720,\n              \u0026quot;city_terms\u0026quot; : {\n                \u0026quot;doc_count_error_upper_bound\u0026quot; : 0,\n                \u0026quot;sum_other_doc_count\u0026quot; : 2267886,\n                \u0026quot;buckets\u0026quot; : [ {\n                    \u0026quot;key\u0026quot; : \u0026quot;北京\u0026quot;,\n                    \u0026quot;doc_count\u0026quot; : 142761\n                  }, {\n                    \u0026quot;key\u0026quot; : \u0026quot;广州\u0026quot;,\n                    \u0026quot;doc_count\u0026quot; : 104677\n                  }\n                ]\n              }\n            }\n          } ]\n        }\n      }\n    }\n  }\n}[/code]响应数据中，我们可以直接看这些 hits 和 doc_count 数据。他们表示：\n[list=1]\n[*]一共命中了『有过卡顿』的视频播放次数：9560309；[/*]\n[*]其中记录下来的播放间隔 33713503 次；[/*]\n[*]里面有 25441559 次是卡顿(减一下即 8271944 次是流畅咯)；[/*]\n[*]里面卡顿时长在 10-200 ms 的是 2521720 次；[/*]\n[*]这些卡顿出现最多的在北京，发生了 142761 次。[/*]\n[/list]\n\n数据蛮有意思吧。ES 能告诉你的还不止这点。更有趣的，明天见。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day3：nested object的查询和聚合示例","uid":"7","views":"4589","votes":"1"},"_type":"doc"}
{"_id":"16","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449418702","category_id":"14","comments":"0","has_attach":"0","id":"16","message":"Elastic 公司最近推出了 beats 系列，在官方的 packet/top/file{beat} 之外，社区也自发制作了一些比如 docker/nginx/\n\n不过很可惜的是：nginxbeat 只支持两个数据来源：标准的 ngx_http_stub_status_module 和商业版 Nginx Plus 的ngx_http_status_module\n\n我们都知道，ngx_http_stub_status_module 输出的信息太少，除了进程级别的连接数，啥都没有。那么，在使用开源版本 Nginx 的我们，还有别的办法么？\n\n在官网的第三方模块列表里，发现了一个韩国人写的 nginx-module-vts。这个扩展可以做到 vhost 级别的状态信息输出。(我知道国人还有很多类似的统计扩展，但是没上官网，不便普及，就忽略吧)\n\n但是，不懂 Golang 的话，没法自己动手实现一个 nginx-vts-beat 啊。怎么办？\n\n其实我们可以用 logstash-input-http_poller 实现类似的功能。\n\n首先，我们要给自己的 Nginx 加上 vts 扩展。编译方式这里就不讲了，和所有其他第三方模块一样。配置方式详见README。我们这里假设是按照核心和非核心接口来统计 URL 的状态：\n[code]http {\n    vhost_traffic_status_zone;\n\n    map $uri $filter_uri {\n        default 'non-core';\n        /2/api/timeline core;\n        ~^/2/api/unread core;\n    }\n\n    server {\n        vhost_traffic_status_filter_by_set_key $filter_uri;\n        location /status {\n            auth_basic \u0026quot;Restricted\u0026quot;; \n            auth_basic_user_file pass_file;\n            vhost_traffic_status_display;\n            vhost_traffic_status_display_format json;\n        }\n    }\n}[/code]然后我们需要下面一段 Logstash 配置来定期获取这个数据：\n\n[code]input {\n  http_poller {\n    urls =\u0026gt; {\n      0 =\u0026gt; {\n        method =\u0026gt; get\n        url =\u0026gt; \u0026quot;http://localhost:80/status/format/json\u0026quot;\n        headers =\u0026gt; {\n          Accept =\u0026gt; \u0026quot;application/json\u0026quot;\n        }\n        auth =\u0026gt; {\n          user =\u0026gt; \u0026quot;YouKnowIKnow\u0026quot;\n          password =\u0026gt; \u0026quot;IKnowYouDonotKnow\u0026quot;\n        }\n      }\n      1 =\u0026gt; {\n        method =\u0026gt; get\n        url =\u0026gt; \u0026quot;http://localhost:80/status/control?cmd=reset\u0026amp;group=*\u0026quot;\n        headers =\u0026gt; {\n          Accept =\u0026gt; \u0026quot;application/json\u0026quot;\n        }\n        auth =\u0026gt; {\n          user =\u0026gt; \u0026quot;YouKnowIKnow\u0026quot;\n          password =\u0026gt; \u0026quot;IKnowYouDonotKnow\u0026quot;\n        }\n      }\n    }\n    request_timeout =\u0026gt; 60\n    interval =\u0026gt; 60\n    codec =\u0026gt; \u0026quot;json\u0026quot;\n  }\n}[/code]这样，就可以每 60 秒，获得一次 vts 数据，并重置计数了。\n\n注意，urls 是一个 Hash，所以他的执行顺序是根据 Hash.map 来的，为了确保我们是先获取数据再重置，这里干脆用 0, 1 来作为 Hash 的 key，这样顺序就没问题了。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day6：用logstash-input-http_poller模拟nginxbeat","uid":"7","views":"3282","votes":"0"},"_type":"doc"}
{"_id":"18","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449630475","category_id":"14","comments":"3","has_attach":"0","id":"18","message":"Kibana4 上线后，又有同事找过来。还好这次是小问题：『新版的这个仪表盘顶部菜单栏太宽了啊。头顶上监控屏幕空间有限，能不能省省？』\n\n跟 Kibana3 相比，确实宽了点。这时候好几个方案瞬间进入我脑子里：\n[list=1]\n[*]浏览器往下拖动一点，不过要确保定期刷新的时候还能回到拖动位置；[/*]\n[*]进 ui/public/chrome/chrome.html 里把 navbar 干掉；[/*]\n[*]添加一个 bootstrap 效果，navbar 默认隐藏，鼠标挪上去自动浮现。[/*]\n[/list]\n\n不过等打开 chrome.html 看了一下，发现 navbar 本身是有相关的隐藏判断的：[code]\u0026lt;nav\n  ng-style=\u0026quot;::{ background: chrome.getNavBackground() }\u0026quot;\n  ng-class=\u0026quot;{ show: chrome.getVisible() }\u0026quot;\n  class=\u0026quot;hide navbar navbar-inverse navbar-static-top\u0026quot;\u0026gt;[/code]这个设置在 ui/public/chrome/api/angular.js 里的 internals.setVisibleDefault(!$location.search().embed);。我们知道 $locatio.search() 是 AngularJS 的标准用法，这里也就是代表 URL 请求参数里是否有 ?embed 选项。\n\n好了，我们试一下，把 http://localhost:5601/app/kibana/#/dashboard/mydash 改成http://localhost:5601/app/kibana/#/dashboard/mydash?embed，回车，果然，整个菜单栏都消失了！同步消失的还有每个 panel 的编辑按钮。\n\n其实呢，embed 在页面上是有说明的，在 dashboard 的 share 连接里，提供了一个 iframe 分享方式，iframe 里使用的，就是 embed 链接！\n\n注意：Kibana4 部分版本的 share 说明中的 embed 位置生成的有问题，请小心。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day8：隐藏仪表盘的菜单栏","uid":"7","views":"2192","votes":"1"},"_type":"doc"}
{"_id":"28","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450362892","category_id":"14","comments":"5","has_attach":"0","id":"28","message":"Advent接力传到我这里了，今天我给大家介绍一下Beats，刚好前几天也有好多人问我它是干嘛的，之前的上海我有分享过Beats的内容，PPT在这里：\n\n[url]https://pan.baidu.com/s/1eS157I6#list/path=%2F%E7%BA%BF%E4%B8%8B%E6%B4%BB%E5%8A%A8%2F%E6%9D%AD%E5%B7%9E%2F2016-6-18[/url] \n\n\n事实上Beats是一系列产品的统称，属于ElasticStack里面收集数据的这一层：Data Shipper Layer，包括以下若干Beats：\n[list=1]\n[*]PacketBeat，用来嗅探和分析网络流量，如HTTP、MySQL、Redis等[/*]\n[*]TopBeat，用来收集系统的监控信息，功能如其名，类似*nix下的top命令，只不过所有的信息都会发送给后端的集中存储：Elasticsearch，这样你就可以很方便的监控所有的服务器的运行情况了[/*]\n[*]FileBeat，用来收集数据源是文件的数据，比如常见的系统日志、应用日志、网站日志等等，FIleBeat思路来自Logstash-forwarder，Beats团队加入之后重构改写而成，解决的就是Logstash作为Agent采集时占用太多被收集系统资源的问题，Beats家族都是Golang编写，效率高，占用内存和CPU比较少，非常适合作为agent跑着服务器上[/*]\n[*]。。。[/*]\n[/list]\n所以Beats其实是一套框架，另外的一个子项目Libbeat，就是所有beats都共用的模块，封装了所有的公共的组件，如配置管理、公共基础类、协议的解析处理、与Elasticsearch的操作等等，你可以很方便基于它实现你自己的beats，这也是Beats的目标，希望将来会出现更多的Beats，做各种各样的事情。\n \n另外PacketBeat比较特殊，它又是网络协议抓包和处理的一个框架，目前支持了常见的一些协议，要扩展未知的协议其实非常简单，PacketBeat作为一个框架，数据抓包和后续的存储已经帮你处理好了，你只需要实现你的协议的解码操作就行了，当然这块也是最难和最业务相关的。\n \n关于PacketBeat我回头再单独写一篇文章来介绍怎样编写一个PacketBeat的协议扩展吧，PacketBeat扩展的其它协议最终还是需要和PacketBeat集成在一起，也就是最终你的代码是要和PacketBeat的代码在一个工程里面的，而其它的Beats使用Libbeat完全是单独的Beat，如Filebeat和TopBeat，完全是独立打包和独立运行，这个也是两大Beats的主要区别。\n \n随便提一下，现在所有的这些Beats已经合并到一个项目里面来方便管理了，golang，you know：[url]https://github.com/elastic/beats[/url]\n \n现在社区已经提交了的Beats：\n[url]https://www.elastic.co/guide/en/beats/libbeat/current/community-beats.html[/url]\n \n明后天在Beijing的ArchSummit2015，我将在Elastic展台，欢迎过来骚扰，领取Elastic的各种贴纸，还有限量的印有Elastic的T恤，数量有限哦\n \n今天的Advent就这些吧。\nAdvent接力活动，规则：[url]http://elasticsearch.cn/article/20[/url]\n ","title":"Day15:Beats是什么东西？","uid":"1","views":"5891","votes":"4"},"_type":"doc"}
{"_id":"147","_index":"forum-mysql","_score":1,"_source":{"addtime":"1491360440","category_id":"2","comments":"6","has_attach":"0","id":"147","message":"大家好，最近这个客题需要大家的帮忙啦，后面会专门录个视频来汇总讲解这些 bad case.\n \nOOM:\n  方式1：\n       版本: all\n       深度分页和大数据量数据返回会导致OOM。  \n  方式2：\n       版本: es 1.x\n       使用delete_by_query删除海量数据时，由于内部没有使用scroll模块，会由深度分页导致OOM\n  方式3：\n       版本: all\n       使用scroll返回大量数据导致OOM\n ","title":"100种让ES宕机的方法，请详细描述过程，且可复现的。","uid":"2363","views":"1689","votes":"0"},"_type":"doc"}
{"_id":"46","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451276034","category_id":"14","comments":"6","has_attach":"1","id":"46","message":"Shield是Elasticsearch一个安全防护插件,提供了权限访问控制和日志审计功能,企业可以很方便的和LDAP或是ActiveDirectory进行集成,重用现有的安全认证体系.\n\n[attach]76[/attach]\n\nElasticsearch使用了Shield后,Elasticsearch就需要权限才能访问了,和默认的调用方式有些不同,下面简单介绍一下HTTP和TCP两种方式的连接.\n\n关于Shield的安装和配置我这里不就具体介绍,创建了一个用户名和密码都是tribe_user的用户,权限是admin.\n\n1.HTTP方式\n现在直接访问es的http接口就会报错\n\ncurl http://localhost:9200\n\n{\u0026quot;error\u0026quot;:{\u0026quot;root_cause\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;security_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;missing authentication token for REST request [/]\u0026quot;,\u0026quot;header\u0026quot;:{\u0026quot;WWW-Authenticate\u0026quot;:\u0026quot;Basic realm=\\\u0026quot;shield\\\u0026quot;\u0026quot;}}],\u0026quot;type\u0026quot;:\u0026quot;security_exception\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;missing authentication token for REST request [/]\u0026quot;,\u0026quot;header\u0026quot;:{\u0026quot;WWW-Authenticate\u0026quot;:\u0026quot;Basic realm=\\\u0026quot;shield\\\u0026quot;\u0026quot;}},\u0026quot;status\u0026quot;:401}\n\nshield支持HttpBasic验证,所以正确的访问姿势是:\n\ncurl -u tribe_user:tribe_user http://localhost:9200 { \u0026quot;name\u0026quot; : \u0026quot;Melter\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;2.1.1\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;805c528f3167980046f224310f9147fa745e5371\u0026quot;, \u0026quot;build_timestamp\u0026quot; : \u0026quot;2015-12-09T20:23:16Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;5.3.1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; }\n\n如果是浏览器访问的话,第一次访问会弹出验证窗口,后续只要不关闭这个浏览器保持这个session就能一直访问.\n注意http basic是不安全的认证方式,仅供开发调试使用,生产环境还需要结合HTTPS的加密通道使用.\n\n2.TransportClient方式的访问Shield加防的Elasticsearch,稍微麻烦点,需要依赖Shield的包,步骤如下:\n2.1 如果你是maven管理的项目,在pom.xml文件里添加Elasticsearch的maven仓库源,如下:\n\n\u0026lt;repositories\u0026gt; \n\u0026lt;repository\u0026gt; \n\u0026lt;id\u0026gt;elasticsearch-releases\u0026lt;/id\u0026gt; \n\u0026lt;url\u0026gt;https://maven.elasticsearch.org/releases\u0026lt;/url\u0026gt; \n\u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \n\u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \n\u0026lt;/repository\u0026gt; \n\u0026lt;/repositories\u0026gt;\n\n2.2 添加依赖的配置\n\n\u0026lt;dependency\u0026gt; \n\u0026lt;groupId\u0026gt;org.elasticsearch.plugin\u0026lt;/groupId\u0026gt;\n\u0026lt;artifactId\u0026gt;shield\u0026lt;/artifactId\u0026gt;\n\u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt;\n\u0026lt;/dependency\n\n2.3 构建TransportClient的地方增加访问用户的配置\n\nimport org.elasticsearch.shield.ShieldPlugin; import org.elasticsearch.shield.authc.support.SecuredString; import static org.elasticsearch.shield.authc.support.UsernamePasswordToken.basicAuthHeaderValue;\n\nString clusterName=\u0026quot;elasticsearch\u0026quot;; String ip= \u0026quot;127.0.0.1\u0026quot;; \nSettings settings = Settings.settingsBuilder()   \n.put(\u0026quot;cluster.name\u0026quot;, clusterName)\n .put(\u0026quot;shield.user\u0026quot;, \u0026quot;tribe_user:tribe_user\u0026quot;) \n.build(); \ntry { client = TransportClient.builder() \n.addPlugin(ShieldPlugin.class) \n.settings(settings).build() \n.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(ip),9300)); \nString token = basicAuthHeaderValue(\u0026quot;tribe_user\u0026quot;, new SecuredString(\u0026quot;tribe_user\u0026quot;.toCharArray()));   client.prepareSearch()\n.putHeader(\u0026quot;Authorization\u0026quot;, token).get();   } \ncatch (UnknownHostException e) \n{ logger.error(\u0026quot;es\u0026quot;,e); }\n \n现在的编辑器贴代码有点恶心,可以看这里:\nhttp://log.medcl.net/item/2015/12/shieldtransportclient-xia-ru-he-shi-yong/#more-1252","title":"Day24: Elasticsearch添加Shield后TransportClient如何连接？","uid":"1","views":"4451","votes":"3"},"_type":"doc"}
{"_id":"49","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452047282","category_id":"2","comments":"5","has_attach":"0","id":"49","message":"1.安装elasticsearch-mapper attachment\n\nbin/plugin install elasticsearch/elasticsearch-mapper-attachments/3.1.1\n 2.按照插件官方文档来测试\n3.插件需要手动把文档内容转化为base64编码然后建立索引，代码如下\nimport java.io.BufferedInputStream;\nimport java.io.BufferedOutputStream;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\n\nimport org.apache.tika.Tika;\nimport org.apache.tika.config.TikaConfig;\nimport org.apache.tika.metadata.Metadata;\nimport org.apache.tika.parser.AutoDetectParser;\nimport org.apache.tika.parser.ParseContext;\nimport org.apache.tika.parser.Parser;\nimport org.apache.tika.parser.pdf.PDFParser;\nimport org.apache.tika.sax.BodyContentHandler;\nimport org.elasticsearch.action.index.IndexResponse;\nimport org.elasticsearch.client.Client;\nimport org.elasticsearch.client.transport.TransportClient;\nimport org.elasticsearch.common.settings.ImmutableSettings;\nimport org.elasticsearch.common.settings.Settings;\nimport org.elasticsearch.common.transport.InetSocketTransportAddress;\nimport org.elasticsearch.common.xcontent.XContentBuilder;\nimport org.xml.sax.ContentHandler;\n\nimport com.spatial4j.core.io.ParseUtils;\n\nimport static org.elasticsearch.common.xcontent.XContentFactory.*;\npublic class sysfiles {\n    public static void main(String[] args) throws Exception{\n        sys();\n}\n\n    private static void sys() throws IOException {\n        // TODO Auto-generated method stub\n        String idxName = \u0026quot;test\u0026quot;;\n        String idxType = \u0026quot;attachments\u0026quot;;\n        Settings settings =ImmutableSettings.settingsBuilder().put(\u0026quot;cluster.name\u0026quot;,\u0026quot;az_bsms_elasticsearch\u0026quot;).build();\n        Client client=new TransportClient(settings).addTransportAddress(new InetSocketTransportAddress(\u0026quot;127.0.0.1\u0026quot;, 9300));\n       String data64=org.elasticsearch.common.Base64.encodeFromFile(filepath);\n        XContentBuilder source = jsonBuilder().startObject()\n            .field(\u0026quot;file\u0026quot;, data64)\n                .field(\u0026quot;text\u0026quot;, data64)\n                .endObject();\n\n        String id = \u0026quot;file\u0026quot;+11;\n        IndexResponse idxResp = client.prepareIndex().setIndex(idxName).setType(idxType).setId(id)\n                .setSource(source).setRefresh(true).execute().actionGet();\n        System.out.println(idxResp);\n        client.close();\n    }\n4.按官方文档正常的搜索就可以了","title":"通过elasticsearch-mapper attachment插件实现文件建立索引","uid":"624","views":"5986","votes":"1"},"_type":"doc"}
{"_id":"231","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503189991","category_id":"18","comments":"0","has_attach":"0","id":"231","message":"1. 自动同步MySQL数据到Elasticsearch：\nhttp://t.cn/RC44piW\n2. 如何使用Filebeat自动跟踪Linux系统日志文件并传送到Elasticsearch\nhttp://t.cn/RCqAWlU\n3. 刷爆朋友圈的「我们是谁」图片，用小程序也能一键生成，超简单超好笑！\nhttp://t.cn/RCwTd4x\n\n编辑：至尊宝\n\n归档：https://elasticsearch.cn/article/231\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第22期 (2017-08-20)","uid":"4460","views":"738","votes":"1"},"_type":"doc"}
{"_id":"235","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503364930","category_id":"2","comments":"1","has_attach":"0","id":"235","message":"有意者请投递简历至邮箱zx@foundingaz.com岗位职责：\n• 能够熟练使用ODPS、Hadoop实现大数据挖掘和统计工作； \n• 能够基于地图积累的大数据，为了业务目标，完成数据清洗、样本去噪、特征选取分析、模型建立和预估实现等整个流程； \n• 对地图和导航具有一定的看法，能够从问题中提取优化点和工作内容，配合部门目标高效开展工作； \n• 使用阿里大数据平台和算法工具完成模型的工程化，并与业务部门沟通合作，将数据模型应用于实际业务；\n任职资格：\n• 数据挖掘理论基础，包括回归、决策树、SVM、朴素贝叶斯、神经网络、k-means、PLSA\\LDA\\HMM等常用算法的适用场景、优点、缺点以及弥补办法 \n• 具有包含上述2种以上的模型算法的项目实践经验 \n• 熟练掌握Hive\\SQL，开展项目工作 \n• JAVA\\C++\\python 至少熟练掌握一种编程语言 \n• 数据掘项目经验丰富，在挖掘模型应用上有成功案例，对数据挖掘方法论有深刻理解，能深入分析、定位业务问题，利用挖掘模型解决 \n• 熟悉Hadoop、Hive、流式计算、实时计算等大数据相关技术者优先 \n• 具有统计理论知识者优先\n有意者请投递简历至邮箱zx@foundingaz.com","title":"【北京 阿里巴巴】 数据挖掘工程师","uid":"4535","views":"450","votes":"0"},"_type":"doc"}
{"_id":"245","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503796018","category_id":"18","comments":"0","has_attach":"0","id":"245","message":"1.floragunn公司的Search Guard，一个Elasticsearch的安全套件：\nhttp://t.cn/RCmlB4S\n2.(自备梯子)在Django项目中使用ElasticSearch作为搜索引擎：\nhttp://t.cn/RCmlFVS\n3.一周热点，为什么我们需要区块链，区块链和传统数据库应用的比较：\nhttp://t.cn/RCmjzIx\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/245\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第29期 (2017-08-27)","uid":"4460","views":"592","votes":"0"},"_type":"doc"}
{"_id":"251","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504218677","category_id":"18","comments":"1","has_attach":"0","id":"251","message":"[size=14]1. 掌握这些Elasticsearch面试知识点，年薪30W+不再是梦！\n[url]http://t.cn/RNbMJjR[/url] [/size]\n\n[size=14]2. 淘宝Elasticsearch搜索建议实战解读\n[url]http://t.cn/Rxb4uau[/url] [/size]\n\n[size=14]3. Spark Streaming + Elasticsearch构建App异常监控平台\n[url]http://t.cn/RNb9Qcn[/url] [/size]\n \n\n[size=14]编辑：laoyang360\n归档：[url]https://www.elasticsearch.cn/article/251[/url] [/size]\n[size=14]订阅：[url]https://tinyletter.com/elastic-daily[/url] [/size]\n\n ","title":"Elastic日报 第34期 (2017-09-01)","uid":"1341","views":"718","votes":"4"},"_type":"doc"}
{"_id":"266","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505004959","category_id":"18","comments":"0","has_attach":"0","id":"266","message":"1.用Elasticsearch处理实体间的关联关系。\nhttp://t.cn/Rpt082p\n2.ELK配合Auditbeat模块跟踪监控Linux系统。\nhttp://t.cn/Rpt0nBT\n3.使用Wireshark，Elasticsearch和Kibana分析网络数据包。\nhttp://t.cn/RptTsyy\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/266\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第43期 (2017-09-10)","uid":"4460","views":"775","votes":"0"},"_type":"doc"}
{"_id":"269","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505125347","category_id":"2","comments":"8","has_attach":"1","id":"269","message":"【携程旅行网  吴晓刚】\n\n上周有用户在社区发了一例Kibana读取超时的问题：[question#2319](https://elasticsearch.cn/question/2319) 。周末找时间帮其调查了下，发现某些较新的ES版本和Kibana搭配，会产生意想不到的缓慢问题。 考虑到这个问题比较普遍，因此在这里总结一下问题的根源和解决办法，希望用到问题版本的用户不要踩到坑。\n\n首先问题的现象在上面的问题链接里有描述，简而言之就是对于一个硬件配置比较高的集群，每天写入一个20亿左右数据的索引，通过kibana的discovery面板查看数据会一直超时。即使时间范围放到最近半小时，超时依旧，有些蹊跷。\n\n周末拿到用户给的测试账号，登陆集群看了下状态。 从机器的硬件配置，集群和索引的配置看，没找到什么特别不对劲的地方。然而点击到Discovery面板，的确数据显示不出来。  集群监控数据看，并没有其他用户在做查询，cpu利用率和集群负载都比较低。因此初步可以判定，就是查询本身比较缓慢所致。\n\n对于诊断查询缓慢问题，我通常的做法，就是将对应面板下的查询拷贝出来，在Kibana Dev Console里手动执行，然后再加上`\u0026quot;profile\u0026quot;：true`选项，看看查询是如何解析和执行的。对应的查询形如下面这样：\n```json\n{\n  \u0026quot;profile\u0026quot;: true,\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;bool\u0026quot;: {\n      \u0026quot;must\u0026quot;: [\n        {\n          \u0026quot;query_string\u0026quot;: {\n            \u0026quot;analyze_wildcard\u0026quot;: true,\n            \u0026quot;query\u0026quot;: \u0026quot;*\u0026quot;\n          }\n        },\n        {\n          \u0026quot;range\u0026quot;: {\n            \u0026quot;@timestamp\u0026quot;: {\n              \u0026quot;gte\u0026quot;: \u0026quot;now-1h\u0026quot;,\n              \u0026quot;lte\u0026quot;: \u0026quot;now\u0026quot;,\n              \u0026quot;format\u0026quot;: \u0026quot;epoch_millis\u0026quot;\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n因为用户query框什么都没有输入，因此默认查询串被Kibana设置为`*`， 然后根据选择的时间范围加了一个range查询。  profile的输出让我稍微有些吃惊，其中 query_string的里的`*`居然被解析成非常复杂的`DisjunctionMaxQuery`，主要查询耗时都在这里了。\n```json\n{\n                    \u0026quot;type\u0026quot;: \u0026quot;DisjunctionMaxQuery\u0026quot;,\n                    \u0026quot;description\u0026quot;: \u0026quot;(ConstantScore(_field_names:remote_addr.keyword) | ConstantScore(_field_names:geoip.country_isocode) | ConstantScore(_field_names:geoip.country_name.keyword) | ConstantScore(_field_names:via) | ConstantScore(_field_names:domain.keyword) | ConstantScore(_field_names:request_method.keyword) | ConstantScore(_field_names:protocol) | ConstantScore(_field_names:xff.keyword) | ConstantScore(_field_names:host) | ConstantScore(_field_names:geoip.city_name.keyword) | ConstantScore(_field_names:client_ip) | ConstantScore(_field_names:host.keyword) | ConstantScore(_field_names:geoip.longitude) | ConstantScore(_field_names:geoip.subdivision_name.keyword) | ConstantScore(_field_names:geoip.country_code) | ConstantScore(_field_names:upstream_addr.keyword) | ConstantScore(_field_names:@version.keyword) | ConstantScore(_field_names:request_uri) | ConstantScore(_field_names:tags) | ConstantScore(_field_names:idc_tag) | ConstantScore(_field_names:size) | ConstantScore(_field_names:http_referer) | ConstantScore(_field_names:message.keyword) | ConstantScore(_field_names:domain) | ConstantScore(_field_names:geoip.latitude) | ConstantScore(_field_names:xff) | ConstantScore(_field_names:protocol.keyword) | ConstantScore(_field_names:geoip.country_code.keyword) | ConstantScore(_field_names:status) | ConstantScore(_field_names:upstream_addr) | ConstantScore(_field_names:http_referer.keyword) | ConstantScore(_field_names:tags.keyword) | ConstantScore(_field_names:client_ip.keyword) | ConstantScore(_field_names:request_method) | ConstantScore(_field_names:upstream_status) | ConstantScore(_field_names:request_time) | ConstantScore(_field_names:geoip.location) | ConstantScore(_field_names:@version) | ConstantScore(_field_names:geoip.country_name) | ConstantScore(_field_names:user_agent) | ConstantScore(_field_names:idc_tag.keyword) | ConstantScore(_field_names:remote_addr) | ConstantScore(_field_names:geoip.country_isocode.keyword) | ConstantScore(_field_names:geoip.city_name) | ConstantScore(_field_names:via.keyword) | ConstantScore(_field_names:message) | ConstantScore(_field_names:user_agent.keyword) | ConstantScore(_field_names:request_uri.keyword) | ConstantScore(_field_names:@timestamp) | ConstantScore(_field_names:upstream_response_time) | ConstantScore(_field_names:geoip.subdivision_name))\u0026quot;,\n                    \u0026quot;time\u0026quot;: \u0026quot;5535.127008ms\u0026quot;,\n                    \u0026quot;time_in_nanos\u0026quot;: 5535127008\n```\n\n也就是说， ES将只含一个`*`的`query_string query`解析成了针对mapping里能找到的所有字段的`field:*`查询，然后合并所有的查询结果。  可想而知，对于比较大，字段比较多的索引这个查询是非常耗时的。而我对于`*`的认知，是其应该被rewrite成一个`match_all query`即可，这样几乎没有什么开销。\n\n为什么会这样？ 查询了一下ES官方关于Query String Query的文档，其中的default_field和all_fields起到了一定作用: \n[elasticsearch/reference/5.5/query-dsl-query-string-query.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/query-dsl-query-string-query.html)\n\n\u0026gt; default_field\n\u0026gt; \n\u0026gt; The default field for query terms if no prefix field is specified. Defaults to the index.query.default_field index settings, which in turn defaults to _all.\n\n\u0026gt; all_fields\n\u0026gt; \n\u0026gt; Perform the query on all fields detected in the mapping that can be queried. Will be used by default when the _all field is disabled and no default_field is specified (either in the index settings or in the request body) and no fields are specified.\n\n根据解释，查询的时候可以带一个`default_field`选项，其默认值为索引级别设置`index.query.default_field`，如果这个设置没有设置，则默认为`_all`。  但一般用户索引日志的时候，都会关掉`_all`字段，用于节省磁盘空间，提升索引速率。那么这时候`default_field`是什么呢？  答案是`all_fields`，也就是ES会将查询转换为对所有字段的查询。\n\n为了验证这个是问题所在，我在索引里加了一个`default_field`的设置，随意挑选了一个字段。 果然问题就解决了，discovery面板渲染速度快了差不多有10倍。\n\n但仔细想想，这也只是绕过了问题。 问题的根源，为什么`*`不被rewrite成`match_all`呢？ \n\n这时候想到我们自己生产的集群似乎没有这个问题，于是用我们自己的集群测试了一下,`*`果然是正常解析成`match_all`了。 于是对比了一下集群ES的版本，我们正常工作的是`5.3.2`，用户的集群是`5.5.0`。\n\n接下来，我想找到这些版本之间，ES对于query string的解析源码层面做了什么改动。经过一番探查，找到了下面这个变更历史:\n[attach]1019[/attach]\n[attach]1018[/attach]\n\n可以看到，在[pull/23433](https://github.com/elastic/elasticsearch/pull/23433)里，为了修复一个`foo:*`解析歧义的问题，对于field为空，类似光一个`*`的Query string查询，不再被解析成`match_all`了，而是扩展成全部字段的DisjunctionMaxQuery查询。 由此Kibana默认的`*`，会引起非常严重的性能问题。\n\n**这个问题会影响5.4和5.5两个小版本的ES/Kibana。**\n\n顺着这个issue里的链接摸下去，找到了对应Kibana相关问题讨论:[issues#12097](https://github.com/elastic/kibana/issues/12097)，以及对应的修复: [pull/13047](https://github.com/elastic/kibana/pull/13047)，修复版本默认发出的查询串是`match all`。\n\n修复的版本则是`5.5.2`及`5.6.0`， 因此有用到`5.4.0`到`5.5.1`之间版本的ELK用户一定要安排升级！\n","title":"ES 5.4+ 引起的Kibana性能问题","uid":"81","views":"2098","votes":"12"},"_type":"doc"}
{"_id":"271","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505181602","category_id":"3","comments":"2","has_attach":"1","id":"271","message":"日誌格式如下\r\n \r\n\u0026lt;30\u0026gt;Sep 11 11:57:24 dnsmasq-dhcp[15643]: DHCPACK(eth1) 192.168.2.22 1c:77:f6:64:99:d3 android-c5a782dc5af0b478\r\n \r\nGrok\r\n[code]%{SYSLOG5424PRI:ID}%{CISCOTIMESTAMP:Date} %{URIHOST:Method}%{NAGIOSTIME:EventID}: %{CISCO_REASON:Content} %{IP:IP} %{MAC:MAC} %{HOSTNAME:DevName}[/code]黃色部份可以解析出 字段 但是 後面   %{IP:IP} %{MAC:MAC} %{HOSTNAME:DevName} 解析不出來。\r\n \r\n[attach]1020[/attach]\r\n \r\n不知道如何解析 (eth1)  該字段...\r\n \r\n ","title":"請問該 日誌 如何寫 Grok 匹配。","uid":"3022","views":"764","votes":"0"},"_type":"doc"}
{"_id":"285","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505877864","category_id":"2","comments":"1","has_attach":"1","id":"285","message":"[size=20][url=https://segmentfault.com/a/1190000011272749]查看更好的排版[/url][/size]\r\n社区里面有人问了如下一个问题：\r\n[quote]\r\n执行 bulk 索引文档的时候，用 index 或者 create 类型并且自定义 doc id 的情况下，是否会像 update 一样每次都要去 get 一遍原始文档？ 比如下面的这条命令：\r\n[/quote]\r\n[code]POST _bulk\r\n\r\n{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;test\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;type1\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot; } }\r\n{ \u0026quot;field1\u0026quot; : \u0026quot;value1\u0026quot; }\r\n{ \u0026quot;create\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;test\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;type1\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;3\u0026quot; } }\r\n{ \u0026quot;field1\u0026quot; : \u0026quot;value3\u0026quot; }[/code]\r\n问题出现的原因是他们在 bulk 测试的时候遇到了写性能的问题，而正巧社区里面前几天有这么一个类似的帖子，说的是 es 5.x 版本里面做 update 操作的性能问题。虽然和这个问题不完全一致，但都涉及到 es 索引数据的部分。\r\n\r\n侯捷老师说：“源码面前，了无秘密”，那我们就来简单看下 es 这部分的相关代码，以便回答开篇提出的问题。\r\n\r\n准备工作\r\n我是用 IntelliJ IDEA 来阅读 elasticsearch 源码的，操作也简单。操作步骤如下：\r\n\r\n1.下载 es 源码，由于 es 的commit信息比较多，可以增加 --depth=1 只下载最近的commit，减少下载时间。\r\n[quote]\r\ngit clone https://github.com/elastic/elasticsearch.git --depth=1\r\n[/quote]\r\n \r\n2.安装 gradle，确保版本在 3.3 及以上，然后在源码目录下执行以下命令准备导入 IntelliJ IDEA 需要的文件\r\n[quote]\r\ngradle idea\r\n \r\n[/quote]\r\n3.下载安装 IntelliJ IDEA，确保版本为 2017.2 及以上版本。安装完成后，将 elasticsearch 以 gradle 形式导入即可。\r\n\r\n大家可以参考 elasticsearch 文档说明 和 elasticsearch 文档说明 这两篇文章，细节我这里就不赘述了。\r\n\r\n另外我是分析的 5.5.0 分支，大家记得 checkout，防止行数对应不起来。另外由于 es 代码结构有些复杂，先不在这篇文章里面梳理整个流程了，直接说核心代码。\r\n\r\n[b][size=20]Index/Create 源码分析[/size][/b]\r\n\r\nes index 和 create 最终都会调用 org/elasticsearch/index/engine/InternalEngine.java 中下面的方法：\r\n[quote]\r\n457 public IndexResult index(Index index) throws IOException\r\n[/quote]\r\n注意这里的 index 中包含有要写入的 doc, 简单画下该方法的执行流程图，代码这里就不贴了，刚兴趣的自己去看。\r\n\r\n\r\n[attach]1057[/attach]\r\n\r\n\r\n请结合上面的流程图来看相应的代码，整个逻辑应该还是很清晰的，接下来我们看 planIndexingAsPrimary 的逻辑。\r\n[quote]\r\n558 private IndexingStrategy planIndexingAsPrimary(Index index) throws IOException {\r\n \r\n[/quote]\r\n这个方法最终返回一个 IndexingStrategy，即一个索引的策略，总共有如下几个策略：\r\n[list]\r\n[*]optimizedAppendOnly[/*]\r\n[*]skipDueToVersionConflict[/*]\r\n[*]processNormally[/*]\r\n[*]overrideExistingAsIfNotThere[/*]\r\n[*]skipAsStale[/*]\r\n[/list]\r\n不同的策略对应了不同的处理逻辑，前面3个是常用的，我们来看下流程图。\r\n\r\n[attach]1058[/attach]\r\n\r\n\r\n这里的第一步判断 是否是自定义 doc id?这一步就是 es 对于日志类非自定义 doc id的优化，感兴趣的可以自己去看下代码，简单讲就是在非自定义 id 的情况下，直接将文档 add ，否则需要 update，而 update 比 add 成本高很多。\r\n\r\n而第二个判断 检查版本号是否冲突？ 涉及到是如何根据文档版本号来确认文档可写入，代码都在index.versionType().isVersionConflictForWrites方法里，逻辑也比较简单，不展开讲了，感兴趣的自己去看吧。\r\n\r\n上面的流程图也比较清晰地列出了策略选择的逻辑，除去 optimizedAppendOnly 策略，其他都需要根据待写入文档的版本号来做出决策。接下来我们就看下获取文档版本号的方法。\r\n[quote]\r\n389 private VersionValue resolveDocVersion(final Operation op) throws IOException {\r\n[/quote]\r\n该方法逻辑比较简单，主要分为2步：\r\n[list=1]\r\n[*]尝试从 versionMap 中读取待写入文档的 version，也即从内存中读取。versionMap 会暂存还没有 commit 到磁盘的文档版本信息。[/*]\r\n[*]如果第 1 步中没有读到，则从 index 中读取，也即从文件中读取。[/*]\r\n[/list]\r\n看到这里，开篇问题便有了答案。es 在 index 或者 create 的时候并不会 get 整个文档，而是只会获取文档的版本号做对比，而这个开销不会很大。\r\n\r\nUpdate 源码分析\r\nes update 的核心代码在 org/elasticsearch/action/update/UpdateHelper.java 中，具体方法如下：[code]    public Result prepare(UpdateRequest request, IndexShard indexShard, LongSupplier nowInMillis) {\r\n        final GetResult getResult = indexShard.getService().get(request.type(), request.id(),\r\n                new String[]{RoutingFieldMapper.NAME, ParentFieldMapper.NAME, TTLFieldMapper.NAME, TimestampFieldMapper.NAME},\r\n                true, request.version(), request.versionType(), FetchSourceContext.FETCH_SOURCE);\r\n        return prepare(indexShard.shardId(), request, getResult, nowInMillis);\r\n    }[/code]\r\n\r\n代码逻辑很清晰，分两步走：\r\n[list=1]\r\n[*]获取待更新文档的数据[/*]\r\n[*]执行更新文档的操作[/*]\r\n[/list]\r\n第 1 步最终会调用 InternalEngine 中的 get 方法，如下：\r\n[quote]\r\n350 public GetResult get(Get get, Function\u0026lt;String, Searcher\u0026gt; searcherFactory, LongConsumer onRefresh) throws EngineException {\r\n[/quote]\r\n这里就接上开篇提到的社区问题中的源码分析了。代码就不展开讲了，感兴趣的自己去看吧。\r\n\r\nupdate 操作需要先获取原始文档的原因也很简单，因为这里是允许用户做部分更新的，而 es 底层每次更新时要求必须是完整的文档（因为 lucene 的更新实际是删除老文档，新增新文档），如果不拿到原始数据的话，就不能组装出更新后的完整文档了。\r\n\r\n因此，比较看重效率的业务，最好还是不要用 update 这种操作，直接用上面的 index 会更好一些。\r\n\r\n[size=20][b]总结[/b][/size]\r\n\r\n本文通过源码分析的方式解决了开篇提到的问题，答案简单总结在下面。\r\nes 在 index 和 create 操作的时候，如果没有自定义 doc id，那么会使用 append 优化模式，否则会获取待写入文档的版本号，进行版本检查后再决定是否写入lucene。所以这里不会去做一个 get 操作，即获取完整的文档信息。\r\n最后，记住侯捷老师的话：\r\n源码面前，了无秘密！\r\n\r\n[url=https://segmentfault.com/a/1190000011272749]查看更好的排版[/url]\r\n\r\n ","title":"elasticsearch index、create和update的源码分析","uid":"86","views":"1561","votes":"7"},"_type":"doc"}
{"_id":"287","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505956927","category_id":"18","comments":"4","has_attach":"0","id":"287","message":"1.使用esrally深入elasticsearch的性能测试 [url]https://elasticsearch.cn/article/275[/url]\n2.还在为设置es的分片数量纠结？一篇文章教你全部 [url]http://t.cn/R0vFh2G[/url]\n3.基于elasticsearch nested object的关联分析 [url]http://t.cn/R0vFMG9[/url]\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/287\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第54期 (2017-09-21)","uid":"668","views":"558","votes":"1"},"_type":"doc"}
{"_id":"292","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506128432","category_id":"18","comments":"0","has_attach":"0","id":"292","message":"1、学习深度定制自己的分析器\n\nhttp://t.cn/RCTbs2d\n\n2. es6.0节省了更多的存储空间，你知道原因吗？\n\nhttp://t.cn/R0LvDlt\n\n3.  一个用elasticsearch追踪网站点击的案例\n\nhttp://t.cn/R9kMs8G\n\n\n\n编辑：bsll\n\n归档：https://www.elasticsearch.cn/article/292\n\n订阅：https://tinyletter.com/elastic-daily","title":"​Elastic日报 第56期 (2017-09-23)","uid":"1874","views":"473","votes":"0"},"_type":"doc"}
{"_id":"294","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506306696","category_id":"18","comments":"0","has_attach":"0","id":"294","message":"1.沃玛特的准实时零售数据分析。\nhttp://t.cn/R0cFOIz\n\n2.(自备梯子)如何完成360亿数据的reindex。\nhttp://t.cn/R0VPRLa\n\n3.使用Beats？elastic发布了一个关于Beats的问卷，填写它来帮助Beats更好的发展。\n[url]http://t.cn/R0VZZAL[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/294\n订阅：https://tinyletter.com/elastic-daily\n ","title":"​Elastic日报 第58期 (2017-09-25)","uid":"4063","views":"574","votes":"0"},"_type":"doc"}
{"_id":"296","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506400251","category_id":"12","comments":"7","has_attach":"0","id":"296","message":"工作地点：杭州\n\n薪资待遇：25k ~ 50k\n\n工作挑战：\n \nPB级数据的检索平台，峰值千万条数据的实时写入，1000+ES节点，数百个线上应用场景的支撑。\n\n工作职责：\n\n1. 独立完成中大型项目的系统分析、设计，并能够完成核心代码的编写，确保技术方案能够按计划要求，高质量的完成；\n2. 具有一定的技术架构思维，确保设计的技术方案、开发的代码有较高性能、质量保障、扩展性，前瞻性；\n3. 对技术有较强的钻研及学习精神，能够深入了解开源技术、现有系统技术等相关技术原理，出现问题时能够通过较强的技术手段较好的解决问题；\n\n岗位要求:\n\n1. JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；\n2. 3年及以上使用JAVA开发的经验，对于用过的开源框架，能了解到它的原理和机制；\n3. 对spring,mybatis,kafka,spark,elasticsearch等开源框架熟悉者优先；\n4. 熟悉分布式系统的设计和应用，能对分布式常用技术进行合理应用，解决问题；\n5. 掌握多线程及高性能的设计与编码及性能调优；有高并发应用开发经验优先；\n6. 学习能力强，适应能力好；具备耐心/细心的品质；\n7. 我们希望你喜欢去看及尝试最新的技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队\n \n简历投递：weizijun@didichuxing.com\n ","title":"【滴滴招聘】ES技术专家","uid":"1703","views":"2162","votes":"2"},"_type":"doc"}
{"_id":"461","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516348567","category_id":"2","comments":"0","has_attach":"0","id":"461","message":"elasticsearch的termvectors包括了term的位置、词频等信息。这些信息用于相应的数据统计或开发其他功能，本文介绍termvecters如何使用，如何通过java客户端获取termvectors相关信息。\n\n\n\n要使用termvctor首先要配置mapping中field的\u0026quot;term_vector\u0026quot;属性，默认状态es不开启termvector，因为这样会增加索引的体积，毕竟多存了不少元数据。\n\n```\nPUT test\n{\n  \u0026quot;mappings\u0026quot;: {\n    \u0026quot;qa_test\u0026quot;: {\n      \u0026quot;dynamic\u0026quot;: \u0026quot;strict\u0026quot;,\n      \u0026quot;_all\u0026quot;: {\n        \u0026quot;enabled\u0026quot;: false\n      },\n      \u0026quot;properties\u0026quot;: {\n        \u0026quot;question\u0026quot;: {\n          \u0026quot;properties\u0026quot;: {\n            \u0026quot;cate\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n            },\n            \u0026quot;desc\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n              \u0026quot;store\u0026quot;: true,\n              \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets_payloads\u0026quot;,\n              \u0026quot;analyzer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n            },\n            \u0026quot;time\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n              \u0026quot;store\u0026quot;: true,\n              \u0026quot;format\u0026quot;: \u0026quot;strict_date_optional_time||epoch_millis||yyyy-MM-dd HH:mm:ss\u0026quot;\n            },\n            \u0026quot;title\u0026quot;: {\n              \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n              \u0026quot;store\u0026quot;: true,\n              \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets_payloads\u0026quot;,\n              \u0026quot;analyzer\u0026quot;: \u0026quot;ik_smart\u0026quot;\n            }\n          }\n        },\n        \u0026quot;updatetime\u0026quot;: {\n          \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;,\n          \u0026quot;store\u0026quot;: true,\n          \u0026quot;format\u0026quot;: \u0026quot;strict_date_optional_time||epoch_millis||yyyy-MM-dd HH:mm:ss\u0026quot;\n        }\n      }\n    }\n  },\n  \u0026quot;settings\u0026quot;: {\n    \u0026quot;index\u0026quot;: {\n      \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot;,\n      \u0026quot;requests\u0026quot;: {\n        \u0026quot;cache\u0026quot;: {\n          \u0026quot;enable\u0026quot;: \u0026quot;true\u0026quot;\n        }\n      },\n      \u0026quot;number_of_replicas\u0026quot;: \u0026quot;1\u0026quot;\n    }\n  }\n}\n```\n注意示例中的\u0026quot;title\u0026quot;的\u0026quot;term_vector\u0026quot;属性。\n\n接下来为索引创建一条数据\n\n```\nPUT qa_test_02/qa_test/1\n{\n  \u0026quot;question\u0026quot;: {\n    \u0026quot;cate\u0026quot;: [\n      \u0026quot;装修流程\u0026quot;,\n      \u0026quot;其它\u0026quot;\n    ],\n    \u0026quot;desc\u0026quot;: \u0026quot;筒灯，大洋和索正这两个牌子，哪个好？希望内行的朋友告知一下，谢谢！\u0026quot;,\n    \u0026quot;time\u0026quot;: \u0026quot;2016-07-02 19:59:00\u0026quot;,\n    \u0026quot;title\u0026quot;: \u0026quot;筒灯大洋和索正这两个牌子哪个好\u0026quot;\n  },\n  \u0026quot;updatetime\u0026quot;: 1467503940000\n}\n```\n\n下面我们看看这条数据上question.title字段的termvector信息\n\n```\nGET qa_test_02/qa_test/1/_termvectors\n{\n  \u0026quot;fields\u0026quot;: [\n    \u0026quot;question.title\u0026quot;\n  ],\n  \u0026quot;offsets\u0026quot;: true,\n  \u0026quot;payloads\u0026quot;: true,\n  \u0026quot;positions\u0026quot;: true,\n  \u0026quot;term_statistics\u0026quot;: true,\n  \u0026quot;field_statistics\u0026quot;: true\n}\n```\n\n结果大概这个样子\n\n```\n{\n  \u0026quot;_index\u0026quot;: \u0026quot;qa_test_02\u0026quot;,\n  \u0026quot;_type\u0026quot;: \u0026quot;qa_test\u0026quot;,\n  \u0026quot;_id\u0026quot;: \u0026quot;1\u0026quot;,\n  \u0026quot;_version\u0026quot;: 1,\n  \u0026quot;found\u0026quot;: true,\n  \u0026quot;took\u0026quot;: 0,\n  \u0026quot;term_vectors\u0026quot;: {\n    \u0026quot;question.title\u0026quot;: {\n      \u0026quot;field_statistics\u0026quot;: {\n        \u0026quot;sum_doc_freq\u0026quot;: 9,\n        \u0026quot;doc_count\u0026quot;: 1,\n        \u0026quot;sum_ttf\u0026quot;: 9\n      },\n      \u0026quot;terms\u0026quot;: {\n        \u0026quot;和\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 2,\n              \u0026quot;start_offset\u0026quot;: 4,\n              \u0026quot;end_offset\u0026quot;: 5\n            }\n          ]\n        },\n        \u0026quot;哪个\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 7,\n              \u0026quot;start_offset\u0026quot;: 12,\n              \u0026quot;end_offset\u0026quot;: 14\n            }\n          ]\n        },\n        \u0026quot;大洋\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 1,\n              \u0026quot;start_offset\u0026quot;: 2,\n              \u0026quot;end_offset\u0026quot;: 4\n            }\n          ]\n        },\n        \u0026quot;好\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 8,\n              \u0026quot;start_offset\u0026quot;: 14,\n              \u0026quot;end_offset\u0026quot;: 15\n            }\n          ]\n        },\n        \u0026quot;正\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 4,\n              \u0026quot;start_offset\u0026quot;: 6,\n              \u0026quot;end_offset\u0026quot;: 7\n            }\n          ]\n        },\n        \u0026quot;牌子\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 6,\n              \u0026quot;start_offset\u0026quot;: 10,\n              \u0026quot;end_offset\u0026quot;: 12\n            }\n          ]\n        },\n        \u0026quot;筒灯\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 0,\n              \u0026quot;start_offset\u0026quot;: 0,\n              \u0026quot;end_offset\u0026quot;: 2\n            }\n          ]\n        },\n        \u0026quot;索\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 3,\n              \u0026quot;start_offset\u0026quot;: 5,\n              \u0026quot;end_offset\u0026quot;: 6\n            }\n          ]\n        },\n        \u0026quot;这两个\u0026quot;: {\n          \u0026quot;doc_freq\u0026quot;: 1,\n          \u0026quot;ttf\u0026quot;: 1,\n          \u0026quot;term_freq\u0026quot;: 1,\n          \u0026quot;tokens\u0026quot;: [\n            {\n              \u0026quot;position\u0026quot;: 5,\n              \u0026quot;start_offset\u0026quot;: 7,\n              \u0026quot;end_offset\u0026quot;: 10\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n下面我们说说如何通过java代码实现termvector的获取，不说废话直接上代码\n\n```\n\t\t\tTermVectorsResponse \ttermVectorResponse = client.prepareTermVectors().setIndex(sourceindexname).setType(sourceindextype)\n\t\t\t\t\t\t.setId(id).setSelectedFields(fieldname).setTermStatistics(true).execute()\n\t\t\t\t\t\t.actionGet();\n\t\t\t\tXContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON);\n\t\t\t\ttermVectorResponse.toXContent(builder, null);\n\t\t\t\tSystem.out.println(builder.string());\n\t\t\t\tFields fields = termVectorResponse.getFields();\n\t\t\t\tIterator\u0026lt;String\u0026gt; iterator = fields.iterator();\n\t\t\t\twhile (iterator.hasNext()) {\n\t\t\t\t\tString field = iterator.next();\n\t\t\t\t\tTerms terms = fields.terms(field);\n\t\t\t\t\tTermsEnum termsEnum = terms.iterator();\n\t\t\t\t\twhile (termsEnum.next() != null) {\n\t\t\t\t\t\tBytesRef term = termsEnum.term();\n\t\t\t\t\t\tif (term != null) {\n\t\t\t\t\t\t\tSystem.out.println(term.utf8ToString() + termsEnum.totalTermFreq());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n```\n获取TermVectorsResponse的代码很好理解，主要是设置索引名称、索引type、索引id以及需要展示的若干属性。\n\n接下来是如何获取某一term的termvector，有两种方案第一种是通过TermVectorsResponse的toXContent方法直接生成XContentBuilder，这种方法可以直接获取和上面通过DSL查询一样的json结果；第二种是通过Fields的iterator遍历fields，获取TermsEnum，熟悉lucene的同学应会更熟悉第二种方法。\n\n\n\n\n\n\n","title":"java 客户端 获取 termvectors","uid":"6713","views":"1217","votes":"0"},"_type":"doc"}
{"_id":"464","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516581937","category_id":"18","comments":"0","has_attach":"0","id":"464","message":"1.如何选择使用logstash还是elasticsearch-ingest节点？\nhttp://t.cn/RQjPCYj\n\n2.为machine learning jobs自定义聚合查询。\nhttp://t.cn/RQjPQdf\n\n3.elasticsearch因为cpu漏洞所受到的性能冲击。\n[url]http://t.cn/RQjh2oD[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/464\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第166期 (2018-01-22)","uid":"4063","views":"320","votes":"0"},"_type":"doc"}
{"_id":"472","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517014909","category_id":"18","comments":"0","has_attach":"0","id":"472","message":"1、社区文章:利用es获取词频的方法\n[https://elasticsearch.cn/article/461](https://elasticsearch.cn/article/461)\n\n2、关于es搜索客户端的源码分析，该博客的一系列es源码分析都值得一看。\n[http://t.cn/RtLXZol](http://t.cn/RtLXZol)\n\n3、一周热点：你是怎么抢火车票的呢？\n[http://t.cn/R8vJ9Rf](http://t.cn/R8vJ9Rf)\n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/472\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第171期 (2018-01-27)","uid":"1874","views":"346","votes":"0"},"_type":"doc"}
{"_id":"473","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517101675","category_id":"18","comments":"0","has_attach":"0","id":"473","message":"1. Puppet使用ELK堆栈进行日志记录--Part 2。\n[http://t.cn/R878jnu](http://t.cn/R878jnu)\n\n2. Kubernetes监测：最佳实践，方法和现有解决方案。\n[http://t.cn/R87HYZE](http://t.cn/R87HYZE)\n\n3. (自备梯子)你职业生涯中的三个问题。\n[http://t.cn/R87YMvk](http://t.cn/R87YMvk)\n\n\n* 编辑：至尊宝\n\n* 归档：https://elasticsearch.cn/article/473\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第172期 (2018-01-28)","uid":"4460","views":"325","votes":"0"},"_type":"doc"}
{"_id":"474","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517190064","category_id":"18","comments":"0","has_attach":"0","id":"474","message":"1.将ruby代码从logstash配置文件中移除\nhttp://t.cn/R8wsVhO\n\n2.使用elastic site search替代即将被关闭的google site search\nhttp://t.cn/R8wsHvl\n\n3.elastic stack APM 线上演示教程，快来预约吧。\n[url]http://t.cn/R8APlEN[/url] \n\n编辑：cybrdak\n归档：https://elasticsearch.cn/article/474\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第173期 (2018-01-29)","uid":"4063","views":"271","votes":"0"},"_type":"doc"}
{"_id":"475","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517275667","category_id":"18","comments":"0","has_attach":"0","id":"475","message":"1.沪江全链路跟踪系统设计与实践。\n[url]http://t.cn/R8yg6ob[/url] \n2.Elasticsearch和Redis的多种整合方式实战。\n[url]http://t.cn/R8LK0Oe[/url] \n3.使用Apache JMeter对Elasticsearch进行性能测试。\n[url]http://t.cn/R8LKlw8[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/475[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第174期 (2018-01-30)","uid":"3788","views":"313","votes":"0"},"_type":"doc"}
{"_id":"476","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517363456","category_id":"18","comments":"0","has_attach":"0","id":"476","message":"1. macos上安装elk详细教程\n[http://t.cn/R8bevN3](http://t.cn/R8bevN3) \n\n2. 自己动手用ELK分析你的支出\n[http://t.cn/R8bko7m](http://t.cn/R8bko7m) \n\n3. 利用es对地理坐标进行索引和搜索\n[http://t.cn/R8bFHB2](http://t.cn/R8bFHB2) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/476\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第175期 (2018-01-31)","uid":"1874","views":"311","votes":"0"},"_type":"doc"}
{"_id":"529","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520904348","category_id":"18","comments":"0","has_attach":"0","id":"529","message":"1.亿级PV的ELK集群实践之路。\n[url]http://t.cn/RnvPElX[/url]\n2.高效管理Elasticsearch中基于时间的索引。\n[url]http://t.cn/REFMMZM[/url]\n3.elastalert，使用ElasticSearch轻松的\u0026amp;灵活警报。\n[url]http://t.cn/REFxc7F[/url]\n \n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/529[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]  ","title":"Elastic日报 第209期 (2018-03-13)","uid":"3788","views":"680","votes":"0"},"_type":"doc"}
{"_id":"493","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518163712","category_id":"2","comments":"0","has_attach":"0","id":"493","message":"[list]\n[*]属性 cluster.name 如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。[/*]\n[*]属性 node.name 节点名可以忽略[/*]\n[*]属性 node.master 指定该节点是否有资格被选举成为node，默认是true[/*]\n[*]属性 index.number_of_shard 设置默认索引分片个数，默认为5片[/*]\n[*]属性 index.number_of_replica 设置默认索引副本个数，默认为1个副本[/*]\n[*]属性 path.conf 设置配置文件的存储路径，默认是es根目录下的config文件夹。[/*]\n[*]属性 path.data 设置索引数据的存储路径，默认是es根目录下的data文件夹[/*]\n[*]属性 path.work 设置临时文件的存储路径，默认是es根目录下的work文件夹[/*]\n[*]属性 path.logs 设置日志文件的存储路径，默认是es根目录下的logs文件夹[/*]\n[*]属性 path.repo 快照存储路径[/*]\n[*]属性 gateway.recover_after_nodes 设置集群中N个节点启动时进行数据恢复，默认为1[/*]\n[*]属性 network.host 映射出来的ip[/*]\n[*]属性 transport.tcp.port 设置节点间交互的tcp端口，默认是9300[/*]\n[*]属性 http.port: 9200 设置对外服务的http端口，默认为9200[/*]\n[*]属性 index.number_of_replicas 索引的复制副本数量[/*]\n[*]属性 indices.fielddata.cache.size fielddata缓存限制,默认无限制[/*]\n[*]属性 indices.breaker.fielddata.limit fielddata级别限制，默认为堆的60% [/*]\n[*]属性 indices.breaker.request.limit request级别请求限制，默认为堆的40% [/*]\n[*]属性 indices.breaker.total.limit 保证上面两者组合起来的限制，默认堆的70%[/*]\n[*]属性 discovery.zen.ping.multicast.enabled 是否广播模式,默认true,广播模式即同一个网段的ES服务只要集群名[cluster.name]一致,则自动集群[/*]\n[*]属性 discovery.zen.ping.unicast.hosts 手动指定,哪个几个可以ping通的es服务做集群,注意该设置应该设置在master节点上,data节点无效[/*]\n[/list]\n----------------------------------------------------------------------------------------------------------------------------------\nGC Logging \nmonitor.jvm.gc.young.warn: 1000ms\nmonitor.jvm.gc.young.info: 700ms\nmonitor.jvm.gc.young.debug: 400ms\n\nmonitor.jvm.gc.old.warn: 10s\nmonitor.jvm.gc.old.info: 5s\nmonitor.jvm.gc.old.debug: 2s","title":"elasticsearch.yml 个人解读","uid":"5030","views":"1039","votes":"2"},"_type":"doc"}
{"_id":"495","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518233377","category_id":"18","comments":"0","has_attach":"0","id":"495","message":"1. Elasticsearch与Hbase特性对比。 \nhttp://t.cn/RRyM1vm\n2. 将Elasticsearch作为Hive的存储？\nhttp://t.cn/RRyxDNZ\n3. 基于Elasticsearch实现搜索推荐 \nhttp://t.cn/RRyJiHx\n\n- 编辑：wt\n- 归档：https://elasticsearch.cn/article/495\n- 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第185期 (2018-02-10)","uid":"3851","views":"489","votes":"0"},"_type":"doc"}
{"_id":"497","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518311171","category_id":"18","comments":"0","has_attach":"0","id":"497","message":"1.如何用Kibana监控AdroitLogic ESB（UltraESB-X）。\nhttp://t.cn/RRbOoII\n2.分析3个月的未读电子邮件。\nhttp://t.cn/RRbMyR8\n3.(自备梯子)使用ELK堆栈实现客户智能。\nhttp://t.cn/RRbx2XL\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/497\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第186期 (2018-02-11)","uid":"4460","views":"323","votes":"0"},"_type":"doc"}
{"_id":"498","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518333062","category_id":"2","comments":"1","has_attach":"0","id":"498","message":"[b]环境准备：[/b]\n[b]   windows10,jdk1.8,elasticsearch-6.1.3,gradle-4.5,intellij[/b]\n[b]过程：[/b]\n[b]   1:从github上下载elasticsearch-6.1.3版本，并且解压[/b]\n[b]   2：安装gradle配置环境变量[/b]\n[b]   3：进入elasticsearch目录执行：gradle idea命令[/b]\n[b]   4：使用intellij导入elasticsearch项目[/b]\n ","title":"elasticsearch源码导入intellij","uid":"7801","views":"675","votes":"1"},"_type":"doc"}
{"_id":"501","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518420160","category_id":"4","comments":"0","has_attach":"0","id":"501","message":"这是链接文章，其中文中提到的添加节点，具体如何操作？http://blog.csdn.net/qq_24129617/article/details/54743845","title":"kibana如何添加添加server.xsrf.disableProtection节点","uid":"7090","views":"390","votes":"0"},"_type":"doc"}
{"_id":"505","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519339050","category_id":"18","comments":"1","has_attach":"0","id":"505","message":"1.ELK玩转你的支付宝账单\nhttp://t.cn/R8e5Gfl\n2.推荐 | kibana索引信息可视化插件\nhttp://t.cn/REhrlVK\n3.支持增删改查一个简单的Lucene工具类\n[url]https://elasticsearch.cn/article/500[/url] \n\n编辑： 铭毅天下\n归档： https://elasticsearch.cn/article/505\n订阅： https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第191期 (2018-02-23)","uid":"1341","views":"415","votes":"0"},"_type":"doc"}
{"_id":"517","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520132385","category_id":"18","comments":"1","has_attach":"0","id":"517","message":"1.Elasticsearch插件初学者指南。\nhttp://t.cn/RENLNC3\n2.(自备梯子)保护Elasticsearch和Kibana。\nhttp://t.cn/RENA3Sb\n3.(自备梯子)如何成功地教自己如何编码。\nhttp://t.cn/RENLbGm\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/517\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第200期 (2018-03-04)","uid":"4460","views":"324","votes":"0"},"_type":"doc"}
{"_id":"530","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520922103","category_id":"16","comments":"3","has_attach":"0","id":"530","message":"## 活动介绍\n\n本期邀请了阿里巴巴、Elastic、eBay、饿了么的技术专家，分享Elasticsearch及其相关组件在搜索、日志分析和监控领域的应用，帮助开发者更好的理解Elastisearch及其相关组件。\n\n## 活动安排\n##### 时间：2018年3月24日周六 13：30-17：30\n#####地点：上海浦东南路855号世界广场B2层路演中心会场\n\n## 活动主题\n* 13:30—14:00 签到\n* 14:00—14:40 《Elasticsearch在智能运维领域的应用》 Elastic布道师 曾勇\n* 14:40—15:20 《Performance Tuning Best Practice in Elasticsearch》 eBay技术专家 王佩\n* 15:20—16:00 《基于Elasticsearch的离线搜索平台架构设计》 阿里巴巴技术专家 杨孔仕\n* 16:00—16:40 《饿了么在ELasticsearch自动化运维平台和监控平台的应用实践》 饿了么资深搜索工程师 徐胜\n* 16:40—17:30 自由交流\n\n##报名通道\n活动报名通道：\n\nhttps://yq.aliyun.com/event/208/join\n\n使用钉钉扫描，加入Elasticsearch技术交流群：\n\n\u0026lt;p style=\u0026quot;text-align:center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://img.alicdn.com/tfs/TB1v57PjOqAXuNjy1XdXXaYcVXa-100-100.jpg\u0026quot; width = \u0026quot;100\u0026quot; height = \u0026quot;100\u0026quot; alt=\u0026quot;QR\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;\n\n##嘉宾介绍\n##### 曾勇 Elastic布道师、Elasticsearch中国社区发起人\n\n在分布式搜索、高性能、高可用架构、自动化运维等方面积累了超过七年的经验。曾勇是Elasticsearch国内首批用户，自2010年起就开始接触Elasticsearch并投入到生产环境中使用，并编写过一系列的中文处理相关的插件。\n\n演讲主题：《Elasticsearch在智能运维领域的应用》\n分享Elasticsearch和X-Pack组件在智能运维领域的技术原理和应用实践，如非监督型机器学习在自动的异常检测、高级关联和分类、根源问题诊断、早期故障预测等方面的应用等。\n\n##### 王佩 eBay技术专家\n\n9年文档存储、索引、搜索领域软件行业从业经验，使用ElasticSearch约3年。现在eBay的ElasticSearch管理平台Pronto项目组工作，主要方向是ElasticSearch集群的部署和性能调优。\n\n演讲主题：《Performance Tuning Best Practice in Elasticsearch》\neBay内部很多个项目组使用了Elasticsearch来提供数据查询和分析服务，其中绝大部分cluster都是建立在Pronto平台上，由Pronto项目组负责管理维护60+集群和监控调优工作。本次分享介绍了Pronto的ElasticSearch性能调优实践流程，调优过程中的注意事项和检查手段。\n\n##### 杨孔仕 阿里巴巴技术专家\n\n2013年加入阿里巴巴, 先后在淘宝终搜和主搜做搜索平台化的工作。2017年加入美柚,负责美柚的搜索工程技术, 同年11月回到阿里巴巴搜索事业部负责Elasticsearch项目开发工作。\n\n演讲主题：《基于Elasticsearch的离线搜索平台架构设计》\n本次分享介绍了基于Elasticsearch的搜索离线平台的系统设计，结合阿里终搜和阿里主搜以及美柚的离线平台的设计,聊聊离线的数据流程。\n\n##### 徐胜 饿了么资深搜索工程师\n\n在ELasticsearch运维配置、性能调优、分布式计算有丰富实践。目前是饿了么搜索推荐研发部的资深搜索工程师，负责饿了么十几条业务线的es集群的运维、查询和监控平台。\n\n演讲主题：《饿了么在ELasticsearch自动化运维平台和监控平台的应用实践》\n饿了么在10+个业务场景下，Elastisearch集群达到数百个node、千万级indices、TB级别数据量规模。嘉宾分享如何对大规模的线上集群进行运维配置、查询和监控应用。\n ","title":"上海Elasticsearch技术沙龙","uid":"6977","views":"1088","votes":"2"},"_type":"doc"}
{"_id":"536","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521080802","category_id":"3","comments":"0","has_attach":"0","id":"536","message":"\n2018-03-14 22:23:56,833 ERROR [FrontShopController.java:45] : ==dianchou.app.boss.pageController.FrontShopControl\nlerjava.lang.NullPointerException\n      at dianchou.app.boss.pageController.FrontShopController.projectDetail(FrontShopController.java:40)\n      at sun.reflect.GeneratedMethodAccessor495.invoke(Unknown Source)\n      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n      at java.lang.reflect.Method.invoke(Method.java:606)\n      at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n\n","title":"我想只记录这一行，如果写logstash规则","uid":"7418","views":"812","votes":"0"},"_type":"doc"}
{"_id":"543","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521618270","category_id":"2","comments":"1","has_attach":"0","id":"543","message":"# EsParser\nphp的操作类库，通过写sql来转化dsl来查询elasticsearch\n### composer使用\n    {\n        \u0026quot;require\u0026quot;: {\n            \u0026quot;qieangel2013/esparser\u0026quot;: \u0026quot;dev-master\u0026quot;\n        }\n    }\n    composer install\n    require __DIR__.'/vendor/autoload.php';\n    $sql = 'select * from alp_dish_sales_saas where sid in(994,290) limit 1,10';\n    //$sql='update alp_dish_sales_saas set mid=3  where adsid=15125110';\n    //$sql='delete from alp_dish_sales_saas where adsid=15546509';\n    $es_config=array(\n\t    'index' =\u0026gt;\u0026quot;alp_dish_sales_saas\u0026quot;,\n\t    'type'  =\u0026gt;\u0026quot;alp_dish_sales_saas\u0026quot;,\n\t    'url'   =\u0026gt;\u0026quot;http://127.0.0.1:9200\u0026quot;,\n        'version' =\u0026gt;\u0026quot;5.x\u0026quot; //1.x 2.x 5.x 6.x,可以不配置，系统会请求获取版本，这样会多一次请求,建议配置一下\n\t );\n    $parser = new EsParser($sql, true,$es_config);//第三个参数是es的配置参数，一定要配置\n    print_r($parser-\u0026gt;result);//打印结果\n    //print_r($parser-\u0026gt;explain());//打印dsl\n### 普通调用\n\trequire_once dirname(__FILE__) . '/src/library/EsParser.php';\n\t$sql = 'select * from alp_dish_sales_saas where sid in(994,290) limit 1,10';\n\t//$sql='update alp_dish_sales_saas set mid=3  where adsid=15125110';\n\t//$sql='delete from alp_dish_sales_saas where adsid=15546509';\n\t$es_config=array(\n        \t'index' =\u0026gt;\u0026quot;alp_dish_sales_saas\u0026quot;,\n        \t'type'  =\u0026gt;\u0026quot;alp_dish_sales_saas\u0026quot;,\n        \t'url'   =\u0026gt;\u0026quot;http://127.0.0.1:9200\u0026quot;,\n            'version' =\u0026gt;\u0026quot;5.x\u0026quot; //1.x 2.x 5.x 6.x,可以不配置，系统会请求获取版本，这样会多一次请求,建议配置一下\n    \t);\n\t$parser = new EsParser($sql, true,$es_config);//第三个参数是es的配置参数，一定要配置\n\tprint_r($parser-\u0026gt;result);//打印结果\n\t//print_r($parser-\u0026gt;explain()); //打印dsl\n### 目前支持的sql函数\n    *  SQL Select\n    *  SQL Delete\n    *  SQL Update\n    *  SQL Where\n    *  SQL Order By\n    *  SQL Group By\n    *  SQL AND \u0026amp; OR \n    *  SQL Like\n    *  SQL COUNT distinct\n    *  SQL In\n    *  SQL avg()\n    *  SQL count()\n    *  SQL max()\n    *  SQL min()\n    *  SQL sum()\n    *  SQL Between\n    *  SQL Aliases\n### 使用注意事项\n    请在配置项填写es的版本,这样系统不会请求获取版本，这样不会多一次请求,建议配置一下\n### 交流使用\n    qq群：578276199\n### 项目地址\n    github：https://github.com/qieangel2013/EsParser\n    oschina：https://gitee.com/qieangel2013/EsParser\n","title":"php的操作类库，通过写sql来转化dsl来查询elasticsearch","uid":"7882","views":"1581","votes":"0"},"_type":"doc"}
{"_id":"550","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522129823","category_id":"12","comments":"0","has_attach":"0","id":"550","message":"[b]工作职责：[/b]\n\n负责京东弹性检索平台的相关研发和架构工作\n\n不断提升系统性能、稳定性、资源使用率\n\n结合业务方解决技术难题，用技术推动业务发展\n\n\n[b]要求：[/b]\n\n5年以上相关工作经验，本科及以上学历\n\n精通java编程，Java 基础扎实，精通常用GC算法、JVM内存结构和参数调优，具备良好的面向对象设计能力和编程习惯\n\n精通nio, epoll， netty等高性能网络编程，具备丰富的高并发，分布式，缓存，消息等编程实战经验\n\n精通elasticsearch，熟悉其各个模块，掌握其源码\n\n精通lucene源码，掌握分词和排序原理\n\n精通系统性能调优\n\n熟悉资源监控和弹性调度者优先\n\n熟悉zookeeper，mq，redis等优先\n\n善于独立思考,良好的学习能力、团队协作能力和沟通；热爱技术，对技术有不懈的追求，喜欢研究开源代码\n\n[b]待遇[/b]：\n\n30k～50k\n\n[b]联系方式：[/b]\n\nhexiaofeng@jd.com\n\n\n\n ","title":"【京东】招聘弹性检索研发工程师","uid":"8096","views":"874","votes":"1"},"_type":"doc"}
{"_id":"551","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522201456","category_id":"18","comments":"0","has_attach":"0","id":"551","message":"1.  Elasticsearch开发实战篇 基于Elasticsearch的SQL报警引擎\n[url]http://t.cn/RnY3AYS[/url] \n2.  统一日志平台构建\n[url]http://t.cn/RM3PxUU[/url] \n3. 日志监控系统\n[url]http://t.cn/R5fzQ70[/url] \n \n编辑:  江水\n归档：[url]https://elasticsearch.cn/article/551[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第224期 (2018-03-28)","uid":"3828","views":"334","votes":"0"},"_type":"doc"}
{"_id":"557","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522719010","category_id":"18","comments":"0","has_attach":"0","id":"557","message":"1.自建ELK vs 日志服务(SLS)全方位对比。\n[url]http://t.cn/RnFWcO6[/url] \n2.Elasticsearch 索引逻辑。\n[url]http://t.cn/RnFONSn[/url] \n3.使用Elasticsearch实现歌词检索。\n[url]http://t.cn/RnF0jYQ[/url] \n[url]http://t.cn/RnF0RrL[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/557[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第230期 (2018-04-03)","uid":"3788","views":"326","votes":"0"},"_type":"doc"}
{"_id":"567","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523242203","category_id":"12","comments":"0","has_attach":"1","id":"567","message":"有意向的小伙伴可以加我的微信，在其它平台上投过简历的就不要找我内推了。\r\n \r\n \r\n \r\n \r\n \r\n \r\n ","title":"苏州 同程艺龙  大数据开发工程师、大数据平台开发工程师、数据仓库开发工程师，内推啦，，，","uid":"2363","views":"674","votes":"0"},"_type":"doc"}
{"_id":"570","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523498506","category_id":"18","comments":"0","has_attach":"0","id":"570","message":"1. filebeat源码分析和grok feature新增。\n[http://t.cn/Rm6mJJ8](http://t.cn/Rm6mJJ8) \n\n2. Elasticsearch的轻量级http代理。\n[http://t.cn/Rm5F6eI](http://t.cn/Rm5F6eI) \n\n3. Elasticsearch分布式一致性原理剖析(二)-Meta篇。\n[http://t.cn/Rm6mjla](http://t.cn/Rm6mjla) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/570\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第239期 (2018-04-12)","uid":"668","views":"335","votes":"0"},"_type":"doc"}
{"_id":"577","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523852533","category_id":"18","comments":"0","has_attach":"0","id":"577","message":"1.ES 5.4-5.5.2引起的Kibana性能问题。\nhttps://elasticsearch.cn/article/269\n\n2.ELK Stack最近在报表方面的改进和增强。\nhttp://t.cn/RmYPe9t\n\n3.使用kibana和Beats 来做安全分析。\n[url]http://t.cn/RmYhwEq[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/577\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第243期 (2018-04-16)","uid":"4063","views":"322","votes":"0"},"_type":"doc"}
{"_id":"579","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524019530","category_id":"18","comments":"0","has_attach":"0","id":"579","message":"1. 死磕 Elasticsearch 方法论\n[url]http://t.cn/Rm73AN3[/url] \n2. Elasticsearch 6.X 去重详解\n[url]http://t.cn/RmudVy7[/url] \n3. Elasticsearch 并发冲突问题\n[url]http://t.cn/RmudmkM[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/579[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"​Elastic日报 第245期 (2018-04-18)","uid":"3828","views":"407","votes":"0"},"_type":"doc"}
{"_id":"581","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524128470","category_id":"44","comments":"0","has_attach":"1","id":"581","message":"[attach]2072[/attach]\n\nElastic Podcast 来啦！让我来先给大家介绍一下什么是 Elastic Podcast，这是一档新的由 Elastic 中文社区发起的谈话类播客节目，我们会定期邀请 Elastic 软件的用户，一起来聊一聊他们与 Elastic 的故事，会围绕各种有意思的话题进行讨论，比如具体的行业应用实践啦、实际的架构部署啦、来自一线的实战经验分享等等。他山之石可以攻玉，相信会对你有帮助。\n\n好啦，回到正题，第一期有什么呢，让我们一起走进位于上海的 DerbySoft（德比软件），德比软件是一家专注于旅游酒店行业管理系统的公司，其客户分布全球，每天有上千台服务器在不停的产生日志，让我们来听听德比软件的解经理给大家介绍，他们是如何用不到 20 台的 Elasticsearch 服务器来支撑总量 800 亿的日志分析，以及了解他们具体是如何使用 Kibana，以及在使用过程中的各种经验和分享。\n\n### 主持人： \n\nElastic 技术布道师，曾勇（Medcl）。 \n\n### 嘉宾：\n \n解恒跃，德比软件研发一部高级技术经理，从事软件开发和管理工作 12 年；擅长 Java 相关技术，webservice，微服务，敏捷软件开发。\n\n### 收听方法\n\n可以点击下面的任意链接来收听（时长约 30 分钟）：\n\n- SoundCloud： [https://soundcloud.com/elastic-cn/elastic-podcast1...](https://soundcloud.com/elastic-cn/elastic-podcast1-xiehengyuederbysoft)\n- 喜马拉雅：[http://m.ximalaya.com/111156131/sound/82918649](http://m.ximalaya.com/111156131/sound/82918649) \n- 蜻蜓 FM：[https://www.qingting.fm/channels/244978/programs/8916389](https://www.qingting.fm/channels/244978/programs/8916389) \n\n### 关于 DerbySoft： \n\n德比软件创立于 2002 年，是专业从事旅游网络营销系统的技术服务公司，近 400 人的员工分布于上海、北京、南京、达拉斯、伦敦、东京等地。是拥有全部产品自主知识产权并为全球酒店行业提供软件服务的公司，是目前全球提供酒店对接服务最好，并且对接上线成功案例最多的公司。https://www.derbysoft.com/","title":"Elastic Podcast 第一期，嘉宾：解恒跃@德比软件","uid":"1","views":"437","votes":"3"},"_type":"doc"}
{"_id":"584","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524272660","category_id":"18","comments":"0","has_attach":"0","id":"584","message":"1. ES分词器总结。\n[http://t.cn/RmssC81](http://t.cn/RmssC81) \n\n2. ES span查询总结。\n[http://t.cn/RUuLlsV](http://t.cn/RUuLlsV) \n\n3. 使用JNoSQL连接ES和Java  EE  。\n[http://t.cn/RmssC83](http://t.cn/RmssC83) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/584 \n\n* 订阅：https://tinyletter.com/elastic-daily\n\n\n","title":"Elastic日报 第248期 (2018-04-21)","uid":"1874","views":"471","votes":"0"},"_type":"doc"}
{"_id":"590","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524541291","category_id":"18","comments":"0","has_attach":"0","id":"590","message":"1.elasticsearch源码深入分析—线程池的封装。\n[url]http://t.cn/Ru4iSx8[/url] \n2.从批处理ETL到流式处理：一个来自Netflix的案例。\n[url]http://t.cn/Ru4i9yg[/url] \n3.dejavum，一种基于客户端渲染方式的 ElasticSearch Web 管理界面。\n[url]http://t.cn/R9DZheQ[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/590[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第251期 (2018-04-24)","uid":"3788","views":"467","votes":"1"},"_type":"doc"}
{"_id":"594","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524781936","category_id":"18","comments":"0","has_attach":"0","id":"594","message":"1、Elasticserch script 脚本使用指南\nhttp://t.cn/RNXjWeG\n2、在Elasticsearch中估算存储文档的成本\nhttp://t.cn/RuMkFA9\n3、支持多表join的Elasticsearch工具推荐\n[url]http://t.cn/Rux5aNW[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/594\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第254期 (2018-04-27)","uid":"1341","views":"458","votes":"1"},"_type":"doc"}
{"_id":"597","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525058085","category_id":"18","comments":"0","has_attach":"0","id":"597","message":"1. 如何使用Metricbeat。\nhttp://t.cn/RuphpbV\n2.用ELK分析Runkeeper的数据。\nhttp://t.cn/RHDk1Xa\n3.DevOps面试十问十答。\nhttp://t.cn/RupAKy4\n \n编辑：wt\n归档：https://elasticsearch.cn/article/597\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第257期 (2018-04-30)","uid":"3851","views":"370","votes":"0"},"_type":"doc"}
{"_id":"603","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525424653","category_id":"2","comments":"0","has_attach":"1","id":"603","message":"开源地址：[url]https://github.com/kppotato/kafka_monitor[/url]\r\n \r\n项目使用：golang开发，数据库:prometheus 图形：grafana","title":"新的kafka集群监控系统使用golang开发","uid":"8488","views":"548","votes":"2"},"_type":"doc"}
{"_id":"607","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525742508","category_id":"18","comments":"0","has_attach":"0","id":"607","message":"1.看Uber如何对Elasticsearch集群进行缩放管理。\n[url]http://t.cn/RusftD1[/url] \n2.在Kubernetes集群上使用Elasticsearch、Fluentd和Kibana进行日志聚合。\n[url]http://t.cn/RusfqHn[/url] \n3.探讨理想的Elasticsearch索引设计原则。\n[url]http://t.cn/Rusfb0U[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/607[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第265期 (2018-05-08)","uid":"3788","views":"376","votes":"0"},"_type":"doc"}
{"_id":"608","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525765207","category_id":"13","comments":"5","has_attach":"0","id":"608","message":"elastic/beats项目中支持mysql协议的解析，但实际使用过程中发现不支持预编译和压缩通信协议的解析，所以扩展了预编译SQL和压缩通信协议的支持，目前已稳定运行在生产环境，所有SQL都能完美解析，已提交PR,有相同需求的同学可参考。","title":"mysql协议解析扩展","uid":"2157","views":"441","votes":"0"},"_type":"doc"}
{"_id":"675","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529390818","category_id":"18","comments":"0","has_attach":"0","id":"675","message":"1.Elasticsearch索引最后一公里，减少最后的延迟。\n[url]http://t.cn/RBubQ7G[/url] \n2.Elasticsearch 6.3对SQL功能介绍。\n[url]http://t.cn/RBuynQh[/url] \n3.Elasticsearch性能调优指南。\n[url]http://t.cn/RBuqkbf[/url] \n\n活动预告\n1. 6月30日南京meetup参会报名中\n[url]https://elasticsearch.cn/m/article/647[/url] \n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/675[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第307期 (2018-06-19)","uid":"3788","views":"336","votes":"0"},"_type":"doc"}
{"_id":"619","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526272474","category_id":"18","comments":"0","has_attach":"0","id":"619","message":"1.使用Apache Spark将数据写入ElasticSearch.。\nhttp://t.cn/R8flF70\n\n2.使用Spark Streaming + Elasticsearch + kafka 构建实时数据聚合平台。\nhttp://t.cn/R3MZEyL\n\n3.(自备翻墙)如何将一个100s的搜索降低到亚秒范围内。\n[url]http://t.cn/R3IQxdo[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/619\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第271期 (2018-05-14)","uid":"4063","views":"345","votes":"0"},"_type":"doc"}
{"_id":"623","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526456095","category_id":"2","comments":"1","has_attach":"0","id":"623","message":"[url]https://www.huaweicloud.com/product/es.html[/url] ","title":"向大家推荐华为云的Elasticsearch，免去您的运维烦恼！欢迎使用~~","uid":"8616","views":"650","votes":"0"},"_type":"doc"}
{"_id":"626","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526593090","category_id":"18","comments":"1","has_attach":"0","id":"626","message":" \n1、Elasticsearch-PHP 中文手册上线了\nhttp://t.cn/R3pKjru\n2、一网打尽Grok Debugger\nhttps://elasticsearch.cn/article/621\n3、C# Elasticsearch实战样例\nhttp://t.cn/R303stO\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/626\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第275期 (2018-05-18)","uid":"1341","views":"358","votes":"1"},"_type":"doc"}
{"_id":"636","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527127801","category_id":"18","comments":"0","has_attach":"0","id":"636","message":"1. 重磅！kibana中文手册发布。\n[http://t.cn/R3eoVvc](http://t.cn/R3eoVvc) \n\n2. Elasticsearch如何实现 SQL语句中 Group By 和 Limit 的功能。\n[http://t.cn/R3k85NN](http://t.cn/R3k85NN) \n\n3. Laravel 中使用 ElasticSearch。\n[http://t.cn/R3k8V48](http://t.cn/R3k8V48) \n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/636 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第281期 (2018-05-24)","uid":"668","views":"370","votes":"0"},"_type":"doc"}
{"_id":"639","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527295749","category_id":"18","comments":"0","has_attach":"0","id":"639","message":"1. postmark使用curator经验分享。\n[http://t.cn/R1wYJxL](http://t.cn/R1wYJxL) \n\n2. kreuzwerker数据从SQL Server迁移到ES经验。\n[http://t.cn/R1wYJxZ](http://t.cn/R1wYJxZ) \n\n3. 在kibana中使用自定义底图描绘区域和坐标。\n[http://t.cn/R1wYJx2](http://t.cn/R1wYJx2) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/639\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第283期 (2018-05-26)","uid":"1874","views":"362","votes":"0"},"_type":"doc"}
{"_id":"155","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493349954","category_id":"2","comments":"9","has_attach":"1","id":"155","message":"[url=https://github.com/unimassystem/esql5]esql[/url]\n[b]Git地址[/b]\n[url]https://github.com/unimassystem/esql5[/url] \n\n[attach]556[/attach]\n [code]create table my_index.my_table (\n     id keyword,\n     name text,\n     age long,\n     birthday date\n);\n\nselect * from my_index.my_type;\n\nselect count(*) from my_index.my_table group by age;\n#Create table\n\n字段参数,ES中分词规则、索引类型、字段格式等高级参数的支持\n\ncreate table my_table (\n\tname text (analyzer = ik_max_word),\n\tdd text (index=no),\n\tage long (include_in_all=false)\n);\n\n\n对象、嵌套字段支持 as\n\ncreate table my_index (\n\tid long,\n\tname text,\n     obj object as (\n         first_name text,\n         second_name text (analyzer=pinyin)\n     )\n);\n\n\ncreate table my_index (\n\tid long,\n\tname text,\n   obj nested as (\n         first_name text,\n         second_name text (analyzer=pinyin)\n   )\n);\n\n\nES索引高级参数支持 with option\n\ncreate table my_index (\n\tid long,\n\tname text\n) with option (\n\tindex.number_of_shards=10,\n   index.number_of_replicas = 1\n);\n#Insert/Bulk\n\n单条数据插入\ninsert into my_index.index (name,age) values ('zhangsan',24);\n\n多条插入\nbulk into my_index.index (name,age) values ('zhangsan',24),('lisi',24);\n\n\n对象数据插入,list,{}Map\n\ninsert into my_index.index (ds) values (['zhejiang','hangzhou']);\n\t\t\ninsert into my_index.index (dd) values ({address='zhejiang',postCode='330010'});\n#select/Aggregations\n\nselect * from my_table.my_index where name like 'john *' and age between 20 and 30 and (hotel = 'hanting' or flight = 'MH4510');\n\n地理位置中心点查询\nselect * from hz_point where geo_distance({distance='1km',location='30.306378,120.247427'});\n\n地理坐标区域查询\nselect * from hz_point where geo_bounding_box({location={top_left='31.306378,119.247427',bottom_right='29.285797,122.172329'}});\n\npipeline统计 move_avg\nselect count(*) as total, moving_avg({buckets_path=total}) from my_index group by date_histogram({field=timestamp,interval='1h'});\nGetting Started\n\n环境要求python \u0026gt;= 2.7\n\nexport PYTHONHOME=(%python_path)\nexport PATH=$PYTHONHOME/bin:$PATH\n\n\n安装第三方依赖包\npip install -r esql5.egg-info/requires.txt\n或python setup.py install\n\n运行esql5服务 \n(standalone):\ncd esql5\npython -m App.app\n\n(with uwsgi)\ncd esql5\nuwsgi --ini conf/uwsgi.ini\n\n\nshell终端:\npython -m elsh.Command[/code]","title":"Sql on Elasticsearch","uid":"1452","views":"5073","votes":"0"},"_type":"doc"}
{"_id":"158","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493907901","category_id":"2","comments":"6","has_attach":"0","id":"158","message":"尽管之前在很多地方都提到过，不过还是有必要单独开篇文章提醒一下大家！\nType 已经打算在6.0移除了，所以在设计 elasticsearch 的数据结构的时候，要注意到后面版本的变化。\n之前在很多的文章和 PPT 都有介绍Elasticsearch 的几个核心概念，Index 对应 DB，Type 对应表，Document 对应记录，然后就真的按数据库的路子用，一个 index 里面 n 个 type 的情况大有存在，但是在 Lucene 里面其实有很多问题，所以现在es移除也是考虑了很久的。\n\n新增参数：[code]index.mapping.single_type: true[/code] \nUID 也会移除掉 _type 的值。\n\nType 移除大概分为两个阶段：\n第一步，不支持新的索引创建多个 type，一个索引只有一个 type，名称也是固定的，不能修改。\n第二步，移除。\n \n相应的 PR 已经 merge 了。\n[url]https://github.com/elastic/elasticsearch/pull/24317[/url]\n ","title":"Elasticsearch 6.0 将移除 Type","uid":"1","views":"7444","votes":"1"},"_type":"doc"}
{"_id":"179","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495796544","category_id":"8","comments":"3","has_attach":"1","id":"179","message":"[url=https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html]Grok[/url] 是一个常用的对日志进行结构化的一个工具，\n可以通过在线工具进行调试：\n[url]http://grokdebug.herokuapp.com[/url]\n[url]http://grokconstructor.appspot.com[/url]\n \n不过有时候比较慢，甚至不能访问，所以现在为大家搭好了一个国内的镜像，方便使用：\n[url]http://grok.elasticsearch.cn/[/url]\n \n目前还是英文，源码fork至：[url]https://github.com/elasticsearch-cn/GrokConstructor[/url]\n欢迎提交PR来进行翻译。\n\n[attach]647[/attach]\n \nPS: \n1. Kibana后续将提供Grok Debug的功能；\n2.如果你的日志每一行都遵循固定格式，你可以考虑使用 [url=https://www.elastic.co/guide/en/logstash/current/plugins-filters-dissect.html]dissect filter[/url]，性能更强更简单。","title":"Grok Debugger 国内镜像","uid":"1","views":"4989","votes":"2"},"_type":"doc"}
{"_id":"181","_index":"forum-mysql","_score":1,"_source":{"addtime":"1495952341","category_id":"2","comments":"2","has_attach":"0","id":"181","message":" \n1、深入详解Elasticearch：[url]http://blog.csdn.net/column/details/deep-elasticsearch.html[/url]\n \n2、这个专栏，起初主要用来研究关系型数据mysql/oracle非关系型数据库mongo与Elaticsearch的实时同步问题，随着延伸和项目需要，还会路线拓展ES java开发等问题；\n \n3、之前的研究都是基于Elasticsearch2.3.4版本。基础原理想通。 5.X，6.X版本后续也会跟进。\n \n欢迎大家品鉴，多提不足！\n \n终生学习者：铭毅天下，博客地址：[url]http://blog.csdn.net/laoyang360[/url]","title":"写了个深入详解Elasticsearch专栏，欢迎大家品鉴！","uid":"1341","views":"2274","votes":"9"},"_type":"doc"}
{"_id":"185","_index":"forum-mysql","_score":1,"_source":{"addtime":"1496732133","category_id":"2","comments":"26","has_attach":"1","id":"185","message":"[quote]\nElasticHD 是一款 ElasticSearch的可视化应用。不依赖ES的插件安装，更便捷；导航栏直接填写对应的ES IP和端口就可以操作Es了。目前支持如下功能：\n[list]\n[*] ES Real time data search[/*]\n[*] ES Dashboard data visualization[/*]\n[*] ES Index Template (在线修改、查看、上传）[/*]\n[*] ES Indices Index deletion and search[/*]\n[*] SQL Converts to Elasticsearch DSL[/*]\n[*] ES 基本查询文档[/*]\n[/list]\n[/quote]\n\n\n[b]Install elasticHD[/b]\n[url=https://github.com/farmerx/elasticHD/releases]Precompiled binaries[/url] for supported operating systems are available.\n[b]Basic Usage[/b]\n[list]\n[*]  linux and MacOs use ElasticHD[/*]\n[/list]\n[list=1]\n[*]下载对应的elasticHD版本，unzip xxx_elasticHd_xxx.zip [/*]\n[*]修改权限 chmod 0777 ElasticHD [/*]\n[*]可指定ip端口运行elastichd ./ElasticHD -p 127.0.0.1:9800 默认 ip和端口也是这个[/*]\n[/list]\n[list]\n[*] windows use ElasticHD [/*]\n[*]直接下载对应windows版本,解压，双击运行。当然想指定端口的话同linux\n[/*]\n[/list]\n  \n[list]\n[/list]\n[b] [/b]Application Info\n ","title":"ElasticHD: ElasticSearch Dashboard Application","uid":"3014","views":"31143","votes":"4"},"_type":"doc"}
{"_id":"187","_index":"forum-mysql","_score":1,"_source":{"addtime":"1497838314","category_id":"16","comments":"6","has_attach":"1","id":"187","message":"报名链接：http://elasticsearch.mikecrm.com/O6o0yq3 \n \n1.举办方\n主办：Elastic 中文社区  \n \n协办：魔蝎科技\n\n[attach]716[/attach]\n\n独家直播：\n \nIT大咖说\n\n[attach]704[/attach]\n\n\n2. 时间地点\n 活动时间：2017年6月25日 13:30 - 18:00 \n 活动地点：杭州市西湖区文一西路767号西溪国际商务中心E座1楼会议室\n\n3. 主题\n\n[b]分享一：基于ElasticSearch构建搜索云服务[/b]\n\n[attach]708[/attach]\n\n演讲者简介：\n陈超，七牛云技术总监，Spark Summit China 出品人， 专注于大规模分布式计算与机器学习领域。\n\n主题简介：\n介绍七牛基于 Elasticsearch 如何构建大规模搜索云服务的经验和思考。\n\n[b]分享二：采用Elasticsearch构建大规模通用搜索平台的经验分享[/b]\n\n[attach]711[/attach]\n \n演讲者简介：\n马华标 - 城破 蚂蚁金服中间件搜索负责人， 12年加入阿里巴巴任职于B2B中文站架构部、数据仓库架构组组长，14年加入蚂蚁金服担任中间件搜索负责人， 从事搜索方面的团队建设与产品研发工作。\n \n主题简介：\n介绍蚂蚁金服采用Elasticsearch构建大规模通用搜索平台的经验分享。\n \n[b]分享三：垂直搜索引擎系统架构[/b]\n\n[attach]709[/attach]\n\n演讲者简介：\n吴英昊  花名：丰坚\n\n蚂蚁金服数据中间件技术专家，曾任职于当当网，担任搜索架构师（兼开发经理）职位，负责当当网的搜索后台的技术架构和技术团队的管理，包括搜索引擎架构，搜索排序和 Query 分析，后在一创业公司负责推荐和广告系统架构和算法相关工作。 目前在蚂蚁金服数据中间件搜索组技术专家。\n主题简介： \n主题 “垂直搜索引擎系统架构”，介绍如何采用 Elasticsearch 构建大规模通用搜索平台。会穿插一些关于ES在垂直搜索中的应用和优化方向。\n\n\n[b]分享四：Metricbeat 在容器监控方面的应用[/b]\n\n[attach]710[/attach]\n\n演讲者简介：\n曾勇（Medcl） Elastic 工程师与布道师\nElasticsearch 爱好者，2015年加入 Elastic，Elastic 中文社区的发起人，Elastic 公司在中国的首位员工。\n\n主题简介：\n使用 Docker 或者其他的容器方案来进行部署已经成为热门，今天的分享将介绍如何使用 Metricbeat 来收集和监控您的容器化部署环境，结合 Elasticsearch 和 Kibana 对容器的性能进行全方位的了解。","title":"【线下活动】2017-06-25 杭州 Elastic Meetup日程安排","uid":"1","views":"3782","votes":"4"},"_type":"doc"}
{"_id":"261","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504851679","category_id":"16","comments":"18","has_attach":"0","id":"261","message":"Elastic 线下活动又双叒叕来啦，????，这次的活动日程是：\n[list]\n[*]1️⃣   [url=https://elasticsearch.cn/article/320]长沙[/url]，2017.10.28[/*]\n[*]2️⃣   [url=https://elasticsearch.cn/article/344]武汉[/url]，2017.11.4[/*]\n[*]3️⃣   [url=https://elasticsearch.cn/article/364]广州[/url]，2017.11.25[/*]\n[*]4️⃣   [url=https://elasticsearch.cn/article/406]深圳[/url]，2017.12.16[/*]\n[/list]\n \n在这些城市的同学快快来报名，可以报名分享，也可以报名参会，更欢迎一起组织✌️。\n \n干货交流，免费参加，不收费（一直都是）！\n\n[b]已有主题(欢迎报名分享)：[/b]\n[list]\n[*]Elastic - Medcl - Elastic Stack 6.0 新功能介绍[/*]\n[*]基于爬虫和 Elasticsearch 快速构建站内搜索引擎[/*]\n[*]芒果 TV - 刘波涛 - 芒果日志之旅[/*]\n[*]尚德机构 - 白凡 - 高吞吐状况下斗鱼搜索引擎优化之路[/*]\n[*]腾讯 - 姜国强- 基于 ES 的时序数据库服务[/*]\n[*]中信银行信用卡中心 - 陈刚 - ES的容器化之路[/*]\n[*]中投证券 - 尉晋洪 - ELK 在证券行业业务监控中的应用[/*]\n[*]网易 - ELK 在藏宝阁中的应用[/*]\n[*]网易 - 网易 ELK 系统综述[/*]\n[*]数说故事 - 吴文杰 - ElasticSearch with OLAP in Datastory[/*]\n[*]酷狗 - 钟旺 - 基于ES的音乐搜索引擎[/*]\n[*]Vivo - 杨振涛 - Elasticsearch在vivo互联网的最佳实践[/*]\n[/list]\n \n报名分享与场地赞助请加微信：medcl123\n\n[b]上半年往期回顾~[/b]\n[list]\n[*]杭州：[url]https://elasticsearch.cn/article/187[/url][/*]\n[*]北京：[url]https://elasticsearch.cn/article/167[/url][/*]\n[*]上海：[url]https://elasticsearch.cn/article/163[/url][/*]\n[*]南京：[url]https://elasticsearch.cn/article/164[/url][/*]\n[/list]\n\n对了，报名链接：[url]http://elasticsearch.mikecrm.com/O6o0yq3[/url]  \n名额有限哦！","title":"线下活动又来啦，长沙，武汉，广州，深圳的同学快来报名啊  ?  ","uid":"1","views":"4137","votes":"11"},"_type":"doc"}
{"_id":"189","_index":"forum-mysql","_score":1,"_source":{"addtime":"1498186410","category_id":"5","comments":"1","has_attach":"1","id":"189","message":"[attach]733[/attach]\n\n[attach]731[/attach]\n\n[attach]732[/attach]\n \nhttps://www.elastic.co/blog/welcome-opbeat-to-the-elastic-family\nhttps://techcrunch.com/2017/06/22/elastic-enters-apm-space-with-opbeat-acquisition/\n \n \nToday, at Elastic’s customer event in London, the company announced it has acquired Opbeat, a SaaS-application performance management vendor for an undisclosed amount. All 15 employees have already joined the Elastic team.\n\nOpbeat focuses on monitoring applications written in Javascript. What’s more, it maps production application issues directly to the relevant developer source code, making it easier to fix the problem without having to hunt in the code to find the problem area.\n\nElastic is probably best known for its search product, Elasticsearch, an open source search tool that runs on some of the world’s biggest properties including Wikipedia, Yelp and eBay. In recent years, the company has moved beyond straight search and into analytics, particularly focusing on log data that puts them squarely in competition with companies like Splunk. Last year, it pulled all of the products together into a platform play they called Elastic Stack.\n\nElastic CEO Shay Banon sees today’s acquisition through a strategic lens, giving his company a leg up on the competition by offering not only a way to search log data, but also giving insights into the applications that are generating the data and why they may be performing poorly.\n\nRasmus Makwarth, who was CEO at Opbeat says joining Elastic allows the company to speed up the product roadmap and take advantage of the breadth of the Elastic platform. “We’ve been running a SaaS platform for some time now, giving application insights to developers, but haven’t been able to give customers insight into the entire application,” he explained. Joining Elastic lets his company take advantage of the search tool, as well as analytics, logging and data visualization available on the Elastic platform to greatly expand the vision.\n\nOpbeat’s employees have already joined Elastic and are working with the Elastic team to build an on-prem application to go with the existing SaaS piece. Banon said that the company hopes to take advantage of Opbeat’s cloud background to expand its cloud offerings.\n\nTaking a cloud-native application and engineering it to be on-prem is no simple task, but the two companies hope to have an on-prem version ready in several month. It’s worth noting that Opbeat was using Elasticsearch in its product, but as Banon pointed out using a product and making it part of the stack are two different matters, and it will take a significant engineering effort to incorporate the new company into the fold as both a cloud and on-prem product.\n\nYou may recall that Cisco bought APM vendor AppDynamics earlier this year for $3.7 billion right before the company was about to IPO. While Banon wouldn’t reveal today’s purchase price, he joked that it was substantially less than that.\n\nGiven that Opbeat was founded in 2013 in Copenhagen, Denmark and has raised approximately $2.8 million, that’s a fair bet. The company will remain in Denmark.","title":"Elastic 收购 Opbeat，进入 APM 领域","uid":"1","views":"1994","votes":"1"},"_type":"doc"}
{"_id":"197","_index":"forum-mysql","_score":1,"_source":{"addtime":"1500865919","category_id":"2","comments":"1","has_attach":"0","id":"197","message":"在jdbc中，如果需要多少使用到时间的值。如果使用lastexecutionstart，分了两次查询，time不一致。对于初始化和热更新都不一致。例如：\nsql : [\n{ \u0026quot;statement\u0026quot; : \u0026quot;select * from table1 where mytimestamp \u0026gt; ?\u0026quot;, \u0026quot;parameter\u0026quot; : [ \u0026quot;$metrics.lastexecutionstart\u0026quot; ] },\n{ \u0026quot;statement\u0026quot; : \u0026quot;select * from table2 where mytimestamp \u0026gt; ?\u0026quot;, \u0026quot;parameter\u0026quot; : [ \u0026quot;$metrics.lastexecutionstart\u0026quot; ] }\n    ],","title":"es中的jdbc，如何使用多次的lastexecutionstart.","uid":"3174","views":"853","votes":"0"},"_type":"doc"}
{"_id":"201","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501423997","category_id":"18","comments":"7","has_attach":"0","id":"201","message":"1. A Practical Introduction to Elasticsearch http://t.cn/R9tzos1\n通过实际案例介绍Elasticsearch，作为入门教程还是不错的，推荐新手阅读！\n\n2. Elasticsearch 5.0 General Performance Recommendations http://t.cn/R9tz3Vc\n关注性能的同学有福了，来看看qbox工程师对于 5.0 调优的建议，干货满满，不要错过哦！\n\n3. Filebeat vs. Logstash — The Evolution of a Log Shipper  http://t.cn/R9tZBFq\n相信不少同学对于 Beats 和 Logstash的定位有疑惑，不妨看下这篇文章！\n \n编辑：rockybean\n归档：[url]https://elasticsearch.cn/article/201[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第1期 (2017-07-30)","uid":"86","views":"2012","votes":"4"},"_type":"doc"}
{"_id":"389","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511227490","category_id":"18","comments":"3","has_attach":"0","id":"389","message":"1.去哪儿网OPS团队基于Mesos/Docker构建的Elasticsearch容器化私有云。\n[url]http://t.cn/RjdGkzi[/url] \n2.图文详解如何部署一套线上的高商用ELK集群。\n[url]http://t.cn/RjdbuAb[/url] \n3.使用ELK处理OSS访问日志详解。\n[url]http://t.cn/RjecYmf[/url] \n \n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/389[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]  \n ","title":"Elastic日报 第107期 (2017-11-21)","uid":"3788","views":"532","votes":"1"},"_type":"doc"}
{"_id":"430","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513990674","category_id":"18","comments":"0","has_attach":"0","id":"430","message":"1、iPrice集团使用elasticsearch集群经验分享\nhttp://t.cn/RTkTb0f\n2、使用Elassandra（Elasticsearch+Apache  Cassandra）进行NBA球员数据探索\nhttp://t.cn/RTkT7SV\n3、如何使用kibana基于时间序列的Visual  Builder展示数据\nhttp://t.cn/RTkJX5s\n4、Elastic Advent Calendar Day 22：忘记elastic密码的解决办法\nhttp://t.cn/RTkWoRR\n\n编辑：bsll\n归档：https://elasticsearch.cn/article/430\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第139期 (2017-12-23)","uid":"1874","views":"543","votes":"0"},"_type":"doc"}
{"_id":"394","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511574030","category_id":"18","comments":"0","has_attach":"0","id":"394","message":"1. 《深入理解Elasticsearch》读书笔记\n[url]http://t.cn/RY4sK7O[/url] \n2. 搭建 Elastic Stack 日志系统\n[url]http://t.cn/RYbhUJi[/url]\n3. Elasticsearch 集群健康值红色终极解决方案\n[url]http://t.cn/RY4sk3v[/url]\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/publish/article/394[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第111期 (2017-11-25)","uid":"3828","views":"369","votes":"0"},"_type":"doc"}
{"_id":"395","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511658732","category_id":"18","comments":"0","has_attach":"0","id":"395","message":"1.关于父子关系的聚合。\nhttp://t.cn/RYbseNx\n2.Nodejs作为Elasticsearch客户端的高级方法和概念。\nhttp://t.cn/RYGhGA5\n3.(自备梯子)来自十九岁美女码农的建议\nhttp://t.cn/RYUSrp5\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/395\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第112期 (2017-11-26)","uid":"4460","views":"396","votes":"0"},"_type":"doc"}
{"_id":"409","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512530638","category_id":"4","comments":"7","has_attach":"1","id":"409","message":"链接：[https://elastic.github.io/eui/](https://elastic.github.io/eui/)\n\n源码：[https://github.com/elastic/eui](https://github.com/elastic/eui)\n\nNPM：[https://www.npmjs.com/package/@elastic/kibana-ui-framework](https://www.npmjs.com/package/@elastic/kibana-ui-framework)\n\nFAQ：[https://github.com/elastic/eui/blob/master/FAQ.md](https://github.com/elastic/eui/blob/master/FAQ.md)\n\n\n[attach]1404[/attach]\n \nElastic UI Framework 来自大家熟悉的开源前端可视化产品 Kibana，Kibana 使用这个 UI Framework 来构建所有的用户界面，Elastic UI Framework 的诞生基于以下几个目的：\n\n## EUI 高度可访问性\n使用高对比度，视障友好的调色风格Use以及增加适当的 [ARIA](https://developer.mozilla.org/zh-CN/docs/Web/Accessibility/ARIA) 标签。\n## EUI 可主题定制性\n简短几行代码即可调整主题风格。\n## EUI 更好的响应式支持\n目前我们的目标是移动设备、笔记本电脑、台式机和桌面端。\n## EUI 更具可玩性\n持续使用动画可以给我们的设计带来生命。\n## EUI 文档完整和测试\n确保代码对新手和专家都是友好的。\n \n\n如果你正打算基于 Kibana 开发一些有趣的插件，借助 Elastic UI Framework 将变得更加轻松。\n\n关于 Kibana 插件开发可以访问：\n\n[https://www.elastic.co/guide/en/kibana/current/kibana-plugins.html](https://www.elastic.co/guide/en/kibana/current/kibana-plugins.html)\n\n如果你开发了有趣的插件，记得要来社区分享哦~","title":"介绍一个新的 UI 框架：Elastic UI Framework","uid":"1","views":"3452","votes":"7"},"_type":"doc"}
{"_id":"419","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513386068","category_id":"18","comments":"0","has_attach":"0","id":"419","message":"1、使用es-hadoop从es导入数据到hive\nhttp://t.cn/RToSes4\n2、推荐一篇社区文章：如何更优雅的定制开发elasicsearch插件\nhttps://elasticsearch.cn/article/339\n3、Elastic Stack 6.1.0已发布\nhttp://t.cn/RTonvjK\n4、Elastic Advent Calendar, Day 15：ES升级到6.0以后，只支持单type,如何利用reindex和script将多type数据导入到集群？\nhttp://t.cn/RToWb4Z\n5、Elastic Meetup 深圳交流会\nhttps://elasticsearch.cn/article/406 \n\n编辑：bsll\n归档：https://elasticsearch.cn/article/419\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第132期 (2017-12-16)","uid":"1874","views":"402","votes":"0"},"_type":"doc"}
{"_id":"412","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512781387","category_id":"18","comments":"0","has_attach":"0","id":"412","message":"1、如何针对spark作业配置ELK？\n\nhttp://t.cn/RYssd1H\n\n2、有对比才有发现，看看ES与MarkLogic的对比\n\nhttp://t.cn/RTvPGm6\n\n3、(中文)Elastic Advent Calendar Day 8,使用 reindex API 迁移数据到 6.x 集群\n\nhttp://t.cn/RYD2I6R\n\n4、一周热点：看不懂的比特币\n\nhttp://t.cn/RYQBICq\n\n5、Elastic Meetup 深圳交流会\n\nhttps://elasticsearch.cn/article/406 \n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/412\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第125期 (2017-12-9)","uid":"1874","views":"429","votes":"0"},"_type":"doc"}
{"_id":"417","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513217216","category_id":"18","comments":"0","has_attach":"0","id":"417","message":"1.ElasticSearch QueryCache漫谈\nhttp://t.cn/RTt7LW7\n2.elasticsearch源码深入分析——启动过程（Bootstrap）\nhttp://t.cn/RTi5xjm\n3.使用elk处理jenkins build日志\nhttp://t.cn/RWGhqav\n4.Elastic Advent Calendar Day 13,filebeat在6.x的配置变更\nhttp://t.cn/RTiqoog\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/417\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第130期 (2017-12-14)","uid":"668","views":"364","votes":"0"},"_type":"doc"}
{"_id":"425","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513646626","category_id":"18","comments":"0","has_attach":"0","id":"425","message":"1.ElasticSearch Bulk 源码解析。\n[url]http://t.cn/RTYMZn8[/url] \n2.Elasticsearch 5.X集群多节点角色配置深入详解。\n[url]http://t.cn/RTY62ym[/url] \n3.使用JestClient连接elasticsearch-5.x对数据进行分组聚合。\n[url]http://t.cn/RTQbUhu[/url] \n4.(韩语)Elastic Advent Calendar, Day 18:解析Doc Value的魔法。\n[url]http://t.cn/RTYN1n8[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/425[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]  \n ","title":"Elastic日报 第135期 (2017-12-19)","uid":"3788","views":"394","votes":"0"},"_type":"doc"}
{"_id":"429","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513896179","category_id":"18","comments":"1","has_attach":"0","id":"429","message":"1、 NMAP扫描结果同步到Elasticsearch\nhttp://t.cn/R94eGiz\n2、elasticsearch对gmail建立索引？\nhttp://t.cn/RZbYIug\n3、es6.1的变化清单\nhttp://t.cn/RTS7BcU\n4、Elastic Advent Calendar Day 21：高性能Elasticsearch建议\nhttp://t.cn/RTezts5\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/429\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第138期 (2017-12-22)","uid":"1341","views":"475","votes":"1"},"_type":"doc"}
{"_id":"431","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514003004","category_id":"2","comments":"2","has_attach":"0","id":"431","message":"ES 版本： 5.2.1\n\n\n### 步骤：\n*  curl localhost:9200/_cat/shards \u0026gt; shards\n*  跑脚本：nohup python recovery.py  \u0026amp;  \n    ### 注意：跑脚本过程会返回大量json，时间较长，请注意放入后台\n* 查看修复shard进度：curl 127.0.0.1:9200/_cat/recovery/你修复shard对应的索引\n* 结果： 找到索引对应的shard，看到existing_store done说明已经从本地修复\n```shell\n     index 19 268ms existing_store done n/a        n/a                    10.0.58.67 node_name\n```\n\n```python\n#!/usr/bin/env python\n#name: recovery.py\n\nimport requests\nimport json\nhost = \u0026quot;http://localhost:9200/_cluster/allocation/explain\u0026quot;\ns= requests.Session()\ndef reroute_shard(index,shard,node):\n    data = {\n    \u0026quot;commands\u0026quot; : [\n        {\n          \u0026quot;allocate_stale_primary\u0026quot; : {\n              \u0026quot;index\u0026quot; : index, \u0026quot;shard\u0026quot; : shard, \u0026quot;node\u0026quot; : node, \u0026quot;accept_data_loss\u0026quot;: True\n          }\n        }\n    ]\n   }\n    print data\n    url = \u0026quot;http://localhost:9200/_cluster/reroute\u0026quot;\n    res = s.post(url,json=data)\n    print res\n\ndef get_node(line):\n    if \u0026quot;UNASSIGNED\u0026quot; in line:\n        line = line.split()\n        index = line[0]\n        shard = line[1]\n        if line[2] != \u0026quot;p\u0026quot;:\n            return\n        body = {\n           \u0026quot;index\u0026quot;: index,\n           \u0026quot;shard\u0026quot;: shard,\n           \u0026quot;primary\u0026quot;: True\n               }\n        res = s.get(host, json = body)\n        for store in res.json().get(\u0026quot;node_allocation_decisions\u0026quot;):\n            if store.get(\u0026quot;store\u0026quot;).get(\u0026quot;allocation_id\u0026quot;):\n               node_name = store.get(\u0026quot;node_name\u0026quot;)\n               reroute_shard(index,shard,node_name)\n    else:\n        return\n\nwith open(\u0026quot;shards\u0026quot;, 'rb') as f:\n    map(get_node,f)\n```\n\n相关文档：\n    * https://www.elastic.co/guide/en/elasticsearch/reference/5.2/cluster-reroute.html\n    * https://www.elastic.co/guide/en/elasticsearch/reference/5.2/cluster-allocation-explain.html","title":"Elasticsearch关于unassigned shards修复","uid":"2989","views":"1430","votes":"2"},"_type":"doc"}
{"_id":"441","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515031147","category_id":"18","comments":"0","has_attach":"0","id":"441","message":"1.同步 MySQL 数据到 Elasticsearch\nhttp://t.cn/RHHK9mr\n2.elasticsearch源码分析-cat API是如何加载的\nhttp://t.cn/RHHKpJM\n3.filebeat 5.3.1 结合 rancher 和 data-volume 实现横向扩展\nhttp://t.cn/RHHKOEf\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/441\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第148期 (2018-01-04)","uid":"668","views":"439","votes":"0"},"_type":"doc"}
{"_id":"443","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515199392","category_id":"18","comments":"0","has_attach":"0","id":"443","message":"1、VSCode的es查询插件\nhttp://t.cn/RHuwwlz\n2、使用Fluentd搜集日志进行分析\nhttp://t.cn/RHuIgzA\n3、一周热点：几乎影响每个人，每台设备的芯片级安全漏洞\nhttp://t.cn/RH8HhRF\n\n编辑：bsll\n归档：https://elasticsearch.cn/article/443\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第150期 (2018-01-06)","uid":"1874","views":"373","votes":"0"},"_type":"doc"}
{"_id":"448","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515550288","category_id":"18","comments":"0","has_attach":"0","id":"448","message":"1. Spring Boot + Elasticsearch 系列\n[url]http://t.cn/RQhaa0f[/url] \n[url]http://t.cn/RQhau76[/url] \n[url]http://t.cn/RQhaDyv[/url] \n2. 手把手教你写 Logstash 插件\n[url]http://t.cn/RGE6QlQ[/url] \n3. ElasticSearch in action（YouTuBe）\n[url]http://t.cn/RQhSBV8[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/448[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第154期 (2018-01-10)","uid":"3828","views":"374","votes":"0"},"_type":"doc"}
{"_id":"216","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502062274","category_id":"18","comments":"0","has_attach":"0","id":"216","message":"1.大规模Elasticsearch集群管理心得 http://t.cn/RSrUeoY\n\n来自携程wood的干货分享，对于大规模100+ node的管理感兴趣的同学快来看看吧！\n\n2.Elasticsearch前沿：ES 5.x改进详解与ES6展望 http://t.cn/R90xiRF\n\nElasticsearch 6.0都快来了，你不会还不知道 5.x 的特性吧？！快来看看 medcl 的分享吧\n\n3.Elastic Stack 官方实例 http://t.cn/RyCRVU4\n\nElastic Stack的产品不会用？！来看看官方的例子吧，从es 到 X-Pack 应有尽有，快来学习吧！\n\n\n\n\n编辑：rockybean\n\n归档：https://elasticsearch.cn/article/216\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第9期 (2017-08-07)","uid":"86","views":"1086","votes":"0"},"_type":"doc"}
{"_id":"641","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527472767","category_id":"18","comments":"0","has_attach":"0","id":"641","message":"1.使用 ES 5.4来搜索汉语、韩语和日语，第一部分:分析器。 \nhttp://t.cn/R1G3z3Q\n\n2.去哪儿网ELK安全监控中心踩坑和实践\nhttp://t.cn/R1qhAYL\n\n3. Elasticsearch内核解析 - 写入篇\nhttp://t.cn/R1q5Y5u\n\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/641\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第285期 (2018-05-28)","uid":"4063","views":"310","votes":"0"},"_type":"doc"}
{"_id":"647","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527752008","category_id":"16","comments":"22","has_attach":"1","id":"647","message":"活动地址：\n[http://meetup.elasticsearch.cn/2018/nanjing.html](http://meetup.elasticsearch.cn/2018/nanjing.html)\n\n## Elastic Meetup 南京\n\n### 主办方\n\nElastic中文社区、趋势科技\n\n[attach]2335[/attach]\n\n### 协办方\n\nIT 大咖说、阿里云、开源中国\n\n|  |  |  |\n| --- | ---  | --- |\n|  [attach]2365[/attach] |  [attach]2411[/attach] | [attach]2429[/attach] |\n\n\n### 时间地点\n\n* 活动时间：2018年6月30日 13:00 - 18:00 \n\n* 活动地点：雨花区软件大道48号苏豪国际广场B座 趋势科技中国研发中心（靠花神庙地铁站）\n\n \n### 报名地址\n\n[http://elasticsearch.mikecrm.com/fUqiv0T](http://elasticsearch.mikecrm.com/fUqiv0T)\n\n[attach]2342[/attach]\n\n   名额有限，速速报名！\n\n\n### 直播地址\n\n\n[attach]2410[/attach]\n\n\n \n### 主题\n\n#### 分享一：Elastic 探秘之遗落的珍珠\n\n标签：elastic stack\n讲师简介：\n\n[attach]2336[/attach]\n \n \n曾勇（Medcl） Elastic 中国首席布道师\nElasticsearch爱好者，2015年加入Elastic，Elastic 中文社区的发起人，Elastic在中国的首位员工。\n\n主题简介：\nElastic Stack 功能越来越丰富了，有很多功能可能你只听说过名字，有很多功能也许没有机会尝试过，其实你可能错过了很多宝贝，所以让我们来探究探究，本次分享主要介绍 Elastic Stack 技术栈里面，一些可能看起来不太起眼但却非常有意思的功能，定义为非干货，尽量轻拍，不过相信对于刚接触 Elastic 的同学来说，也会有所收获。\n \n\n#### 分享二：基于ELK的大数据分析平台实践\n\n标签：运维、DevOps\n讲师简介：\n\n[attach]2337[/attach]\n \n \n涂海波 南京云利来有限公司\n曾在亚信联创电信事业部从事计费产品工作多年，2年前加入南京云利来。\n\n主题简介：\n主题围绕Elasticsearch在集群搭建和运维过程中的使用经验，分享工作期间主要遇到的问题和解决思路，希望能够帮助大家在elasticsearch使用过程中少走一些弯路\n \n#### 分享三：ElasticLog with ES in CloudEdge\n\n标签：Ops、AWS、Log\n\n讲师简介：\n\n[attach]2338[/attach]\n\n \n赵伟，趋势科技CloudEdge Team\n负责大数据研发，个人技术兴趣广泛，擅长系统设计与服务调优，目前专注于大数据领域。\n主题简介：\n作为趋势科技下一代应用安全网关产品，CloudEdge的用户规模不断增长。面对每日数亿级数据，如何实现快速处理与查询？本次演讲，主要分享CloudEdge的大数据架构，介绍如何在AWS云上构建大数据系统，如何利用Elasticsearch实现热数据查询，以及在Elasticsearch方面的诸多实践经验\n \n\n#### 分享四：华泰证券Elasticsearch应用实践\n\n标签：金融IT、大数据、DevOps、日志\n\n讲师简介：\n\n[attach]2466[/attach]\n\n李文强，华泰证券数据平台架构师\n负责Hadoop平台和Elasticsearch集群的管理、架构和部分项目管理，目前正积极研究基于k8s的人工智能平台落地方案。\n\n主题简介：\n经过几年的发展，Elasticsearch已经在华泰证券内部生根发芽，已经有不少业务都使用了Elasticsearch，其中一个非常重要的应用是日志搜索和分析系统，该系统统一收集和分析各个系统的日志，既提升运维效率，又提高运营质量。在这些实践中，我们也不断地对Elasticsearch进行调优，使其能够长期稳定运行，保障业务稳定。\n \n \n#### 分享五：es在苏宁的实践\n\n标签：实践，大数据，平台化\n\n讲师简介：\n\n[attach]2339[/attach]\n\n \n韩宝君，苏宁大数据平台  ES平台组负责人\n2015年从事大数据研究工作，目前负责Elasticsearch的源码研究工作和定制化开发，对苏宁使用Elasticsearch的业务提供技术支持和解决方案。\n\n主题简介：\n本次分享大纲如下：\n1. 苏宁ES平台总体介绍，典型使用场景和规模；\n2. ES平台化之路-演进路线以及过程中我们的思考；\n3. 实战经验：遇到的问题及对应的解决方案；\n ","title":"【线下活动】2018-06-30 南京Elastic Meetup日程安排","uid":"1263","views":"3819","votes":"7"},"_type":"doc"}
{"_id":"650","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527835348","category_id":"3","comments":"6","has_attach":"0","id":"650","message":"在filter中处理\n ruby {   \n   code =\u0026gt; \u0026quot;event.set('timestamp', event.get('@timestamp').time.localtime + 8*60*60)\u0026quot;   \n }  \n ruby {  \n   code =\u0026gt; \u0026quot;event.set('@timestamp',event.get('timestamp'))\u0026quot;  \n }  \n mutate {  \n   remove_field =\u0026gt; [\u0026quot;timestamp\u0026quot;]  \n } ","title":"logstash5.X 时差8小时问题","uid":"2371","views":"671","votes":"1"},"_type":"doc"}
{"_id":"653","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528075704","category_id":"18","comments":"0","has_attach":"0","id":"653","message":"1.Elasticsearch内核解析 - 查询篇。\nhttp://t.cn/R1HIXKN\n\n2.跨AZ高可用之Elasticsearch实践。\nhttp://t.cn/RQJGPGV\n\n3.kibana timelion 高级数学插件 : mathlion\n[url]http://t.cn/R1H6coe[/url] \n\n编辑：cyerdak\n归档：https://elasticsearch.cn/article/653\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第292期 (2018-06-04)","uid":"4063","views":"272","votes":"0"},"_type":"doc"}
{"_id":"658","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528364941","category_id":"12","comments":"2","has_attach":"0","id":"658","message":"微信：13868891931","title":"高薪聘请ES(elasticsearch)搜索研发工程师","uid":"8850","views":"1251","votes":"0"},"_type":"doc"}
{"_id":"660","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528507664","category_id":"18","comments":"0","has_attach":"0","id":"660","message":"1. 怎么安全无损的从集群中下线部分节点？\n[http://t.cn/RBzKJvO](http://t.cn/RBzKJvO) \n\n2.老生常谈：ES性能调优\n[http://t.cn/RBzS0cG](http://t.cn/RBzS0cG) \n\n3. 基于python使用ES\n[http://t.cn/RBzKP6H](http://t.cn/RBzKP6H) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/660 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第297期 (2018-06-09)","uid":"1874","views":"335","votes":"0"},"_type":"doc"}
{"_id":"661","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528533938","category_id":"2","comments":"0","has_attach":"1","id":"661","message":"\r\n[attach]2393[/attach]\r\n[code]$params = [\r\n    'index' =\u0026gt; 'soso_*',\r\n    'type' =\u0026gt; 'links_1',\r\n    'body' =\u0026gt; [\r\n        'query' =\u0026gt; [\r\n            'match' =\u0026gt; [\r\n                'title' =\u0026gt; $kw\r\n            ]\r\n        ],\r\n                'highlight' =\u0026gt; [\r\n                    'pre_tags'  =\u0026gt; '\u0026lt;em\u0026gt;',\r\n                    'post_tags' =\u0026gt; '\u0026lt;/em\u0026gt;',\r\n                    'fields'    =\u0026gt; [\r\n                       'title' =\u0026gt; new \\stdClass()\r\n                    ]\r\n                ],\r\n    ]\r\n];[/code]","title":"highlight 返回来的title 不全 看截图","uid":"7849","views":"282","votes":"0"},"_type":"doc"}
{"_id":"671","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529040964","category_id":"2","comments":"0","has_attach":"0","id":"671","message":"最近一直在搞同义词搜索的问题，踩了一些坑，总结了一些经验，尤其是刚刚接触搜索和 ES，所以如果有不对的，或者不完备的地方也希望大家能提出改进意见。。。\n\n下面是自己留下的文档记录：\n\n----\n\n\n## 需求\n\n同义词检索也是搜索引擎必备的功能之一，例如，我们希望用户在搜索**广东话**的同时，也能找出和**粤语**有关的信息；用户在搜索**苹果手机**的同时，包含**iPhone**的内容也能被检索并呈现。\n\n在现实生活中，相同语义的表述词汇往往有很多，而用户在检索的时候很难在一条 query 中将它们全部体现，所以识别和提供同义词检索显然可以获得更高的召回率。\n\n## 需求剖析\n\n在思考解决方案之前，我们不妨再来看看刚才提到的两个例子：\n\n1. **苹果手机**与**iPhone**\n2. **广东话**与**粤语**\n\n我们先来看第一个，**苹果手机**和**iPhone**。\n\n显然，这两个词是等价的，因为苹果公司发布的所有手机产品都叫 iPhone，而 iPhone 这个名字也没有被其他公司使用过。\n\n于是，当用户搜索“苹果手机购买”的时候，我们也就有理由将它拆分成“苹果手机购买”和“iPhone购买”，分别进行检索，再将结果合并返回。\n\n----\n\n语言学中对这样的词组，称为是同义词中的**相对同义词**，或是**等义词**，**等义同义词**。它们表达意思完全一致，在绝大多数语境中都可以相互替换，同时对上下文也不会产生影响。\n\n这样的词组还有很多，例如：**猫熊**和**熊猫**，**柚子**和**文旦**等等，这些等义词大抵来说有这样几种来源：\n\n1. 音节减缩形成：**机枪**和**机关枪**，**坦克**和**坦克车**，**电扇**和**电风扇**\n2. 音译和音译形成：**出租车**和**的士** ，**维生素**和**维他命**\n3. 地域叫法不同，或新旧叫法：**单车**，**自行车**和**脚踏车**，**西红柿**和**番茄**，**马铃薯**，**洋芋**和**土豆**，**黄瓜**和**胡瓜**\n4. 昵称代称：**周杰伦**和**周董**\n5. 描述角度不同，学名方言差异：**电脑**和**计算机**，**曲别针**和**回形针**\n\n这些词组多以名词呈现，数量比较少，词组规模也较小，同时变化也很小。\n\n---\n\n接下来我们再来看第二组词：**广东话**和**粤语**。\n\n**广东话**和**粤语**这两个词代表的意思是相同的吗？它们也是可以相互替换的吗？\n\n答案显然是否定的。\n\n**广东话**从语义本身来说是一个比较粗糙的概念，它不仅指广东省内的粤语，还涵盖了潮汕话，客家话，雷州话等其他方言。而**粤语**却是一个非常严肃的概念，对语音语调都有非常详细的规定，不仅通用于广东省大部分地区，还包括广西、香港、澳门等地，甚至东南亚和北美。它们联系在于，大部分广东地区的人说的是粤语。\n\n如此说来，给**广东话**和**粤语**这样非常相似却又并不完全一致的词直接划上等号是有失偏颇的。当然，其实仔细考虑也不难发现，和**广东话**有相似之处却又不完全相同的词还有很多，例如：**客家话**、**广州话**、**广府话**等等。\n\n---\n\n语言学中把这样的词汇，称作是**相对同义词**，或是**近义词**。它们在意义上有一些相似之处，只能在特定的语境中进行替换。\n\n它们的差别可能包括：\n\n1. 语义上：**毁坏**和**损坏**（前者更严重），**介绍**和**说明**（前者可以对人施加作用）\n2. 色彩上：**团结**和**勾结**\n\n对于这类相似却又不完全相同的**近义词**，在搜索的时候提供关联搜索是一个不错的方案。例如用户搜索“毁坏公物如何处罚”的时候，查询结果可以由**90%**的“损坏公物如何处罚”和**10%**的“毁坏公物如何处罚”查询结果合并后返回，从而获得更多的召回。\n\n这些**近义词**以动词为主，不仅数量多，词组的规模也大，例如**靠近**的近义词可以是：**靠拢**，**逼近**，**接近**，**迫近**等等。\n\n\n## 解决思路\n\n在**可替换**的等义词问题中，我们可以直接使用 Elasticsearch 原生的 synonyms 功能来完成。虽说原生 synonyms 功能不支持热更新，而且需要将词典事先放进制定目录，不过好在这类等义词数量并不多，变化也并不大，尚且属于一劳永逸的任务。\n\n对于**不可直接替换**的近义词问题，如果直接套用原生的 Synonyms 虽然可能会带来更多召回，但是查准率却骤降。\n\n对于这类问题，我们期待的场景是，一旦发现用户 query 中的某个词有近义词，我们就将它拆分替换，成为多个 query 进行联合搜索。就像前面的例子：用户搜索“损坏公物如何处罚”的时候，查询结果可以由**90%**的“损坏公物如何处罚”和**10%**的“毁坏公物如何处罚”查询结果合并后返回。如此说来，使用 Elasticsearch 提供的 boosting_query 就成为了一个自然而然的想法。\n\n不过稍加思考也不难发现，boosting_query 中 weight 的获得并不容易，也就是前面例子中的**90%**和**10%**这组数字应该怎么设定，这也是近义词联合搜索中的重点。\n\n先回到我们刚才的例子：当用户搜索“损坏公物如何处罚”的时候，我们本能地觉得用**90%**的**损坏**和**10%**的**毁坏**合并在一起是“合理的”，这样的本能其实是来自于：我们主观地认为在检索“搞坏公物”这个事实的时候，90%的用户会使用**毁坏**来描述，10%的用户会使用**损坏**来描述。\n\n简而言之，这组数字可以理解为用户群体描述同一个问题时，对词组选择的组成比例。再换个说法，也就是**在当前这条 query 中，原词和近义词之间的可替换程度**。\n\n再举一例，在“广东话入门”这条 query 中，从“表达学习语言”的语义上来看，**广东话**和**粤语**差别并不大，这条 query 自然可以拆分成“广东话入门”和“粤语入门”，进行联合搜索，而且它们的 weight 甚至可以设置为 1：1 来获得更多合理的召回。\n\n反过来，在“粤语歌曲推荐”这条 query 中，**广东话**的 weight 就需要慎重考虑，一方面是因为本身就没有“广东话歌曲”这种说法，另一方面也因为在广泛的语料中，**歌曲**和**广东话**这两个词极少同时被提及。所以几遍是“粤语歌曲推荐”的拆分成分中有“广东话歌曲推荐”，weight 也需要被设置地非常低（倘若真的没有“粤语歌曲”相关的内容，推荐“广东话”的内容作为替补）。\n\n说到这里，其实已经很明白了，语言模型是可以在这里被使用的，而语言模型的困惑度也与前面提到的 weight 一脉相承。\n\n所以大致计算流程可以是：获得用户的query之后进行分词，在词组中寻找所有可能的同义词替换，将所有替换后的 query 分别放进语言模型中获得困惑度（或其他 metrics），依据它们来作为 boosting query 中的 weight。\n\n\n```mermaid\ngraph TD;\n广东话入门--\u0026gt;'广东话','入门';\n'广东话','入门'--\u0026gt;_'广东话','入门'_;\n'广东话','入门'--\u0026gt;_'粤语','入门'_;\n_'广东话','入门'_--\u0026gt;语言模型;\n_'粤语','入门'_--\u0026gt;语言模型;\n语言模型--\u0026gt;PPL:0.65;\n语言模型--\u0026gt;PPL:0.35;\n```\n\n对于这里语言模型的选择，可以使用传统的ngram，也可以使用双向的LSTM这样一些成熟的方案从语料中训练，也可以使用一些现成的方案：http://ai.baidu.com/tech/nlp/dnnlm_cn\n\n","title":"关于同义词检索方案的一点实践经验","uid":"5757","views":"1000","votes":"0"},"_type":"doc"}
{"_id":"692","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530322288","category_id":"18","comments":"1","has_attach":"0","id":"692","message":"1. elastic技能官方认证通道。\n[http://t.cn/Ruuvok6](http://t.cn/Ruuvok6) \n\n2. 如何用ES6.2搜索中文、韩文和日文系列。\n\n 1) [http://t.cn/R1G3z3Q](http://t.cn/R1G3z3Q) \n\n 2) [http://t.cn/RrHKXVm](http://t.cn/RrHKXVm) \n\n 3) [http://t.cn/RrHKC2J](http://t.cn/RrHKC2J) \n\n3. JVM问题定位的典型案例分析（视频）。\n[http://t.cn/RrHKU5P](http://t.cn/RrHKU5P) \n\n4. 只等你来 | Elastic Meetup 广州交流会\n[https://elasticsearch.cn/article/364](https://elasticsearch.cn/article/364) \n\n活动预告\n1. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n\n编辑:  bsll\n\n归档：https://elasticsearch.cn/article/{id}\n\n订阅：https://tinyletter.com/elastic-daily \n","title":"Elastic日报 第318期 (2018-06-30)","uid":"1874","views":"352","votes":"0"},"_type":"doc"}
{"_id":"699","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530688543","category_id":"2","comments":"2","has_attach":"0","id":"699","message":"阅读本文前，请先阅读[ES内存分析](https://elasticsearch.cn/article/698)。\nES默认配置下，heap是存在超卖情况的。\n\n\n| 类目 | 默认占比 | 是否常驻 | 淘汰策略(在控制大小情况下) | 控制参数 |\n| --- | --- | --- | --- | --- |\n| query cache | 10% | 是 | LRU | indices.queries.cache.size |\n| request cache | 1% | 是 | LRU | indices.requests.cache.size |\n| fielddata cache | 无限制 | 是 | LRU | indices.fielddata.cache.size |\n| segment memory | 无限制 | 是 | 无 | 不能通过参数控制 |\n| common space | 70% | 否 | GC | 通过熔断器 indices.breaker.total.limit 限制 |\n\ncommon space(可GC)\n\n\n| 子类目 | 默认占比 | 控制参数 |\n| --- | --- | --- |\n| indexing buffer | 10% | indices.memory.index\\_buffer\\_size |\n| request agg data | 60% | indices.breaker.request.limit |\n| in-flight data | 100% | network.breaker.inflight\\_requests.limit |\n\n通过上表可知，segment memory是非常重要，而且是不可通过参数干预的内存空间，而cache部分则可以提升性能，可以被清除。common space 是运行时的动态空间，可以被GC。\n\n综上所述，需要保证segment memory+cache+common space不超过100%。由于熔断器是按整个heap大小来计算的，所以如果segment memory 过大，仍然可能会导致OOM。为了减少这种情况的发生，需要预留足够空间给segment。\n优化\n1. 限制fielddata大小，fielddata是针对text类型进行排序、聚合才用到。正常应该避免这种情况发生。\n2. 限制request agg data大小，这个参数会影响聚合使用的内存，如果触发熔断，业务需要进行优化。\n\n## 内存分配\n\n\n\u0026lt;div class=\u0026quot;bi-table\u0026quot;\u0026gt;\n  \u0026lt;table\u0026gt;\n    \u0026lt;colgroup\u0026gt;\n      \u0026lt;col width=\u0026quot;auto\u0026quot; /\u0026gt;\n      \u0026lt;col width=\u0026quot;auto\u0026quot; /\u0026gt;\n      \u0026lt;col width=\u0026quot;auto\u0026quot; /\u0026gt;\n    \u0026lt;/colgroup\u0026gt;\n    \u0026lt;tbody\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;segment memory\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;预留10%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;fielddata cache\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制在20%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;query cache\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制10%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;request cache\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制1%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;indexing buffer\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制10%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;request agg data\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制1%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;2\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;父熔断器配置30%，扣除fielddata,agg剩余的就是in-flight\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n      \u0026lt;tr height=\u0026quot;34px\u0026quot;\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;in-flight data\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n        \u0026lt;td rowspan=\u0026quot;1\u0026quot; colSpan=\u0026quot;1\u0026quot;\u0026gt;\n          \u0026lt;div data-type=\u0026quot;p\u0026quot;\u0026gt;限制9%\u0026lt;/div\u0026gt;\n        \u0026lt;/td\u0026gt;\n      \u0026lt;/tr\u0026gt;\n    \u0026lt;/tbody\u0026gt;\n  \u0026lt;/table\u0026gt;\n\u0026lt;/div\u0026gt;\n\n参数设置\n```plain\nindices.fielddata.cache.size:1%--需要重启节点\n\nPUT _cluster/settings\n{\n  \u0026quot;persistent\u0026quot;: {\n    \u0026quot;indices.breaker.fielddata.limit\u0026quot;:\u0026quot;20%\u0026quot;,\n    \u0026quot;indices.breaker.request.limit\u0026quot;:\u0026quot;1%\u0026quot;,\n    \u0026quot;indices.breaker.total.limit\u0026quot;:\u0026quot;70%\u0026quot;\n\n  }\n}\n```\n","title":"ES内存分配规划","uid":"1629","views":"717","votes":"1"},"_type":"doc"}
{"_id":"700","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530754465","category_id":"18","comments":"0","has_attach":"0","id":"700","message":"1.使用python操作ES\nhttp://t.cn/RBzKP6H\n2.使用Beats模块将日志和指标导入ES\nhttp://t.cn/RdLtJJp\n3.如何在生产环境中重启Elasticsearch集群\n[url]http://t.cn/RdL4oxk[/url] \n\n活动预告\n1. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655 \n\n编辑：sterne vencel\n归档：https://elasticsearch.cn/article/700\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第323期 (2018-07-05)","uid":"8625","views":"235","votes":"0"},"_type":"doc"}
{"_id":"709","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531276239","category_id":"18","comments":"0","has_attach":"0","id":"709","message":"1. Elasticsearch索引迁移的四种方式\n[url]http://t.cn/RdnqiW0[/url] \n2. 使用ELK在DC / OS中进行日志管理\n[url]http://t.cn/Rdn5hfQ[/url] \n3.使用Logstash收集Mesos日志\n[url]http://t.cn/Rdn5QaI[/url] \n \n1. 7月21日上海meetup倒计时\n[url]https://elasticsearch.cn/m/article/655[/url] \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/709[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第329期 (2018-07-11)","uid":"3828","views":"291","votes":"0"},"_type":"doc"}
{"_id":"715","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531618634","category_id":"18","comments":"0","has_attach":"0","id":"715","message":"1.Elasticsearch设置和配置。\nhttp://t.cn/Rg2fx0m\n2.elasticsearch集群轻松部署在kubernetes。\nhttp://t.cn/RiuNMXw\n3.(自备梯子)如果人们支付他们的数据会怎样。\n[url]http://t.cn/Rg2o6lA[/url] \n \n\n\n活动预告\n1. 7月21日上海meetup倒计时（更大场地，等您来！）\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/715\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第333期 (2018-07-15)","uid":"4460","views":"256","votes":"0"},"_type":"doc"}
{"_id":"717","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531803475","category_id":"18","comments":"0","has_attach":"0","id":"717","message":"1.如何为Elasticsearch开发属于你自己的安全扩展和自定义领域。\nhttp://t.cn/RgfWl6d\n2.通过启用 Cognito 身份验证来保护 AWS Elasticsearch Service。\nhttp://t.cn/RgfWEpG\n3.Elasticsearch史上最全最常用工具清单。\n[url]http://t.cn/RgfDHQr[/url] \n\n活动预告\n1. 7月21日上海meetup倒计时\nhttps://elasticsearch.cn/m/article/655\n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/717\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第335期 (2018-07-17)","uid":"3788","views":"329","votes":"0"},"_type":"doc"}
{"_id":"721","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532040269","category_id":"18","comments":"0","has_attach":"0","id":"721","message":"1、如何监控Elasticsearch？\nhttp://t.cn/RdT4xjw\n2、Elasticsearch 专属的性能压测工具：Rally 正式发布 1.0.0 版本！\nhttp://t.cn/RdEJlzR\n3、Elasticsearch 上生产环境之前，要考虑哪些设置，重要的配置都在这里了\nhttp://t.cn/RdtzzaG\n\n活动预告\n1. 7月21日上海meetup倒计时（更大场地，等您来！）\nhttps://elasticsearch.cn/m/article/655 \n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/721\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第338期 (2018-07-20)","uid":"1341","views":"358","votes":"0"},"_type":"doc"}
{"_id":"726","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532145235","category_id":"3","comments":"3","has_attach":"0","id":"726","message":"Logstash 是 Elastic Stack 中功能最强大的 ETL 工具，相较于 beats 家族，虽然它略显臃肿，但是强在功能丰富、处理能力强大。大家在使用的过程中肯定也体验过其启动时的慢吞吞，那么有什么办法可以减少等待 Logstash 的启动时间，提高编写其处理配置文件的效率呢？本文给大家推荐一个小技巧，帮助大家解决如下两个问题，让大家更好地与这个笨重的大家伙相处。\n\n1.  减少 Logstash 重启的次数，也就节省宝贵的时间\n2.  方便快捷地向 Logstash 输入需要处理的内容\n\n\n## 1. 打开 reload 配置开关\n\nLogstash 启动的时候可以加上 `-r` 的参数来做到配置文件热加载，效果是：\n\n* 当你修改了配置文件后，无需重启 Logstash 即可让新配置文件生效。\n\n它的含义如下：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721111655.png)\n\n当你写好配置文件，比如 test.conf ，启动命令如下：\n\n\u0026gt; bin/logstash -f test.conf -r\n\n启动完毕，修改 test.conf 的内容并保存后，过 1 秒钟，你会发现 Logstash 端有类似如下日志输出（注意红色框标记的部分），此时说明 reload 的成功。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721112111.png)\n\n如果你修改的配置文件有错误，会看到报错的日志，你可以根据错误提示修改。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721112255.png)\n\n\n\n至此，第一个问题解决！\n\n## 2. 使用 HTTP INPUT \n\n编写配置文件的另一个痛点是需要针对不同格式的输入内容进行详细的测试，以防解析报错的情况出现。此时大家常用标准输入来解决这个问题(stdin input)，但是标准输入对于文字编辑支持不太友好，而且配置文件热更新的功能也不支持标准输入。\n\n在这里向大家推荐使用 http input 插件，配置如下：\n\n```\ninput{\n    http{\n        port =\u0026gt; 7474\n        codec =\u0026gt; \u0026quot;json\u0026quot;\n    }\n}\n```\n\n然后大家再用自己喜欢的 http 请求工具，比如 POSTMan、Insomnia 等向 `http://loclahost:7474`发送待测试内容即可，如下是 Insomnia 的截图。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721114408.png)\n\n\n\n至此，第二个问题也解决了。\n\n\n\n## 3. 总结\n\n相信看到这里，大家一定是跃跃欲试了，赶紧打开电脑，找到 Logstash，然后编辑 test.conf，输入如下内容：\n\n```\ninput{\n    http{\n        port =\u0026gt; 7474\n        codec =\u0026gt; \u0026quot;json\u0026quot;\n    }\n}\n\nfilter{\n\n}\n\noutput{\n        stdout{\n        codec =\u0026gt; rubydebug{\n            metadata =\u0026gt; true\n        }\n    }\n}\n```\n\n然后执行启动命令：\n\n\u0026gt;  bin/logstash -f test.conf -r\n\n打开 Insomnia ，输入要测试的内容，点击发送，开始舒爽流畅的配置文件编写之旅吧！\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)","title":"ET001 不可不掌握的 Logstash 使用技巧","uid":"86","views":"573","votes":"2"},"_type":"doc"}
{"_id":"733","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532644433","category_id":"18","comments":"0","has_attach":"0","id":"733","message":"1、Elasticsearch原理分析\nhttp://t.cn/Rebp8sc\n2、ES中使用mmap存储的索引会锁定内存不释放?\nhttp://t.cn/RebCIr8\n3、实战 | ElasticSearch的备份与恢复\n[url]http://t.cn/RebCSFQ[/url] \n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/733\n订阅：https://tinyletter.com/elastic-daily","title":" ​ Elastic日报 第345期 (2018-07-27)","uid":"1341","views":"346","votes":"0"},"_type":"doc"}
{"_id":"743","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533348437","category_id":"18","comments":"0","has_attach":"0","id":"743","message":"1. lucene中使用bloom Filter的原理。\n[http://t.cn/ReFUk9G](http://t.cn/ReFUk9G) \n\n2. 在OpenShift处理多行日志以传入ELK的方法(需翻墙）。\n[http://t.cn/ReFtZn0](http://t.cn/ReFtZn0) \n\n3. ES中id长度的限制。\n[http://t.cn/ReFVJli](http://t.cn/ReFVJli) \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n* 编辑:  bsll\n\n* 归档：https://elasticsearch.cn/article/743\n\n* 订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第353期 (2018-08-04)","uid":"1874","views":"261","votes":"0"},"_type":"doc"}
{"_id":"749","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533852309","category_id":"18","comments":"0","has_attach":"0","id":"749","message":"1、使用 Apache Spark 和 Elasticsearch 构建一个推荐系统\nhttp://t.cn/RrdR6Hp\n2、ElasticSearch + Canal 开发千万级的实时搜索系统\nhttp://t.cn/RDXr8Qm\n3、在Python中使用Elasticsearch\nhttp://t.cn/RDXrs0v\n\n活动预告：\nElastic 中国开发者大会预热票今天发售！\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/749\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第359期 (2018-08-10)","uid":"1341","views":"282","votes":"0"},"_type":"doc"}
{"_id":"753","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534125806","category_id":"18","comments":"0","has_attach":"0","id":"753","message":"1.来自AWS的ES报警设置实践。\nhttp://t.cn/RDTns2Y\n2.利用HDFS备份实现 Elasticsearch 容灾。\nhttp://t.cn/RDT3UHT\n3.360私有云平台Elasticsearch服务初探。\nhttp://t.cn/RYDV14C\n \n活动预告：\nElastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：cyberdak\n归档：https://elasticsearch.cn/article/753\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第362期 (2018-08-13)","uid":"4063","views":"244","votes":"0"},"_type":"doc"}
{"_id":"761","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534500414","category_id":"16","comments":"0","has_attach":"1","id":"761","message":"阿里云MVP(Most Valuable Professional，最有价值专家)第六期全球招募开始了! 面向全球开发者，寻找热爱技术、乐于分享的Coder！\r\n \r\n什么是阿里云 MVP？阿里云MVP(Most Valuable Professional，最有价值专家)，是专注于帮助他人充分了解和使用阿里云产品和服务的技术实践领袖。截止到2018年6月已经有232位全球各国家和地区的Coder们参加了5期认证。\r\n\r\n[attach]2827[/attach]\r\n \r\n只要成为MVP，即可享受免费云栖大会门票、最新产品的优先使用权、官方渠道推广等丰厚权益。升级后，还有全球技术留学、高端闭门会议，与顶级技术专家交流学习。与您一同打造《MVP 时间》将您的技术能量传播给更多人，定期邀请阿里技术专家在MVP学院与您共同交流学习提升技术实力。\r\n \r\n[attach]2829[/attach]\r\n\r\n\r\n本期MVP项目与本社区合作推荐技术达人成为候选人，通过认证您还可以在9月到杭州参与一年一度的MVP高端闭门峰会，第6期认证结果将在9月中旬公布结果。\r\n\r\n[b]什么样的人可以成为阿里云 MVP？[/b]\r\n\r\n你交叉使用过阿里云多款产品；\r\n你有丰富的技术沉淀、勇于创新、乐于分享；\r\n你希望能寻找志同道合的资深技术圈，希望建立个人技术影响力。\r\n你可以马上点击Elastic社区专属申请链接提交申请或扫码填写申请：\r\nhttps://mvp.aliyun.com/mvp/apply?recommendType=2\u0026amp;recommendId=65OqTgvP5IKmKgAI6pMhqw==\r\n \r\n[attach]2828[/attach]\r\n\r\n[b]对于阿里云 MVP申请的一些疑问：[/b]\r\n \r\n[list]\r\n[*]多久评选一次MVP？[/*]\r\n[/list]\r\n每个季度会评选一次，并会在每个季度末宣布MVP入围情况，如果遗憾落选，可在公布名单后，重新到MVP平台提交申请。\r\n[list]\r\n[*]MVP代表阿里云吗？[/*]\r\n[/list]\r\n不代表。MVP不是阿里巴巴的员工，他们也不代表阿里云发言。MVP仅是因其在技术社区中的杰出成就，而获得阿里云认可和奖励的第三方个人。\r\n[list]\r\n[*]阿里云MVP大奖的有效期为多长时间？[/*]\r\n[/list]\r\nMVP大奖的有效期为一年。在此期间，MVP奖获奖者享有阿里云MVP荣誉称号以及大奖所包括的所有特权。","title":"阿里云 MVP 第6期招募与 Elastic 社区合作启动","uid":"1","views":"260","votes":"1"},"_type":"doc"}
{"_id":"765","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534830668","category_id":"18","comments":"0","has_attach":"0","id":"765","message":"1.使用Ranking Evaluation API对Elasticsearch进行测试驱动的相关性调整。\nhttp://t.cn/Rk6P3lQ\n2.（自备翻墙）使用Cloud Dataflow将文档索引到Elasticsearch中。\nhttp://t.cn/Rk6Pev2\n3.（自备翻墙）Kubernetes使用Elasticsearch、Fluent Bit和Kibana的最佳实践。\n[url]http://t.cn/Rk6hvy0[/url] \n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/765\n订阅：https://tinyletter.com/elastic-daily\n ","title":"  Elastic日报 第370期 (2018-08-21)","uid":"3788","views":"305","votes":"0"},"_type":"doc"}
{"_id":"770","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535171645","category_id":"18","comments":"0","has_attach":"0","id":"770","message":"1. ES6.4发布。\n[http://t.cn/RkHPfV6](http://t.cn/RkHPfV6) \n\n2. 在Django项目中使用es。\n[http://t.cn/RkR2as4](http://t.cn/RkR2as4) \n\n3. ElasticHQ:  基于python的es监控管理插件。\n[http://t.cn/Rk8ioV0](http://t.cn/Rk8ioV0) \n\n活动预告\n\n1、Elastic 中国开发者大会最后一波早鸟票发售进行中\n\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\n\nhttps://elasticsearch.cn/article/759\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/770\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第374期 (2018-08-25)","uid":"1874","views":"222","votes":"0"},"_type":"doc"}
{"_id":"771","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535208257","category_id":"2","comments":"1","has_attach":"0","id":"771","message":"初次接触 Elasticsearch 的同学经常会遇到分词相关的难题，比如如下这些场景：\n\n1. 为什么明明有包含搜索关键词的文档，但结果里面就没有相关文档呢？\n2. 我存进去的文档到底被分成哪些词(term)了？\n3. 我得自定义分词规则，但感觉好麻烦呢，无从下手\n\n如果你遇到过类似的问题，希望本文可以解决你的疑惑。\n\n\n# 1. 上手\n\n让我们从一个实例出发，如下创建一个文档：\n\n```json\nPUT test/doc/1\n{\n  \u0026quot;msg\u0026quot;:\u0026quot;Eating an apple a day keeps doctor away\u0026quot;\n}\n```\n\n然后我们做一个查询，我们试图通过搜索 `eat`这个关键词来搜索这个文档\n\n```json\nPOST test/_search\n{\n  \u0026quot;query\u0026quot;:{\n    \u0026quot;match\u0026quot;:{\n      \u0026quot;msg\u0026quot;:\u0026quot;eat\u0026quot;\n    }\n  }\n}\n```\n\nES的返回结果为0。这不太对啊，我们用最基本的字符串查找也应该能匹配到上面新建的文档才对啊！\n\n各位不要急，我们先来看看什么是分词。\n\n\n# 2. 分词\n\n搜索引擎的核心是倒排索引（这里不展开讲），而倒排索引的基础就是分词。所谓分词可以简单理解为将一个完整的句子切割为一个个单词的过程。在 es 中单词对应英文为 `term`。我们简单看个例子：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180825091854.png)\n\nES 的倒排索引即是根据分词后的单词创建，即 `我`、`爱`、`北京`、`天安门`这4个单词。这也意味着你在搜索的时候也只能搜索这4个单词才能命中该文档。\n\n实际上 ES 的分词不仅仅发生在文档创建的时候，也发生在搜索的时候，如下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180825103328.png)\n\n`读时分词`发生在用户查询时，ES 会即时地对用户输入的关键词进行分词，分词结果只存在内存中，当查询结束时，分词结果也会随即消失。而`写时分词`发生在文档写入时，ES 会对文档进行分词后，将结果存入倒排索引，该部分最终会以文件的形式存储于磁盘上，不会因查询结束或者 ES 重启而丢失。\n\nES 中处理分词的部分被称作分词器，英文是`Analyzer`，它决定了分词的规则。ES 自带了很多默认的分词器，比如`Standard`、 `Keyword`、`Whitespace`等等，默认是 `Standard`。当我们在读时或者写时分词时可以指定要使用的分词器。\n\n\n# 3. 写时分词结果\n\n回到上手阶段，我们来看下写入的文档最终分词结果是什么。通过如下 api 可以查看：\n\n```json\nPOST test/_analyze\n{\n  \u0026quot;field\u0026quot;: \u0026quot;msg\u0026quot;,\n  \u0026quot;text\u0026quot;: \u0026quot;Eating an apple a day keeps doctor away\u0026quot;\n}\n```\n\n其中 `test`为索引名，`_analyze` 为查看分词结果的 `endpoint`，请求体中 `field` 为要查看的字段名，`text`为具体值。该 api 的作用就是请告诉我在 test 索引使用 msg 字段存储一段文本时，es 会如何分词。\n\n返回结果如下:\n\n```json\n{\n  \u0026quot;tokens\u0026quot;: [\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;eating\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 0,\n      \u0026quot;end_offset\u0026quot;: 6,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 0\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;an\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 7,\n      \u0026quot;end_offset\u0026quot;: 9,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 1\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;apple\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 10,\n      \u0026quot;end_offset\u0026quot;: 15,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 2\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;a\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 16,\n      \u0026quot;end_offset\u0026quot;: 17,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 3\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;day\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 18,\n      \u0026quot;end_offset\u0026quot;: 21,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 4\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;keeps\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 22,\n      \u0026quot;end_offset\u0026quot;: 27,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 5\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;doctor\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 28,\n      \u0026quot;end_offset\u0026quot;: 34,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 6\n    },\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;away\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 35,\n      \u0026quot;end_offset\u0026quot;: 39,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 7\n    }\n  ]\n}\n```\n\n返回结果中的每一个 `token`即为分词后的每一个单词，我们可以看到这里是没有 `eat` 这个单词的，这也解释了在上手中我们搜索 `eat` 没有结果的情况。如果你去搜索 `eating` ，会有结果返回。\n\n写时分词器需要在 mapping 中指定，而且一经指定就不能再修改，若要修改必须新建索引。如下所示我们新建一个名为`ms_english` 的字段，指定其分词器为 `english`：\n\n```json\nPUT test/_mapping/doc\n{\n  \u0026quot;properties\u0026quot;: {\n    \u0026quot;msg_english\u0026quot;:{\n      \u0026quot;type\u0026quot;:\u0026quot;text\u0026quot;,\n      \u0026quot;analyzer\u0026quot;: \u0026quot;english\u0026quot;\n    }\n  }\n}\n```\n\n\n\n# 4. 读时分词结果\n\n由于读时分词器默认与写时分词器默认保持一致，拿 上手 中的例子，你搜索 `msg` 字段，那么读时分词器为 `Standard` ，搜索 `msg_english` 时分词器则为 `english`。这种默认设定也是非常容易理解的，读写采用一致的分词器，才能尽最大可能保证分词的结果是可以匹配的。\n\n然后 ES 允许读时分词器单独设置，如下所示：\n\n```json\nPOST test/_search\n  {\n    \u0026quot;query\u0026quot;:{\n      \u0026quot;match\u0026quot;:{\n        \u0026quot;msg\u0026quot;:{\n          \u0026quot;query\u0026quot;: \u0026quot;eating\u0026quot;,\n          \u0026quot;analyzer\u0026quot;: \u0026quot;english\u0026quot;\n        }\n      }\n    }\n  }\n```\n\n如上 `analyzer` 字段即可以自定义读时分词器，一般来讲不需要特别指定读时分词器。\n\n如果不单独设置分词器，那么读时分词器的验证方法与写时一致；如果是自定义分词器，那么可以使用如下的 api 来自行验证结果。\n\n```json\nPOST _analyze\n  {\n    \u0026quot;text\u0026quot;:\u0026quot;eating\u0026quot;,\n    \u0026quot;analyzer\u0026quot;:\u0026quot;english\u0026quot;\n  }\n```\n\n返回结果如下：\n\n```json\n{\n  \u0026quot;tokens\u0026quot;: [\n    {\n      \u0026quot;token\u0026quot;: \u0026quot;eat\u0026quot;,\n      \u0026quot;start_offset\u0026quot;: 0,\n      \u0026quot;end_offset\u0026quot;: 6,\n      \u0026quot;type\u0026quot;: \u0026quot;\u0026lt;ALPHANUM\u0026gt;\u0026quot;,\n      \u0026quot;position\u0026quot;: 0\n    }\n  ]\n}\n```\n\n由上可知 `english`分词器会将 `eating`处理为 `eat`，大家可以再测试下默认的 `standard`分词器，它没有做任何处理。\n\n\n\n# 5. 解释问题\n\n现在我们再来看下 上手 中所遇问题的解决思路。\n\n1. 查看文档写时分词结果\n2. 查看查询关键词的读时分词结果\n3. 匹对两者是否有命中\n\n我们简单分析如下：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180825212343.png)\n\n由上图可以定位问题的原因了。\n\n\n\n# 6. 解决需求\n\n由于 `eating`只是 `eat`的一个变形，我们依然希望输入 `eat`时可以匹配包含 `eating`的文档，那么该如何解决呢？\n\n答案很简单，既然原因是在分词结果不匹配，那么我们就换一个分词器呗~ 我们可以先试下 ES 自带的 `english`分词器，如下：\n\n```json\n# 增加字段 msg_english，与 msg 做对比\nPUT test/_mapping/doc\n{\n  \u0026quot;properties\u0026quot;: {\n    \u0026quot;msg_english\u0026quot;:{\n      \u0026quot;type\u0026quot;:\u0026quot;text\u0026quot;,\n      \u0026quot;analyzer\u0026quot;: \u0026quot;english\u0026quot;\n    }\n  }\n}\n\n# 写入相同文档\nPUT test/doc/1\n{\n  \u0026quot;msg\u0026quot;:\u0026quot;Eating an apple a day keeps doctor away\u0026quot;,\n  \u0026quot;msg_english\u0026quot;:\u0026quot;Eating an apple a day keeps doctor away\u0026quot;\n}\n\n# 搜索 msg_english 字段\nPOST test/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;match\u0026quot;: {\n      \u0026quot;msg_english\u0026quot;: \u0026quot;eat\u0026quot;\n    }\n  }\n}\n```\n\n\n\n执行上面的内容，我们会发现结果有内容了，原因也很简单，如下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180825212639.png)\n\n由上图可见 `english`分词器会将 `eating`分词为 `eat`，此时我们搜索 `eat`或者 `eating`肯定都可以匹配对应的文档了。至此，需求解决。\n\n\n# 7. 深入分析\n\n最后我们来看下为什么`english`分词器可以解决我们遇到的问题。一个分词器由三部分组成：char filter、tokenizer 和 token filter。各部分的作用我们这里就不展开了，我们来看下 `standard`和`english`分词器的区别。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180825215109.png)\n\n从上图可以看出，`english`分词器在 Token Filter 中和 `Standard`不同，而发挥主要作用的就是 `stemmer`，感兴趣的同学可以自行去看起它的作用。\n\n\n# 8. 自定义分词\n\n如果我们不使用 `english`分词器，自定义一个分词器来实现上述需求也是完全可行的，这里不详细讲解了，只给大家讲一个快速验证自定义分词器效果的方法，如下：\n\n```json\nPOST _analyze\n{\n  \u0026quot;char_filter\u0026quot;: [], \n  \u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\n  \u0026quot;filter\u0026quot;: [\n    \u0026quot;stop\u0026quot;,\n    \u0026quot;lowercase\u0026quot;,\n    \u0026quot;stemmer\u0026quot;\n  ],\n  \u0026quot;text\u0026quot;: \u0026quot;Eating an apple a day keeps doctor away\u0026quot;\n}\n```\n\n通过上面的 api 你可以快速验证自己要定制的分词器，当达到自己需求后，再将这一部分配置加入索引的配置。\n\n\n\n至此，我们再看开篇的三个问题，相信你已经心里有答案了，赶紧上手去自行测试下吧！\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)","title":"掌握 analyze API，一举搞定 Elasticsearch 分词难题","uid":"86","views":"1186","votes":"6"},"_type":"doc"}
{"_id":"777","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535508276","category_id":"18","comments":"0","has_attach":"0","id":"777","message":"1.基于 Elasticsearch 的人才搜索架构\n[url]http://t.cn/RKYPGL3[/url] \n2.ElasticSearch 深入理解系列\n[url]http://t.cn/RF2LdiG[/url] \n[url]http://t.cn/RF2zPF9[/url] \n[url]http://t.cn/RF2zABQ[/url] \n[url]http://t.cn/RF22Efd[/url] \n3.使用ELK构建微服务的日志平台\n[url]http://t.cn/Rkb1wdM[/url] \n​\n1、活动预告：Elastic 中国开发者大会最后一波早鸟票发售进行中\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\n[url]https://elasticsearch.cn/article/759[/url] \n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/777[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第378期 (2018-08-29)","uid":"3828","views":"308","votes":"0"},"_type":"doc"}
{"_id":"780","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535668448","category_id":"18","comments":"0","has_attach":"0","id":"780","message":"1、Elasticsearch存储详解\nhttp://t.cn/RFcyAtp\n2、Elastic stack 针对 Azure 云的监控解决方案\nhttp://t.cn/RFc4ew4\n3、SpringBoot集成ElasticSearch\nhttp://t.cn/RFcyKM2\n\n活动预告：\n1、Elastic 中国开发者大会最后一波早鸟票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/780\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第380期 (2018-08-31)","uid":"1341","views":"262","votes":"0"},"_type":"doc"}
{"_id":"790","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536241704","category_id":"18","comments":"0","has_attach":"0","id":"790","message":"1.Mmap fs可能让大索引访问变得缓慢\nhttps://elasticsearch.cn/article/754\n2.高效管理 Elasticsearch 中基于时间的索引\nhttp://t.cn/RshNpsO\n3.利用elasticsearch实时监控JMeter测试结果\nhttp://t.cn/RshNrE4\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n \n编辑：金桥\n归档：https://elasticsearch.cn/article/790\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第386期 (2018-09-06)","uid":"668","views":"226","votes":"0"},"_type":"doc"}
{"_id":"794","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536544748","category_id":"18","comments":"1","has_attach":"0","id":"794","message":"Elastic日报 第390期 (2018-09-10)\n\n1.elastic APM 的 java 客户端，有性能分析的同学可以尝试。\nhttp://t.cn/RslU1Cz\n2.使用 Elasticsearch 实现博客站内搜索。\nhttp://t.cn/R4ajYTZ\n3.安全实践：在FIPS 140-2环境中部署elasticsearch。\nhttp://t.cn/RslIvR9\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/794\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第390期 (2018-09-10)","uid":"4063","views":"289","votes":"0"},"_type":"doc"}
{"_id":"795","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536650985","category_id":"18","comments":"0","has_attach":"0","id":"795","message":"1.使用KSQL聚合窗口时间并以Elasticsearch可视化展示。\nhttp://t.cn/Rsm4fTt\n2.Elasticsearch存储深入详解。\nhttp://t.cn/Rsm4ovu\n3.Elasticsearch，why和how。\nhttp://t.cn/Rsm4Nvw\n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/795\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第391期 (2018-09-11)","uid":"3788","views":"258","votes":"0"},"_type":"doc"}
{"_id":"796","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536730753","category_id":"18","comments":"0","has_attach":"0","id":"796","message":"1. Elasticsearch 存储深入详解\nhttp://t.cn/RsRYucC\n2. 利用 ELK 搭建 Docker 容器化应用日志中心\nhttp://t.cn/Rsklfju\n3. 收集 Kubernetes 控制台日志及元数据(fluent-bit+es+kibana 搭建)\nhttp://t.cn/RsDTGoX\n \n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/796[/url]\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第392期 (2018-09-12)","uid":"3828","views":"285","votes":"0"},"_type":"doc"}
{"_id":"798","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536836732","category_id":"18","comments":"0","has_attach":"0","id":"798","message":"1.使用上下文推荐丰富Elasticsearch的自动完成功能\nhttp://t.cn/EvZIss5\n2.ES地理坐标类型在Spring Data中的常见使用问题整理解答\nhttp://t.cn/EvZMqGn\n3.一个业务问题引发的ES排序思考\nhttp://t.cn/EvZMcEc\n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：金桥\n归档：https://elasticsearch.cn/article/798\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第393期 (2018-09-13)","uid":"668","views":"249","votes":"0"},"_type":"doc"}
{"_id":"799","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536885047","category_id":"18","comments":"0","has_attach":"0","id":"799","message":"1、Top10 Elasticsearch国外博客推荐\nhttp://t.cn/EvwhwJ0\n2、Nginx plus结合Elasticsearch使用\nhttp://t.cn/RGnQHFc\n3、小心！记录Elasticsearch object的坑及解决方案\nhttp://t.cn/Evwh0uW\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/799\n订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第394期 (2018-09-14)","uid":"1341","views":"258","votes":"0"},"_type":"doc"}
{"_id":"804","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537276794","category_id":"18","comments":"0","has_attach":"0","id":"804","message":"1、如果你关注 ES 跨集群数据同步的特性，可以来关注下这个 Feature 的进展： Elasticsearch Cross Cluster Replication(CCR)\nhttp://t.cn/Evljgpg\n2、(自备梯子)基于 React 和 Elasticsearch 来快速实现一个 Github Repo 的查询系统\nhttp://t.cn/EvlYyST\n3、(自备梯子)来自 DevCon 2018 的 Learning to rank search 演讲\nhttp://t.cn/EvlY9YH\n\n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n\n编辑: rockybean\n归档：https://elasticsearch.cn/article/804\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第398期 (2018-09-18）","uid":"86","views":"287","votes":"0"},"_type":"doc"}
{"_id":"815","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537792974","category_id":"18","comments":"0","has_attach":"0","id":"815","message":"1.微软azure团队:零停机时间升级es以及nest。\nhttp://t.cn/EPteTLJ\n2.ELK借助ElastAlert实现故障提前感知预警功能\nhttp://t.cn/EPtDABm\n3.es的另类使用：sonar中的内嵌代码搜索服务器\nhttp://t.cn/EPtDeII\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/815\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第404期 (2018-09-24)","uid":"4063","views":"214","votes":"0"},"_type":"doc"}
{"_id":"814","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537668242","category_id":"18","comments":"0","has_attach":"0","id":"814","message":"1.将Apache Hive与ElasticSearch一起使用。\nhttp://t.cn/EPzJFKK\n2.大数据与分析与数据科学：有什么区别？\nhttp://t.cn/EPzxm6P\n3.(自备梯子)招聘数据科学家之前需要做的3件事。\nhttp://t.cn/EPz6j4f\n\n活动预告：\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/814\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第403期 (2018-09-23)","uid":"4460","views":"219","votes":"0"},"_type":"doc"}
{"_id":"823","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539064645","category_id":"18","comments":"0","has_attach":"0","id":"823","message":"1、通透理解Elasticsearch聚合。\nhttp://t.cn/E7vQMXJ\n2.ElasticSearch之基本用法API。\nhttp://t.cn/EhsfRF9\n3.（自备翻墙）使用ELK分析自定义日志。\nhttp://t.cn/Ehsfae3\n\n活动预告\n\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/823\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第412期 (2018-10-09)","uid":"3788","views":"260","votes":"1"},"_type":"doc"}
{"_id":"992","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539832207","category_id":"16","comments":"5","has_attach":"0","id":"992","message":"Elastic中文社区联合东方航空公司，将于2018年12月08日，在上海举办一次线下技术交流活动。 本次活动交流内容不限于Elastic Stack，可以是搜索、推荐、机器学习、商业智能、智能运维等任意大数据相关技术的最佳应用实践。 活动分享主题正?征集中！ \n \n有意参与本次主题分享的同学，请发送邮件至[i][u]kennywu76@outlook.com[/u][/i]，并提供如下信息:\n[list=1]\n[*]个人简介[/*]\n[*]分享主题[/*]\n[*]内容提纲[/*]\n[/list]\n \n为确保本次活动的紧凑，分享主题将控制在5个以内。 部分同学提交的内容可能无法安排进本次活动日程，但我们将保留所有提交的主题，并尽力安排在后续的线下活动进行分享 。\n \n[b]征集截止时间:[/b]  2018年11月10日\n[b]活动时间:[/b]  2018年12月08日（暂定)\n[b]活动地址[/b]:  东航城（上海市闵行区虹翔三路）\n \n欢迎社区同学踊跃报名，期待你的分享！","title":"【线下活动 - 分享主题征集 - 上海】2018 Elastic \u0026amp; 东方航空大数据技术沙龙","uid":"81","views":"979","votes":"7"},"_type":"doc"}
{"_id":"997","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540104341","category_id":"44","comments":"2","has_attach":"1","id":"997","message":"\n[attach]3048[/attach]\n\n欢迎来到 Elastic 社区电台的第六期节目，本期节目我们来到了位于北京的神州泰岳研发中心。神州泰岳在国内 IT 运维管理市场上拥有相当广泛的客户群，覆盖电信、金融、政府、能源、交通等行业，是国内领先的 IT 运维管理软件开发商、解决方案提供商和服务提供商。神州泰岳及其下属子公司大量使用了 Elastic Stack 来解决多个业务场景下的多种需求，这期的节目我们请来了神州泰岳 IT 监控产品线和应用产品线的两位总监来给大家带来分享，快来收听本期节目了解他们具体是如何使用 Elasticsearch 的吧。\n\n\n## 嘉宾：\n蔡国兴，北京神州泰岳软件股份有限公司研发中心 IT 监控产品线副总监，现致力于网络管理类产品建设和解决方案的提供。 \n韩炳海，神州泰岳研发中心应用产品线研发总监，有十几年的研发经历，现聚焦APM、微服务领域。\n\n\n## 主持人：\nElastic 技术布道师，曾勇（Medcl）。\n\n\n## 可以点击下面的任意链接来收听（时长约 50 分钟）：\n\n- Apple iTunes: https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/\n- 喜马拉雅：https://www.ximalaya.com/keji/14965410/124736791\n- 蜻蜓 FM：https://www.qingting.fm/channels/244978/programs/9817402\n\n## 关于神州泰岳\n\n神州泰岳是国内领先的综合类软件产品及服务提供商，着力于用信息技术手段推动行业发展和社会进步，提升人们工作和生活品质。自公司成立以来，始终以市场为导向，深耕细作、创新拓展，形成了以“ICT运营管理”、“手机游戏”、“人工智能与大数据”、“物联网与通讯技术应用”为核心的相关多元化发展格局。\n\n\n## 关于 Elastic 社区电台\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。","title":"Elastic 社区电台 第六期，嘉宾：韩炳海、蔡国兴@神州泰岳","uid":"1","views":"195","votes":"0"},"_type":"doc"}
{"_id":"1000","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540350758","category_id":"18","comments":"0","has_attach":"0","id":"1000","message":"1. 牢记这7点，技术小白也能玩转 Elasticsearch \nhttp://t.cn/EvTWYdA\n2. Elasticsearch Nested类型深入详解\nhttp://t.cn/EZ2j4Gh\n3. Elasticsearch 的滚动（scroll）\nhttp://t.cn/R34TnrJ\n \n祝大家 1024 节日快乐\n \n编辑：江水\n归档：https://elasticsearch.cn/article/1000\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第427期 (2018-10-24)","uid":"3828","views":"219","votes":"0"},"_type":"doc"}
{"_id":"1002","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540432781","category_id":"18","comments":"0","has_attach":"0","id":"1002","message":"1.唯品会Dragonfly日志系统的Elasticsearch实践\nhttp://t.cn/EZUmLoC\n2.美团点评基于 Flink 的实时数仓建设实践\nhttp://t.cn/Ez3sEMH\n3.golang实现Elasticsearch做短信查询统计\nhttp://t.cn/EZUmxOr\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/1002\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第428期 (2018-10-25)","uid":"668","views":"177","votes":"0"},"_type":"doc"}
{"_id":"1003","_index":"forum-mysql","_score":1,"_source":{"addtime":"1540461181","category_id":"12","comments":"8","has_attach":"0","id":"1003","message":"公司介绍：\n\n上海普翔是 elastic 在中国的[b]核心合作伙伴[/b]，相关业务有 Elastic 商业产品代理、Elastic 技术咨询与实施等，拥有国内最早一批通过 Elastic Certified Engineer 认证考试的工程师，也是 2018年 Elastic 开发者大会的[b]钻石级赞助商[/b]，现服务零售、银行、证券等众多行业的客户，帮助他们更好地将 Elastic 产品应用到实际业务中。\n\n工作地点：上海、深圳\n\n招聘职位： Elastic 初中级技术支持工程师\n\n薪资待遇：14k ~ 22k\n\n工作内容：\n\n1、根据架构设计方案，完成 ELK 集群的搭建工作。\n\n2、根据架构师设计的数据收集与分析方案，理解并基于 Elastic 产品如 Filebeat Logstash Elasticsearch Kibana等快速高效地完成方案的实施落地工作。\n\n3、帮助客户快速掌握 Elastic 商业产品的使用方法，如安全认证、监控告警、机器学习等功能。\n\n4、参与 Elastic 在国内的社区推广工作，如编写博文、参与直播、workshop 等活动。\n\n职位要求：\n\n1、本科以上学历，计算机相关专业有加分，1年以上工作经验，有一定的运维经验。\n\n2、了解 Elastic 产品（如 Elasticsearch Kibana Logstash Beats）的组成和基本使用方法，有ELK 项目经验的有加分。\n\n3、需要良好的学习和研究能力，面对一个新产品或者特性时，可以在较快的时间内掌握。\n\n4、有良好的沟通和表达能力。\n\n5、经常参加elastic 线下活动有加分，经常在中文社区讨论问题有加分。\n\n招聘职位： Elastic 中高级技术支持工程师\n\n薪资待遇：22k ~ 30k\n\n工作内容：\n\n1、根据客户需求完成合理的 ELK 集群架构设计方案，并能快速完成 ELK 集群的搭建工作。\n\n2、与客户沟通其数据收集与分析的需求，并合理设计解决方案，可以基于 Elastic 产品如 Filebeat Logstash Elasticsearch Kibana 等快速高效地完成方案的实施落地工作。\n\n3、向客户介绍 Elastic 开源与商业产品，并根据客户需求提供对应的商业解决方案，帮助客户快速掌握 Elastic 商业产品的使用方法，如安全认证、监控告警、机器学习等功能。\n\n4、参与 Elastic 在国内的社区推广工作，如编写博文、参与直播、workshop 等活动。\n\n职位要求：\n\n1、本科以上学历，计算机专业有加分，3年以上工作经验，需要有运维经验。\n\n2、熟悉 Elastic 产品（如 Elasticsearch Kibana Logstash Beats ）的组成和使用，了解其底层的运行机制，掌握常见的排障技巧与优化方案。\n\n3、需要良好的学习和研究能力，面对一个新产品或者特性时，可以在较快的时间内掌握。\n\n4、有良好的沟通和表达能力，擅长倾听客户的问题并快速定位解决问题的关键点。\n\n5、经常参加elastic 线下活动有加分，经常在中文社区讨论问题有加分。\n\n特别说明：\n\n1. 如果你还没有使用过 Elastic 产品，但有 2 年以上运维经验，熟悉常见系统日志、软件日志的查询与分析策略，对 ETL 有一定了解，或者你有其他大数据产品如 hadoop、kafka 等的使用经验，同时对 Elastic 产品抱有极大的学习热情，也欢迎投简历来沟通，我们有完善的培训机制，可以帮助你快速掌握相关知识。\n\n2. 如果你通过了 Elastic Certified Engineer 认证考试并成功入职我司，我们会报销你的考试费用！！！\n\n如果你对 elasticsearch Logstash Beats Kibana等感兴趣，请加入我们，我们这里有实战、有直播、有源码分析活动、有培训，还有与elastic 原厂工程师面对面交流的机会！\n\n如果你对 elastic 在中国的商业化发展感兴趣，更要加入我们，我们是 elastic 在中国的核心合作伙伴，会与 elastic 原厂紧密合作一同推动其中国业务的快速拓展！\n\n 如果你对围绕 elastic 开发周边产品感兴趣，也请加入我们，让我们一起参与 elastic 生态的产品研发，为开源世界贡献自己的力量！\n\n欢迎投递简历至：weibinway@puxiangtech.com\n\n添加微信沟通：rockybean","title":"上海普翔诚招 Elastic 技术支持工程师","uid":"86","views":"534","votes":"0"},"_type":"doc"}
{"_id":"6344","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548329597","category_id":"18","comments":"0","has_attach":"0","id":"6344","message":"1.Elasticsearch搜索Suggest功能优化\nhttp://t.cn/E5BoAmR\n2.Elasticsearch translog文件介绍\nhttp://t.cn/E5BoqXd\n3.Elasticsearch结合百度地图实现区域查询检索\nhttp://t.cn/E5Bofgd\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6344\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第519期 (2019-01-24)","uid":"668","views":"74","votes":"0"},"_type":"doc"}
{"_id":"6345","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548379092","category_id":"18","comments":"0","has_attach":"0","id":"6345","message":"1、帮助识别公开 Elasticsearch 服务器上的敏感信息开源项目\nhttp://t.cn/EGszEDf\n2、Elasticsearch + neo4j图搜索\nhttp://t.cn/E53j9ZA\n3、支持6.X版本的Elasticsearch PHP客户端\nhttp://t.cn/R5IqIG6\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/6345\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第520期 (2019-01-25)","uid":"1341","views":"74","votes":"0"},"_type":"doc"}
{"_id":"6340","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548121692","category_id":"18","comments":"0","has_attach":"0","id":"6340","message":"1、使用logstash搜集csv日志。\nhttp://t.cn/E5Ml4lv\n2、日志监控和分析：ELK、Splunk和Graylog对比。\nhttp://t.cn/E5MlcsH\n3、从 10 秒到 2 秒！ElasticSearch 性能调优。\nhttp://t.cn/E59fgLI\n编辑：叮咚光军\n归档：\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第517期 (2019-01-22)","uid":"3788","views":"151","votes":"0"},"_type":"doc"}
{"_id":"6335","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547796895","category_id":"4","comments":"3","has_attach":"0","id":"6335","message":"在6.0版本以前，登录kibana之后，默认会路由到`app/kibana`下的`discover`应用。\n在6.3版本以后，新增了一个home路径`/app/kibana#/home?_g=h@44136fa`，访问根路径`\\`会直接跳到以上路径。\n\n希望在kibana上做更多定制化开发的同学，或许会有需求在登录kibana之后能够跳转到自己的页面。\n\n要完成以上需求，只需要在kibana的配置文件里面增加一行：\n```\nserver.defaultRoute: /app/system_portal\n```\n以上例子，我让kibana登录之后直接跳到我自己的app插件system_portal\n\n配置默认路由的文件, `src/server/http/get_default_route.js`：\n```js\nimport _ from 'lodash';\n\nexport default _.once(function (kbnServer) {\n  const {\n    config\n  } = kbnServer;\n  // 根目录basePath加上defaultRoute\n  return `${config.get('server.basePath')}${config.get('server.defaultRoute')}`;\n});\n```\n\n默认路由就是定义在server.defaultRoute中，默认值是`app/kibana`，可查看`src/server/config/schema.js`:\n```js\nimport Joi from 'joi';\nimport { constants as cryptoConstants } from 'crypto';\nimport os from 'os';\n\nimport { fromRoot } from '../../utils';\nimport { getData } from '../path';\n\nexport default async () =\u0026gt; Joi.object({\n  pkg: Joi.object({\n    version: Joi.string().default(Joi.ref('$version')),\n    branch: Joi.string().default(Joi.ref('$branch')),\n    buildNum: Joi.number().default(Joi.ref('$buildNum')),\n    buildSha: Joi.string().default(Joi.ref('$buildSha')),\n  }).default(),\n\n  env: Joi.object({\n    name: Joi.string().default(Joi.ref('$env')),\n    dev: Joi.boolean().default(Joi.ref('$dev')),\n    prod: Joi.boolean().default(Joi.ref('$prod'))\n  }).default(),\n\n  dev: Joi.object({\n    basePathProxyTarget: Joi.number().default(5603),\n  }).default(),\n\n  pid: Joi.object({\n    file: Joi.string(),\n    exclusive: Joi.boolean().default(false)\n  }).default(),\n\n  cpu: Joi.object({\n    cgroup: Joi.object({\n      path: Joi.object({\n        override: Joi.string().default()\n      })\n    })\n  }),\n\n  cpuacct: Joi.object({\n    cgroup: Joi.object({\n      path: Joi.object({\n        override: Joi.string().default()\n      })\n    })\n  }),\n\n  server: Joi.object({\n    uuid: Joi.string().guid().default(),\n    name: Joi.string().default(os.hostname()),\n    host: Joi.string().hostname().default('localhost'),\n    port: Joi.number().default(5601),\n    maxPayloadBytes: Joi.number().default(1048576),\n    autoListen: Joi.boolean().default(true),\n    defaultRoute: Joi.string().default('/app/kibana').regex(/^\\//, `start with a slash`),\n    basePath: Joi.string().default('').allow('').regex(/(^$|^\\/.*[^\\/]$)/, `start with a slash, don't end with one`),\n    rewriteBasePath: Joi.boolean().when('basePath', {\n      is: '',\n      then: Joi.default(false).valid(false),\n      otherwise: Joi.default(false),\n    }),\n    customResponseHeaders: Joi.object().unknown(true).default({}),\n    ssl: Joi.object({\n      enabled: Joi.boolean().default(false),\n      redirectHttpFromPort: Joi.number(),\n      certificate: Joi.string().when('enabled', {\n        is: true,\n        then: Joi.required(),\n      }),\n      key: Joi.string().when('enabled', {\n        is: true,\n        then: Joi.required()\n      }),\n      keyPassphrase: Joi.string(),\n      certificateAuthorities: Joi.array().single().items(Joi.string()).default(),\n      supportedProtocols: Joi.array().items(Joi.string().valid('TLSv1', 'TLSv1.1', 'TLSv1.2')),\n      cipherSuites: Joi.array().items(Joi.string()).default(cryptoConstants.defaultCoreCipherList.split(':'))\n    }).default(),\n    cors: Joi.when('$dev', {\n      is: true,\n      then: Joi.object().default({\n        origin: ['*://localhost:9876'] // karma test server\n      }),\n      otherwise: Joi.boolean().default(false)\n    }),\n    xsrf: Joi.object({\n      disableProtection: Joi.boolean().default(false),\n      whitelist: Joi.array().items(\n        Joi.string().regex(/^\\//, 'start with a slash')\n      ).default(),\n      token: Joi.string().optional().notes('Deprecated')\n    }).default(),\n  }).default(),\n\n  logging: Joi.object().keys({\n    silent: Joi.boolean().default(false),\n\n    quiet: Joi.boolean()\n      .when('silent', {\n        is: true,\n        then: Joi.default(true).valid(true),\n        otherwise: Joi.default(false)\n      }),\n\n    verbose: Joi.boolean()\n      .when('quiet', {\n        is: true,\n        then: Joi.valid(false).default(false),\n        otherwise: Joi.default(false)\n      }),\n\n    events: Joi.any().default({}),\n    dest: Joi.string().default('stdout'),\n    filter: Joi.any().default({}),\n    json: Joi.boolean()\n      .when('dest', {\n        is: 'stdout',\n        then: Joi.default(!process.stdout.isTTY),\n        otherwise: Joi.default(true)\n      }),\n\n    useUTC: Joi.boolean().default(true),\n  })\n    .default(),\n\n  ops: Joi.object({\n    interval: Joi.number().default(5000),\n  }).default(),\n\n  plugins: Joi.object({\n    paths: Joi.array().items(Joi.string()).default(),\n    scanDirs: Joi.array().items(Joi.string()).default(),\n    initialize: Joi.boolean().default(true)\n  }).default(),\n\n  path: Joi.object({\n    data: Joi.string().default(getData())\n  }).default(),\n\n  optimize: Joi.object({\n    enabled: Joi.boolean().default(true),\n    bundleFilter: Joi.string().default('!tests'),\n    bundleDir: Joi.string().default(fromRoot('optimize/bundles')),\n    viewCaching: Joi.boolean().default(Joi.ref('$prod')),\n    watch: Joi.boolean().default(false),\n    watchPort: Joi.number().default(5602),\n    watchHost: Joi.string().hostname().default('localhost'),\n    watchPrebuild: Joi.boolean().default(false),\n    watchProxyTimeout: Joi.number().default(5 * 60000),\n    useBundleCache: Joi.boolean().default(Joi.ref('$prod')),\n    unsafeCache: Joi.when('$prod', {\n      is: true,\n      then: Joi.boolean().valid(false),\n      otherwise: Joi\n        .alternatives()\n        .try(\n          Joi.boolean(),\n          Joi.string().regex(/^\\/.+\\/$/)\n        )\n        .default(true),\n    }),\n    sourceMaps: Joi.when('$prod', {\n      is: true,\n      then: Joi.boolean().valid(false),\n      otherwise: Joi\n        .alternatives()\n        .try(\n          Joi.string().required(),\n          Joi.boolean()\n        )\n        .default('#cheap-source-map'),\n    }),\n    profile: Joi.boolean().default(false)\n  }).default(),\n  status: Joi.object({\n    allowAnonymous: Joi.boolean().default(false)\n  }).default(),\n  map: Joi.object({\n    manifestServiceUrl: Joi.string().default(' https://catalogue.maps.elastic.co/v2/manifest'),\n    emsLandingPageUrl: Joi.string().default('https://maps.elastic.co/v2'),\n    includeElasticMapsService: Joi.boolean().default(true)\n  }).default(),\n  tilemap: Joi.object({\n    url: Joi.string(),\n    options: Joi.object({\n      attribution: Joi.string(),\n      minZoom: Joi.number().min(0, 'Must be 0 or higher').default(0),\n      maxZoom: Joi.number().default(10),\n      tileSize: Joi.number(),\n      subdomains: Joi.array().items(Joi.string()).single(),\n      errorTileUrl: Joi.string().uri(),\n      tms: Joi.boolean(),\n      reuseTiles: Joi.boolean(),\n      bounds: Joi.array().items(Joi.array().items(Joi.number()).min(2).required()).min(2)\n    }).default()\n  }).default(),\n  regionmap: Joi.object({\n    includeElasticMapsService: Joi.boolean().default(true),\n    layers: Joi.array().items(Joi.object({\n      url: Joi.string(),\n      format: Joi.object({\n        type: Joi.string().default('geojson')\n      }).default({\n        type: 'geojson'\n      }),\n      meta: Joi.object({\n        feature_collection_path: Joi.string().default('data')\n      }).default({\n        feature_collection_path: 'data'\n      }),\n      attribution: Joi.string(),\n      name: Joi.string(),\n      fields: Joi.array().items(Joi.object({\n        name: Joi.string(),\n        description: Joi.string()\n      }))\n    }))\n  }).default(),\n\n  i18n: Joi.object({\n    defaultLocale: Joi.string().default('en'),\n  }).default(),\n\n  // This is a configuration node that is specifically handled by the config system\n  // in the new platform, and that the current platform doesn't need to handle at all.\n  __newPlatform: Joi.any(),\n\n}).default();\n```","title":"如何修改kibana的默认主页","uid":"5649","views":"168","votes":"3"},"_type":"doc"}
{"_id":"6330","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547445638","category_id":"18","comments":"0","has_attach":"0","id":"6330","message":"1.ElasticSearch架构反向思路\nhttp://t.cn/Eq9VgsV\n\n2.在kibana中集中管理rollup任务\nhttp://t.cn/EqtKAf7\n\n3.在es崩溃以后自动重启\nhttp://t.cn/Eq9IJFG\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6330\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第509期 (2019-01-14) ","uid":"4063","views":"162","votes":"0"},"_type":"doc"}
{"_id":"6328","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547283197","category_id":"18","comments":"0","has_attach":"0","id":"6328","message":"1、在kibana里创建、管理、可视化汇总数据\n[http://t.cn/EqtKAf7](http://t.cn/EqtKAf7)\n\n2、在Spring Boot使用ES教程\n[http://t.cn/Eqt9rC4](http://t.cn/Eqt9rC4)\n\n3、一周热点：GitHub提供免费私有Repo\n[http://t.cn/EGmbUQX](http://t.cn/EGmbUQX)\n\n* 编辑:  bsll\n* 归档：https://elasticsearch.cn/article/6328\n* 订阅：https://tinyletter.com/elastic-daily \n","title":"Elastic日报 第507期 (2019-01-12）","uid":"1874","views":"157","votes":"0"},"_type":"doc"}
{"_id":"6329","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547347413","category_id":"18","comments":"0","has_attach":"0","id":"6329","message":"1.创建DSL。\nhttp://t.cn/EqcmScm\n2.使用ANTLR从GSA迁移到Elasticsearch。\nhttp://t.cn/Eqc3j1w\n3.(自备梯子)将定义2019年的技术。\nhttp://t.cn/EqUQ61i\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6329\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第508期 (2019-01-13)","uid":"4460","views":"190","votes":"0"},"_type":"doc"}
{"_id":"6321","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546849064","category_id":"13","comments":"0","has_attach":"0","id":"6321","message":"\n[size=16][b]问题[/b][/size]\nkibana展示数据表明数据采集中断了，没有新的日志数据进来了。\n[b][size=16]排查[/size][/b]\n查看logstash日志：[code][2019-01-07T14:59:27,435][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer\n[2019-01-07T14:59:29,870][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer\n[2019-01-07T14:59:29,870][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer\n[2019-01-07T14:59:41,719][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer\n[2019-01-07T14:59:42,777][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer\n[2019-01-07T14:59:48,227][INFO ][org.logstash.beats.BeatsHandler] Exception: Connection reset by peer[/code]\n查看filebeat日志：[code]2019-01-07T15:00:13+08:00 INFO No non-zero metrics in the last 30s\n2019-01-07T15:00:43+08:00 INFO Non-zero metrics in the last 30s: libbeat.logstash.call_count.PublishEvents=1 libbeat.logstash.publish.write_bytes=241120\n2019-01-07T15:00:48+08:00 ERR Failed to publish events (host: 10.68.24.138:5044:10200), caused by: read tcp 10.68.24.46:59310-\u0026gt;10.68.24.138:5044: i/o timeout\n2019-01-07T15:00:48+08:00 INFO Error publishing events (retrying): read tcp 10.68.24.46:59310-\u0026gt;10.68.24.138:5044: i/o timeout\n2019-01-07T15:01:13+08:00 INFO Non-zero metrics in the last 30s: libbeat.logstash.publish.read_errors=1 libbeat.logstash.published_but_not_acked_events=2034[/code]\n查看的初步结果是，filebeat连不上logstash，logstash一直重置filebeat的连接，但是这两个机器是一点问题没有。\n \n日志看过了，没有明显的问题，那就按部就班一步一步查吧\n\n1、先来最基本的，查看elasticsearch、logstash、filebeat是否启动。\n2、网络，网络环境是之前配置好的，一直没有变的，网络的可能性小一些，但是也是使用telnet测试一下各个端口是不是通的。\n3、logstash故障，查看是不是因为logstash的未知故障，记录logstash的日志，然后重启logstash，看看重启logstash后是否解决问题了。\n4、日志，查看日志是否是在更新，在5分钟以内是否在更新，因为是在运行的环境，日志一般不会断，所以我把这个检查放在了第四步。\n5、查看ES的硬盘和内存。[code]GET /_cat/allocation?v\nGET _cat/nodes?v[/code]\n问题排查到第五步已经发现原因了：ES其中一台机器的内存满了。\n\n[b][size=16]原因始末[/size][/b]\n在部署这套ELK环境的时候，由于服务器提供方当时提供的两台ES机器的内存不一样，一台是8G的，一台是4G的，所以在使用的的时候，我配置的ES的堆内存一台是4G，一台是2G；ES集群就两台机器，也没配置数据节点和客户端节点，其实三台、四台我也都不配置的，集群太小再分开配置，就没有服务器了。\n开始使用的时候是没有问题的，但是当日志达到一定量的时候，2G的那台机器堆内存耗光了，然后就出现了日志不能采集的i/o timeout问题。\n\n[b][size=16]经验[/size][/b]\n在使用ELK的过程中，以上的五种原因导致的filebeat日志采集异常，我都遇见过，其中容易忽略的就是ES的内存和硬盘是否已经满了，当ES集群中其中一台机器的堆内存和硬盘满了的话，都会引起日志采集异常。所以在配置ES集群的时候最好所有的data节点的内存和硬盘配置一致。\n ","title":"一次filebeat i/o timeout 问题记录-ES内存引起","uid":"3221","views":"159","votes":"2"},"_type":"doc"}
{"_id":"6313","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546324933","category_id":"18","comments":"0","has_attach":"0","id":"6313","message":"1、ELK在Nginx运维监控中的使用。\nhttp://t.cn/EbuMzr1\n2、从分布式系统设计看Elasticsearch集群及数据结构。\nhttp://t.cn/EbuIFh6\n3、Elasticsearch、Graphite与InfluxDB系统属性比较。\nhttp://t.cn/Ebuh1js\n\nbtw：2019年的第一天，Elastic中文社区祝大家元旦快乐，把时间花在美好的事物上，常来常惦记Elasticsearch中文社区。\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/6313\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第496期 (2019-01-01)","uid":"3788","views":"197","votes":"0"},"_type":"doc"}
{"_id":"6309","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545889963","category_id":"18","comments":"0","has_attach":"0","id":"6309","message":"1.filebeat源码解析\nhttp://t.cn/EyX3TRu\n2.彻底解决es的unassigned shards症状\nhttp://t.cn/EbP4B07\n3.链家全链路跟踪平台设计实践\nhttp://t.cn/EyI5qWI\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6309\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第491期 (2018-12-27)","uid":"668","views":"245","votes":"0"},"_type":"doc"}
{"_id":"6311","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546053152","category_id":"18","comments":"0","has_attach":"0","id":"6311","message":"1. 400+节点的Elasticsearch集群运维经验。\n[http://t.cn/EbJXsTM](http://t.cn/EbJXsTM) \n\n2. Elasticsearch index、create和update的源码分析。\n[http://t.cn/EbJSwbP](http://t.cn/EbJSwbP) \n\n3. 全文搜索引擎选Elasticsearch还是Solr？。\n[http://t.cn/EbJSRp9](http://t.cn/EbJSRp9) \n\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6311\n\n* 订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第493期 (2018-12-29）","uid":"1874","views":"213","votes":"0"},"_type":"doc"}
{"_id":"6224","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545797283","category_id":"18","comments":"0","has_attach":"0","id":"6224","message":"1. Elastic Stack实战学习教程 日志数据的收集、分析与可视化\nhttp://t.cn/EbPvOva\n2. 新浪是如何分析处理32亿条实时日志的\nhttp://t.cn/RUuylp6\n3. 苏宁大数据离线任务开发调度平台实践\nhttp://t.cn/EbP7Kav\n\n编辑：江水\n归档：https://elasticsearch.cn/article/6224\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第490期 (2018-12-26)","uid":"3828","views":"192","votes":"0"},"_type":"doc"}
{"_id":"6217","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545445312","category_id":"18","comments":"0","has_attach":"0","id":"6217","message":"1. 京东到家订单中心 Elasticsearch 演进历程。\n[http://t.cn/E4MXmyD](http://t.cn/E4MXmyD) \n\n2. 机器学习在solr,es,vespa上的应用（需翻墙）。\n[http://t.cn/E46pLF4](http://t.cn/E46pLF4) \n\n3. 将Firestore数据导入到es教程。\n[http://t.cn/E46OPrz](http://t.cn/E46OPrz) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6217\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第486期 (2018-12-22）","uid":"1874","views":"184","votes":"0"},"_type":"doc"}
{"_id":"6216","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545384440","category_id":"14","comments":"1","has_attach":"0","id":"6216","message":"[quote]\n作者：杨振涛 搜索引擎架构师@vivo \n首次发布：Elasticsearch中文社区\n发布日期：2018-12-22\n[/quote]\n搜索引擎作为互联网发展历史中一个非常典型的产品/业务形态，时至今日并没有太大的突破性变化；主流形态可以划分为大搜、垂搜、企业级搜索和站内/app内搜索等。除了Google, Yahoo, Bing, Ask 等以及国内百度、搜狗、360、神马等是人们熟识的大搜之外，非业内人士还真不知道其他还有哪些公司以及有哪些搜索产品或业务场景。 实际上，在信息爆炸的时代，几乎每家有点儿规模的公司都或多或少要涉及到搜索引擎，最起码你需要接触SEO/SEM。本文将从非大搜企业的搜索需求出发，并基于开源技术栈来介绍和探讨搜索引擎在实践中的几个核心任务及其主要解决思路。同时为了避免重复，本文以外链形式引用了大量网络已有的国内外公开资料，方便大家参考，需要注意的是部分内容可能会随着时间推移而过期或链接失效。\n\n提到开源搜索引擎，在Java技术栈里以Lucene, Solr/SolrCloud及Elasticsearch为代表的几个项目可能最为流行。本文的写作初衷是解答”熟练使用ES等开源搜索引擎解决方案以后，要如何才能做好搜索产品/业务？“ 希望对你有所帮助，如果你有关于此话题的更多实践经验或不同见解，欢迎留言评论交流。 \n \n[size=20][b]1. 做好搜索引擎意味着什么？[/b][/size]\n \n有一位同行的文章总结了好的搜索引擎的衡量维度：\n[list]\n[*]相关性[/*]\n[*]体验[/*]\n[*]性能[/*]\n[/list]\n\n其中相关性是非常重要的一个维度，这里我将通过引用一篇文章来介绍什么是”相关性工程“以及”相关性工程师“ http://www.flax.co.uk/blog/2018/06/25/defining-relevance-engineering-part-1-the-background/ 。\n\n相关性工程中的“相关性”，主要是指代用户的Query与索引库中的Doc之间的相关性，所以可以分别从索引数据和Query两个方面来考虑。\n\n相关性工程考虑的第一个特征就是基于已有索引数据的文本相关度计算，通常有TF-IDF、BM25、BM25F等。Elasticsearch早期的版本默认都是TF-IDF，目前已更改为BM25。对于中文数据，分词方法和策略也会直接影响到文本相关度的计算；其次匹配方式也非常重要；最后就是基于此的相关性算分了。\n\n相关性工程还可以考虑更多的特征，尤其是从索引数据之外来挖掘出的特征，比如索引文档的权威性、时效性、专业性、质量与口碑评分、热度与流行度等。结合NLP技术，相关性工程还可以考虑语义距离等特征，丰富召回结果。当然这些特征的处理与机器学习中的特征工程基本一致，比如涉及归一化问题、权重问题、稀疏性问题、非典型分布等等。\n\n相关性工程考虑的另一个重要特征是用户点击反馈数据，即对于用户所看到的搜索结果列表，点击行为被看作是对当前搜索结果的一种认可，用户点了哪个位置的doc对于继续优化相关性至关重要。这两天有个著名案例就是Google的劈柴在听证会上解释为什么在Google搜索Idiot出现的都是特朗普的照片。\n\n\n体验涉及的方面较多，最重要的就是产品功能和交互方面的体验了，比如一个典型的搜索产品，C端可能具备以下功能：\n[list]\n[*]搜索前：搜索框，搜索入口，热搜榜/飙升榜/大家都在搜，搜索发现，默认搜索词，历史搜索记录，猜你想搜，分类搜索，语音输入搜索/图片搜索； 广告位[/*]\n[*]搜索中：搜索联想直达，搜索联想词，输入纠错，关键词匹配高亮[/*]\n[*]搜索后：搜索结果列表，列表页推荐/广告，特形展示，列表穿插，搜了还搜，搜索详情页，详情页搜索推荐，无结果及少结果填充 ，筛选条件/筛选器，自主排序，列表样式切换（宫格 | 列表）[/*]\n[/list]\n\n除了产品功能，还需要考虑搜索引擎的可运营性，比如搜索运营管理系统，至少要具备基本功能的各种黑白灰名单，包括人工干预，优化分词的自定义词典、同义词典、停用词典，以及对查询词的强制改写或者升降权；对索引内容的管控，比如对检索字段的；对召回和排序的相关参数的优化和调整等等；此外，还有配套的SEO或ASO系统，以及各种数据指标相关的看板系统。\n\n而搜索结果中的特形展示，也是目前比较主流的产品形式，不管是自然结果还是搜索广告，都可以提供更快捷的体验，甚至一度成为知识图谱在搜索产品中应用的代表性功能。另外搜索联想中的直达服务，也是目前比较流行的，可以进一步缩短用户的操作路径，直达目标内容或服务。\n\n更多关于产品体验和设计类问题可以参考  http://www.woshipm.com/tag/搜索功能 \n\n性能方面，搜索引擎的每一次查询理论上都是实时运算，大部分搜索引擎系统都是实时或准实时的，这就要求在用户感知上要有基本的响应时间（RT）保障，比如在国内公网环境下，200ms是比较优秀的体验，300ms-500ms是正常的体验，500ms+就需要尽快去优化。除去其中的网络I/O等开销，对于后端搜索服务的RT，一般是T99在100ms以内，T90在50ms以内，具体标准取决与当事业务和产品。除了RT，可用性也是非常重要的，一般要求99.9%以上；另外，索引数据的生效时间也很重要，比如新加入的索引，或者已有索引的更新和删除，秒级生效是比较好的体验。需要明确的一点是，这里的性能指标我们针对的是To C用户，如果是企业级搜索甚至是基于ES的一个即时查询分析系统，可能复杂查询的秒级响应也是很正常的。\n\n延伸阅读：\n\n阿里云-开放搜索-最佳实践-功能篇-相关性实践 https://help.aliyun.com/document_detail/29186.html \nDefining relevance engineering 什么是相关性工程 http://www.flax.co.uk/blog/2018/06/25/defining-relevance-engineering-part-1-the-background/ \n \n[size=20][b]2. 搜索引擎是典型的机器学习问题[/b][/size]\n \n云计算、大数据、AI 先后成为IT与互联网行业的热点，三者经常被称为CBA或ABC技术，而这些都与一家公司密切相关，那就是 Google !   众所周知 Google 是一家著名的全球搜索引擎公司，但其产品远不止搜索引擎。从Google的三驾马车 GFS, MapReduce, BigTable开始，后来有了 Yahoo牵头的开源实现Hadoop（Hadoop最早来自于Nutch，是的，没错，就是那个开发了 Lucene 的 Doug Cutting所开源的Nutch，他被称作Hadoop之父），到后来的云计算与大数据技术蓬勃，到今天的AI热潮，各种深度学习各种NN， Google Brain，开源的Tensorflow，对Google来说这一切都是搜索引擎业务驱动的水到渠成的发展轨迹。 可以说搜索引擎是天生的机器学习问题，有着诸多的机器学习/深度学习应用场景。这里顺便DISS下一些眼高手低的迷糊党，互联网圈儿曾有人遇到求职者表示想做AI，却不做搜索不做推荐不做广告！（本人内心：你咋不上天呢！请记住AI is a buzzword. ）当今的互联网或移动互联网，搜索、推荐与广告是三大典型的所谓AI应用落地方向，其他的也有但并未发展成熟，至少还没有成熟的变现模式；而这三者或多或少有些交集，搜索几乎是最基础的一个，比如推荐也需要建立索引，需要检索TOP N，搜索广告也需要做召回和排序。\n\n如果我们把搜索引擎的核心模型简化下，其实主要是在解决三大类问题： \n\n- 数据： 内容侧的爬虫，预处理，内容分析和理解，索引建立和存储 ；用户侧的Query理解，改写，意图识别等\n- 算法/模型 ：把相关性和排序等业务问题抽象为回归或分类/聚类问题，特征工程，离线训练模型，在线预测\n- 策略：为满足业务需求而制定并持续优化的一系列规则、模型或模型组合、参数优化等活动，并通过工程化实现体现到线上系统，以及配套的试验和评估系统 \n \n[size=16][b]2.1 Ranking  排序[/b][/size]\n\n常见的排序策略有：\n[list]\n[*]单维度排序：顾名思义按照单个维度来排序，没有任何复杂性可言，在召回结果集不太大的情况下实时排序即可。[/*]\n[*]优先级排序：相对单维度排序而已一般是先按维度A排，当A的排序依据一样或相等时再按维度B排序，以此类推。[/*]\n[*]加权排序   ：针对多个维度或特征，赋予不同权重，并按求和之后的得分来排序；实践中通常会采用分层加权排序（第一层加权排序之后，得到不少于2个得分，继续加权后排序），或者分组加权排序（第一层分组来加权排序后，对所得到的得分可能按业务需求进行非求和类的运算比如乘法，再按最终得分排序）的策略。 加权排序的难点在于，如何设置并持续优化这些权重，通常会建模为典型的机器学习问题来拟合。[/*]\n[*]机器学习排序 ：即所谓LTR，根据用户点击或人工标注数据集建立学习目标，然后通过特征工程来挖掘与目标有关系的一系列特征，并建立学习模型，通过训练集获得模型参数，以该组参数为基准做预测，上线后再基于用户点击数据持续优化该模型的参数。LTR是一个通用方法的称谓，不是某一个具体算法的名称，具体算法名称参见下文。[/*]\n[/list]\n\n排序问题可以简单抽象成为预测用户点击列表中对象的概率问题。\n \n[size=16][b]2.2 ES生态内的 LTR [/b][/size]\n\n关于LTR的理论和方法学，已经有很多论文和资料了 ( 参考 [url=https://en.wikipedia.org/wiki/Learning_to_rank]wikipedia [/url], [url=http://times.cs.uiuc.edu/course/598f16/l2r.pdf]LTR简介-微软亚研院[/url]， [url=https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf]LTR Pairwise to Listwise [/url],  [url=https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/35662.pdf]大规模LTR-Google[/url]，[url=https://ieeexplore.ieee.org/document/8186875]LTR书籍 [/url])，感兴趣的可以阅读，这里主要提供几个JAVA和ES生态的工程实现参考。\n\nes-ltr插件  http://es-learn-to-rank.labs.o19s.com/ \n\nSet of command line tools for Learning To Rank https://github.com/SeaseLtd/ltr-tools\n\nes的ranking evaluation api https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html \n\nJava LTR类库： RankLib  https://sourceforge.net/p/lemur/wiki/RankLib/\n\n支持算法如下：\n[list]\n[*]MART (Multiple Additive Regression Trees, a.k.a. Gradient boosted regression tree) [/*]\n[*]RankNet [/*]\n[*]RankBoost [/*]\n[*]AdaRank [/*]\n[*]Coordinate Ascent [/*]\n[*]LambdaMART [/*]\n[*]ListNet [/*]\n[*]Random Forests  [/*]\n[/list]\n\n延伸阅读：\n[list]\n[*]vivo互联网技术： 搜索引擎与其他机器学习有何不同   https://mp.weixin.qq.com/s/uWg3m5xIGBAKNqqDmxzw2Q[/*]\n[*]InfoQ：在 Elasticsearch 中应用机器学习排序 LTR https://www.infoq.cn/article/we-are-bringing-learning-to-rank-to-elasticsearch[/*]\n[*]InfoQ：认识机器学习排序 LTR https://www.infoq.cn/article/machine-learning-sequencing-ltr[/*]\n[*]InfoQ：机器学习排序 LTR 入门——线性模型 https://www.infoq.cn/article/2017%2F10%2FMachine-learn-LTR-linear-model[/*]\n[/list]\n \n[size=16][b]2.3 典型垂搜[/b][/size]\n\n[b]电商与O2O搜索[/b]\n\n案例： 天猫，淘宝，京东，美丽说蘑菇街，有赞 ，美团点评，饿了么 \n\n阿里研究员徐盈辉：在线AI技术在搜索与推荐场景的应用 https://yq.aliyun.com/articles/107941  \n阿里巴巴资深算法专家三桐：人工智能在搜索中的应用 https://yq.aliyun.com/articles/288065  \n阿里巴巴年度技术总结 - 人工智能在搜索的应用和实践 http://www.sohu.com/a/214123235_680198\n 电子商务搜索系统架构参考 （京东） https://blog.csdn.net/hongsejiaozhu/article/details/53408067  \n电商搜索之动态属性值（特征值）聚合 （举例 京东和solr实现）  https://blog.csdn.net/hu948162999/article/details/49280071  \n劈开迷雾，蘑菇街电商搜索架构及搜索排序实现 https://blog.csdn.net/huangshulang1234/article/details/78746694\n有赞搜索引擎实践(工程篇)  https://www.cnblogs.com/hsydj/p/5303050.html\n有赞搜索引擎实践(算法篇)  https://www.cnblogs.com/hsydj/p/5402945.html \n有赞搜索系统的架构演进   https://tech.youzan.com/search-tech-1/   \n有赞搜索系统的技术内幕  https://tech.youzan.com/search-tech-2/  \n\n电商系统如何做搜索引擎？ https://blog.csdn.net/zysgdhf4253/article/details/82253999  \n\n电商检索系统总结——功能篇 https://www.cnblogs.com/wanghuaijun/p/7112952.html \n\n[b]App搜索 [/b]\n\n案例：Google Play, 应用宝，各种手机助手，Apple App Store及各大其他手机厂商的应用商店/应用市场以及互联网电视/机顶盒等的应用商店/应用市场  \n \n[size=20][b]3. 搜索引擎的效果评价[/b][/size]\n\n我们在团队内有句戏言：看一个搜索团队是否专业，就看他们是否做效果评价。 在与国内外的搜索工程师交流和学习过程中，还有一个说法是：搜素引擎的优化就像一个打地鼠游戏，你解决一类bad case的同时很难确认其是否会带来新的bad case以及会带来多少。\n\n需要区别的是，搜索引擎中使用到的机器学习/深度学习算法本身的效果评估（如分类算法的Accuracy、Precision、Recall、F1、ROC、AUC 等）并不能直接代替搜索引擎的效果评价。通常我们分为人工主观评测和业务指标评测。\n\n参考：\n[list]\n[*]搜索质量概述 https://opensourceconnections.com/blog/2018/11/19/an-introduction-to-search-quality/ [/*]\n[*]nDCG排序打分工具  https://opensourceconnections.com/blog/2018/02/26/ndcg-scorer-in-quepid/[/*]\n[*]百度众测任务： Query与广告之间的相关性评估规则  http://test.baidu.com/mark/task/view/id/2584923 [/*]\n[*]Search Quality Evaluation Tool for Apache Solr \u0026amp; Elasticsearch search-based infrastructures https://github.com/SeaseLtd/rated-ranking-evaluator [/*]\n[/list]\n \n[size=20][b]4. NLP 自然语言处理[/b][/size]\n\n我们知道搜索引擎的上游学科是信息检索（IR），这也是搜索引擎的理论基础。而自然语言处理（NLP）在信息检索领域尤其是搜索引擎中有着至关重要的地位和作用。一方面我们对于被搜索的内容数据的理解，需要借助NLP来提升语义性和智能程度，另一方面我们对于用户Query和意图的理解，也需要借助NLP相关方法和技术来完成。\n\n实际上ES的很多特性已经非常强大， 可以作为基本的文本分析和挖掘工具使用，这也是解释了ES官方博客以及其他博客有分享一些文章，主题是关于使用ES来进行文本分类或者实现推荐系统。\n\n\n总结一下，想要做好一个典型的搜索引擎产品，除了熟练使用ES，还需要考虑搜索产品的功能完备性、体验优劣、性能以及相关性，而相关性涉及对内容数据的理解和挖掘、对用户Query的理解和意图识别，以及检索过程中的特征选取和权重优化、算分、排序，最后是比较重要的效果评价。这个过程中NLP的应用也非常多，除了基本的分词，还可能涉及非必留、词性识别、纠错、繁简体、多语言、文本向量化及语义距离计算等。\n\n\n最后推荐一本搜索必读书籍—— 吴军的《数学之美》第二版 https://book.douban.com/subject/26163454/   \n[img]https://img12.360buyimg.com/n1/jfs/t535/313/495218117/815050/9be8097a/546b1647N4326ba2c.jpg[/img]\n第1 章　文字和语言 vs 数字和信息\n第2 章　自然语言处理 — 从规则到统计\n第3 章　统计语言模型\n第4 章　谈谈分词\n第5 章　隐含马尔可夫模型\n第6 章　信息的度量和作用\n第7 章　贾里尼克和现代语言处理\n第8 章　简单之美 — 布尔代数和搜索引擎\n第9 章　图论和网络爬虫\n第10章　PageRank — Google的民主表决式网页排名技术\n第11章　如何确定网页和查询的相关性\n第12章　有限状态机和动态规划 — 地图与本地\n第13章　Google AK-47 的设计者 — 阿米特· 辛格博士\n第14章　余弦定理和新闻的分类\n第15章　矩阵运算和文本处理中的两个分类问题\n第16章　信息指纹及其应用\n第17章　由电视剧《暗算》所想到的 — 谈谈密码学的数学原理\n第18章　闪光的不一定是金子 — 谈谈搜索引擎\n第19章　谈谈数学模型的重要性\n第20章　不要把鸡蛋放到一个篮子里 — 谈谈最\n第21章　拼音输入法的数学原理\n第22章　自然语言处理的教父马库斯和他的优秀弟子们\n第23章　布隆过滤器\n第24章　马尔可夫链的扩展 — 贝叶斯网络\n第25章　条件随机场、文法分析及其他\n第26章　维特比和他的维特比算法\n第27章　上帝的算法 — 期望最大化算法\n第28章　逻辑回归和搜索广告\n第29章　各个击破算法和Google 云计算的基础\n第30章　Google 大脑和人工神经网络\n第31章　大数据的威力——谈谈数据的重要性\n \n \n \n \n ","title":"Day22 - 熟练使用ES离做好搜索还差多远？","uid":"54","views":"789","votes":"11"},"_type":"doc"}
{"_id":"6212","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545305076","category_id":"18","comments":"0","has_attach":"0","id":"6212","message":"1.kibana本地文件安全漏洞CVE-2018-17246说明\nhttp://t.cn/E45chlT\n2.有赞全链路压测实战\nhttp://t.cn/E45cViJ\n3.Elasticsearch bool query小结\nhttp://t.cn/E45cKEi\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6212\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第484期 (2018-12-20)","uid":"668","views":"183","votes":"0"},"_type":"doc"}
{"_id":"6139","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542422904","category_id":"18","comments":"0","has_attach":"0","id":"6139","message":"1. 如何迁移到kibana空间\n[http://t.cn/E2yMhZi](http://t.cn/E2yMhZi) \n\n2. 利用kibana空间优化管理权限。\n[http://t.cn/E2yJq1b](http://t.cn/E2yJq1b) \n\n3. Elasitcsearch索引优化。\n[http://t.cn/E2y6afZ](http://t.cn/E2y6afZ) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6139\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第451期 (2018-11-17）","uid":"1874","views":"186","votes":"0"},"_type":"doc"}
{"_id":"6135","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542180110","category_id":"2","comments":"0","has_attach":"0","id":"6135","message":"本次活动报名已截止，因为名额限制无法报名成功的小伙伴也不用着急，届时会议将采用zoom进行直播，在 PC、Mac、iPhone/iPad、安卓手机/平板上，点击https://www.zoomus.cn/j/1524425455 即可轻松加入观看。","title":"【 报名已结束】2018 Elastic \u0026amp; 东方航空大数据技术沙龙","uid":"81","views":"744","votes":"0"},"_type":"doc"}
{"_id":"6130","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542037199","category_id":"18","comments":"0","has_attach":"0","id":"6130","message":"1.如何改进Elasticsearch用于日志分析？ http://t.cn/EwwRUZd \n2.剖析Elasticsearch的IndexSorting:一种查询性能优化利器 \nhttp://t.cn/EAlDnwc \n3.记一次ElasticSearch集群灾难恢复。 \nhttp://t.cn/EAlk7Et \n \n编辑：cyberdak \n归档：https://elasticsearch.cn/article/6130\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第446期 (2018-11-12) ","uid":"3851","views":"231","votes":"0"},"_type":"doc"}
{"_id":"6123","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541558534","category_id":"18","comments":"0","has_attach":"0","id":"6123","message":"1. 浅谈Elasticsearch基础与架构\nhttp://t.cn/EwklpZS\n2. Elasticsearch.net项目实战\nhttp://t.cn/Ewklktq\n3. Elasticsearch mapping 设计总结\nhttp://t.cn/EwkjXZA\n \n编辑：江水\n归档：https://elasticsearch.cn/article/6123\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第441期 (2018-11-07)","uid":"3828","views":"271","votes":"0"},"_type":"doc"}
{"_id":"3682","_index":"forum-mysql","_score":1,"_source":{"addtime":"1541119866","category_id":"18","comments":"1","has_attach":"0","id":"3682","message":"1.Elasticsearch搜索词组，如何更准？\nhttp://t.cn/EZFBj2R\n2.Lucene倒排索引简述 之倒排表\nhttp://t.cn/Ew5bwiE\n3.Elasticsearch下分布式存储的数据分布\nhttp://t.cn/Ew5bU5G\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/3682\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第436期 (2018-11-02)","uid":"1341","views":"273","votes":"1"},"_type":"doc"}
{"_id":"6205","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545016753","category_id":"2","comments":"0","has_attach":"0","id":"6205","message":"近两年随着Elastic Stack的愈发火热，其近乎成为构建实时日志应用的工业标准。在小型数据应用场景，最新的6.5版本已经可以做到开箱即用，无需过多考虑架构上的设计工作。 然而一旦应用规模扩大到数百TB甚至PB的数据量级，整个系统的架构和后期维护工作则显得非常重要。借着2018 Elastic Advent写文的机会，结合过去几年架构和运维公司日志集群的实践经验，对于大规模日志型数据的管理策略，在此做一个总结性的思考。 文中抛出的观点，有些已经在我们的集群中有所应用并取得比较好的效果，有些则还待实践的检验。抛砖引玉，不尽成熟的地方，还请社区各位专家指正。\n\n对于日志系统，最终用户通常有以下几个基本要求:\n1. 数据从产生到可检索的实时性要求高，可接受的延迟通常要求控制在数秒，至多不超过数十秒\n2. 新鲜数据(当天至过去几天)的查询和统计频率高，返回速度要快(毫秒级，至多几秒)\n3. 历史数据保留得越久越好。\n\n针对这些需求，加上对成本控制的必要性，大家通常想到的第一个架构设计就是冷热数据分离。\n\n# 冷热数据分离\n冷热分离的概念比较好理解，热结点做数据的写入，保存近期热数据，冷数据定期迁移到冷数据结点，就这么简单。不过实际操作起来可能还是碰到一些具体需要考虑的细节问题。\n1. 冷热结点集群配置的JVM heap配置要差异化。热结点无需存放太多数据，对于heap的要求通常不是太高，在够用的情况下尽量配置小一点。可以配置在26GB左右甚至更小，而不是大多数人知道的经验值31GB。原因在于这个size的heap，可以启用`zero based` Compressed Oops，JVM运行效率是最高的， 参考: [heap-size](https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html)。而冷结点存在的目的是尽量放更多的数据，性能不是首要的，因此heap可以配置在31GB。\n2. 数据迁移过程有一定资源消耗，为避免对数据写入产生显著影响，通常定时在业务低峰期，日志产出量比较低的时候进行，比如半夜。\n3. 索引是否应该启用压缩，如何启用？最初我们对于热结点上的索引是不启用压缩的，为了节省CPU消耗。只在冷结点配置里，增加了索引压缩选项。这样索引迁移到冷结点后，执行force merge操作的时候，ES会自动将结点上配置的索引压缩属性套用到merge过后新生成的segment，这样就实现了热结点不压缩，冷结点merge过后压缩的功能。极大节省了冷结点的磁盘空间。后来随着硬件的升级，我们发现服务器的cpu基本都是过剩的，磁盘IO通常先到瓶颈。 因此尝试在热结点上一开始创建索引的时候，就启用压缩选项。实际对比测试并没有发现显著的索引吞吐量下降，并且因为索引压缩后磁盘文件size的大幅减少，每天夜间的数据迁移工作可以节省大量的时间。至此我们的日志集群索引默认就是压缩的。\n4. 冷结点上留做系统缓存的内存一般不多，加上数据量非常巨大。索引默认的mmapfs读取方式，很容易因为系统缓存不够，导致数据在内存和磁盘之间频繁换入换出。严重的情况下，整个结点甚至会因为io持续在100%无法响应。 实践中我们发现对冷结点使用niofs效果会更好。\n\n实现了冷热结点分离以后，集群的资源利用率提升了不少，可管理性也要好很多了. 但是随着接入日志的类型越来越多（我们生产上有差不多400种类型的日志)，各种日志的速率差异又很大，让ES自己管理shard的分布很容易产生写入热点问题。 针对这个问题，可以采用对集群结点进行分组管理的策略来解决。\n\n# 热结点分组管理\n所谓分组管理，就是通过在结点的配置文件中增加自定义的标签属性，将服务器区分到不同的组别中。然后通过设置索引的`index.routing.allocation.include`属性，控制改索引分布在哪个组别。同时配合设置`index.routing.allocation.total_shards_per_node`，可以做到某个索引的shard在某个group的结点之间绝对均匀分布。\n\n比如一个分组有10台机器，对一个5 primary ，1 replica的索引，让该索引分布在该分组的同时，设置`total_shards_per_node`为1，让每个节点上只能有一个分片，这样就避免了写入热点问题。 该方案的缺陷也显而易见，一旦有结点挂掉，不会自动recovery，某个shard将一直处于unassigned状态，集群状态变成yellow。 但我认为，热数据的恢复开销是非常高的，与其立即在其他结点开始复制，之后再重新rebalance，不如就让集群暂时处于yellow状态。 通过监控报警的手段，及时通知运维人员解决结点故障。 待故障解决之后，直接从恢复后的结点开始数据复制，开销要低得多。\n\n在我们的生产环境主要有两种类型的结点分组，分别是10台机器一个分组，和2台机器一个分组。10台机器的分组用于应对速率非常高，shard划分比较多的索引，2台机器的分组用于速率很低，一个shard（加一个复制片）就可以应对的索引。\n\n这种分组策略在我们的生产环境中经过验证，非常好的解决了写入热点问题。那么冷数据怎么管理？ 冷数据不做写入，不存在写入热点问题，查询频率也比较低，业务需求方面对查询响应要求也不那么严苛，所以查询热点问题也不是那么突出。因此为了简化管理，冷结点我们是不做shard分布的精细控制，所有数据迁移到冷数据结点之后，由ES默认的shard分布则略去控制数据的分布。\n\n不过如果想进一步提高冷数据结点服务器资源的利用率，还是可以有进一步挖掘的的空间。我们知道ES默认的shard分布策略，只是保证一个索引的shard尽量分布在不同的结点，同时保证每个节点上shard数量差不多。但是如果采用默认按天创建索引的策略，由于索引速率差异很大，不同索引之间shard的大小差异可能是1-2个数量级的。如果每个shard的size差异不大就好了，那么默认的分布策略，基本上可以保证冷结点之间数据量分布的大致均匀。 能实现类似功能的是ES的rollover特性。\n\n# 索引的Rollover\nRollover api可以让索引根据预先定义的时间跨度，或者索引大小来自动切分出新索引，从而将索引的大小控制在计划的范围内。合理的应用rollver api可以保证集群shard大小差别不会太大。 只是集群索引类别比较多的时候，rollover全部手动管理负担比较大，需要借助额外的管理工具和监控工具。我们出于管理简便的考虑，暂时没有应用到这个特性。\n\n# 索引的Rollup\n我们发现生产有些用户写入的“日志”，实际上是多维的metrcis数据，使用的时候不是为了查询日志的详情，仅仅是为了做各种维度组合的过滤和聚合。对于这种类型的数据，保留历史数据过多一来浪费存储空间，二来每次聚合都要在裸数据上跑，非常浪费资源。 ES从6.3开始，在x-pack里推出了rollup api，通过定期对裸数据做预先聚合，大大缩减了保存在磁盘上的数据量。对于不需要查询裸日志的应用场景，合理应用该特性，可以将历史数据的磁盘消耗降低几个数量级，同时rollup search也可以大大提升聚合速度。不过rollup也有其局限性，即他的实现是通过定期任务，对间隔期数据跑聚合完成的，有一定的计算开销。 如果数据写入速率非常高，集群压力很大，rollup可能无法跟上写入速率，而不具有实用性。 所以实际环境中，还是需要根据应用场景和资源使用情况，进行灵活的取舍。\n\n# 多集群的便利性\n数据量大到一定程度以后，单集群由于master node单点的限制，会遇到各种集群状态数据更新时得性能问题。 由此现在一些大规模的应用已经开始利用到多集群互联和cross cluster search的特性。 这种结构除了解决单集群数据容量限制问题以外，我们还发现在做容量均衡方面还有比较好的便利性。应用日志写入量通常随着业务变化也会剧烈变化，好不容易规划好的容量，不久就被业务的增长给打破，数倍或者数10倍的流量增长很可能就让一组结点过载出现写入延迟。 如果只有一个集群，在结点之间重新平衡shard比较费力，涉及到数据的迁移，可能非常缓慢，还会影响写入。 但如果有多集群互联，切换就可以做到非常的快速和简单。 原理上只需要在新集群中加入对应的索引配置模版，然后更新写入程序的配置，写入目标指向新集群，重启写入程序即可。并且，可以进一步将整个流程工具化，在GUI上完成一键切换。 \n\n","title":"Day 17 - 关于日志型数据管理策略的思考","uid":"81","views":"779","votes":"15"},"_type":"doc"}
{"_id":"6200","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544866690","category_id":"18","comments":"0","has_attach":"0","id":"6200","message":"1.滴滴Elasticsearch多集群架构实践。\n[http://t.cn/EUNLkNU](http://t.cn/EUNLkNU) \n\n2. 用es作为存储进行机器学习的python库。\n[http://t.cn/EUWeDoI](http://t.cn/EUWeDoI) \n\n3. 一周热点：职场寒冬，给你讲四个小故事\n[http://t.cn/Eydyut9](http://t.cn/Eydyut9) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6200\n\n* 订阅：https://tinyletter.com/elastic-daily\n","title":"Elastic日报 第479期 (2018-12-15）","uid":"1874","views":"187","votes":"0"},"_type":"doc"}
{"_id":"6198","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544774300","category_id":"45","comments":"0","has_attach":"1","id":"6198","message":"\n[attach]3296[/attach]\n \n https://github.com/unimassystem/elasticsearch-jdbc[code]\tBasicDataSource basicDataSource = new BasicDataSource();\n\t// 创建连接池 一次性创建多个连接池\n\n\t// 连接池 创建连接 ---需要四个参数\n\tbasicDataSource.setDriverClassName(\u0026quot;com.elasticsearch.jdbc.ElasticsearchDriver\u0026quot;);\n\tbasicDataSource.setUrl(\u0026quot;jdbc:elasticsearch://127.0.0.1:5000\u0026quot;);\n\n\t// 从连接池中获取连接\n\tConnection conn = basicDataSource.getConnection();\n\tString sql = \u0026quot;select SRC_IP,SRC_PORT from \\\u0026quot;my_test-*\\\u0026quot;\u0026quot;;\n\tStatement stmt = conn.createStatement();\n\tResultSet rs = stmt.executeQuery(sql);\n\twhile (rs.next()) {\n\t\tSystem.out.println(rs.getString(\u0026quot;SRC_IP\u0026quot;));\n\t}\n\tbasicDataSource.close();\n\n\n\tString sql = \u0026quot;select SRC_IP,SRC_PORT from my_test* where SRC_PORT between 10 and 100 limit 1000\u0026quot;;\n\tString url = \u0026quot;jdbc:elasticsearch://127.0.0.1:5000\u0026quot;;\n\tConnection connection = DriverManager.getConnection(url, \u0026quot;test\u0026quot;, null);\n\tStatement statement = connection.createStatement();\n\tResultSet rs = statement.executeQuery(sql);\n\tResultSetMetaData meta = rs.getMetaData();\n\tString columns = \u0026quot;|\u0026quot;;\n\tfor (int i = 0; i \u0026lt; meta.getColumnCount(); i++) {\n\t\tcolumns += meta.getColumnLabel(i) + \u0026quot; | \u0026quot;;\n\t}\n\tSystem.out.println(columns);\n\twhile (rs.next()) {\n\t\tString row = \u0026quot;|\u0026quot;;\n\t\tfor (int i = 0; i \u0026lt; meta.getColumnCount(); i++) {\n\t\t\trow += rs.getString(i) + \u0026quot; | \u0026quot;;\n\t\t}\n\t\tSystem.out.println(row);\n\t}   \n[/code]","title":"JDBC with ESQL","uid":"1452","views":"113","votes":"0"},"_type":"doc"}
{"_id":"6193","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544626351","category_id":"18","comments":"0","has_attach":"0","id":"6193","message":"1. 快来学习下如何便捷地记录文档插入 es 的时间？\nhttp://t.cn/EUfESt7\n2. 6.5.3发布了，还没升级到6的同学又多了一个新的选择！\nhttp://t.cn/EUfEHvA\n3. (自备梯子)如何不停机修改索引的 mapping？\nhttp://t.cn/EUfErLr\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/6193\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第476期 (2018-12-12)","uid":"86","views":"188","votes":"0"},"_type":"doc"}
{"_id":"6190","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544585302","category_id":"4","comments":"0","has_attach":"1","id":"6190","message":"当我们搭建elasitc stack集群时，大多数时候会在我们的架构中加入kafka作为消息缓冲区，即从beats -\u0026gt; kafka -\u0026gt; logstash -\u0026gt; elasticsearch这样的一个消息流。使用kafka可以给我们带来很多便利，但是也让我们需要额外多维护一套组件，elasitc stack本身已经提供了monitoring的功能，我们可以方便的从kibana上监控各个组件中各节点的可用性，吞吐和性能等各种指标，但kafka作为架构中的组件之一却游离在监控之外，相当不合理。\n\n幸而elastic真的是迭代的相当快，在metricbeat上很早就有了对kafka的监控，但一直没有一个直观的dashboard，终于在6.5版本上，上新了kafka dashboard。我们来看一下吧。\n\n### 安装和配置metricbeat\n\n[安装包下载地址](https://www.elastic.co/downloads/beats/metricbeat)，下载后，自己安装。\n然后，将`/etc/metricbeat/modules.d/kafka.yml.disable`文件重命名为`/etc/metricbeat/modules.d/kafka.yml`。(即打开kafka的监控)。稍微修改一下文件内容, **注意，这里需填入所有你需要监控的kafka服务器的地址**：\n\n```\n# Module: kafka\n# Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.4/metricbeat-module-kafka.html\n\n- module: kafka\n  metricsets:\n    - partition\n    - consumergroup\n  period: 20s\n  hosts: [\u0026quot;10.*.*.*:9092\u0026quot;,\u0026quot;10.*.*.*:9092\u0026quot;,\u0026quot;10.*.*.*:9092\u0026quot;,\u0026quot;10.*.*.*:9092\u0026quot;]\n\n  #client_id: metricbeat\n  #retries: 3\n  #backoff: 250ms\n\n  # List of Topics to query metadata for. If empty, all topics will be queried.\n  #topics: []\n\n  # Optional SSL. By default is off.\n  # List of root certificates for HTTPS server verifications\n  #ssl.certificate_authorities: [\u0026quot;/etc/pki/root/ca.pem\u0026quot;]\n\n  # Certificate for SSL client authentication\n  #ssl.certificate: \u0026quot;/etc/pki/client/cert.pem\u0026quot;\n\n  # Client Certificate Key\n  #ssl.key: \u0026quot;/etc/pki/client/cert.key\u0026quot;\n\n  # SASL authentication\n  #username: \u0026quot;\u0026quot;\n  #password: \u0026quot;\u0026quot;\n```\n运行metricbeat，这里，一定要注意enable kibana dashboard。\n\n然后就可以在kibana里面看到：\n\n[attach]3281[/attach]\n[attach]3280[/attach]\n\n\n这样，我们就可以通过sentinl等类似的插件，自动做kafka的告警等功能了","title":"用elasitc stack监控kafka","uid":"5649","views":"330","votes":"0"},"_type":"doc"}
{"_id":"6188","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544583975","category_id":"4","comments":"5","has_attach":"1","id":"6188","message":"使用过Kibana的同学应该都知道，当我们在kibana的配置文件中打开或者关闭功能，或者安装、卸载额外的插件后，重启kibana会触发一个优化的过程（optimize），如下图：\n\n\n[attach]3282[/attach]\n\n\n这个过程或长或短，视你电脑的性能而定。这里简单介绍一下该过程所要完成的事情。\n\n### Kibana是一个单页Web应用\n首先，Kibana是一个单页的web应用。何为单页web应用？即所有的页面的读取都是在浏览器上完成，而与后台服务器无关。与后台服务器的通信只关乎数据，而非页面。所以，应用上所有的UI都被打包在一起，一次性的发送到了浏览器端，而不是通过URL到后台进行获取。所以，我们看到kibana的首页是下面这样的：\n`http://localhost:5601/app/kibana#/`\n注意这里的`#`后，代表`#`后面的内容会被浏览器提取，不往服务器端进行url的情况，而是在浏览器上进行内部重新渲染。因为所有的页面都是存储在浏览器的，所有在初次访问的时候，会加载大量的代码到浏览器端，这些代码都是被压缩过的bundle文件：\n\n\n[attach]3283[/attach]\n\n\n而optimize的过程，就是把这些原本可读性的源代码压缩为bundle.js的过程。因此，每当你对Kibana进行裁剪之后重启，因为前端的部分是完全由浏览器负责的，**所有bundle文件需要重新生成后再发给浏览器**，所以会触发optimize的过程。\n\nKibana在6.2.0版本之后，常规版本已经默认自带了xpack（当然，你还是可以直接下载不带xpack的开源社区版），导致Kibana的size已经到了200M左右，而且越往后的版本，功能越多，代码量越大，每次optimize的过程都会耗费更多的时间。一般来说，我们会将Kibana部署在单独的机器上，因为这仅仅是一个web后端，通常我们不会分配比较优质的资源，（2C4G都算浪费的了），这种情况下面，每次我们裁剪后重启Kibana都会耗费半个小时～1个小时的时间，更有甚者直接hang住，查看系统日志才知道OOM了。\n\n### Nodejs的内存机制\nKibana是用Nodejs编写的程序，在一般的后端语言中，基本的内存使用上基本没有什么限制，但是在nodeJs中却只能使用部分内存。在64位系统下位约为1.4G，在32位系统下约为0.7G，造成这个问题的主要原因是因为nodeJs基于V8构建，V8使用自己的方式来管理和分配内存，这一套管理方式在浏览器端使用绰绰有余，但是在nodeJs中这却限制了开发者，在应用中如果碰到了这个限制，就会造成进程退出。\n\n### Nodejs内存机制对Kibana优化的影响\n因为Kibana的代码体量越来越大，将所有的代码加载到内存之后，再解析语法树，进行bundle的转换所耗费的内存已经接近1.4G的限制了，当你安装更多插件，比如sentinl的时候，系统往往已经无法为继，导致Kibana无法启动\n\n### 解决方案\n\n这种情况下，我们需要在Kibana启动的时候，指定NodeJs使用更多的内存。这个可以通过设置Node的环境变量办到。\n```\nNODE_OPTIONS=\u0026quot;--max-old-space-size=4096\u0026quot;\n```\n当然，我的建议是直接指定在kibana的启动脚本当中，修改`/usr/share/kibana/bin/kibana`文件为：\n```shell\n#!/bin/sh\nSCRIPT=$0\n\n# SCRIPT may be an arbitrarily deep series of symlinks. Loop until we have the concrete path.\nwhile [ -h \u0026quot;$SCRIPT\u0026quot; ] ; do\n  ls=$(ls -ld \u0026quot;$SCRIPT\u0026quot;)\n  # Drop everything prior to -\u0026gt;\n  link=$(expr \u0026quot;$ls\u0026quot; : '.*-\u0026gt; \\(.*\\)$')\n  if expr \u0026quot;$link\u0026quot; : '/.*' \u0026gt; /dev/null; then\n    SCRIPT=\u0026quot;$link\u0026quot;\n  else\n    SCRIPT=$(dirname \u0026quot;$SCRIPT\u0026quot;)/\u0026quot;$link\u0026quot;\n  fi\ndone\n\nDIR=\u0026quot;$(dirname \u0026quot;${SCRIPT}\u0026quot;)/..\u0026quot;\nNODE=\u0026quot;${DIR}/node/bin/node\u0026quot;\ntest -x \u0026quot;$NODE\u0026quot; || NODE=$(which node)\nif [ ! -x \u0026quot;$NODE\u0026quot; ]; then\n  echo \u0026quot;unable to find usable node.js executable.\u0026quot;\n  exit 1\nfi\n\nNODE_ENV=production exec \u0026quot;${NODE}\u0026quot; $NODE_OPTIONS --max_old_space_size=3072 --no-warnings \u0026quot;${DIR}/src/cli\u0026quot; ${@}\n\n```\n改动在最后一句：`NODE_ENV=production exec \u0026quot;${NODE}\u0026quot; $NODE_OPTIONS --max_old_space_size=3072 --no-warnings \u0026quot;${DIR}/src/cli\u0026quot; ${@}`\n\n这样，我们可以保证Kibana能顺利的完成optimize的过程\n\n\n","title":"Kibana优化过程(Optimize)过长或无法结束的解决方案","uid":"5649","views":"269","votes":"2"},"_type":"doc"}
{"_id":"6182","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544360961","category_id":"14","comments":"0","has_attach":"0","id":"6182","message":"## 参考 \nhttps://elasticsearch.cn/article/113\n\nhttps://www.elastic.co/blog/build-your-own-beat\n\n## 介绍\n公司内部有统一的log收集系统，并且实现了定制的filebeat进行log收集。为了实现实时报警和监控，自定义的beat并没有直接把输出发给elasticsearch后端，而是中间会经过storm或者durid进行实时分析，然后落入es或者hdfs。同时由于是统一log收集，所以目前还没有针对具体的不同应用进行log的内容的切分，导致所有的log都是以一行为单位落入后端存储。于是需要针对不同的业务部门定制不同的beat。\n本文初步尝试定制一个可以在beat端解析hdfs audit log的beat，限于篇幅，只实现了基本的文件解析功能。下面会从环境配置，代码实现，运行测试三个方面进行讲解。\n\n##环境配置\ngo version go1.9.4 linux/amd64\n\npython version: 2.7.9\n\n不得不吐槽下python的安装，各种坑。因为系统默认的python版本是2.7.5，而cookiecutter建议使用2.7.9\n\n\n###下面的工具会提供python本身需要依赖的一些native包\n```\nyum install openssl -y\nyum install openssl-devel -y\nyum install zlib-devel -y\nyum install zlib -y\n```\n\n###安装python\n```\nwget https://www.python.org/ftp/python/2.7.9/Python-2.7.9.tgz\ntar -zxvf Python-2.7.9.tgz\ncd ~/python/Python-2.7.9\n./configure --prefix=/usr/local/python-2.7.9\nmake\nmake install\n\nrm -f /bin/python\nln -s /usr/local/python-2.7.9/bin/python /bin/python\n```\n\n###安装工具包 distribute, setuptools, pip\n```\ncd ~/python/setuptools-19.6 \u0026amp;\u0026amp; python setup.py install\ncd ~/python/pip-1.5.4  \u0026amp;\u0026amp; python setup.py install\ncd ~/python/distribute-0.7.3  \u0026amp;\u0026amp; python setup.py install\n```\n\n### 安装cookiecutter\n```\npip install --user cookiecutter\n```\n\n### 安装cookiecutter所依赖的工具\n```\npip install backports.functools-lru-cache\npip install six\npip install virtualenv\n```\n\n*** virtualenv 安装好了之后，所在目录是在python的目录里面 (/usr/local/python-2.7.9/bin/virtualenv)，需要配置好PATH，这个工具稍后会被beat的Makefile用到\n\n\n## 代码实现\n\n需要实现的功能比较简单，目标是打开hdfs-audit.log文件，然后逐行读取，同时解析出必要的信息，组装成event，然后发送出去，如果对接的es的话，需要同时支持自动在es端创建正确的mapping\n\n### 使用官方提供的beat模板创建自己的beat\n\n* 需要设置好环境变量$GOPATH，本例子中GOPATH=/root/go\n\n```\n$ go get github.com/elastic/beats\n$ cd $GOPATH/src/github.com/elastic/beats\n$ git checkout 5.1\n\n[root@minikube-2830379 suxingfate]# cookiecutter /root/go/src/github.com/elastic/beats/generate/beat\nproject_name [Examplebeat]: hdfsauditbeat\ngithub_name [your-github-name]: suxingfate\nbeat [hdfsauditbeat]:\nbeat_path [github.com/suxingfate]:\nfull_name [Firstname Lastname]: xinglong\n\nmake setup\n```\n\n到这里，模板就生成了，然后就是定制需要的东西。\n\n* 1 _meta/beat.yml  # 配置模板文件，定义我们的beat会接受哪些配置项\n* 2 config/config.go #使用go的struct定义整个config对象，包含所有的配置项\n* 3 beater/hdfsauditbeat.go # 核心逻辑代码\n* 4 _meta/fields.yml #这里是跟es对接的时候给es定义的mapping\n\n\n\n#### 1 _meta/beat.yml\n这里增加了path，为后面配置hdfs-audit.log文件的位置留好坑\n```\n[root@minikube-2830379 hdfsauditbeat]# cat _meta/beat.yml\n################### Hdfsauditbeat Configuration Example #########################\n\n############################# Hdfsauditbeat ######################################\n\nhdfsauditbeat:\n  # Defines how often an event is sent to the output\n  period: 1s\n  path: \u0026quot;.\u0026quot;\n```\n\n#### 2 config/config.go\n这里把path定义到struct里面，后面核心代码就可以从config对象获得path了\n\n```\n[root@minikube-2830379 hdfsauditbeat]# cat config/config.go\n// Config is put into a different package to prevent cyclic imports in case\n// it is needed in several locations\n\npackage config\n\nimport \u0026quot;time\u0026quot;\n\ntype Config struct {\n\tPeriod time.Duration `config:\u0026quot;period\u0026quot;`\n        Path   string        `config:\u0026quot;path\u0026quot;`\n}\n\nvar DefaultConfig = Config{\n\tPeriod: 1 * time.Second,\n        Path:   \u0026quot;.\u0026quot;,\n}\n```\n\n#### 3 beater/hdfsauditbeat.go\n这里需要改动的地方是：\n3.1 定义了一个catAudit函数来解析目标文件的每一行，同时生成自定义的event，然后发送出去 \n3.2 Run函数调用自定义的catAudit函数，从而把我们的功能嵌入\n\n```\n[root@minikube-2830379 hdfsauditbeat]# cat beater/hdfsauditbeat.go\npackage beater\n\nimport (\n\t\u0026quot;fmt\u0026quot;\n\t\u0026quot;time\u0026quot;\n        \u0026quot;os\u0026quot;\n        \u0026quot;io\u0026quot;\n        \u0026quot;bufio\u0026quot;\n        \u0026quot;strings\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/beat\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/common\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/logp\u0026quot;\n\t\u0026quot;github.com/elastic/beats/libbeat/publisher\u0026quot;\n\n\t\u0026quot;github.com/suxingfate/hdfsauditbeat/config\u0026quot;\n)\n\ntype Hdfsauditbeat struct {\n\tdone   chan struct{}\n\tconfig config.Config\n\tclient publisher.Client\n}\n\n// Creates beater\nfunc New(b *beat.Beat, cfg *common.Config) (beat.Beater, error) {\n\tconfig := config.DefaultConfig\n\tif err := cfg.Unpack(\u0026amp;config); err != nil {\n\t\treturn nil, fmt.Errorf(\u0026quot;Error reading config file: %v\u0026quot;, err)\n\t}\n\n\tbt := \u0026amp;Hdfsauditbeat{\n\t\tdone: make(chan struct{}),\n\t\tconfig: config,\n\t}\n\treturn bt, nil\n}\n\nfunc (bt *Hdfsauditbeat) Run(b *beat.Beat) error {\n\tlogp.Info(\u0026quot;hdfsauditbeat is running! Hit CTRL-C to stop it.\u0026quot;)\n\n\tbt.client = b.Publisher.Connect()\n\tticker := time.NewTicker(bt.config.Period)\n\tcounter := 1\n\tfor {\n\t\tselect {\n\t\tcase \u0026lt;-bt.done:\n\t\t\treturn nil\n\t\tcase \u0026lt;-ticker.C:\n\t\t}\n\n\t\tbt.catAudit(bt.config.Path)\n\n\t\tlogp.Info(\u0026quot;Event sent\u0026quot;)\n\t\tcounter++\n\t}\n}\n\nfunc (bt *Hdfsauditbeat) Stop() {\n\tbt.client.Close()\n\tclose(bt.done)\n}\n\nfunc (bt *Hdfsauditbeat) catAudit(auditFile string) {\n    file, err := os.OpenFile(auditFile, os.O_RDWR, 0666)\n    if err != nil {\n        //fmt.Println(\u0026quot;Open file error!\u0026quot;, err)\n        return\n    }\n    defer file.Close()\n\n    buf := bufio.NewReader(file)\n    for {\n        line, err := buf.ReadString('\\n')\n        line = strings.TrimSpace(line)\n        if line == \u0026quot;\u0026quot; {\n            return\n        }\n\n\ttimeEnd := strings.Index(line, \u0026quot;,\u0026quot;)\n        timeString := line[0 :timeEnd]\n        tm, _ := time.Parse(\u0026quot;2006-01-02 03:04:05\u0026quot;, timeString)\n\n        ugiStart := strings.Index(line, \u0026quot;ugi=\u0026quot;) + 4\n        ugiEnd := strings.Index(line, \u0026quot; (auth\u0026quot;)\n        ugi := line[ugiStart :ugiEnd]\n\n        cmdStart := strings.Index(line, \u0026quot;cmd=\u0026quot;) + 4\n        line = line[cmdStart:len(line)]\n        cmdEnd := strings.Index(line, \u0026quot; \u0026quot;)\n        cmd := line[0 : cmdEnd]\n\n        srcStart := strings.Index(line, \u0026quot;src=\u0026quot;) + 4\n        line = line[srcStart:len(line)]\n        srcEnd := strings.Index(line, \u0026quot; \u0026quot;)\n        src := line[0:srcEnd]\n\n        dstStart := strings.Index(line, \u0026quot;dst=\u0026quot;) + 4\n        line = line[dstStart:len(line)]\n        dstEnd := strings.Index(line, \u0026quot; \u0026quot;)\n        dst := line[0:dstEnd]\n\n        event := common.MapStr{\n                \u0026quot;@timestamp\u0026quot;: common.Time(time.Unix(tm.Unix(), 0)),\n                \u0026quot;ugi\u0026quot;:       ugi,\n                \u0026quot;cmd\u0026quot;:       cmd,\n                \u0026quot;src\u0026quot;:    src,\n                \u0026quot;dst\u0026quot;:   dst,\n            }\n            bt.client.PublishEvent(event)\n\n        if err != nil {\n            if err == io.EOF {\n                //fmt.Println(\u0026quot;File read ok!\u0026quot;)\n                break\n            } else {\n                //fmt.Println(\u0026quot;Read file error!\u0026quot;, err)\n                return\n            }\n        }\n    }\n}\n\n```\n\n#### 4 _meat/fields.yml\n```\n[root@minikube-2830379 hdfsauditbeat]# less _meta/fields.yml\n- key: hdfsauditbeat\n  title: hdfsauditbeat\n  description:\n  fields:\n    - name: counter\n      type: long\n      required: true\n      description: \u0026gt;\n        PLEASE UPDATE DOCUMENTATION\n    #new fiels added hdfsaudit\n    - name: entrytime\n      type: date\n    - name: ugi\n      type: keyword\n    - name: cmd\n      type: keyword\n    - name: src\n      type: keyword\n    - name: dst\n      type: keyword\n```\n\n## 测试\n\n首先编译好项目\n```\nmake update\nmake\n```\n然后会发现生成了一个hdfsauditbeat文件，这个就是二进制的可执行文件。下面进行测试，这里偷了个懒，没有发给es，而是吐到console进行观察。\n修改了一下配置文件，需要指定正确的需要消费的audit log文件的路径，另外就是修改了output为console\n\n```\n[root@minikube-2830379 hdfsauditbeat]# cat hdfsauditbeat.yml\n################### Hdfsauditbeat Configuration Example #########################\n\n############################# Hdfsauditbeat ######################################\n\nhdfsauditbeat:\n  # Defines how often an event is sent to the output\n  period: 1s\n  path: \u0026quot;/root/go/hdfs-audit.log\u0026quot;\n\n#================================ General =====================================\n\n# The name of the shipper that publishes the network data. It can be used to group\n# all the transactions sent by a single shipper in the web interface.\n#name:\n\n# The tags of the shipper are included in their own field with each\n# transaction published.\n#tags: [\u0026quot;service-X\u0026quot;, \u0026quot;web-tier\u0026quot;]\n\n# Optional fields that you can specify to add additional information to the\n# output.\n#fields:\n#  env: staging\n\n#================================ Outputs =====================================\n\n# Configure what outputs to use when sending the data collected by the beat.\n# Multiple outputs may be used.\n#-------------------------- Elasticsearch output ------------------------------\n#output.elasticsearch:\n  # Array of hosts to connect to.\n#  hosts: [\u0026quot;localhost:9200\u0026quot;]\n\n  # Optional protocol and basic auth credentials.\n  #protocol: \u0026quot;https\u0026quot;\n  #username: \u0026quot;elastic\u0026quot;\n  #password: \u0026quot;changeme\u0026quot;\n\n#----------------------------- Logstash output --------------------------------\n#output.logstash:\n  # The Logstash hosts\n  #hosts: [\u0026quot;localhost:5044\u0026quot;]\n\n  # Optional SSL. By default is off.\n  # List of root certificates for HTTPS server verifications\n  #ssl.certificate_authorities: [\u0026quot;/etc/pki/root/ca.pem\u0026quot;]\n\n  # Certificate for SSL client authentication\n  #ssl.certificate: \u0026quot;/etc/pki/client/cert.pem\u0026quot;\n\n  # Client Certificate Key\n  #ssl.key: \u0026quot;/etc/pki/client/cert.key\u0026quot;\n\noutput.console:\n  pretty: true\n#================================ Logging =====================================\n\n# Sets log level. The default log level is info.\n# Available log levels are: critical, error, warning, info, debug\n#logging.level: debug\n\n# At debug level, you can selectively enable logging only for some components.\n# To enable all selectors use [\u0026quot;*\u0026quot;]. Examples of other selectors are \u0026quot;beat\u0026quot;,\n# \u0026quot;publish\u0026quot;, \u0026quot;service\u0026quot;.\n#logging.selectors: [\u0026quot;*\u0026quot;]\n```\n\n开始执行\n```\n[root@minikube-2830379 hdfsauditbeat]# ./hdfsauditbeat\n{\n  \u0026quot;@timestamp\u0026quot;: \u0026quot;2018-12-09T03:00:00.000Z\u0026quot;,\n  \u0026quot;beat\u0026quot;: {\n    \u0026quot;hostname\u0026quot;: \u0026quot;minikube-2830379.lvs02.dev.abc.com\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;minikube-2830379.lvs02.dev.abc.com\u0026quot;,\n    \u0026quot;version\u0026quot;: \u0026quot;5.1.3\u0026quot;\n  },\n  \u0026quot;cmd\u0026quot;: \u0026quot;create\u0026quot;,\n  \u0026quot;dst\u0026quot;: \u0026quot;null\u0026quot;,\n  \u0026quot;src\u0026quot;: \u0026quot;/app-logs/app/logs/application_1540949675029_717305/lvsdpehdc25dn0444.stratus.lvs.abc.com_8042.tmp\u0026quot;,\n  \u0026quot;ugi\u0026quot;: \u0026quot;appmon@APD.ABC.COM\u0026quot;\n}\n{\n  \u0026quot;@timestamp\u0026quot;: \u0026quot;2018-12-09T03:00:00.000Z\u0026quot;,\n  \u0026quot;beat\u0026quot;: {\n    \u0026quot;hostname\u0026quot;: \u0026quot;minikube-2830379.lvs02.dev.abc.com\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;minikube-2830379.lvs02.dev.abc.com\u0026quot;,\n    \u0026quot;version\u0026quot;: \u0026quot;5.1.3\u0026quot;\n  },\n  \u0026quot;cmd\u0026quot;: \u0026quot;create\u0026quot;,\n  \u0026quot;dst\u0026quot;: \u0026quot;null\u0026quot;,\n  \u0026quot;src\u0026quot;: \u0026quot;/app-logs/appmon/logs/application_1540949675029_717305/lvsdpehdc25dn0444.stratus.lvs.abc.com_8042.tmp\u0026quot;,\n  \u0026quot;ugi\u0026quot;: \u0026quot;appmon@APD.ABC.COM\u0026quot;\n}\n```\n\n## 结束\n\n使用自定义beat给我们提供了很大的灵活性，虽然pipline或者logstash也可以做到，但是使用场景还是有很大差别的。如果是调用特殊的命令获得输出，或者是本文的场景都更适合定制化beat。","title":"Day 9 - 动手实现一个自定义beat","uid":"10526","views":"344","votes":"1"},"_type":"doc"}
{"_id":"6158","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543328094","category_id":"18","comments":"0","has_attach":"0","id":"6158","message":"1. 浅谈搜索系统\nhttp://t.cn/Ri9e4Ss\n2. 多个ES集群一致性问题\nhttp://t.cn/RIwrbul\n3. 使用elasticsearch与jieba分词搭建搜索服务\nhttp://t.cn/ELXEWPv\n\n编辑：wt\n归档：https://elasticsearch.cn/article/6158\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第461期 (2018-11-27)","uid":"3851","views":"238","votes":"0"},"_type":"doc"}
{"_id":"6161","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543460159","category_id":"18","comments":"0","has_attach":"0","id":"6161","message":"1.使用Canvas和Elasticsearch监控机场安全运营\nhttp://t.cn/ELp5dHT\n2.Lucene 内核解析之Point索引\nhttp://t.cn/ELptLV7\n3.部署安全插件searchguard\nhttp://t.cn/ELptMbj\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/6161\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第463期 (2018-11-29)","uid":"668","views":"208","votes":"0"},"_type":"doc"}
{"_id":"6166","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543739353","category_id":"14","comments":"9","has_attach":"1","id":"6166","message":"大家好，我是来自尚德机构ES平台的负责人，白凡，今天为大家分享一些在6.x版本中拼音分词高亮问题爬坑的心路历程~，其实问题不复杂，主要介绍下思路。\n\n首先简单讲下背景~可能在很多公司的很多部门，都有使用到ES。包括在尚德，由于很多部门的业务都涉及到ES，于是我们为了统一管理及维护，专门成立了ES平台部门，主要扮演的是类似于op dba角色，帮助业务部门部署维护ES集群，并根据业务需求提供解决方案。当然，除此之外，我们也会在公司内部推荐业务方去尝试除了日志和搜索以外的应用场景，比如分布式计算存储、监控、安全等方面。毕竟ES相比于其他组建，搭建部署更加方便，更轻量级，查询方式更丰富。所以，现如今在尚德机构，ES平台不仅用于了传统的日志和搜索领域，也在分布式数据存储和计算方面有很多应用。当然，这里只是为大家提供一些ES应用场景及其团队构建的思路。主要还是ES这个工具确实好用。\n\n广告先做到这，回到正文。所以，前段日子，我们接收了一个新的业务部门需求，大致是：他们之前使用的自己搭建ES 2.x集群，现在接入到我们6.x的平台上来。我们帮忙设计了mapping，数据写入及同步方案之后，数据就慢慢接入进来。但问题也随即出现，原来在2.x上使用正常的拼音高亮mapping，在6.x上只能检索但无法高亮了？\n\n2.x field如下：\n\u0026quot;index\u0026quot; : {\n\u0026quot;analysis\u0026quot; : {\n\u0026quot;analyzer\u0026quot; : {\n\u0026quot;pinyin_analyzer\u0026quot; : {\n\u0026quot;tokenizer\u0026quot; : \u0026quot;my_pinyin\u0026quot;\n}\n},\n\u0026quot;tokenizer\u0026quot; : {\n\u0026quot;my_pinyin\u0026quot; : {\n\u0026quot;type\u0026quot; : \u0026quot;pinyin\u0026quot;,\n\u0026quot;keep_full_pinyin\u0026quot; : false,\n\u0026quot;limit_first_letter_length\u0026quot; : 16,\n\u0026quot;lowercase\u0026quot; : true,\n\u0026quot;remove_duplicated_term\u0026quot;:true,\n\u0026quot;keep_first_letter\u0026quot;:true,\n\u0026quot;keep_separate_first_letter\u0026quot; :true\n}\n}\n}\n}\nPOST /medcl/doc/_mapping\n{\n\u0026quot;properties\u0026quot;: {\n\u0026quot;name\u0026quot;:{\n\u0026quot;analyzer\u0026quot;: \u0026quot;pinyin_analyzer\u0026quot;,\n\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n}\n}\n}\n\n可以从上面例子看出，这个analyzer并没有问题，但是在搜索时，能得到结果，却无法高亮，即分词结果中start_offset及end_offset为0，这个如何解决呢？\n\n回到medcl的拼音分词项目：\nhttps://github.com/medcl/elasticsearch-analysis-pinyin\n其中，有个配置项引起了我们的注意：\n\n[attach]3204[/attach]\n\n没跑了，应该是要将这个参数设置为false。\n并且查看了源码，在PinyinTokenizer这个类下面，看到了这一行：\n\n[attach]3205[/attach]\n\n确定了我们的思路，于是乎，在tokenizer中将此参数设为false，如下：\n\u0026quot;tokenizer\u0026quot; : {\n\u0026quot;my_pinyin\u0026quot; : {\n\u0026quot;type\u0026quot; : \u0026quot;pinyin\u0026quot;,\n\u0026quot;keep_full_pinyin\u0026quot; : true,\n\u0026quot;keep_original\u0026quot; : false,\n\u0026quot;limit_first_letter_length\u0026quot; : 16,\n\u0026quot;lowercase\u0026quot; : true,\n\u0026quot;remove_duplicated_term\u0026quot;:true,\n\u0026quot;ignore_pinyin_offset\u0026quot;: false,\n\u0026quot;keep_first_letter\u0026quot;:true,\n\u0026quot;keep_separate_first_letter\u0026quot; :true\n}\n}\n\n写入一条数据，高亮没问题了，问题“看似”解决了。\n当然，没有那么简单。因为在批量写入一部分数据后，总会报如下异常：\nstartOffset must be non-negative, and endOffset must be \u0026gt;= startOffset\n这个异常，导致数据无法写入集群。\n这里又是为什么呢？\n这个问题，我也搞了一段时间，始终没找到很好的解决方案，此处只能先@medcl。\n只是猜测在end()或者reset()方法内，需要lastOffset置0或者offsetAtt清空。但尝试了几次，依然报错。。。\n\n这就比较头疼了，不过好在条条道路通罗马。在某次蹲坑过程中，灵感如尿崩。\n\n如果Tokenizer解决不了，为何不仅用filter就行了呢？可以先用其他分词器，按我们业务的需求进行分词，再用filter，将分词过滤为拼音呢？\n\n大致思路如下：\n目前我们这个业务，需要如对于“尚德机构”这个词，搜索“shang”,“shangde”,“deji”时，能返回结果并高亮。\n所以我们先用ngram分词，将“尚德机构”这个词分为“尚”，“尚德”，“徳机”，“德机构”等等。。\n再用pinyin filter将各分词过滤为拼音，即“shang”,“shangde”,“deji”等。\n并在搜索时，采用standard分词。\nMapping如下：\n{\n\u0026quot;settings\u0026quot;: {\n\u0026quot;analysis\u0026quot;: {\n\u0026quot;analyzer\u0026quot;: {\n\u0026quot;pinyin_analyzer\u0026quot;: {\n\u0026quot;tokenizer\u0026quot;: \u0026quot;my_ngram\u0026quot;,\n\u0026quot;filter\u0026quot;: [\n\u0026quot;pinyin_filter\u0026quot;\n]\n}\n},\n\u0026quot;tokenizer\u0026quot;: {\n\u0026quot;my_ngram\u0026quot;: {\n\u0026quot;type\u0026quot;: \u0026quot;ngram\u0026quot;,\n\u0026quot;min_gram\u0026quot;: 1,\n\u0026quot;max_gram\u0026quot;: 50,\n\u0026quot;token_chars\u0026quot;: [\n\u0026quot;letter\u0026quot;,\n\u0026quot;digit\u0026quot;,\n\u0026quot;punctuation\u0026quot;,\n\u0026quot;symbol\u0026quot;\n]\n}\n},\n\u0026quot;filter\u0026quot;: {\n\u0026quot;pinyin_filter\u0026quot;: {\n\u0026quot;type\u0026quot;: \u0026quot;pinyin\u0026quot;,\n\u0026quot;keep_full_pinyin\u0026quot;: false,\n\u0026quot;keep_joined_full_pinyin\u0026quot;: true,\n\u0026quot;keep_none_chinese_in_joined_full_pinyin\u0026quot;: true,\n\u0026quot;none_chinese_pinyin_tokenize\u0026quot;: false,\n\u0026quot;remove_duplicated_term\u0026quot;: true\n}\n}\n}\n},\n\u0026quot;mappings\u0026quot;: {\n\u0026quot;abia321\u0026quot;: {\n\u0026quot;properties\u0026quot;: {\n\u0026quot;name\u0026quot;: {\n\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n\u0026quot;analyzer\u0026quot;: \u0026quot;pinyin_analyzer\u0026quot;,\n\u0026quot;search_analyzer\u0026quot;: \u0026quot;standard\u0026quot;,\n\u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;\n}\n}\n}\n}\n}\n最后，高亮问题解决，数据写入问题同样解决。\n当然有朋友肯定还会需要搜索拼音首字母进行搜索，如搜“s”,“sd”,“dj”,也返回结果。\n其实，只需要再专门设置个field，并调整pinyin filter参数，\n搜索时用bool查询，逻辑should查询，同时对完整拼音field和拼音首字母field进行搜索即可。\n在此就不做过多赘述。\n\n当然，这里仅仅只是提供一种ES在选择analyzer，tokenizer，filter解决需求的思路。拼音分词这个问题，还是需要等待后续修复\n\n最后，这里有较为完整的issue：\nhttps://github.com/medcl/elasticsearch-analysis-pinyin/issues/169","title":"Day 2 - ES 6.x拼音分词高亮爬坑记","uid":"10152","views":"571","votes":"1"},"_type":"doc"}
{"_id":"6170","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543891922","category_id":"18","comments":"0","has_attach":"0","id":"6170","message":"1、创建MySQL同Elasticsearch间的数据实时同步。\nhttp://t.cn/EyyWjcy\n2、详细介绍如何在kubernetes上构建EFK。\nhttp://t.cn/EyyTOef\n3、Laravel 使用 scout 集成 elasticsearch 做全文搜索。\nhttp://t.cn/EyyWr5o\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/publish/article/6170\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第468期 (2018-12-04)","uid":"3788","views":"189","votes":"0"},"_type":"doc"}
{"_id":"6171","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543927822","category_id":"14","comments":"2","has_attach":"1","id":"6171","message":"从2018年7月在开始在某阿里云数据中心部署Elasticsearch软件，到2018年12月共创建了15个集群，服务于客户的文档检索、交通视频检索、地理信息检索、日志安全审计等业务。其中数据规模最大的一个业务，共有800张表，7万亿条数据，每天新增500亿条记录，数据要求存储半年，单条记录大小1KB左右，存储规模约10PB，需要支持1000并发查询。\n\n\n\n一、数据存储空间规划。\n\n数据中心能用于搭建Elasticsearch集群的SSD盘共700TB，SATA盘共50PB。根据业务类型、时间范围划分热数据和冷数据，一部分重要数据存储在SSD盘的热数据集群，其它数据存储在SATA盘的冷数据集群。热数据集群主要存储各类实体信息，包括人员、物品、事件、地址、组织数据，以及最新轨迹数据。冷数据集群主要存储历史轨迹信息。热数据和冷数据按照业务拆分多个小集群，每个集群规模保持在50个节点左右，单个集群最大不超过200个节点。利用阿里云平台弹性伸缩的能力，每个Elasticsearch集群可以先从小规模创建，根据资源使用情况来弹性扩展节点规模。\n\nElasticsearch集群节点配置\n[attach]3219[/attach]\n\n\n\n二、索引设计。\n\n1.索引别名(alias)。每类数据根据数据源表名建立索引(index)，索引中只包含一个类型(type)。配置索引别名(alias),业务上根据别名写入、查询数据，索引重建等数据维护操作可以通过别名切换对业务透明。\n\n2.按时间分表。轨迹类数据按时间(日/月)拆分，每个索引存储数据量保持在1TB(10亿)左右，索引名带上日期/月份后缀，拆分后的索引配置别名区分冷热数据。配置索引模板，指定索引分片数和副本数、字段类型、分词器。配置Linux crontab定时任务，通过shell脚本创建索引。\n\n3.分片(shard)设置。索引按照单个分片10-40GB数据大小设计分片数，数据量少于10GB(1000万)的索引设置1个分片即可，数据量大于1TB(10亿)的索引设置分片数为集群节点数整数倍(例如50个节点的集群配置50个分片)。 \n\n4.副本(replica)设置。数据首次批量导入时索引副本数设置为0，快速写入数据。生产环境索引副本数设置为1，避免集群节点故障数据丢失。 \n\n\n\n三、索引mapping设计。\n\n1.精心设计索引字段类型。在开发环境配置Elasticsearch允许自动创建索引，从数据源每张表取1000条记录批量写入Elasticsearch，自动创建索引mapping，然后再根据业务需要修改mapping配置合适的字段类型，指定字段索引分词器、是否存储、是否索引、是否合并至全文检索字段。 对于数据量大的表尤其要精心设计字段类型，尽量减少索引存储空间占用。在生产环境中建议配置不允许自动创建索引。\n\n2.配置全文检索字段。如果业务需要全文检索，可以配置开启全文字段，同时需要占用更多存储空间；如果业务上只是按字段查询，可以配置禁用全文字段，减少存储空间。Elasticsearch5.X及之前的版本默认启用_all字段，合并所有字段的值。Elasticsearch6.X及之后的版本默认禁用_all字段，可以通过copy_to将多个字段值合并成一个全文字段。对于数据查全率要求高的业务场景，建议对全文字段配置cjk分词器(Elasticsearch和Lucene中自带，对中日韩文进行二元分词的分词器)。\n\n3.通用字段统一命名。各个索引中的姓名、证件号码、时间（开始时间、结束时间）、地点（始发地、目的地）等常用字段统一命名。用户指定证件号、时间范围等精确字段查询条件时，可以使用统一的查询条件并行查询多个索引。\n\n\n\n四、分词设置。\n\n1.选择合适的分词器。Elasticsearch中内置了很多分词器：standard、cjk、nGram等,也可以安装ik、pinyin等开源分词器, 可以根据业务场景选择合适的分词器。\n常用分词器：\nstandard：Elasticsearch默认分词，英文按空格切分，中文按单个汉字切分。\ncjk：根据二元索引（两个相邻的字作为一个词条）对中日韩文分词，可以保证查全率。\nNGram：可以将英文按照字母切分，结合Elasticsearch的短语搜索（match_phrase）使用。\nik：比较热门的中文分词，能按照中文语义切分，可以自定义词典。\npinyin：可以让用户输入拼音，就能查找到相关的关键词。\n对于查全率要求较高的场景，建议使用cjk分词，同时能支持比较快的响应速度。对于查准率要求较高的场景，建议使用ik分词。\n\nCJK分词和IK分词对比(测试环境：Elasticsearch5.5.3，8335万条人员档案信息，10节点集群，单节点16核CPU、64G内存、2T SSD盘，1个线程批量写入，1个并发查询)\n[attach]3220[/attach]\n\n测试分词效果：\ncurl -XPOST \u0026quot;http://localhost:9200/_analyze\u0026quot; -H 'Content-Type: application/json' -d'\n{\n  \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n  \u0026quot;text\u0026quot;:     \u0026quot;南京市长江大桥\u0026quot;\n}'\n\n2.NGram分词。对于像车牌号之类数字和字母连在一起的字符，默认会被切成一个完整词条，但是业务上又需要支持前缀、后缀模糊匹配，可以根据业务需求进行分词。车牌号建议增加一个分词字段，配置NGram分词器，切分1元至7元的组合。身份证号码建议增加分词字段，根据业务需要切分18位完整词条、前2位（省）、前4位（省市）、前6位（省市区县）、后4位、出生年月日、出生年份、出生年月、出生月日等组合。\n\n3.单字分词。对于像姓名类字段，业务上需要支持完整匹配，又需要支持单字查询。可以配置1个keyword字段（不分词）；1个text字段（分词），分词器选择Elasticsearch默认分词器standard，按单个汉字切分。\n\n\n\n\n五、数据写入策略。\n\n1.批量离线数据导入。各类业务数据源主要在数据仓库MaxCompute(原ODPS)，为了把表数据从MaxCompute表导入到ElasticSearch集群中， 我们基于MaxCompute MapReduce开发了MaxCompute到ElasticSearch的数据导出作业，通过简单的配置就可以把数据导入到ElasticSearch中。\n数据源在关系数据库RDS或者NoSQL的数据，可以通过配置DataWorks(dataX企业版)导入Elasticsearch集群。\n\n2.实时数据导入。实时数据源主要是流式数据服务DataHub，\n配置DataHub任务即可同步至Elasticsearch集群。也可以自己开发程序调用DataHub的SDK获取实时数据，经过业务处理后，调用ES Rest Client SDK批量写入Elasticsearch。\n\n3.冷热数据自动迁移。轨迹类实时数据默认先写入热数据集群(SSD盘Elasticsearch集群)，对于热数据集群过期的索引(例如1个月前的索引)需要迁移到冷数据集群(SATA盘Elasticsearch)。为了实现数据跨集群迁移，我们开发了snapshot插件将索引备份到对象存储服务OSS或分布式文件系统盘古。配置定时任务，将热数据集群索引备份后，从冷数据集群恢复，然后再删除热集群中的过期索引，保持热数据集群只存储较小规模数据。冷数据集群的索引如果超过半年，则关闭索引，减少JVM堆内存占用。\n\n4.配置索引主键字段。为了保证Elasticsearch集群和数据源记录的一致性，建议所有索引配置主键字段，而不是让Elasticsearch自动生成主键。配置数据业务主键字段作为Elasticsearch主键字段。如果没有主键字段，则将原始数据能确定记录惟一性的几个字段合并为主键，或者将所有字段值合并起来计算MD5值作为主键。\n\n5.配置写入路由。如果业务上需要经常根据某个字段查询，例如用户ID、车牌号等的字段，写入时可以指定路由字段。\n\n6.写入参数调优。调整数据写入任务参数，避免写入操作占用过多磁盘IO和CPU。使用批量请求，配置合理的写入线程数，调大索引刷新时间间隔refresh interval，调整事务日志translog同步策略。\n\n\n\n\n六、数据查询策略。\n\n1.冷热库异步查询。用户输入关键词查询时，优先从热数据集群查询，有结果立即返回，并估算命中记录条数。热数据集群命中结果集不足时，再查询冷数据集群。\n\n2.跨集群搜索。业务上需要多个Elasticsearch集群一起参与检索时，可以通过Cross Cluster Search同时对多个集群发起检索请求合并检索结果。单独创建一个5节点的Cross Cluster，设置远程集群节点信息，用于跨集群搜索，不存储业务数据。\n\n3.快速返回和超时设置。查询请求中设置参数teminate_after指定每个分片(shard)最多匹配N条记录后返回(例如10000)，设置查询超时时间timeout(例如10s)，避免查询一些宽泛的条件时耗费过多系统资源。\n\n4.查询语法解析。解析用户查询条件，识别用户的查询类型，例如用户输入车牌号、证件号、年龄段等条件时，查询条件改写为字段精确匹配，无法识别的查询条件默认从全文字段匹配。\n\n5.查询条件调优。查询结果不需要相关度排序时使用过滤器(filter),尽量使用路由(routing),设置较少的查询读取记录条数和字段,避免前缀模糊匹配,设置search_after规避深度翻页性能问题。\n\n\n\n七、数据写入、查询性能测试。\n\nSSD盘集群写入性能测试（测试环境：Elasticsearch6.3.2集群，单节点16核CPU、64G内存、2T SSD盘，写入10亿条记录，单条记录1KB，副本数为0，1台写入服务器）：\n[attach]3221[/attach]\n\nSSD盘集群查询性能测试\n[attach]3222[/attach]\n\nSATA盘集群写入性能测试（测试环境：Elasticsearch5.5.3集群，单节点56核CPU、128G内存、12块 6T SATA盘，分别写入1亿、3亿、5亿、30亿、300亿条记录，单条记录1KB，0副本，50台写入服务器）：\n[attach]3223[/attach]\n\nSATA盘集群查询性能测试\n[attach]3224[/attach]\n\n\n参考文档：\n1.\t阿里云Elasticsearch帮助文档 https://help.aliyun.com/product/57736.html\n2.\tElasticsearch参考\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/index.html \n3.\t《Elasticsearch: 权威指南》\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html\n4.\t《深入理解Elasticsearch》https://detail.tmall.com/item.htm?id=551001166567\n5.\t《死磕Elasticsearch方法论》https://blog.csdn.net/laoyang360/article/details/79293493\n6.\tElasticsearch索引别名和零停机\nhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/index-aliases.html\n7.\tElasticsearch自动按天创建索引脚本\nhttps://blog.csdn.net/reblue520/article/details/80553317\n8.\tElasticsearch NGram分词器\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenizer.html\n9.\tElasticsearch开源权限管理认证插件Search Guard\nhttps://github.com/floragunncom/search-guard\n10.\tElasticsearch开源可视化管理插件cerebro\nhttps://github.com/lmenezes/cerebro\n11.\tElasticsearch开源SQL插件 https://github.com/NLPchina/elasticsearch-sql\n12.\tElasticsearch快照及恢复 https://help.aliyun.com/document_detail/65675.html\n\nElasticsearch技术交流钉钉群\n[attach]3218[/attach]\n\n\n\n\n","title":"Day 4 - PB级规模数据的Elasticsearch分库分表实践","uid":"10530","views":"2011","votes":"5"},"_type":"doc"}
{"_id":"6176","_index":"forum-mysql","_score":1,"_source":{"addtime":"1544110818","category_id":"14","comments":"3","has_attach":"0","id":"6176","message":"Logstash 在 6.0 推出了 multiple pipeline 的解决方案，即在一个 logstash 实例中可以同时进行多个独立数据流程的处理工作，如下图所示。\n\n![](https://ws1.sinaimg.cn/large/6d3e3053gy1fxxe0myt06j20jw09omxr.jpg)\n\n而在这之前用户只能通过在单机运行多个 logstash 实例或者在配置文件中增加大量 if-else 条件判断语句来解决。要使用 multiple pipeline 也很简单，只需要将不同的 pipeline 在 `config/pipeline.yml`中定义好即可，如下所示：\n\n```yaml\n- pipeline.id: apache\n  pipeline.batch.size: 125\n  queue.type: persisted\n  path.config: \u0026quot;/path/to/config/apache.cfg\u0026quot;\n- pipeline.id: nginx\n  path.config: \u0026quot;/path/to/config/nginx.cfg\u0026quot;\n```\n\n其中 `apache`和`nginx`作为独立的 pipeline 执行，而且配置也可以独立设置，互不干扰。`pipeline.yml`的引入极大地简化了 logstash 的配置管理工作，使得新手也可以很快完成复杂的 ETL 配置。\n\n在 6.3 版本中，Logstash 又增加了 `Pipeline-to-Pipeline`的管道机制（beta），即管道和管道之间可以连接在一起组成一个完成的数据处理流。熟悉 linux 的管道命令 `|`的同学应该可以很快明白这种模式的好处。这无疑使得 Logstash 的配置会更加灵活，今天我们就来了解下这种灵活自由的配置方式。\n\n\n\n## 1. 上手\n\n废话少说，快速上手。修改 `config/pipeline.yml`文件如下：\n\n```yaml\n - pipeline.id: upstream\n   config.string: input { stdin {} } output { pipeline { send_to =\u0026gt; [test_output] } }\n - pipeline.id: downstream\n   config.string: input { pipeline { address =\u0026gt; test_output } } output{ stdout{}}\n```\n\n\n\n然后运行 logstash，其中 `-r` 表示配置文件有改动时自动重新加载，方便我们调试。 \n\n\u0026gt; bin/logstash -r\n\n在终端随意输入字符(比如`aaa`)后回车，会看到屏幕输出了类似下面的内容，代表运行成功了。\n\n```json\n{\n    \u0026quot;@timestamp\u0026quot; =\u0026gt; 2018-12-06T14:43:50.310Z,\n    \u0026quot;@version\u0026quot; =\u0026gt; \u0026quot;1\u0026quot;,\n    \u0026quot;message\u0026quot; =\u0026gt; \u0026quot;aaa\u0026quot;,\n    \u0026quot;host\u0026quot; =\u0026gt; \u0026quot;rockybean-MacBook-Pro.local\u0026quot;\n}\n```\n\n我们再回头看下这个配置，`upstream`output 使用了名为 `pipeline` 的 plugin，然后  `send_to`的输出对象`test_output`是在 `downstream`的  `input pipeline plugin` 中定义的。通过这个唯一的`address`(虚拟地址)就能够把不同的 `pipeline` 连接在一起组成一个更长的`pipeline`来处理数据。类似下图所示：\n\n![](https://ws1.sinaimg.cn/large/6d3e3053gy1fxxyu8psraj20xe0wijy9.jpg)\n\n\n\n当数据由 `upstream`传递给 `downstream`时会进行一个复制操作，这也意味着在这两个 pipeline 中的数据是完全独立的，互不影响。有一点要注意的是：数据的复制会增加额外的性能开销，比如会加大 JVM Heap 的使用。\n\n## 2. 使用场景\n\n使用方法是不是很简单，接下来我们来看下官方为我们开的几个脑洞。\n\n### 2.1 Distributor Pattern 分发者模式\n\n该模式执行效果类似下图所示：\n\n![](https://ws1.sinaimg.cn/large/6d3e3053gy1fxxfiryb6ej20s00mqdl1.jpg)\n\n在一个 pipeline 处理输入，然后根据不同的数据类型再分发到对应的 Pipeline 去处理。这种模式的好处在于统一输入端口，隔离不同类型的处理配置文件，减少由于配置文件混合在一起带来的维护成本。大家可以想一想如果不用这种`Pipeline-to-Pipeline`的方式，我们如果轻松做到一个端口处理多个来源的数据呢？\n\n这种模式的参考配置如下所示：\n\n```yaml\n# config/pipelines.yml\n- pipeline.id: beats-server\n  config.string: |\n    input { beats { port =\u0026gt; 5044 } }\n    output {\n        if [type] == apache {\n          pipeline { send_to =\u0026gt; weblogs }\n        } else if [type] == system {\n          pipeline { send_to =\u0026gt; syslog }\n        } else {\n          pipeline { send_to =\u0026gt; fallback }\n        }\n    }\n- pipeline.id: weblog-processing\n  config.string: |\n    input { pipeline { address =\u0026gt; weblogs } }\n    filter {\n       # Weblog filter statements here...\n    }\n    output {\n      elasticsearch { hosts =\u0026gt; [es_cluster_a_host] }\n    }\n- pipeline.id: syslog-processing\n  config.string: |\n    input { pipeline { address =\u0026gt; syslog } }\n    filter {\n       # Syslog filter statements here...\n    }\n    output {\n      elasticsearch { hosts =\u0026gt; [es_cluster_b_host] }\n    }\n- pipeline.id: fallback-processing\n    config.string: |\n    input { pipeline { address =\u0026gt; fallback } }\n    output { elasticsearch { hosts =\u0026gt; [es_cluster_b_host] } }\n```\n\n\n\n### 2.2 Output Isolator Pattern 输出隔离模式\n\n虽然 Logstash 的一个 pipeline 可以配置多个 output，但是这多个 output 会相依为命，一旦某一个 output 出问题，会导致另一个 output 也无法接收新数据。而通过这种模式可以完美解决这个问题。其运行方式如下图所示：\n\n![](https://ws1.sinaimg.cn/large/6d3e3053gy1fxxfvj14mhj20ne0mi78p.jpg)\n\n通过输出到两个独立的 pipeline，解除相互之间的影响，比如 http service 出问题的时候，es 依然可以正常接收数据，而且两个 pipeline 可以配置独立的队列来保障数据的完备性，其配置如下所示：\n\n```yaml\n# config/pipelines.yml\n- pipeline.id: intake\n  queue.type: persisted\n  config.string: |\n    input { beats { port =\u0026gt; 5044 } }\n    output { pipeline { send_to =\u0026gt; [es, http] } }\n- pipeline.id: buffered-es\n  queue.type: persisted\n  config.string: |\n    input { pipeline { address =\u0026gt; es } }\n    output { elasticsearch { } }\n- pipeline.id: buffered-http\n  queue.type: persisted\n  config.string: |\n    input { pipeline { address =\u0026gt; http } }\n    output { http { } }\n```\n\n### 2.3 Forked Path Pattern 克隆路径模式\n\n这个模式类似 Output Isolator Pattern，只是在不同的 output pipeline 中可以配置不同的 filter 来完成各自输出的数据处理需求，这里就不展开讲了，可以参考如下的配置，其中不同 output pipeline 的 filter 是不同的，比如 partner 这个 pipeline 去掉了一些敏感数据：\n\n```\n# config/pipelines.yml\n- pipeline.id: intake\n  queue.type: persisted\n  config.string: |\n    input { beats { port =\u0026gt; 5044 } }\n    output { pipeline { send_to =\u0026gt; [\u0026quot;internal-es\u0026quot;, \u0026quot;partner-s3\u0026quot;] } }\n- pipeline.id: buffered-es\n  queue.type: persisted\n  config.string: |\n    input { pipeline { address =\u0026gt; \u0026quot;internal-es\u0026quot; } }\n    # Index the full event\n    output { elasticsearch { } }\n- pipeline.id: partner\n  queue.type: persisted\n  config.string: |\n    input { pipeline { address =\u0026gt; \u0026quot;partner-s3\u0026quot; } }\n    filter {\n      # Remove the sensitive data\n      mutate { remove_field =\u0026gt; 'sensitive-data' }\n    }\n    output { s3 { } } # Output to partner's bucket\n```\n\n### 2.4 Collector Pattern 收集者模式\n\n从名字可以看出，该模式是将所有 Pipeline 汇集于一处的处理模式，如下图所示：\n\n![](https://ws1.sinaimg.cn/large/6d3e3053gy1fxxg8e2ilyj20kg0lc41y.jpg)\n\n其配置参考如下：\n\n```\n# config/pipelines.yml\n- pipeline.id: beats\n  config.string: |\n    input { beats { port =\u0026gt; 5044 } }\n    output { pipeline { send_to =\u0026gt; [commonOut] } }\n- pipeline.id: kafka\n  config.string: |\n    input { kafka { ... } }\n    output { pipeline { send_to =\u0026gt; [commonOut] } }\n- pipeline.id: partner\n  # This common pipeline enforces the same logic whether data comes from Kafka or Beats\n  config.string: |\n    input { pipeline { address =\u0026gt; commonOut } }\n    filter {\n      # Always remove sensitive data from all input sources\n      mutate { remove_field =\u0026gt; 'sensitive-data' }\n    }\n    output { elasticsearch { } }\n```\n\n\n\n## 3. 总结\n\n本文简单给大家讲解了 `Pipeline-to-Pipeline`的使用方法及官方推荐的几种模式，希望可以给大家有所帮助。另外这个机制目前还处于 Beta 阶段，尝鲜需谨慎！\n\n","title":"Day 6 - Logstash Pipeline-to-Pipeline 尝鲜","uid":"86","views":"427","votes":"5"},"_type":"doc"}
{"_id":"6154","_index":"forum-mysql","_score":1,"_source":{"addtime":"1543023027","category_id":"18","comments":"0","has_attach":"0","id":"6154","message":"1. ES结合深度学习提升查找相似文档的效率。\n[http://t.cn/ELhMvpM](http://t.cn/ELhMvpM) \n\n2. Elasticsearch在物流数据中心的应用。\n[http://t.cn/E2ky75a](http://t.cn/E2ky75a) \n\n3. 国产好片推荐：《无名之辈》。\n[http://t.cn/E2zSj92](http://t.cn/E2zSj92) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/6154\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第458期 (2018-11-24）","uid":"1874","views":"206","votes":"0"},"_type":"doc"}
{"_id":"6152","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542902541","category_id":"2","comments":"3","has_attach":"0","id":"6152","message":"## 一、准备安装\n### 1、修改系统 hosts\n```\nvi /etc/hosts   # 修改 hosts 文件，添加下面的内容\n\n192.168.11.1    sky-00\n192.168.11.2    sky-01\n192.168.11.3    sky-02\n192.168.11.4    sky-03\n192.168.11.5    sky-04\n192.168.11.6    sky-05\n192.168.11.7    sky-06\n```\n\n### 2、角色分配\n主机名 | 角色 | 内存分配\n---|---|---\nsky-00|Master|4G\nsky-01|Master|8G\nsky-02|Master+Data|12G\nsky-03|Data|12G\nsky-04|Data|12G\nsky-05|Data|12G\nsky-06|Data|12G\n\n### 3、创建 ES 用户\n```shell\nadduser elastic  # 新增用户\npasswd elastic   # 修改用户密码\n```\n\n### 4、创建 ES 数据和日志目录\n```\ncd /data/\nmkdir elastic\ncd elastic\nmkdir data      # 创建数据目录\nmkdir log       # 创建日志目录\nchown -R elastic /data/elastic/  # 修改拥有着\n```\n\n### 5、调整文件句柄数以及可用进程数\nElasticsearch 要求其可用的文件句柄至少为 65536，同时要求其进程数限制至少为 2048，可用按照下面的指令进行修改。\n\n分别对应以下两个报错信息：\n- max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]\n- max number of threads [1024] for user [es] is too low, increase to at least [2048]\n\n```shell\nvi /etc/security/limits.conf\n\n*     soft   nofile  100001\n*     hard   nofile  100002\n*     soft   nproc   4096\n*     hard   nproc   8192\nelastic soft memlock unlimited\nelastic hard memlock unlimited\n```\n\n### 6、设置内核交换\n为了避免不必要的磁盘和内存交换，影响效率，需要将 `vm.swappiness` 修改为 1（进行最少量的交换，而不禁用交换）或者 10（当系统存在足够内存时，推荐设置为该值以提高性能），其默认值为 60。\n\n此外需要修改最大虚拟内存 `vm.max_map_count` 防止启动时报错：`max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]`。\n\n```shell\nvi /etc/sysctl.conf\n\nvm.swappiness = 1\nvm.max_map_count = 262144\n```\n\n### 7、下载安装文件\n```shell\nmkdir /opt/downloads/\nmkdir /opt/soft/\ncd /opt/downloads/\n\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.1.tar.gz\nwget https://artifacts.elastic.co/downloads/kibana/kibana-6.5.1-linux-x86_64.tar.gz\nwget http://download.oracle.com/otn/java/jdk/xxxxxx/jdk-8u191-linux-x64.tar.gz\n\ntar -zxvf elasticsearch-6.5.1.tar.gz -C /opt/soft/\ntar -zxvf jdk-8u191-linux-x64.tar.gz -C /opt/soft/\ntar -zxvf kibana-6.5.1-linux-x86_64.tar.gz -C /opt/soft/\n\nchown -R elastic /opt/soft/elasticsearch-6.5.1/\nchown -R elastic /opt/soft/kibana-6.5.1/\n```\n\n## 二、开始安装\n### 1、配置 Java 环境\n```\nsu elastic             #切换到 elastic 用户\nvi ~/.bashrc          #只修改 elastic 用户自己的环境变量\n\nexport JAVA_HOME=/opt/soft/jdk1.8.0_191\nexport JRE_HOME=/opt/soft/jdk1.8.0_191/jre\nexport CLASSPATH=.:/opt/soft/jdk1.8.0_191/lib:/opt/soft/jdk1.8.0_191/jre/lib\nexport PATH=$PATH:/opt/soft/jdk1.8.0_191/bin:/opt/soft/jdk1.8.0_191/jre/bin\n```\n\n### 2、配置 ES 内存占用\n```\ncd /opt/soft/elasticsearch-6.5.1/config/\nvi jvm.options \n\n-Xms4g      # 请根据自己机器配置调整\n-Xmx4g\n```\n\n### 3、配置 Elasticsearch\n下面的配置已经过多个生产环境验证，具体设置值仅供参考，请务必根据实际情况进行调整。\n\n```\n# ---------------------------------- Cluster -----------------------------------\n#\n# 设置集群名\ncluster.name: cluster-name\n#\n# ------------------------------------ Node ------------------------------------\n#\n# 设置节点名\nnode.name: node01\n\n# 设置角色\nnode.master: true   \nnode.data: false\nnode.ingest: true\n\n# 设置机架信息\n#node.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# 设置数据路径\npath.data: /data/elastic/data\n\n# 设置日志路径\npath.logs: /data/elastic/log\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# 设置内存锁定\nbootstrap.memory_lock: true\nbootstrap.system_call_filter: false\n#\n# ---------------------------------- Network -----------------------------------\n#\n# 设置ip和端口\nnetwork.bind_host: sky-00\nnetwork.publish_host: 0.0.0.0\nhttp.port: 9200\n\n# 设置跨域访问\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \u0026quot;*\u0026quot;\nhttp.max_content_length: 500mb\n\n# --------------------------------- Discovery ----------------------------------\n\n# 设置zen发现范围（只需要填写主节点的 ip 即可）\ndiscovery.zen.ping.unicast.hosts: [\u0026quot;sky-00\u0026quot;, \u0026quot;sky-01\u0026quot;, \u0026quot;sky-02\u0026quot;]\n\ndiscovery.zen.no_master_block: write\ndiscovery.zen.fd.ping_timeout: 10s\n\n# 设置最小主节点个数，一般为：(master_node_count+1)/2\ndiscovery.zen.minimum_master_nodes: 2\n\n\n# ---------------------------------- Gateway -----------------------------------\n#\n# 设置在有4个节点后进行数据恢复\ngateway.recover_after_nodes: 4\ngateway.expected_nodes: 7\ngateway.recover_after_time: 1m\n#\n# ---------------------------------- Various -----------------------------------\n# 禁止通配符模式删除索引\naction.destructive_requires_name: true\n\nindices.recovery.max_bytes_per_sec: 200mb\nindices.memory.index_buffer_size: 20%\n\n# 默认开启全部类型脚本，可以通过下面配置进行限制\n#script.allowed_types: inline\n#script.allowed_contexts: search, update\n\n# 关闭xpack的安全校验\nxpack.security.enabled: false\n\n# 开启 monitoring\nxpack.monitoring.enabled: true\nxpack.monitoring.collection.enabled: true\n\n# 设置 monitoring 写入信息\nxpack.monitoring.exporters:\n  sky:\n    type: http\n    host: [\u0026quot;sky-02\u0026quot;, \u0026quot;sky-03\u0026quot;, \u0026quot;sky-04\u0026quot;, \u0026quot;sky-05\u0026quot;, \u0026quot;sky-06\u0026quot;]\n    # 设置 monitoring 索引格式，默认是 YYYY-MM-DD（按天新建）\n    index.name.time_format: YYYY-MM\n    headers:\n      # 设置 Basic 认证信息（详见插件安装部分说明）\n      Authorization: \u0026quot;Basic XXXXXXXXXXXXXXX\u0026quot;\n```\n\n## 三、安装插件\n### 1、安装插件\n推荐安装的插件有：\n- IK 中文分词插件\n- Readonlyrest 安全认证插件\n- elasticsearch-head 集群监控管理插件（chrome 插件）\n\n\u0026gt; 插件下载链接: https://pan.baidu.com/s/1r_322unsIjoWlhY8u7pkBA 提取码: aupq \n\n使用下面命令即可安装。\n```\n$ES_HOME/bin/elasticsearch-plugin -install file:///data/downloads/elasticsearch-analysis-ik-6.5.1.zip\n$ES_HOME/bin/elasticsearch-plugin -install file:///data/downloads/readonlyrest-1.16.29_es6.5.1.zip\n```\n\n### 2、配置 Readonlyrest 安全认证\n下面只简单介绍 Readonlyrest 的 Basic 认证，更高级的用法可以去官方网站查看，在 ES 安装目录的 conf 目录下新建文件 `readonlyrest.yml`，并添加下面内容。\n```\nreadonlyrest:\n    access_control_rules:\n    - name: \u0026quot;Require HTTP Basic Auth\u0026quot;\n      type: allow\n      auth_key: 用户名:密码\n```\n\n### 3、启动 ES\n全部安装完成后，即可使用 elastic 用户启动 ES。\n```\n# 默认 ES 不支持 root 用户启动\nsu elastic\ncd /opt/soft/elasticsearch-6.5.1/bin\n./elasticsearch -d\n```\n\n## 四、在 Kibana 里面监控\n在安装 ES 的时候，我们配置了 ES 的监控信息，这样我们就可以在 Kibana 中查看 ES 索引信息、node 信息等。\n\n### 1、配置 Kibana\n进入 Kibana 的解压目录下的 conf 文件夹，打开配置文件 `kibana.yml`。\n```\n# 配置 kibana ui 的端口\nserver.port: 5601\n\n# 配置 kibana 访问 ip\nserver.host: \u0026quot;0.0.0.0\u0026quot;\n\n# 设置 ES 地址\nelasticsearch.url: \u0026quot;http://sky-00:9200\u0026quot;\n\n# dashboards. Kibana creates a new index if the index doesn't already exist.\n#kibana.index: \u0026quot;.kibana\u0026quot;\n\n# 打开 kibana 时默认页面\n#kibana.defaultAppId: \u0026quot;home\u0026quot;\n\n# ES Basic 认证信息\nelasticsearch.username: \u0026quot;用户名\u0026quot;\nelasticsearch.password: \u0026quot;密码\u0026quot;\n\n# 设置时区信息\n#i18n.locale: \u0026quot;en\u0026quot;\n\n# 开启监控\nxpack.monitoring.enabled: true\n\n# 关闭 kibana 监控，默认为 true\nxpack.monitoring.kibana.collection.enabled: false\n```\n\n### 2、对 Kibana 配置文件的说明\n- ES Basic 认证信息配置（在启动时对 Kibana 索引进行维护）完成后，登陆 kibana 时，依旧需要输入认证信息；\n- 由于 kibana 的 monitoring 无法设置新建的索引的索引名（无法配置 index.name.time_format），这样 kibana 每天会新建一个索引，由于 kibana 只是作为管理查看工具，因此关闭了 kibana 监控；\n- `elasticsearch.url` 该配置项无法设置多个 es 地址；如果你想实现类似负载均衡的功能，最简单的方法就是在 Kibana 机器上运行一个协调（Coordinating）节点。\n\n### 3、监控界面\n全部配置完成后，启动 kibana，打开 monitoring 即可开始监控 node、index 等。\n\n![使用 Kibana 监控节点状态](http://img.luooqi.com/FmmRM-BWiizWOZ3v1YwEC4J5V9RJ)\n\n## 五、设置索引模板\n具体请参考之前发布的文章[基于 IK 分词器的 ES 通用索引模板](https://juejin.im/post/5bed17daf265da614e2ba73e)\n\n\n---\n`Any Code，Code Any！`\n\n扫码关注『AnyCode』，编程路上，一起前行。\n\n![](https://user-gold-cdn.xitu.io/2018/10/14/16672d99876e4363?w=258\u0026amp;h=258\u0026amp;f=png\u0026amp;s=45449)","title":"CentOS 7.4 下安装 ES 6.5.1 搜索集群","uid":"8031","views":"787","votes":"1"},"_type":"doc"}
{"_id":"6146","_index":"forum-mysql","_score":1,"_source":{"addtime":"1542603098","category_id":"18","comments":"0","has_attach":"0","id":"6146","message":"1. 使用elasticsearch来分析北京租房数据\nhttp://t.cn/E2aQmeA\n2. 如何租到靠谱的房子？Scrapy爬虫帮你一网打尽各平台租房信息！\nhttp://t.cn/E2a8AoX\n3. 理解elasticsearch的parent-child关系\nhttp://t.cn/E2a89kd\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6146\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第453期 (2018-11-19)","uid":"4063","views":"192","votes":"0"},"_type":"doc"}
{"_id":"56","_index":"forum-mysql","_score":1,"_source":{"addtime":"1453384575","category_id":"2","comments":"0","has_attach":"0","id":"56","message":"RT\nhttps://qbox.io/blog/author/sloan-ahrens","title":"推荐一个ES做机器学习的blog，我觉得非常的酷","uid":"744","views":"3850","votes":"0"},"_type":"doc"}
{"_id":"58","_index":"forum-mysql","_score":1,"_source":{"addtime":"1456042765","category_id":"2","comments":"4","has_attach":"0","id":"58","message":"我新写了一个用 SQL 查询 Elasticsearch 的工具 [url]https://github.com/taowen/es-monitor[/url]，欢迎大家使用。详细的文档参见：[url]https://segmentfault.com/a/1190000003502849[/url]\n \n在此之前，有这么三个SQL查询Elasticsearch的工具：\n[list]\n[*]Crate.io[/*]\n[*][url]http://sqltoelasticsearch.fr/[/url][/*]\n[*][url]https://github.com/NLPchina/elasticsearch-sql[/url][/*]\n[/list]\n \nCrate.io 的问题是它不是Elasticsearch，它的聚合是自己实现的版本，和Elasticsearch的Aggregation是两套东西。\nhttp://sqltoelasticsearch.fr/ 语法支持很不晚上，同时 WHERE 和 GROUP BY 就翻译错了。\nhttps://github.com/NLPchina/elasticsearch-sql 的问题在于其用Java来翻译SQL太笨拙了，如果要达到同样的SQL语法支持程度还要增加大量的Java代码。\n如果只是支持SQL，很多Elasticsearch的功能是无法被充分释放的。比如Elasticsearch支持sub aggregation，每个sub aggregation就是OLAP里的下钻一次的概念。而且每下钻一次都可以有自己的指标计算。简单的SQL是无法表达这样的特性的。所以我扩充了一下SQL的语义，使得其更贴近Elasticsearch聚合的工作方式：\n [code]$ cat \u0026lt;\u0026lt; EOF | ./es_query.py http://127.0.0.1:9200 \n    WITH SELECT MAX(market_cap) AS max_all_times FROM symbol AS all_symbols; \n    WITH SELECT MAX(market_cap) AS max_at_2000 FROM all_symbols WHERE ipo_year=2000 AS year_2000; \n    WITH SELECT MAX(market_cap) AS max_at_2001 FROM all_symbols WHERE ipo_year=2001 AS year_2001;\nEOF[/code]希望我的小工具可以帮到你\n ","title":"使用 SQL 查询 Elasticsearch","uid":"908","views":"11985","votes":"6"},"_type":"doc"}
{"_id":"61","_index":"forum-mysql","_score":1,"_source":{"addtime":"1458787814","category_id":"5","comments":"2","has_attach":"0","id":"61","message":"线上交流不过瘾？那就参加线下交流活动吧！\n这里是搜罗的最新的线下交流活动预告：\n[list]\n[*]广州：[url]http://www.meetup.com/guangzhou-Elastic-Meetup/[/url] [/*]\n[*]上海：[url]http://www.meetup.com/shanghai-Elastic-Meetup/[/url][/*]\n[*]北京：[url]http://www.meetup.com/beijing-Elastic-Meetup/[/url][/*]\n[/list]\n \n大家分别找到组织报名参加吧，貌似有些还需要场地支持，大家一起出谋划策，把活动办起来吧。","title":"Elastic线下交流活动走起来！","uid":"1","views":"2717","votes":"1"},"_type":"doc"}
{"_id":"63","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459179042","category_id":"2","comments":"6","has_attach":"0","id":"63","message":"前言\n\n在了解jest框架前，楼主一直尝试用官方的Elasticsearch java api连接es服务的，可是，不知何故，一直报如下的异常信息，谷歌了很久，都说是jvm版本不一致导致的问题，可我是本地测试的，jvm肯定是一致的，这个问题现在都木有解决，but，这怎么能阻止我探索es的脚步呢，so，让我发现了jest 这个框架   \n\n\norg.elasticsearch.transport.RemoteTransportException: Failed to deserialize exception response from stream Caused by: org.elasticsearch.transport.TransportSerializationException: Failed to deserialize exception response from stream\n我的测试代码是参考官方api实例的，官方api地址：Elasticsearch java api,代码如下：\n\n\n\nClient client = new TransportClient().addTransportAddress(new InetSocketTransportAddress(\u0026quot;127.0.0.1\u0026quot;, 9300)); QueryBuilder queryBuilder = QueryBuilders.termQuery(\u0026quot;content\u0026quot;, \u0026quot;搜\u0026quot;); SearchResponse searchResponse = client.prepareSearch(\u0026quot;indexdata\u0026quot;).setTypes(\u0026quot;fulltext\u0026quot;) .setQuery(queryBuilder) .execute() .actionGet(); SearchHits hits = searchResponse.getHits(); System.out.println(\u0026quot;查询到记录数:\u0026quot; + hits.getTotalHits()); SearchHit[] searchHists = hits.getHits(); for(SearchHit sh : searchHists){ System.out.println(\u0026quot;content:\u0026quot;+sh.getSource().get(\u0026quot;content\u0026quot;)); } client.close();\n如果有人知道怎么回事，告诉一下楼主吧，让楼主坑的明白，感激不尽了，我的es版本是2.2.0\n\n\n进入正题\n\n了解jest\n\njest是一个基于 HTTP Rest 的连接es服务的api工具集，功能强大，能够使用es java api的查询语句，项目是开源的，github地址：https://github.com/searchbox-io/Jest\n\n\n\n\n我的测试用例\n\n分词器：ik，分词器地址：https://github.com/medcl/elasticsearch-analysis-ik ，es的很多功能都是基于插件提供的，es版本升级都2.2.0后，安装插件的方式不一样了，如果你安装ik分词插件有问题，请点击右上角的qq联系博主\n\n新建索引\n\ncurl -XPUT http://localhost:9200/indexdata\n\n\n创建索引的mapping，指定分词器\n\ncurl -XPOST http://localhost:9200/indexdata/fulltext/_mapping\n\n{\n  \u0026quot;fulltext\u0026quot;: {\n    \u0026quot;_all\u0026quot;: {\n      \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n      \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n      \u0026quot;term_vector\u0026quot;: \u0026quot;no\u0026quot;,\n      \u0026quot;store\u0026quot;: \u0026quot;false\u0026quot;\n    },\n    \u0026quot;properties\u0026quot;: {\n      \u0026quot;content\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n        \u0026quot;store\u0026quot;: \u0026quot;no\u0026quot;,\n        \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n        \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;include_in_all\u0026quot;: \u0026quot;true\u0026quot;,\n        \u0026quot;boost\u0026quot;: 8\n      },\n      \u0026quot;description\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n        \u0026quot;store\u0026quot;: \u0026quot;no\u0026quot;,\n        \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n        \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;include_in_all\u0026quot;: \u0026quot;true\u0026quot;,\n        \u0026quot;boost\u0026quot;: 8\n      },\n      \u0026quot;title\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n        \u0026quot;store\u0026quot;: \u0026quot;no\u0026quot;,\n        \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n        \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;include_in_all\u0026quot;: \u0026quot;true\u0026quot;,\n        \u0026quot;boost\u0026quot;: 8\n      },\n      \u0026quot;keyword\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n        \u0026quot;store\u0026quot;: \u0026quot;no\u0026quot;,\n        \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n        \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n        \u0026quot;include_in_all\u0026quot;: \u0026quot;true\u0026quot;,\n        \u0026quot;boost\u0026quot;: 8\n      }\n    }\n  }\n}\n\nmapping信息可以用head插件查看，如下\n\n\n导入数据和查询，看代码吧\n\n\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(classes = ElasticSearchTestApplication.class) public class JestTestApplicationTests { @Autowired private KlarticleDao klarticleDao; //得到JestClient实例 public JestClient getClient()throws Exception{ JestClientFactory factory = new JestClientFactory(); factory.setHttpClientConfig(new HttpClientConfig .Builder(\u0026quot;http://127.0.0.1:9200\u0026quot;) .multiThreaded(true) .build()); return factory.getObject(); } /** * 导入数据库数据到es * @throws Exception */ @Test public void contextLoads() throws Exception{ JestClient client=getClient(); Listlists=klarticleDao.findAll(); for(Klarticle k:lists){ Index index = new Index.Builder(k).index(\u0026quot;indexdata\u0026quot;).type(\u0026quot;fulltext\u0026quot;).id(k.getArcid()+\u0026quot;\u0026quot;).build(); System.out.println(\u0026quot;添加索引----》\u0026quot;+k.getTitle()); client.execute(index); } //批量新增的方式,效率更高 Bulk.Builder bulkBuilder = new Bulk.Builder(); for(Klarticle k:lists){ Index index = new Index.Builder(k).index(\u0026quot;indexdata\u0026quot;).type(\u0026quot;fulltext\u0026quot;).id(k.getArcid()+\u0026quot;\u0026quot;).build(); bulkBuilder.addAction(index); } client.execute(bulkBuilder.build()); client.shutdownClient(); } //搜索测试 @Test public void JestSearchTest()throws Exception{ SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\u0026quot;content\u0026quot;, \u0026quot;搜索\u0026quot;)); Search search = new Search.Builder(searchSourceBuilder.toString()) // multiple index or types can be added. .addIndex(\u0026quot;indexdata\u0026quot;) .build(); JestClient client =getClient(); SearchResult result= client.execute(search); // List\u0026gt; hits = result.getHits(Klarticle.class); Listarticles = result.getSourceAsObjectList(Klarticle.class); for(Klarticle k:articles){ System.out.println(\u0026quot;-------\u0026gt;：\u0026quot;+k.getTitle()); } } }下面是依赖的jar，maven项目\u0026lt;!--jest依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.searchbox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jest\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--jest 日志依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.elasticsearch\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elasticsearch\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;\n去我的博客查看原文：[url]http://www.kailing.pub/article/index/arcid/84.html[/url]","title":"java使用HTTP Rest client 客户端Jest连接操作es，功能很强大","uid":"1032","views":"19116","votes":"0"},"_type":"doc"}
{"_id":"64","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459264222","category_id":"2","comments":"1","has_attach":"1","id":"64","message":"[b]前言[/b]\r\n为了测试es的完美功能，笔者使用爬虫爬取了Elastic中文社区和CSDN的大量数据，作为测试之用，下面简单介绍一下折腾的过程\r\n[b]认识 WebCollector[/b]\r\nWebCollector是一个无须配置、便于二次开发的JAVA爬虫框架（内核），它提供精简的的API，只需少量代码即可实现一个功能强大的爬虫。WebCollector-Hadoop是WebCollector的Hadoop版本，支持分布式爬取。\r\nWebCollector致力于维护一个稳定、可扩的爬虫内核，便于开发者进行灵活的二次开发。内核具有很强的扩展性，用户可以在内核基础上开发自己想要的爬虫。源码中集成了Jsoup，可进行精准的网页解析。2.x版本中集成了selenium，可以处理javascript生成的数据。\r\n官网地址：[url]http://crawlscript.github.io/WebCollector/[/url]\r\n[b]使用步骤[/b]\r\n导入jar依赖，笔者是maven项目，所有加入如下pom.xml依赖\r\nps:笔者这里是使用的最新版的，maven仓库目前最新版的是2.09，所以使用最新的就自己下载打包吧 \r\n环境有了后，直接新建一个类继承BreadthCrawler类重新​visit方法，你的处理逻辑都在visit方法里面，下面楼主贴下我的代码\r\n[b]​爬取Elastic中文社区资源[/b]\r\n[code]/**\r\n * Created by 小陈 on 2016/3/29.\r\n */\r\n@Component\r\npublic class ElasticCrawler extends BreadthCrawler {\r\n    @Autowired\r\n     IpaDao ipaDao;\r\n    public ElasticCrawler() {\r\n        super(\u0026quot;crawl\u0026quot;, true);\r\n        /*start page*/\r\n        this.addSeed(\u0026quot;xxx\u0026quot;);\r\n        /*fetch url like http://news.hfut.edu.cn/show-xxxxxxhtml*/\r\n        this.addRegex(\u0026quot;xxx\u0026quot;);\r\n        /*do not fetch jpg|png|gif*/\r\n        this.addRegex(\u0026quot;-.*\\\\.(jpg|png|gif).*\u0026quot;);\r\n        /*do not fetch url contains #*/\r\n//        this.addRegex(\u0026quot;-.*#.*\u0026quot;);\r\n    }\r\n    @Override\r\n    public void visit(Page page, CrawlDatums next) {\r\n        String url = page.getUrl();\r\n        String content=\u0026quot;\u0026quot;;\r\n        try {\r\n             content = ContentExtractor.getContentByUrl(url);\r\n        }catch (Exception e){\r\n            e.printStackTrace();\r\n        }\r\n          /*抽取标题*/\r\n        String title=page.getDoc().title();\r\n        System.out.println(\u0026quot;--------------------\u0026gt;\u0026quot;+title);\r\n        if(!title.isEmpty() \u0026amp;\u0026amp; ! content.isEmpty()){\r\n                Pa pa=new Pa(title,content);\r\n               ipaDao.save(pa);//持久化到数据库\r\n            }\r\n    }[/code][b]爬取CSDN资源[/b]\r\n[code]/**\r\n * @author kl by 2016/3/29\r\n * @boke www.kailing.pub\r\n */\r\n@Component\r\npublic class CSDNCrawler extends BreadthCrawler {\r\n    @Autowired\r\n    IpaDao ipaDao;\r\n    public CSDNCrawler() {\r\n        super(\u0026quot;crawl\u0026quot;, true);\r\n        /*start page*/\r\n        this.addSeed(\u0026quot;http://blog.csdn.net/.*\u0026quot;);//添加种子地址\r\n        /*fetch url like http://news.hfut.edu.cn/show-xxxxxxhtml*/\r\n        this.addRegex(\u0026quot;http://blog.csdn.net/.*/article/details/.*\u0026quot;);\r\n        /*do not fetch jpg|png|gif*/\r\n        this.addRegex(\u0026quot;-.*\\\\.(jpg|png|gif).*\u0026quot;);\r\n        /*do not fetch url contains #*/\r\n//        this.addRegex(\u0026quot;-.*#.*\u0026quot;);\r\n    }\r\n    @Override\r\n    public void visit(Page page, CrawlDatums next) {\r\n        String url = page.getUrl();\r\n        String content=\u0026quot;\u0026quot;;\r\n        try {\r\n            content = ContentExtractor.getContentByUrl(url);\r\n        }catch (Exception e){\r\n            e.printStackTrace();\r\n        }\r\n        if (page.matchUrl(\u0026quot;http://blog.csdn.net/.*/article/details/.*\u0026quot;)) {\r\n            String title = page.select(\u0026quot;div[class=article_title]\u0026quot;).first().text();\r\n            String author = page.select(\u0026quot;div[id=blog_userface]\u0026quot;).first().text();//获取作者名\r\n            System.out.println(\u0026quot;title:\u0026quot; + title + \u0026quot;\\tauthor:\u0026quot; + author);\r\n            if(!title.isEmpty() \u0026amp;\u0026amp; ! content.isEmpty()){\r\n                Pa pa=new Pa(title,content);\r\n                ipaDao.save(pa);\r\n            }\r\n        }\r\n    }[/code][b]ps:Elastic中文社区的爬取规则和谐了，楼主是爱社区的，大家可以放心的爬CSDN吧，WebCollector功能很强大，爬虫的一个关键就是需要知道网站的url规则，有兴趣的可以研究​ 下，Elastic的数据不多，分吧钟就够了，CSDN爬了5，6分钟，没有做深度的爬，取了大概二三十万的数据样子，只取标题和正文 [/b]\r\n \r\n[b]去我博客查看原文 [url]http://www.kailing.pub/article/index/arcid/86.html[/url][/b]\r\n下面是导入数据的截图\r\n\r\n[attach]120[/attach]\r\n\r\n[attach]121[/attach]\r\n ","title":"java爬虫爬取Elastic中文社区用作es测试数据","uid":"1032","views":"4061","votes":"1"},"_type":"doc"}
{"_id":"68","_index":"forum-mysql","_score":1,"_source":{"addtime":"1459388165","category_id":"5","comments":"1","has_attach":"1","id":"68","message":"Mountain View, Calif. and Amsterdam, The Netherlands – March 30, 2016，[url=https://www.elastic.co/press/elastic-brings-real-time-graph-analytics-to-the-elastic-stack]英文原文[/url]\n\n[attach]133[/attach]\n\nElastic 今天宣布发布一个新的用于 Elasticsearch 和 Kibana 的插件，通过它们您可以很方便的发现、理解和探索您现有数据之间的关系。通过结合速度与相关度的搜索与图分析，Graph 已开启一页新的篇章同时为 Elastic Stack 带来更多的使用场景。\n \n“我们构建 Graph 来帮助您以更多的方式来分析您存储在 Elasticsearch 中的数据” -- Steve Kearns，Elastic 高级产品总监提到， “通过把相关度作为切入点来查看数据间的关系，以前需要涉及到多个系统、批量作业甚至机器学习才能做到的事情，现在变成容易解决的问题。”\n\n[b]Graph 为 Elastic Stack 开启新的使用场景[/b]\n\n当您往 Elasticsearch 存储数据时 -- 产品信息、用户资料、文档、日志 -- 这些数据通常会包含对象（实体、人员、角色或者机器等）之间的引用关系。最好的探索这些关系的方法就是以可视化的方式去查看，Graph 通过以 Kibana 插件的方式提供了这样的能力。和 Elastic 的所有产品一样，它的 UI 界面设计简单易用，API 接口丰富强大，借助于 Elastic 在相关性评分的丰富经验，挖掘出您数据中最有价值的关系信息。这种独特的图形探索方式，并且无需引入新的索引格式，允许用户直接查询现有的数据，为 Elastic Stack 打开了一个新的更广泛的使用场景。\n\nGraph 让一些复杂问题和场景（如行为分析、反欺诈、网络安全、药物发现、个性化医疗，或者基于持续的实时数据构建个性化推荐）的处理变得简单。Graph 通过相关性评分计算分离噪音和有用信息，自动识别最重要的这些关系。由于构建于 Elasticsearch 之上，Graph 天然具备高可用和近实时的能力。\n\n[b]Graph 为关系性探索带来相关度[/b]\n\n当数据添加到 Elasticsearch 后，索引进程会跟踪和记录该文档每个字段每个值，更新全局词频信息，并准备相关数据用于大的范围查询。这些统计信息还被用来计算搜索的相关度以及有效的用于 Aggregation 中。通过 Graph，Elastic Stack 将以一种新的方式来使用这些统计信息 -- 首先是识别文档间的关系，然后再为指定查询按最相关的关系进行优先级排序处理。\n\n相比之下，传统的图分析技术仅基于给定关系的简单的频次统计。这种方法的缺点是关系连接最多的元素 -- 如《肖申克的救赎》的电影推荐指数或在星巴克的信用卡购买数据 -- 被认为是最重要的而返回但不一定最有价值。Elasticsearch 中的 Graph，相关度会根据与每个关系的重要程度来进行计算而不是简单的平均处理，返回的是重要的结果，避免出现频繁或平常的连接关系\n\n“Graph 是一个极好的例子，让大家看到我们的产品所带来的无限可能性以及我们如何努力让我们的用户尽可能容易的得益于 Elastic Stack。” -- Shay Banon，Elastic CTO 与联合创始人说 -- “我很自豪地看到我们的公司在持续创新，然后也迫不及待的想要看到我们的客户采用 Graph 这种新方法来解决真正具有挑战性的问题和案例.”\n\n[b]了解更多：[/b]\n[url=https://www.elastic.co/products/graph]Graph 产品首页[/url]\n[url=https://www.elastic.co/webinars/sneak-peek-of-graph-capabilities-with-elasticsearch/?view=1]观看 Graph 在线研讨会[/url]\n \n[b]关于 Elastic[/b]\nElastic 是世界领先的软件提供商，致力于结构化和非结构化数据的实时可用性，用户场景包括搜索、日志和数据分析等领域。公司由 Elasticsearch、Kibana、Logstash 和 Beats 这些开源项目背后的开发人员于2012年创立，Elastic Stack、X-Pack 和 Elastic Cloud 这些产品迄今累计已超过5千万次下载。\nElastic 由 Benchmark Capital、Index Ventures 及 NEA 投资，总部位于阿姆斯特丹和加州山景城，公司员工及办事处遍布全球各地。欲了解更多，请访问 [url]http://elastic.co[/url]。","title":"Elastic 为 Elastic Stack 带来新的 Graph 实时图分析功能","uid":"1","views":"8261","votes":"6"},"_type":"doc"}
{"_id":"74","_index":"forum-mysql","_score":1,"_source":{"addtime":"1461552538","category_id":"1","comments":"2","has_attach":"1","id":"74","message":"前言\r\n\r\n之前学习Lucene和ElasticSearch的时候经常逛逛Elastic的中文社区，发现社区做的蛮不错的，风格和ui都比较清新，今天突然看到了一个站和其风格类似，我就肯定是个开源的产品二次开发的，后来发现了WeCenter，一个很不错的社区问答系统\r\n\r\n简介\r\n\r\nWeCenter 是一款知识型的社交化开源社区程序，专注于企业和行业社区内容的整理、归类、检索和再发行。\r\n\r\n为什么选择WeCenter\r\n\r\n管理中心，一手掌控\r\n管理中心为你建立起快速通路，所有功能开关，只需轻点一下，即可轻松完成配置，如此众多的操控，任你一挥而就\r\n\r\n开放源码，便捷开发\r\nWeCenter 含有多项创新功能，遵循 MVC 架构，充分利用当下最新技术，对于开发者来说都会大有帮助，二次开发，更强定制，更易上手\r\n\r\n个性路由，个性定制\r\nWeCenter 让你用你喜欢的方式，更灵活地定制 URL 路由，URL 地址不再是千篇一律的样式，在 SEO 优化上祝你一臂之力\r\n设计之妙，上手即知\r\n我们创造的每一件产品，从来都不仅仅追求设计的美观。我们在考虑设计的同时，更希望用户更能容易定制模板，最终我们选择了 Bootstrap，定制模板时你会发现一切都是那么的方便，简易\r\n\r\n安装初体验\r\n\r\n从官网下载源代码后将UPLOAD放入你的http服务器入目下，开始安装体验之旅\r\n\r\n[attach]160[/attach]\r\n原文地址：[url]http://www.kailing.pub/article/index/arcid/101.html[/url]","title":"社区使用WeCenter,一个开源的php+mysql社区问答系统搭建","uid":"1032","views":"2718","votes":"0"},"_type":"doc"}
{"_id":"75","_index":"forum-mysql","_score":1,"_source":{"addtime":"1461665075","category_id":"2","comments":"4","has_attach":"1","id":"75","message":"4月23日，首届Elasticsearch中文社区技术沙龙【广州站】在广州筑梦咖啡成功举行。\r\n\r\n\r\n2016年ES中文社区全国巡回技术沙龙，分别在北京、上海、广州三地召开。【广州站】由ES中文社区和数说故事共同举办，主题为“企业级搜索引擎与大数据实战分享”，共吸引了来自腾讯、网易、欢聚时代、金蝶及舜飞科技等企业的共120+观众到现场交流。来自于欢聚时代的赖鸿智、数说故事的黄耀鸿、塔布数据的何金城三位ES大牛从入门到实战经验给现场观众带来了一次关于ES的干货分享。\r\n \r\n\r\n\r\n[attach]162[/attach]\r\n \r\n三位讲师分别从【入门】：ES优化技巧及工具推荐、【重点】基于父子文档实现的ES关联查询、【实战】亿级规模的ES查询优化实战三个层面对ES进行了介绍。赖鸿智指出自己在2011年就已经接触到ES，对于ES的初学者他从管理及监控两个方面做了一些工具的推荐。\r\n \r\n更多精彩内容，下载讲师ppt吧\r\n[url]http://pan.baidu.com/s/1sliR7qP[/url]\r\n提取密码：v5p3\r\n \r\n ","title":"【内附讲师干货PPT】首届ES中文社区技术沙龙广州站圆满举行咯","uid":"1103","views":"2729","votes":"2"},"_type":"doc"}
{"_id":"76","_index":"forum-mysql","_score":1,"_source":{"addtime":"1461745943","category_id":"2","comments":"0","has_attach":"0","id":"76","message":"{\n    \u0026quot;settings\u0026quot;: {\n        \u0026quot;index\u0026quot;: {\n            \u0026quot;number_of_replicas\u0026quot;: \u0026quot;0\u0026quot;,\n            \u0026quot;number_of_shards\u0026quot;: \u0026quot;5\u0026quot;,\n            \u0026quot;refresh_interval\u0026quot;: \u0026quot;-1\u0026quot;,\n            \u0026quot;translog.flush_threshold_ops\u0026quot;: \u0026quot;100000\u0026quot;\n        }\n    },\n    \u0026quot;mappings\u0026quot;: {\n        \u0026quot;etp_t\u0026quot;: {\n            \u0026quot;properties\u0026quot;: {\n                \u0026quot;dd\u0026quot;: {\n                    \u0026quot;type\u0026quot;: \u0026quot;multi_field\u0026quot;,\n                    \u0026quot;fields\u0026quot;: {\n                        \u0026quot;pn\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                            \u0026quot;store\u0026quot;: \u0026quot;yes\u0026quot;,\n                            \u0026quot;analyzer\u0026quot;: \u0026quot;pinyin_first_letter\u0026quot;,\n                            \u0026quot;search_analyzer\u0026quot;: \u0026quot;pinyin_first_letter\u0026quot;\n                        },\n                        \u0026quot;pk\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                            \u0026quot;store\u0026quot;: \u0026quot;yes\u0026quot;,\n                            \u0026quot;analyzer\u0026quot;: \u0026quot;pinyin_ngram_analyzer\u0026quot;,\n                            \u0026quot;search_analyzer\u0026quot;: \u0026quot;pinyin_ngram_analyzer\u0026quot;\n                        },\n                        \u0026quot;cn\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                            \u0026quot;store\u0026quot;: \u0026quot;yes\u0026quot;,\n                            \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n                            \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\n                            \u0026quot;term_vector\u0026quot;: \u0026quot;with_positions_offsets\u0026quot;,\n                            \u0026quot;boost\u0026quot;: 10\n                        },\n                        \u0026quot;un\u0026quot;: {\n                            \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                            \u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;\n                        }\n                    }\n                }\n            }\n        }\n    }\n}","title":"es分词索引创建","uid":"1121","views":"4708","votes":"0"},"_type":"doc"}
{"_id":"83","_index":"forum-mysql","_score":1,"_source":{"addtime":"1465373197","category_id":"2","comments":"0","has_attach":"0","id":"83","message":"--添加数据\nIndexRequestBuilder requestBuilder = null;\nrequestBuilder = client.prepareIndex(index, type, key).setRefresh(false);\nrequestBuilder.setSource(value).get();\n\n--批量数据\nBulkRequestBuilder bulkRequest = null;\nbulkRequest = client.prepareBulk();\nfor (Map.Entry\u0026lt;String, Object\u0026gt; map : doc.entrySet()) {\nbulkRequest.add(client.prepareIndex(index, type, map.getKey())\n.setSource(CouchbaseUtil.GJSON.toJson(map.getValue())).setRefresh(false));\n}\nbulkRequest.get();\nbulkRequest.request().requests().clear();\n\n--更新数据\nclient.prepareUpdate().setIndex(index).setType(type).setId(id).setDoc(map).get();\n\n--批量删除数据\nBulkRequestBuilder bulk = null;\nbulk = client.prepareBulk();\nfor (String id : ids) {\nbulk.add(client.prepareDelete().setIndex(index).setType(type).setId(id));\n}\nbulk.get();","title":"elasticsearch java api 增删改 操作","uid":"1121","views":"4521","votes":"0"},"_type":"doc"}
{"_id":"90","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738533","category_id":"15","comments":"0","has_attach":"0","id":"90","message":"[code]前言\n\n就拿百度说事吧，使用百度搜索引擎的时候，你会发现，卧槽，这什么玩意，前面的几个结果根本就不是老子要的东西，都是些推广的内容，而结果匹配度高的还排在老后面去了，百度这铲屎的干嘛吃的！这也不能怪百度，毕竟人家靠推广吃饭的，自然把交了钱的结果权值提高了 ！这算文档域加权的使用场景吧\n\n说明\n\n所谓索引域加\u0026quot;权\u0026quot;，就是根据需求的不同，对不同的关键值或者不同的关键索引分配不同的权值，因为查询的时候Lucene的评分机制和权值的高低是成正比的，这样权值高的内容更容易被用户搜索出来，而且排在前面。在Lucene3.x版本的时候可以给文档加权，到4.x版本后就取消了给文档加权了，就只有给文档域加权了，如果想达到给文档加权的效果，就要该文档的每个域都加权处理                                                                                                                                                  \n\nps：博主前篇博文谈过IKAnalyzer与paoding中文分词，今天我们使用的是可用于中日韩的二元分词器CJKAnalyzer\n\n闲话少说，直接上代码，看结果\n\n\npackage com.kl.luceneDemo;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.cjk.CJKAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.*;\nimport org.apache.lucene.queryparser.classic.QueryParser;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.FSDirectory;\nimport org.junit.Test;\nimport java.io.IOException;\nimport java.nio.file.Paths;\n/**\n * @author kl by 2016/3/19\n * @boke www.kailing.pub\n */\npublic class FieldSetBoostTest {\n    //索引目录\n    String indexDir=\u0026quot;E:\\\\LuceneIndex\u0026quot;;\n    //测试数据\n    String theme=\u0026quot;中国\u0026quot;;\n    String []title={\u0026quot;中国是一个伟大的国家\u0026quot;,\u0026quot;我爱你的的祖国,美丽的中国\u0026quot;,\u0026quot;是什么，中国令美日等国虎视眈眈\u0026quot;};\n    /**\n     * Lucence5.5返回IndexWriter实例\n     * @param directory\n     * @return\n     */\n    public IndexWriter getIndexWriter(Directory directory){\n        Analyzer analyzer=new CJKAnalyzer();//中日韩二元分词\n        IndexWriterConfig writerConfig=new IndexWriterConfig(analyzer);\n        IndexWriter writer=null;\n        try {\n            writer =new IndexWriter(directory,writerConfig);\n        }catch (Exception e){\n            e.printStackTrace();\n        }\n        return writer;\n    }\n    public Directory getDirctory(String indexDir){\n        Directory directory=null;\n        try {\n            directory=FSDirectory.open(Paths.get(indexDir));\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n        return directory;\n    }\n    /**\n     * 创建索引不加权\n     * @throws Exception\n     */\n    public void Indexer()throws Exception{\n       IndexWriter writer=getIndexWriter(getDirctory(indexDir));\n        Document doc=null;\n        for(String str:title){\n            doc=new Document();\n            //Lucence5.5 Fileld有多个实现，StringFIeld不分词  TextField分词\n            doc.add(new StringField(\u0026quot;theme\u0026quot;,theme, Field.Store.YES));\n            Field field=new TextField(\u0026quot;title\u0026quot;,str, Field.Store.YES);\n            doc.add(field);\n            writer.addDocument(doc);\n        }\n        writer.close();\n    }\n    /**\n     * 创建索引,指定文档域加权\n     * @throws Exception\n     */\n    public void IndexerSetBoot()throws Exception{\n        IndexWriter writer=getIndexWriter(getDirctory(indexDir));\n        Document doc=null;\n        for(String str:title){\n            doc=new Document();\n            //Lucence5.5 Fileld有多个实现，StringFIeld不分词  TextField分词\n            doc.add(new StringField(\u0026quot;theme\u0026quot;,theme, Field.Store.YES));\n            Field field=new TextField(\u0026quot;title\u0026quot;,str, Field.Store.YES);\n            if(str.indexOf(\u0026quot;是什么\u0026quot;)!=-1)\n                field.setBoost(2);//提高权值\n            doc.add(field);\n            writer.addDocument(doc);\n        }\n        writer.close();\n    }\n    @Test\n    public void searcherTest()throws Exception{\n        IndexerSetBoot();\n//        Indexer();\n        IndexReader reader= DirectoryReader.open(getDirctory(indexDir));\n        IndexSearcher is=new IndexSearcher(reader);\n        System.out.println(\u0026quot;总的文档数：\u0026quot;+reader.numDocs());\n        QueryParser qp=new QueryParser(\u0026quot;title\u0026quot;,new CJKAnalyzer());\n        Query query=qp.parse(\u0026quot;中国\u0026quot;);\n        TopDocs tDocs=is.search(query,11);//一次查询多少个结果\n        System.out.println(\u0026quot;总共有【\u0026quot;+tDocs.totalHits+\u0026quot;】条结果\u0026quot;);\n        for (ScoreDoc scoredoc:tDocs.scoreDocs){\n            Document doc = is.doc(scoredoc.doc);\n            System.out.println(doc.getField(\u0026quot;title\u0026quot;).stringValue());\n        }\n    }\n}\n加权和不加权的结果如下\n\n\n\n[/code]原文地址：[url]http://www.kailing.pub/article/index/arcid/77.html[/url]","title":"Lucene5.5入门第七篇——Lucene索引文档域加权","uid":"1032","views":"3355","votes":"0"},"_type":"doc"}
{"_id":"91","_index":"forum-mysql","_score":1,"_source":{"addtime":"1466738636","category_id":"15","comments":"0","has_attach":"0","id":"91","message":"[code]前言\n\n为了解决复杂的查询业务，Lucene给我们提供了一个查询语义分析器，一套完整的语法规则，能够满足大部分的查询需求，而不用关心底层是使用什么Query实现类，就好比写sql一样。 Lucene推荐我们使用QueryParser，而不是各种Query的实现类。但是，QueryParser不能满足所有的查询有求，比如多文档域联合查询 。有时候还是需要使用到Query的相关实现类，好了，下面我们就来看看QueryParser能够解析什么语法，解决什么问题，以及多文档域的查询 \n\n\n直接上代码\n\n每个语法都可以多测试一遍，看看结果，能够加深你的理解，因为这边测试的实在是多，测试结果我就不贴了；       \n\nps:各个查询语义可以交叉使用的,下面代码有部分也用到了，但是这边因为是写的例子，为了能更好的区分每个语义的作用，所有没有做太多的尝试\n\n/**\n * @author kl by 2016/3/20\n * @boke www.kailing.pub\n */\npublic class QueryTest {\n    //索引目录\n    String indexDir=\u0026quot;E:\\\\LuceneIndex\u0026quot;;\n    //测试数据目录\n    String dataDir=\u0026quot;E:\\\\LuceneTestData\u0026quot;;\n    /**\n     * Lucence5.5返回IndexWriter实例\n     * @param directory\n     * @return\n     */\n    public IndexWriter getIndexWriter(Directory directory){\n        Analyzer analyzer=new StandardAnalyzer();\n        IndexWriterConfig writerConfig=new IndexWriterConfig(analyzer);\n        IndexWriter writer=null;\n        try {\n            writer =new IndexWriter(directory,writerConfig);\n        }catch (Exception e){\n            e.printStackTrace();\n        }\n        return writer;\n    }\n    public Directory getDirctory(String indexDir){\n        Directory directory=null;\n        try {\n            directory= FSDirectory.open(Paths.get(indexDir));\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n        return directory;\n    }\n    @Test\n    public void TestIndexer()throws Exception{\n        File[] files= new File(dataDir).listFiles();\n        IndexWriter writer=getIndexWriter(getDirctory(indexDir));\n        for(File file:files){\n            Document doc=new Document();\n            doc.add(new TextField(\u0026quot;filePath\u0026quot;,file.getCanonicalPath(), Field.Store.YES));\n            doc.add(new TextField(\u0026quot;context\u0026quot;,new  FileReader(file)));\n            writer.addDocument(doc);\n        }\n        System.out.println(\u0026quot;总共添加了\u0026quot;+writer.numDocs()+\u0026quot;个文档\u0026quot;);\n        writer.close();\n    }\n    @Test\n    public void testSearcher()throws  Exception{\n        IndexReader reader= DirectoryReader.open(getDirctory(indexDir));\n        IndexSearcher searcher=new IndexSearcher(reader);\n        QueryParser queryParser=new QueryParser(\u0026quot;context\u0026quot;,new StandardAnalyzer());\n       Query queryw=queryParser.parse(\u0026quot;Licensor\u0026quot;);//完整匹配分词查询\n        /**\n         * 通配符 ？，*的使用\n         */\n         Query queryy=queryParser.parse(\u0026quot;Lice?sor\u0026quot;);//使用？匹配单个字符查询\n         Query queryx=queryParser.parse(\u0026quot;L*r\u0026quot;);//使用*匹配多个字符查询\n        /**\n         * 布尔运算AND, OR，NOT,+,-的使用,注意：一定要是大写的AND和OR,NOT\n         */\n        Query queryo=queryParser.parse(\u0026quot;Licensor OR ce*\u0026quot;);//使用OR联合多关键字查询,也可用空格代替OR\n        Query queryoo=queryParser.parse(\u0026quot; Licensor ce*\u0026quot;);//这个和使用OR一样的效果\n        Query queryjia=queryParser.parse(\u0026quot;+Licensor Wildcard\u0026quot;);//+代表必须的条件，搜索文档必须包含Licensor 可能有Wildcard\n        Query querya=queryParser.parse(\u0026quot;Licensor AND ce* AND Licenso?\u0026quot;);//使用AND取多个关键字的并集查询\n        Query queryNot=queryParser.parse(\u0026quot;'Lincensor Apache' NOT 'Apache Licensor'\u0026quot;);//搜索Lincensor Apache而不是Apache Licensor\n        Query queryjian=queryParser.parse(\u0026quot;'Lincensor Apache' - 'Apache Licensor'\u0026quot;);//\u0026quot;-\u0026quot;同NOT的效果一样\n\n        /**\n         * 使用正则表达式查询\n         */\n        Query queryRegular=queryParser.parse(\u0026quot;/[Lab]icensor/\u0026quot;);//这个匹配Lincensor，aicensor，bicensor分词\n        Query queryRegularr=queryParser.parse(\u0026quot;/[Lab]icenso[a-z]/\u0026quot;);//根据需要可以更灵活的使用\n        /**\n         * 使用~模糊匹配查询\n         * 这个要和*号的用法区分下，*号完整通配多个字符查询，而~不是简单的通配，这个模糊匹配和Lucene的评分有关\n         */\n        Query queryFuzzy=queryParser.parse(\u0026quot;icensor~\u0026quot;);//可以查到Licensor关键字，而queryParser.parse(\u0026quot;icensor*\u0026quot;)查不到\n        Query queryFuzzyparam=queryParser.parse(\u0026quot;Licens~1\u0026quot;);//~后面可加0-2的整数来制定模糊匹配度，默认不加为1\n        Query queryFuzzyParam=queryParser.parse(\u0026quot;Licens cens ~0\u0026quot;);//~还可以模糊匹配差异化N字符数的多个关键字\n        /**\n         * 范围查询,多用于数字和时间的查询\n         */\n        Query queryRange =queryParser.parse(\u0026quot;{abc TO Licens}\u0026quot;);//{}abc与Licenszhi间的文件，不包含\n        Query queryRangex =queryParser.parse(\u0026quot;[abc TO Licens]\u0026quot;);//{}abc与Licenszhi间的文件,包含本身\n        /**\n         * 关键字加权处理查询\n         */\n        //默认为1，可加权可降权，可通过加权处理给匹配的结果排序\n        Query queryBoosting  =queryParser.parse(\u0026quot;Licensor Wildcard^4 \u0026quot;);\n\n        /**\n         * Grouping组合查询\n         */\n        Query queryGrouping  =queryParser.parse(\u0026quot;(+Licensor  +Wildcard) AND easier\u0026quot;);//可使用（）组合多个条件查询\n\n         //ps: 查询部分字符需要转义处理，如（+ - \u0026amp;\u0026amp; || ! ( ) { } [ ] ^ \u0026quot; ~ * ? : \\ /）\n\n        /**\n         * 使用MultiFieldQueryParser进行多个文档域查询\n         */\n        Map boost=new HashMap();\n        boost.put(\u0026quot;filePath\u0026quot;,1.5F);//设置文档域的权值\n        boost.put(\u0026quot;context\u0026quot;,2F);\n        QueryParser multiField=new MultiFieldQueryParser(new String[]{\u0026quot;filePath\u0026quot;,\u0026quot;context\u0026quot;},new StandardAnalyzer(),boost);\n        Query queryq=multiField.parse(\u0026quot;lucenetestdata\u0026quot;);\n\n        TopDocs topDocs= searcher.search(queryq,10);\n        System.out.println(\u0026quot;查询结果共有\u0026quot;+topDocs.totalHits+\u0026quot;条\u0026quot;);\n        for(ScoreDoc scoreDoc:topDocs.scoreDocs){\n            Document document=searcher.doc(scoreDoc.doc);\n            System.out.println(document.get(\u0026quot;filePath\u0026quot;)+\u0026quot;--评分：\u0026quot;+scoreDoc.score);\n        }\n    }\n\n} \nps:代码中有大量注释，有些不一定理解到位了，深入了解 请参考官方说明：\n\nhttps://lucene.apache.org/core/5_5_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#Wildcard_Searches[/code]原文地址：[url]http://www.kailing.pub/article/index/arcid/79.html[/url]","title":"Lucene5.5入门第八篇——使用QueryParser实现高级查询","uid":"1032","views":"3485","votes":"0"},"_type":"doc"}
{"_id":"102","_index":"forum-mysql","_score":1,"_source":{"addtime":"1474362996","category_id":"2","comments":"3","has_attach":"1","id":"102","message":"以球员信息为例，player索引的player type包含5个字段，姓名，年龄，薪水，球队，场上位置。\nindex的mapping为：[code]\u0026quot;mappings\u0026quot;: {\n\t\u0026quot;player\u0026quot;: {\n\t\t\u0026quot;properties\u0026quot;: {\n\t\t\t\u0026quot;name\u0026quot;: {\n\t\t\t\t\u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;,\n\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n\t\t\t},\n\t\t\t\u0026quot;age\u0026quot;: {\n\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n\t\t\t},\n\t\t\t\u0026quot;salary\u0026quot;: {\n\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;\n\t\t\t},\n\t\t\t\u0026quot;team\u0026quot;: {\n\t\t\t\t\u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;,\n\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n\t\t\t},\n\t\t\t\u0026quot;position\u0026quot;: {\n\t\t\t\t\u0026quot;index\u0026quot;: \u0026quot;not_analyzed\u0026quot;,\n\t\t\t\t\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n\t\t\t}\n\t\t},\n\t\t\u0026quot;_all\u0026quot;: {\n\t\t\t\u0026quot;enabled\u0026quot;: false\n\t\t}\n\t}\n}[/code]\n索引中的全部数据：\n\n[attach]289[/attach]\n \n首先，初始化Builder：[code]SearchRequestBuilder sbuilder = client.prepareSearch(\u0026quot;player\u0026quot;).setTypes(\u0026quot;player\u0026quot;);[/code]接下来举例说明各种聚合操作的实现方法，因为在es的api中，多字段上的聚合操作需要用到子聚合(subAggregation)，初学者可能找不到方法（网上资料比较少，笔者在这个问题上折腾了两天，最后度了源码才彻底搞清楚T_T），后边会特意说明多字段聚合的实现方法。另外，聚合后的排序也会单独说明。\n[list]\n[*][b]group by/count[/b][/*]\n[/list]\n例如要计算每个球队的球员数，如果使用SQL语句，应表达如下：[code]select team, count(*) as player_count from player group by team;[/code]ES的java api：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;player_count \u0026quot;).field(\u0026quot;team\u0026quot;);\nsbuilder.addAggregation(teamAgg);\nSearchResponse response = sbuilder.execute().actionGet();[/code] \n[list]\n[*][b]group by多个field[/b][/*]\n[/list]\n例如要计算每个球队每个位置的球员数，如果使用SQL语句，应表达如下：[code]select team, position, count(*) as pos_count from player group by team, position;[/code]ES的java api：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;player_count \u0026quot;).field(\u0026quot;team\u0026quot;);\nTermsBuilder posAgg= AggregationBuilders.terms(\u0026quot;pos_count\u0026quot;).field(\u0026quot;position\u0026quot;);\nsbuilder.addAggregation(teamAgg.subAggregation(posAgg));\nSearchResponse response = sbuilder.execute().actionGet();[/code] \n[list]\n[*][b]max/min/sum/avg[/b][/*]\n[/list]\n例如要计算每个球队年龄最大/最小/总/平均的球员年龄，如果使用SQL语句，应表达如下：[code]select team, max(age) as max_age from player group by team;[/code]ES的java api：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;player_count \u0026quot;).field(\u0026quot;team\u0026quot;);\nMaxBuilder ageAgg= AggregationBuilders.max(\u0026quot;max_age\u0026quot;).field(\u0026quot;age\u0026quot;);\nsbuilder.addAggregation(teamAgg.subAggregation(ageAgg));\nSearchResponse response = sbuilder.execute().actionGet();[/code]\n[list]\n[*][b]对多个field求max/min/sum/avg[/b][/*]\n[/list]\n例如要计算每个球队球员的平均年龄，同时又要计算总年薪，如果使用SQL语句，应表达如下：[code]select team, avg(age)as avg_age, sum(salary) as total_salary from player group by team;[/code]ES的java api：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;team\u0026quot;);\nAvgBuilder ageAgg= AggregationBuilders.avg(\u0026quot;avg_age\u0026quot;).field(\u0026quot;age\u0026quot;);\nSumBuilder salaryAgg= AggregationBuilders.avg(\u0026quot;total_salary \u0026quot;).field(\u0026quot;salary\u0026quot;);\nsbuilder.addAggregation(teamAgg.subAggregation(ageAgg).subAggregation(salaryAgg));\nSearchResponse response = sbuilder.execute().actionGet();[/code] \n[list]\n[*][b]聚合后对Aggregation结果排序[/b][/*]\n[/list]\n例如要计算每个球队总年薪，并按照总年薪倒序排列，如果使用SQL语句，应表达如下：[code]select team, sum(salary) as total_salary from player group by team order by total_salary desc;[/code]ES的java api：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;team\u0026quot;).order(Order.aggregation(\u0026quot;total_salary \u0026quot;, false);\nSumBuilder salaryAgg= AggregationBuilders.avg(\u0026quot;total_salary \u0026quot;).field(\u0026quot;salary\u0026quot;);\nsbuilder.addAggregation(teamAgg.subAggregation(salaryAgg));\nSearchResponse response = sbuilder.execute().actionGet();[/code]需要特别注意的是，排序是在TermAggregation处执行的，Order.aggregation函数的第一个参数是aggregation的名字，第二个参数是boolean型，true表示正序，false表示倒序。 \n[list]\n[*][b]Aggregation结果条数的问题[/b][/*]\n[/list]\n默认情况下，search执行后，仅返回10条聚合结果，如果想反悔更多的结果，需要在构建TermsBuilder 时指定size：[code]TermsBuilder teamAgg= AggregationBuilders.terms(\u0026quot;team\u0026quot;).size(15);[/code] \n[list]\n[*][b]Aggregation结果的解析/输出[/b][/*]\n[/list]\n得到response后：[code]Map\u0026lt;String, Aggregation\u0026gt; aggMap = response.getAggregations().asMap();\nStringTerms teamAgg= (StringTerms) aggMap.get(\u0026quot;keywordAgg\u0026quot;);\nIterator\u0026lt;Bucket\u0026gt; teamBucketIt = teamAgg.getBuckets().iterator();\nwhile (teamBucketIt .hasNext()) {\nBucket buck = teamBucketIt .next();\n//球队名\nString team = buck.getKey();\n//记录数\nlong count = buck.getDocCount();\n//得到所有子聚合\nMap subaggmap = buck.getAggregations().asMap();\n//avg值获取方法\ndouble avg_age= ((InternalAvg) subaggmap.get(\u0026quot;avg_age\u0026quot;)).getValue();\n//sum值获取方法\ndouble total_salary = ((InternalSum) subaggmap.get(\u0026quot;total_salary\u0026quot;)).getValue();\n//...\n//max/min以此类推\n}[/code] \n[list]\n[*][b]总结[/b][/*]\n[/list]\n综上，聚合操作主要是调用了SearchRequestBuilder的addAggregation方法，通常是传入一个TermsBuilder，子聚合调用TermsBuilder的subAggregation方法，可以添加的子聚合有TermsBuilder、SumBuilder、AvgBuilder、MaxBuilder、MinBuilder等常见的聚合操作。\n \n从实现上来讲，SearchRequestBuilder在内部保持了一个私有的 SearchSourceBuilder实例， SearchSourceBuilder内部包含一个List\u0026lt;AbstractAggregationBuilder\u0026gt;，每次调用addAggregation时会调用 SearchSourceBuilder实例，添加一个AggregationBuilder。\n同样的，TermsBuilder也在内部保持了一个List\u0026lt;AbstractAggregationBuilder\u0026gt;，调用addAggregation方法（来自父类addAggregation）时会添加一个AggregationBuilder。有兴趣的读者也可以阅读源码的实现。\n \n如果有什么问题，欢迎一起讨论，如果文中有什么错误，欢迎批评指正。\n \n注：文中使用的Elastic Search API版本为2.3.2\n\n\n\n\n\n\n ","title":"ElasticSearch java API - 聚合查询","uid":"1706","views":"30943","votes":"8"},"_type":"doc"}
{"_id":"122","_index":"forum-mysql","_score":1,"_source":{"addtime":"1482915151","category_id":"8","comments":"1","has_attach":"0","id":"122","message":"本月10号在北京的第一次 Elastic 中国开发者大会的资料现在已经可以下载了，没有去现场的或者去现场的还想回顾的都可以去看看，欢迎大家踊跃交流讨论！\n \n[url]https://pan.baidu.com/s/1slbCZ9b[/url]\n\n ","title":"Elastic{ON}DevChina2016 资料下载","uid":"1","views":"4979","votes":"5"},"_type":"doc"}
{"_id":"186","_index":"forum-mysql","_score":1,"_source":{"addtime":"1497493931","category_id":"2","comments":"1","has_attach":"0","id":"186","message":"之前我在社区里写过 [url=https://elasticsearch.cn/article/171 ]《ElasticSearch集群故障案例分析: 警惕通配符查询》[/url]一文，讲的是关于通配符查询可能引起ES集群负载过高的问题。 当时提到wildcard query构造的non-deterministic automaton要经历一个determinize的过程，其间如果生成的状态数量过高，可能引起集群负载彪高，影响对外服务。 但因为determinize的过程中，Lucene对生成的状态数量做了限制，因此在问题查询过去以后，集群还是可以恢复常态。\n \n然而近期我们线上的另外一起故障，使我意识到，Prefix/Regex/Fuzzy一类的模糊查询可能直接让整个集群直接挂掉。\n \n问题出现时，ES服务端日志有如下报错:\n[quote]\n[2017-06-14T21:06:39,330][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [xx.xx.xx.xx] fatal error in thread [elasticsearch[xx.xx.xx.xx][search][T#29]], exiting\njava.lang.StackOverflowError\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n[/quote]\n调查后发现，Prefix/Regex/Fuzzy一类的Query，是直接构造的deterministic automaton，如果查询字符串过长，或者pattern本身过于复杂，构造出来的状态过多，之后一个isFinite的Lucene方法调用可能产生堆栈溢出。\n \n一个可以复现问题的regex query如下:[code]POST /test/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;regexp\u0026quot;: {\n      \u0026quot;test\u0026quot;: \u0026quot;t{1,9500}\u0026quot;\n    }\n  }\n}[/code]Github上的issue链接： [url=https://github.com/elastic/elasticsearch/issues/24553]issues/24553[/url]。 \n\n对于我们这次特定的问题，是因为prefix Query里没有限制用户输入的长度。 看ES的源码，PrefixQuery继承自Lucene的AutomatonQuery，在实例化的时候，maxDeterminizedStates传的是Integer.MAX_VALUE, 并且生成automaton之前，prefix的长度也没有做限制。 个人认为这里可能应该限制一下大小，避免产生过多的状态:[code]public class PrefixQuery extends AutomatonQuery {\n\n  /** Constructs a query for terms starting with \u0026lt;code\u0026gt;prefix\u0026lt;/code\u0026gt;. */\n  public PrefixQuery(Term prefix) {\n    // It's OK to pass unlimited maxDeterminizedStates: the automaton is born small and determinized:\n    super(prefix, toAutomaton(prefix.bytes()), Integer.MAX_VALUE, true);\n    if (prefix == null) {\n      throw new NullPointerException(\u0026quot;prefix must not be null\u0026quot;);\n    }\n\n\n\n\n[/code] 最终抛出异常的代码是\norg.apache.lucene.util.automaton.Operations.isFinite，  \n可以看到这段代码里用了递归，递归的深度取决于状态转移的数量。根据注释的说明，这是一段待完善的代码，因为使用了递归，可能导致堆栈溢出:[code]  // TODO: not great that this is recursive... in theory a\n  // large automata could exceed java's stack\n  private static boolean isFinite(Transition scratch, Automaton a, int state, BitSet path, BitSet visited) {\n    path.set(state);\n    int numTransitions = a.initTransition(state, scratch);\n    for(int t=0;t\u0026lt;numTransitions;t++) {\n      a.getTransition(state, t, scratch);\n      if (path.get(scratch.dest) || (!visited.get(scratch.dest) \u0026amp;\u0026amp; !isFinite(scratch, a, scratch.dest, path, visited))) {\n        return false;\n      }\n    }\n    path.clear(state);\n    visited.set(state);\n    return true;\n  }[/code]\n由此可见，在项目里使用了模糊查询的同学，一定一定要注意限制用户输入长度，否则可能导致集群负载过高或者整个挂掉。 \n \n虽然Lucene/Elasticsearch应该在代码层面做一些限制，确保有问题的query不会导致stack overflow，但是当用到这类查询的时候，程序员的思维方式还局限在RDBMS开发的时代。 我们应该多在数据索引阶段下功夫，确保尽量用最高效的term query来完成绝大多数的查询。 ","title":"模糊查询导致Elasticsearch服务宕机","uid":"81","views":"3471","votes":"10"},"_type":"doc"}
{"_id":"133","_index":"forum-mysql","_score":1,"_source":{"addtime":"1487138858","category_id":"5","comments":"4","has_attach":"0","id":"133","message":"[b]Elasticsearch 5.2.1 发布内容[/b]\n \n基于 Lucene 6.4.1，所有5.2.0 用户都应该升级到该版本，修正了很多 bug，尤其了 Lucene6.4.1修复了两个重要的内存泄漏：\n[list]\n[*]当存储字段配置为“best_compression\u0026quot;,我们依赖于 JVM 回收机制来释放解压缩实例（Deflater/Inflater instances）。然而这些类也行只使用了很少的 JVM 堆栈内存，却使用了大量了本地内存，所以可能 会出现在 JVM 回收解压缩实例之前而操作系统先用完了本地内存。 [url=https://issues.apache.org/jira/browse/LUCENE-7647]LUCENE-7647[/url]。[/*]\n[*]特定的查询可能会持有 IndexReader 的一个引用，当这些查询被缓存之后，本来应该已经被删除的段会因为这个引用而继续被 Lucene 持有。[url=https://issues.apache.org/jira/browse/LUCENE-7657]LUCENE-7657[/url]。[/*]\n[/list]\n \n[b]功能废弃：[/b]\n[list]\n[*]Geo distance range 废弃，请使用`geo_distance` bucket aggregation 或 geo_distance sort来替代。[url=https://github.com/elastic/elasticsearch/pull/22835]#22835[/url]。[/*]\n[/list]\n [b]改进增强：[/b]\n[list]\n[*]分配解释 API（allocation explaining）在未分配主分片信息中包含陈旧的副本信息（不管是陈旧还是损坏的）[url=https://github.com/elastic/elasticsearch/pull/22826]#22826[/url]。[/*]\n[/list]\n \n[b]Bug 修复：[/b]\n[list]\n[*]如果查询超时，将缓存结果置为无效。[url=https://github.com/elastic/elasticsearch/pull/22807]#22807[/url]。[/*]\n[*]Reindex 接口支持来源 es 版本\u0026lt;2.0，当不能清除旧的 scroll 不记录日志。[/*]\n[*]将参数：search.highlight.term_vector_multi_value 保留为节点级别。[/*]\n[/list]\n \n其他细节详见 [url=https://www.elastic.co/guide/en/elasticsearch/reference/5.2/release-notes-5.2.1.html]Release notes[/url]。 \n[url=https://www.elastic.co/downloads/elasticsearch]Download Elasticsearch 5.2.1[/url]\n[url=https://www.elastic.co/guide/en/x-pack/current/xpack-release-notes.html#xpack-5.2.1]X-Pack 5.2.1 release notes[/url]\n \n[b]Kibana 5.2.1 发布内容：[/b]\n \n在该版本中主要包括了一些重要的 bug 修复，包含一个安全风险的 fix 以及可能造成 kibana 崩溃的问题。\n在5.0早期的版本中，如果配置了 SSL，特定的请求会造成 Kibana 无法释放文件打开句柄，这会造成进程随着时间推移的崩溃。请求在发生数据之前被取消也会造成进程的崩溃。还有一个安全的风险：[url=https://www.elastic.co/community/security]ESA-2017-02[/url]（Http 头信息可能泄露敏感信息的问题，注：Kibana4不受影响）。\n \n其他详见：[url=https://www.elastic.co/guide/en/kibana/current/release-notes-5.2.1.html]Release notes[/url]\n[url=https://www.elastic.co/downloads/kibana]Download Kibana 5.2.1[/url]\n \nBeats,Logstash 发布内容见：\n[url]https://www.elastic.co/guide/en/beats/libbeat/5.2/release-notes-5.2.1.html[/url]\n[url]https://www.elastic.co/guide/en/logstash/5.2/logstash-5-2-1.html[/url]\n \n ","title":"Elastic Stack 5.2.1 发布","uid":"1","views":"2917","votes":"0"},"_type":"doc"}
{"_id":"141","_index":"forum-mysql","_score":1,"_source":{"addtime":"1489649080","category_id":"5","comments":"11","has_attach":"1","id":"141","message":"[attach]512[/attach]\n\n[b]【线上活动】[/b]\n\n[b]在线直播[/b]\n直播工具Zoom：https://elastic.zoom.us/j/522710614，房间号：522710614（密码进群索取)\n[list]\n[*]《Elastic{ON}17 Keynote 回顾》，QQ 群(190605846)，2017-3-17 21:00 PM，[url=https://v.qq.com/x/page/q0385ljqgzg.html]回放[/url][/*]\n[*]《What's new in Elasticsearch 5》，QQ 群(190605846)，2017-3-20 21:00 PM，[url=https://v.qq.com/x/page/b0385dux2qx.html]回放[/url][/*]\n[*]《What's new in Logstash 5》，QQ 群(190605846)，2017-3-21 21:00 PM，[url=https://v.qq.com/x/page/z0386v8vuj3.html]回放[/url][url=https://v.qq.com/x/page/z0386v8vuj3.html] [/url][/*]\n[/list]\n \n \n \n[b]【线下活动】[/b]\n\n [b]Workshop[/b]\n[list]\n[*]Elastic Workshop，北京，2017-04-10【报名结束】[/*]\n[*]Elastic Workshop，上海，2017-04-17【报名结束】[/*]\n[*]Elastic Workshop，深圳，2017-04-20【报名结束】[/*]\n[*]Elastic Workshop，上海，2017-06-29【报名结束】[/*]\n[*]Elastic Workshop，广州，2017-07-04【报名结束】[/*]\n[*]Elastic Workshop，深圳，2017-07-06【报名结束】[/*]\n[/list]\n \n[b]Meetup[/b]\n[list]\n[*]Elastic Meetup Shanghai ，上海，2017.5.14， 【报名结束】【[url=https://elasticsearch.cn/article/163]日程[/url]】[/*]\n[*]Elastic Meetup Beijing ，北京，2017.5.21  【报名结束】【[url=https://elasticsearch.cn/article/167]日程[/url]】【[url=http://www.itdks.com/dakashuo/playback/333]直播回放[/url]】[/*]\n[*]Elastic Meetup Nanjing，南京，2017.6.10 【报名结束】【[url=https://elasticsearch.cn/article/164]日程[/url]】【[url=http://www.itdks.com/dakashuo/playback/913]直播回放[/url]】[/*]\n[*]Elastic Meetup Hangzhou，杭州，2017.6.25 【报名结束​】【[url=https://elasticsearch.cn/article/187]日程[/url]】【[url=http://www.itdks.com/dakashuo/play/2563]直播回放[/url]】[/*]\n[*]Elastic Meetup Changsha，长沙，2017.10.28 【报名结束​】【[url=https://elasticsearch.cn/article/320]日程[/url]】[/*]\n[*]Elastic Meetup Wuhan，武汉，2017.11.4 【报名结束​】【[url=https://elasticsearch.cn/article/344]日程[/url]】[/*]\n[*]Elastic Meetup Guangzhou，广州，2017.11.25 【报名结束​】【[url=https://elasticsearch.cn/article/364]日程[/url]】[/*]\n[*]Elastic Meetup Shenzhen，深圳，2017.12.16 【报名结束​】【[url=https://elasticsearch.cn/article/406]日程[/url]】[/*]\n[/list]\n \n[b]【会议参展】[/b]\n\nElastic 今年继续赞助和支持各种开发者会议，欢迎届时来展台交流。\n[list]\n[*]Gopher China，上海，2017.04.15-2017.04.16[/*]\n[*]OSC Shanghai ，上海，2017.5.13[/*]\n[*]The China-R Conf，北京，2017.5.19-2017.5.21[/*]\n[*]OSC Hangzhou，杭州，2017.6.24[/*]\n[*]ArchSummit Shenzhen，深圳，2017.7.7-2017.7.8[/*]\n[*]OSC Jinan，济南，2017.7.22[/*]\n[*]OSC Zhuhai，珠海，2017.8.27[/*]\n[*]RubyConf China，杭州，2017.9.16-17[/*]\n[*]OSC Chengdu， 成都，2017.9.23[/*]\n[*]OSC Chongqing，重庆，2017.9.24[/*]\n[*]ArchSummit Beijing，2017.12.8-2017.12.9[/*]\n[/list]\n \n[b]上面是暂时确定的活动，部分活动报名链接晚点放出来，请关注本页面。[/b]\n[b]欢迎各个不同的城市的同学一起帮忙举办线下活动。[/b]\n[b]各个城市的线下活动欢迎报名分享，大家多交流，话题无论大小。[/b]","title":"2017 Elastic 官方及社区国内活动日程安排","uid":"1","views":"6482","votes":"23"},"_type":"doc"}
{"_id":"148","_index":"forum-mysql","_score":1,"_source":{"addtime":"1491360567","category_id":"2","comments":"6","has_attach":"0","id":"148","message":"希望大家踊跃发言。","title":"做为接入方，你的痛点是什么？","uid":"2363","views":"2370","votes":"0"},"_type":"doc"}
{"_id":"228","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502932953","category_id":"18","comments":"0","has_attach":"0","id":"228","message":"1.用if else 来清洗多个数据流？Logstash 6.0给你呈现新的解决办法：http://t.cn/RC7P3LH\n\n2.还在用shell管理elasticsearch数据？out啦！这篇文章教你用elasticsearch-curator管理elasticsearch数据：http://t.cn/RC7Pdvv\n\n3.用ansible来部署你的elastic stack：http://t.cn/RC7Peo9\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/228\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第19期 (2017-08-17)","uid":"668","views":"629","votes":"0"},"_type":"doc"}
{"_id":"230","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503103942","category_id":"18","comments":"0","has_attach":"0","id":"230","message":"1. filters操作一定在query前执行吗？事实比你想象的要复杂一点！\n\nhttp://t.cn/RCwV6RP\n\n   \n\n2. 深度好文，看看你的集群还有哪里可以继续优化?   \n\npart1:http://t.cn/RCwMJWl \n\npart2:http://t.cn/RCwMSzb \n\npart3:http://t.cn/RCwMKrA \n\n\n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/230\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第21期 (2017-08-19)","uid":"1874","views":"543","votes":"0"},"_type":"doc"}
{"_id":"234","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503363701","category_id":"18","comments":"0","has_attach":"0","id":"234","message":"1.你知道ES可以索引PDF、IP地理位置、用户代理信息吗，qbox工程师为你解惑。[url]http://t.cn/RC2HmNs[/url] \n\n2.ES6强大的集群认证和TLS安全特性，让我们来一探究竟。[url]http://t.cn/RCxlBuj[/url] \n\n3.内功修练，面试必备，Solr和ES TOP15的差异，你能道出多少？[url]http://t.cn/RC2Rf1G[/url] \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/234\n订阅：https://tinyletter.com/elastic-daily \n ","title":"Elastic日报 第24期 (2017-08-22)","uid":"3788","views":"627","votes":"0"},"_type":"doc"}
{"_id":"237","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503450383","category_id":"18","comments":"0","has_attach":"0","id":"237","message":"1. 京东架构师带你了解基于 Elasticsearch 的卖家日志系统：\n[url]http://t.cn/RChUuuA[/url] \n\n2. 老牌架构 ELK 和后起之秀 Graylog 究竟有何差别：\n[url]http://t.cn/RCSZiFj[/url] \n\n3. 基于 Elasticsearch 和 Tensorflow 的搜索引擎，花式玩法、仅供参考：\n[url]http://t.cn/Ri83uFG[/url] \n \n编辑：江水\n \n归档：[url]https://elasticsearch.cn/article/237[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第25期 (2017-08-23)","uid":"3828","views":"864","votes":"1"},"_type":"doc"}
{"_id":"239","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503539499","category_id":"12","comments":"6","has_attach":"0","id":"239","message":"[b]【腾讯 - 深圳】 ES研发工程师[/b]\n工作职责：\nElasticsearch相关产品的新功能设计、开发、运营和维护工作；\nElasticsearch内核的修改、特性增强等工作；\n跟进研究业界前沿技术，推动产品技术升级；\n\n职位要求：\n1. 编程能力扎实，熟悉Java/C++中的一种，具有良好的数据结构、算法、操作系统等计算机基本知识；\n2. 熟悉ElasticSearch/Lucene开源系统，有实际开发经验者优先；\n3. 熟悉Hadoop、HBase、InfluxDB等开源系统，有云计算相关开发经验者优先；\n4. 具有敏捷开发、完整产品生命周期开发者优先；\n5. 学习能力强，善于独立思考，思维活跃，对技术有强烈激情；\n\n腾讯正在推动ES相关云产品，工作地点深圳，欢迎投递简历：johngqjiang@tencent.com\n ","title":"【腾讯 - 深圳】ES研发工程师","uid":"4610","views":"2086","votes":"0"},"_type":"doc"}
{"_id":"246","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503882694","category_id":"18","comments":"0","has_attach":"0","id":"246","message":"1. 删除的文档还会增加index体积？点击这里查看lucene如何处理被删除的文档\nhttp://t.cn/RC1APZi\n2. kibana数据无法区别?使用kibana-own-home来给每个用户的kibana数据有一个自己的家吧\nhttp://t.cn/RC16dXZ\n3. 还在用es 2.x ? 一行代码让你的查询速度加快30倍\n[url]http://t.cn/RI5vDAB[/url] \n\n编辑：cyberdak\n归档：https://www.elasticsearch.cn/article/246\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第30期 (2017-08-28)","uid":"4063","views":"898","votes":"0"},"_type":"doc"}
{"_id":"247","_index":"forum-mysql","_score":1,"_source":{"addtime":"1503962676","category_id":"18","comments":"0","has_attach":"0","id":"247","message":"1.Spark2最令人关注的Spark Structured Streaming，ES-Hadoop 6.0将对其完美支持。[url]http://t.cn/RCgciXG[/url] \n\n2.五个你需要知道的Logstash的过滤器插件。[url]http://t.cn/RCe9Zy2[/url] \n\n3.Yelp将核心商家搜索功能迁移至Elasticsearch，看看他们是如何一步步攻克技术难题的吧！[url]http://t.cn/R9flGaF[/url] \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/247\n订阅：https://tinyletter.com/elastic-daily \n ","title":"Elastic日报 第31期 (2017-08-29)","uid":"3788","views":"605","votes":"0"},"_type":"doc"}
{"_id":"250","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504142504","category_id":"18","comments":"0","has_attach":"0","id":"250","message":"1.中文专题：怎么将elasticsearch当数据库使用\nhttp://t.cn/RG6eSVE\n\n2.用react与elasticsearch构建一个搜索的最简单的方法\nhttp://t.cn/Rqv3jow\n\n3.看Collector Bank怎么使用elastic stack驱动业务创新\nhttp://t.cn/RNyCFSp\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/250\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第33期 (2017-08-31)","uid":"668","views":"577","votes":"0"},"_type":"doc"}
{"_id":"252","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504230295","category_id":"2","comments":"9","has_attach":"1","id":"252","message":"最近发现es节点在gc时，引起节点脱落，将配置改成如下后，过了一阵又发生节点脱落的情况。discovery.zen.fd.ping_timeout: 60s\r\ndiscovery.zen.fd.ping_interval: 10s\r\ndiscovery.zen.fd.ping_retries: 10\r\n \r\n这个配置值如何设置？另是否还有其他的解决方案\r\n ","title":"es 由于gc 引起的节点脱落","uid":"2729","views":"781","votes":"0"},"_type":"doc"}
{"_id":"255","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504489059","category_id":"18","comments":"0","has_attach":"0","id":"255","message":"1.使用sql来搜索Elasticsearch数据:\n\nhttp://t.cn/RNWqqUx\n\n2.使用Elasticsearch做全站搜索？快来学习 targetprocess 对全站搜索的优化（自备梯子）：\n\nhttp://t.cn/RNW5sWH\n\n3. 使用Elasticsearch做数据分析？那么你一定要来看看kibi，一个更加智能的数据平台（自备梯子）：\n\nhttp://t.cn/RNWVW6h\n编辑：cyberdak\n\n归档：https://elasticsearch.cn/article/255\n\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第37期 (2017-09-04)","uid":"4063","views":"691","votes":"0"},"_type":"doc"}
{"_id":"257","_index":"forum-mysql","_score":1,"_source":{"addtime":"1504658894","category_id":"18","comments":"0","has_attach":"0","id":"257","message":"1.如何基于 Java 和 Elasticsearch 打造一个搜索框架\n[url]http://t.cn/RNDj4cz[/url] \n\n2.有赞搜索引擎实践\n工程篇  [url]http://t.cn/RNDHO1W[/url] \n算法篇  [url]http://t.cn/RqjlyIR[/url] \n\n3. 民生银行基于 ELK 的选型以及基本应用\n[url]http://t.cn/RND80vn[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/257[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第39期 (2017-09-06)","uid":"3828","views":"651","votes":"0"},"_type":"doc"}
{"_id":"272","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505262012","category_id":"18","comments":"0","has_attach":"0","id":"272","message":"1. 来自哔哩哔哩的日志系统\n[url]http://t.cn/RpNq18p[/url] \n2.亚马逊自研的存储检索系统与Elasticsearch的全方位对比\n[url]http://t.cn/RpN578C[/url] \n3.用Elasticsearch存储Kubernetes监控数据并用Kibana展示\n[url]http://t.cn/RpN9Piz[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/272[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第46期 (2017-09-13)","uid":"3828","views":"562","votes":"0"},"_type":"doc"}
{"_id":"275","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505374430","category_id":"2","comments":"25","has_attach":"0","id":"275","message":"[url=https://segmentfault.com/a/1190000011174694?_ea=2549617]点击查看更好的排版[/url]\n \n [size=14]由于 Elasticsearch（后文简称es） 的简单易用及其在大数据处理方面的良好性能，越来越多的公司选用 es 作为自己的业务解决方案。然而在引入新的解决方案前，不免要做一番调研和测试，本文便是介绍官方的一个 es 压测工具 esrally，希望能为大家带来帮助。[/size]\n \n[b][size=18]为什么要压测？[/size][/b]\n \n[size=14]关于压测，我们先来看下百度百科上的一个定义。[/size]\n[quote]\n压测，即压力测试，是确立系统稳定性的一种测试方法，通常在系统正常运作范围之外进行，以考察其功能极限和隐患。\n[/quote]\n[size=14]从定义不难看出压测的目的，是要测出一个系统的极限，提早发现隐患，早作打算。那么对于 es 来讲，我认为压测一般有以下几个目的：[/size]\n[list=1]\n[*][size=14]验证 es 的性能，尽管网上把 es 的性能夸上天了，还是自己跑一下才放心。[/size][/*]\n[*][size=14]针对 es 的某些配置做试验性测试，比如关闭索引的 _all 特性，是否能提高写性能，具体能提高多少。[/size][/*]\n[*][size=14]对比 es 新版本和旧版本的性能差异。众所周知，es 的版本升级非常快，用着 2.x 的同学们还没来得及升级 5.x ，眼看 6.x 都要发布了。此时，你到底要不要升级呢？答案虽然是肯定的，但是你怎么说服你的 leader 呢？很简单：压测新版本，和旧版本做对比，用表格、图表指明新版本在写性能、读性能方面的改善等等，搞定。[/size][/*]\n[*][size=14]对 es 集群做容量规划。俗话说“人无远虑，必有近忧”，容量规划就是“远虑”。简单讲就是你线上的 es 集群一共需要多少节点？每个节点的配置如何？这个集群的写性能极限是多少？读性能呢？如果你回答不了这些问题，那就说明你没有做过容量规划，只是两眼一抹黑，说干就干，上了再说，好在有惊无险，没有碰到性能问题。至于什么时候会遇到问题，你也说不准，感觉是个概率和人品问题……对面的老板已经黑脸了…… 对于这个问题我们在最后再来详细讨论。[/size][/*]\n[/list]\n \n[b][size=18]如何进行压测？[/size][/b]\n \n \n[size=14]现在我们知道压测的目的了，接下来该如何进行压测呢？一般有以下几个方案：[/size]\n[list=1]\n[*][size=14]自己写代码。无需多言，想怎么写怎么写，难点在于如果确保测试代码的专业性。这里有一些开源项目，留给大家自己探索：esperf 和 elasticsearch-stress-test[/size][/*]\n[*][size=14]http压测工具。es 对外暴露了 Restful API，因此所有的针对 http 协议的压测工具都可以用来测试 es，比如 JMeter、httpload等等。[/size][/*]\n[*][size=14]elastic 官方工具 esrally。[/size][/*]\n[/list]\n\n[size=14]各个压测方案各有优劣，大家可以根据自己的需求和工具熟悉度来选择自己的压测工具。接下来我们就来具体了解下 esrally。[/size]\n \n[b][size=18]入门[/size][/b]\n[size=16][b]简介[/b][/size]\n[size=14]esrally 是 elastic 官方开源的一款基于 python3 实现的针对 es 的压测工具，源码地址为https://github.com/elastic/rally，相关博客介绍在这里。esrally主要功能如下：[/size]\n[list]\n[*]自动创建、压测和销毁 es 集群[/*]\n[*][size=14]可分 es 版本管理压测数据和方案[/size][/*]\n[*][size=14]完善的压测数据展示，支持不同压测之间的数据对比分析，也可以将数据存储到指定的es中进行二次分析[/size][/*]\n[*][size=14]支持收集 JVM 详细信息，比如内存、GC等数据来定位性能问题[/size][/*]\n[/list]\n\n[size=14]elastic 官方也是基于 esrally 进行 es 的性能测试，并将结果实时发布到 https://elasticsearch-benchmarks.elastic.co/ ，大家可以从该网站上直接查看 es 的性能。官方使用两台服务器进行压测，一台运行 esrally ，一台运行 es，服务器的配置如下：[/size]\n[quote]\n[size=14]CPU: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz\nRAM: 32 GB\nSSD: Crucial MX200\nOS: Linux Kernel version 4.8.0-53\nJVM: Oracle JDK 1.8.0_131-b11[/size]\n[/quote]\n \n[size=14]网站顶部的 Geonames、Geopoint、Percolator等都是针对不同的数据集做的压测，比如下面这些图展示了 logging 日志类数据的压测结果。[/size]\n \n[size=14][img]http://upload-images.jianshu.io/upload_images/21242-caa1e3473a19fbbc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img][/size]\n[size=14][img]http://upload-images.jianshu.io/upload_images/21242-32b90af1542c711d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img][img]http://upload-images.jianshu.io/upload_images/21242-fd684330b3882829.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img][/size]\n \n[b][size=16]快速入门[/size][/b]\n \n[size=14]esrally 的文档在这里，这里简单说下安装与运行。\nesrally 对于软件环境的要求如下：[/size]\n[list]\n[*]Python 3.4+ 和 pip3[/*]\n[*][size=14]JDK 8[/size][/*]\n[*][size=14]git 1.9+[/size][/*]\n[/list]\n \n[size=14]安装方法为：[/size]\n[quote]\npip3 install esrally\n[/quote]\n \n[quote]\n[size=14]Tips:\n可以使用国内的pip源，比如豆瓣或者阿里的，这样安装会快很多。[/size]\n[/quote]\n\n安装完毕后执行如下的配置命令，确认一些数据存放的路径即可。\n[quote]\nesrally configure\n[/quote]\n\n接下来就可以开跑了，比如下面这条命令是针对 es 5.0.0 版本进行压力测试。\n[quote]\nesrally --distribution-version=5.0.0\n[/quote]\n\n运行结束后，会得到如下的结果。\n[img]http://upload-images.jianshu.io/upload_images/21242-e96159e9ad62c680.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]\n对于第一次见到压测结果的同学来说可能有些晕，这么多数据，该怎么看？！别急，一步步来！\n[quote]\nTips:\n由于 esrally 的测试数据存储在国外 aws 上，导致下载很慢甚至会超时失败，从而导致整个压测无法进行。后面我会把这些测试数据的压缩包放到国内，大家可以下载后直接放到 esrally 的数据文件夹下面，保证压测的正常进行。另外由于数据量过大，压测的时间一般会很久，可能在1个小时左右，所以大家要有耐心哦~\n如果你只是想体验下，可以加上 --test-mode 的参数，此时只会下载1000条文档进行测试。\n[/quote]\n \n[b][size=16]相关术语[/size][/b]\n \n[size=14]rally 是汽车拉力赛的意思，也就是说 esrally 是将压测比作了汽车拉力赛，因此其中的很多术语都是从汽车拉力赛中借鉴来的。[/size]\n \n[size=16][b]track[/b][/size]\n \n[size=14]track 是赛道的意思，在这里是指压测用的数据和测试策略，详细文档在这里。esrally 自带的track都在 github 上，地址在这里 https://github.com/elastic/rally-tracks。在该 repository 中，有很多测试数据，比如 geonames geopoint logging nested 等，每个数据文件夹中的 README.md 中有详细的数据介绍，而 track.json 便是压测策略的定义文件。\n我们来看下 loggins/track.json 文件[/size][code]{% import \u0026quot;rally.helpers\u0026quot; as rally with context %}\n\n{\n  \u0026quot;short-description\u0026quot;: \u0026quot;Logging benchmark\u0026quot;,\n  \u0026quot;description\u0026quot;: \u0026quot;This benchmark indexes HTTP server log data from the 1998 world cup.\u0026quot;,\n  \u0026quot;data-url\u0026quot;: \u0026quot;http://benchmarks.elasticsearch.org.s3.amazonaws.com/corpora/logging\u0026quot;,\n  \u0026quot;indices\u0026quot;: [\n    {\n      \u0026quot;name\u0026quot;: \u0026quot;logs-181998\u0026quot;,\n      \u0026quot;types\u0026quot;: [\n        {\n          \u0026quot;name\u0026quot;: \u0026quot;type\u0026quot;,\n          \u0026quot;mapping\u0026quot;: \u0026quot;mappings.json\u0026quot;,\n          \u0026quot;documents\u0026quot;: \u0026quot;documents-181998.json.bz2\u0026quot;,\n          \u0026quot;document-count\u0026quot;: 2708746,\n          \u0026quot;compressed-bytes\u0026quot;: 13815456,\n          \u0026quot;uncompressed-bytes\u0026quot;: 363512754\n        }\n      ]\n    },\n    {\n      \u0026quot;name\u0026quot;: \u0026quot;logs-191998\u0026quot;,\n      \u0026quot;types\u0026quot;: [\n        {\n          \u0026quot;name\u0026quot;: \u0026quot;type\u0026quot;,\n          \u0026quot;mapping\u0026quot;: \u0026quot;mappings.json\u0026quot;,\n          \u0026quot;documents\u0026quot;: \u0026quot;documents-191998.json.bz2\u0026quot;,\n          \u0026quot;document-count\u0026quot;: 9697882,\n          \u0026quot;compressed-bytes\u0026quot;: 49439633,\n          \u0026quot;uncompressed-bytes\u0026quot;: 1301732149\n        }\n      ]\n    }\n  ],\n  \u0026quot;operations\u0026quot;: [\n    {{ rally.collect(parts=\u0026quot;operations/*.json\u0026quot;) }}\n  ],\n  \u0026quot;challenges\u0026quot;: [\n    {{ rally.collect(parts=\u0026quot;challenges/*.json\u0026quot;) }}\n  ]\n}[/code]该 json 文件主要包含下面几个部分：\n[list]\n[*]description 和 short-description: track 的描述文字[/*]\n[*]data-url: 一个url地址，指明测试数据的下载根路径，与下方 indices 中的 documents 结合，可得到数据的下载地址。[/*]\n[*]indices: 指定该track可以操作的索引，包括创建、更新、删除等操作。详细信息可以参见这里。[/*]\n[*]operations: 指定具体的操作，比如 index 索引数据的操作、force-merge 强制合并segment的操作、search 搜索的操作等等。具体例子可以看下面的示例。详细信息可以参见这里。[/*]\n[*]challenges: 通过组合 operations 定义一系列 task ，再组合成一个压测的流程，请参照下方的 例子。详细信息可以参见这里。[/*]\n[/list]\n \n[size=14]operations/default.json 中的一个定义如下：[/size][code]{\n      \u0026quot;name\u0026quot;: \u0026quot;index-append\u0026quot;,\n      \u0026quot;operation-type\u0026quot;: \u0026quot;index\u0026quot;,\n      \u0026quot;bulk-size\u0026quot;: 5000\n}\n\n\n\n\n[/code]其中 operation-type 包含 index、force-merge、index-stats、node-stats、search等，每一个operation-type都有自己的可定义参数，比如 index 中可以通过指定 bulk-size 来决定批量写入的文档数。\n\nchallenges/default.json 中的一个定义如下：[code]{\n      \u0026quot;name\u0026quot;: \u0026quot;append-no-conflicts\u0026quot;,\n      \u0026quot;description\u0026quot;: \u0026quot;\u0026quot;,\n      \u0026quot;default\u0026quot;: true,\n      \u0026quot;index-settings\u0026quot;: {\n        \u0026quot;index.number_of_replicas\u0026quot;: 0\n      },\n      \u0026quot;schedule\u0026quot;: [\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;index-append\u0026quot;,\n          \u0026quot;warmup-time-period\u0026quot;: 240,\n          \u0026quot;clients\u0026quot;: 8\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;force-merge\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;index-stats\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 100,\n          \u0026quot;target-throughput\u0026quot;: 50\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;node-stats\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 100,\n          \u0026quot;target-throughput\u0026quot;: 50\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;default\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 500,\n          \u0026quot;target-throughput\u0026quot;: 10\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;term\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 500,\n          \u0026quot;target-throughput\u0026quot;: 60\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;range\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 200,\n          \u0026quot;target-throughput\u0026quot;: 2\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;hourly_agg\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 100,\n          \u0026quot;target-throughput\u0026quot;: 0.2\n        },\n        {\n          \u0026quot;operation\u0026quot;: \u0026quot;scroll\u0026quot;,\n          \u0026quot;clients\u0026quot;: 1,\n          \u0026quot;warmup-iterations\u0026quot;: 100,\n          \u0026quot;iterations\u0026quot;: 200,\n          \u0026quot;target-throughput\u0026quot;: 10\n        }\n      ]\n    }[/code]这里定义了一个名为 append-no-conflicts 的 challenge。由于每次压测只能运行一个challenge，这里的 default 参数是指当压测未指定时默认运行的 challenge。schedule 中指定了该 challenge 中按顺序执行 index-append、force-merge、index-stats、node-stats、default、term、range、hourly_agg、scroll 等 9 个task，其中每个 task 都指定了 一个 operation，除此之外还可以设定 clients （并发客户端数）、warmup-iterations（预热的循环次数）、iterations（operation 执行的循环次数）等，详情请参见此处。\n \n通过下面的命令可以查看当前 esrally 可用使用的track。\n[quote]\nesrally list tracks\n[/quote]\n\nesrally 的 track 数据位于 rally 目录(mac默认是 ~/.rally)中 benchmarks/tracks/ 下面。\n \n[size=16][b]car[/b][/size]\n \n[size=14]car 是赛车的意思，这里是指不同配置的 es 实例。通过下面的命令可以查看 esrally 当前可用的 car。[/size]\n[quote]\n[size=14]esrally list cars[/size]\n[/quote]\n[code]Name\n----------\n16gheap\n1gheap\n2gheap\n4gheap\n8gheap\ndefaults\nea\nverbose_iw\n\n\n\n\n[/code]\ncars 的配置位于 rally 目录(mac默认是 ~/.rally)中 benchmarks/teams/default/cars/ 下面。具体配置可以参见 cars 的文档，除了 heap 的配置，所有的 es 配置都可以修改。\n\n[b][size=16]race[/size][/b]\nrace 是一次比赛的意思，这里是指某一次压测。要比赛，就要有赛道和赛车，如果不指定赛车，就用 default 配置，如果不指定赛道，则默认使用 geonames track。通过下面的命令来执行一次 race。\n[quote]\nesrally race --track=logging --challenge=append-no-conflicts --car=\u0026quot;4gheap\u0026quot;\n[/quote]\n上面的命令便是执行一次压测，并指定使用 logging 的track，运行该 track 中的 append-no-conflicts 的 challenge，指定的 car 为 4gheap 的 es 实例。详情可以查看 race 相关文档。\n \n[b][size=16]Tournament[/size][/b]\ntournament 是锦标赛的意思，是由多个 race 组成的。通过下面的命令可以查看所有的 race。\n[quote]\nesrally list races\n[/quote]\n[code]Recent races:\n\nRace Timestamp    Track    Challenge            Car       User Tag\n----------------  -------  -------------------  --------  ------------------------------\n20160518T122341Z  pmc      append-no-conflicts  defaults  intention:reduce_alloc_1234\n20160518T112057Z  pmc      append-no-conflicts  defaults  intention:baseline_github_1234\n20160518T101957Z  pmc      append-no-conflicts  defaults\n\n\n\n\n[/code]当有了多个 race 后，可以通过下面的命令方便地比较不同 race 之间的数据。\n[quote]\nesrally compare --baseline=20160518T112057Z --contender=20160518T112341Z\n[/quote]\n[img]http://upload-images.jianshu.io/upload_images/21242-ef38be5fa9e08e78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]\n详细信息可以参见 tournament 的文档。\n\n[size=16][b]Pipeline[/b][/size]\n\nPipeline 在这里是指压测的一个流程，通过下面的命令可以查看已有的pipeline。\n[quote]\n[size=14]esrally list pipeline[/size]\n[/quote]\n[code]Name                     Description\n-----------------------  ---------------------------------------------------------------------------------------------\nfrom-sources-complete    Builds and provisions Elasticsearch, runs a benchmark and reports results.\nfrom-sources-skip-build  Provisions Elasticsearch (skips the build), runs a benchmark and reports results.\nfrom-distribution        Downloads an Elasticsearch distribution, provisions it, runs a benchmark and reports results.\nbenchmark-only           Assumes an already running Elasticsearch instance, runs a benchmark and reports results\n\n\n\n\n[/code]\n[list]\n[*]from-sources-complete 是从源代码编译 es 后再运行，可以通过 --revision 参数指明要编译的commit hash ，这样就可以针对某一个提交版本就行测试了。[/*]\n[*]from-sources-skip-build 如果已经编译好了，使用该 pipeline，可以跳过编译的流程，节省测试时间[/*]\n[*]from-distribution 通过 --distribution-version 指定 es 版本，esrally 会从官网直接下载该版本的可执行文件，然后进行测试。[/*]\n[*]benchmark-only 此 pipeline 将 es 集群的管理交由用户来处理， esrally 只做压测。如果你想针对已有集群进行测试，那么要将pipeline设定为该模式。[/*]\n[/list]\n\n详细信息请参见 pipeline 的文档。\n \n[size=16][b]压测流程[/b][/size]\n \n[size=14]esrally 的压测流程主要分为以下三个步骤：[/size]\n[list=1]\n[*]根据参数设定自行编译或者下载 es 可执行实例，然后根据 car 的约定，创建并启动 es 集群。如果使用 benchmark-only 的pipeline，则该步骤省略。[/*]\n[*][size=14]根据指定 track 去下载数据，然后按照指定的 challenge 进行操作。[/size][/*]\n[*][size=14]记录并输出压测结果数据。[/size][/*]\n[/list]\n \n[size=14]压测结果分析\n\n压测结束后，esrally 会将结果输出到终端和结果文件（位于 esrally 目录logs 和 benchmarks/races）中，如下图所示：[/size]\n[img]http://upload-images.jianshu.io/upload_images/21242-e96159e9ad62c680.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]\n \n[size=14]在 Metric 一栏，有非常多的指标数据，详细的解释可以参见该文档。一般要关注的数据有：[/size]\n[list]\n[*]throughput 每个操作的吞吐量，比如 index、search等[/*]\n[*][size=14]latency 每个操作的响应时长数据[/size][/*]\n[*][size=14]Heap used for x 记录堆栈的使用情况[/size][/*]\n[/list]\n \n[size=14]先搞懂每个 metric 的含义，然后根据自己的需求去确认自己要关注的指标。\n\n每一次压测都会以压测时的时间命名，比如 logs/rally_out_20170822T082858Z.log ，这个日志便是记录的 2017年8月22日 8:28:58开始的压测日志。而在 benchmarks/races/2017-08-22-08-28-58 中记录着最终的结果和 es 的运行日志。\n\n另外对于 benchmark-only 模式的测试，即针对已有集群的压力测试，也可以通过安装 X-Pack Basic 版本进行监控（Monitoring），在压测的过程中就能查看相关指标。[/size]\n \n[size=14][img]http://upload-images.jianshu.io/upload_images/21242-33a810a7484ff8b4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img][/size]\n[size=14]esrally 可以在配置的时候指定将所有的 race 压测结果数据存入一个指定的 es 实例中，配置如下(在 esrally 目录中 rally.ini 文件中)：[/size][code][reporting]\ndatastore.type = elasticsearch\ndatastore.host = localhost\ndatastore.port = 9200\ndatastore.secure = False\ndatastore.user =\ndatastore.password =[/code]esrally 会将数据存储在如下 3 个index中，下面 * 代指月份，即按月存储结果数据。\n[list]\n[*]rally-metrics-* 该索引分指标记录每次 race 的结果，如下图所示为某一次race的所有 metric 数据。[/*]\n[*][img]http://upload-images.jianshu.io/upload_images/21242-ee53bf01f5d81b67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]第一列时间是指某一次压测的时间，第二列时间是指标采集的时间，第三列 operation 指具体执行的操作，operation 为空的指标都是总计类的，比如indexing total time 记录的是总索引数据的时间、segments_count 是总段数等等。其他的 operation 都记录了每一个操作的数据。需要注意的是，这里记录的是 operation 的所有采样数据，不是一个最终的汇总数据。上面截图中也可以看出同一个 hour_agg 的operation 有多项名为 service_time 的指标数据，但他们的采集时间是不同的。基于这些数据，我们可以做出某一次 race 中某个指标的可视化图表，比如你想观察本次 race 中 index-log 这个 task 的 throughput 指标数据，便可以通过如下图的方式实现。[/*]\n[*] [/*]\n[*][img]http://upload-images.jianshu.io/upload_images/21242-b219402593343dc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img][/*]\n[*] [/*]\n[*]rally-result-* 该索引分指标记录了每次 race 的最终汇总结果，比如下面这条数据。[/*]\n[/list]\n [code]{\n   \u0026quot;user-tag\u0026quot;: \u0026quot;shardSizeTest:size6\u0026quot;,\n   \u0026quot;distribution-major-version\u0026quot;: 5,\n   \u0026quot;environment\u0026quot;: \u0026quot;local\u0026quot;,\n   \u0026quot;car\u0026quot;: \u0026quot;external\u0026quot;,\n   \u0026quot;plugins\u0026quot;: [\n     \u0026quot;x-pack\u0026quot;\n   ],\n   \u0026quot;track\u0026quot;: \u0026quot;logging\u0026quot;,\n   \u0026quot;active\u0026quot;: true,\n   \u0026quot;distribution-version\u0026quot;: \u0026quot;5.5.2\u0026quot;,\n   \u0026quot;node-count\u0026quot;: 1,\n   \u0026quot;value\u0026quot;: {\n     \u0026quot;50_0\u0026quot;: 19.147876358032228,\n     \u0026quot;90_0\u0026quot;: 21.03116340637207,\n     \u0026quot;99_0\u0026quot;: 41.644479789733886,\n     \u0026quot;100_0\u0026quot;: 47.20634460449219\n   },\n   \u0026quot;operation\u0026quot;: \u0026quot;term\u0026quot;,\n   \u0026quot;challenge\u0026quot;: \u0026quot;default-index\u0026quot;,\n   \u0026quot;trial-timestamp\u0026quot;: \u0026quot;20170831T063724Z\u0026quot;,\n   \u0026quot;name\u0026quot;: \u0026quot;latency\u0026quot;\n }[/code]这个记录了 term operation 的 latency 指标数据，汇总值以 percentile(百分位数) 的形式展示。基于该数据，我们可以绘制针对某个指标的多race对比，比如下图便是对比多 race 之间 hourly_agg(按小时做聚合)、default(match_all 查询)、term(term查询)、range(range查询)的latency(延迟时间)对比。\n[img]http://upload-images.jianshu.io/upload_images/21242-33dd3a56eb1431ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]\n \n \nrally-races-* 该索引记录了所有 race 的最终结果，即命令行执行的输出结果。\n除了es相关指标数据外，esrally 还会同时记录测试的一些环境信息，比如操作系统、JVM等等，你可以方便的查看本次测试的软硬件环境。\n\n \n[b][size=18]实战[/size][/b]\n\n终于到了开赛的时候，下面我们采用问答的形式来进行，希望大家看到问题后先自己思考下再看答案。\n\n[b]问题一[/b]\n\n提问：如何对比 5.5.0 相比 2.4.6 的性能改进？\n\n回答：\n\n分别针对 5.5.0 和 2.4.6 做一次压测，然后比较两者两者的相关指标即可，这里我们的 track 和 challenge 如下：\n\ntrack: nyc_taxis\nchallenge: append-no-conflicts\n\n测试步骤如下：\n1.测试 2.4.6 的性能\n[quote]\nesrally race --distribution-version=2.4.6 --track=nyc_taxis --challenge=append-no-conflicts --user-tag=\u0026quot;version:2.4.6\u0026quot;\n[/quote]\n2.测试 5.5.0 的性能\n[quote]\nesrally race --distribution-version=5.5.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag=\u0026quot;version:5.5.0\u0026quot;\n[/quote]\n3.对比两次 race 的结果\n[quote]\nesrally list races\nesrally compare --baseline=[2.4.6 race] --contender=[5.5.0 race]\n[/quote]\n[quote]\nTips:\n--user-tag 用于为 race 打标签，方便后续查找\n如果只是试一下，可以加上 --test-mode ，用测试数据来跑，很快。\n[/quote]\n \n问题二\n\n提问：如何测试 _all 关闭后对于写性能的影响？\n\n回答：\n\n针对 5.5.0 版本的 es 做两次测试，第一次开启 _all，第二次关闭 _all，对比两次的结果，由于只测试写性能，所以我们只需要 index 类型的 operation执行。这里我们的 track 和 challenge 如下：\n[list]\n[*]track: nyc_taxis[/*]\n[*]challenge: append-no-conflicts[/*]\n[/list]\n\n测试步骤如下：\n\n1.默认 nyc_taxis 的 mapping 设置是将 _all 关闭的，直接测试 _all 关闭时的性能。\n[quote]\nesrally race --distribution-version=5.5.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag=\u0026quot;enableAll:false\u0026quot; --include-tasks=\u0026quot;type:index\u0026quot;\n[/quote]\n2.修改 nyc_taxis 的 mapping 设置，打开 _all。mapping 文件位于 rally 主目录 benchmarks/tracks/default/nyc_taxis/mappings.json，修改 _all.enabled 为 true。\n[quote]\nesrally race --distribution-version=5.5.0 --track=nyc_taxis --challenge=append-no-conflicts --user-tag=\u0026quot;enableAll:true\u0026quot; --include-tasks=\u0026quot;type:index\u0026quot;\n[/quote]\n3.对比两次 race 的结果\n[quote]\nesrally list races\nesrally compare --baseline=[enableAll race] --contender=[disableAll race]\n[/quote]\n \n下图是我在 --test-mode 模式下运行的对比结果，也可以看出关闭 _all 可以提升写性能。\n[img]http://upload-images.jianshu.io/upload_images/21242-c58d07006dcf2909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240[/img]\n[quote]\nTips:\n--include-tasks 用于只运行 challenge 中的部分 task\n[/quote]\n \n[b]问题三[/b]\n\n提问：如何测试已有集群的性能？\n\n回答：\n\n使用 benchmark-only 的 pipeline 即可，这里我们的 track 和 challenge 如下： \n[list]\n[*]track: nyc_taxis[/*]\n[*]challenge: append-no-conflicts[/*]\n[/list]\n\n测试步骤如下：\n\n1.执行下方命令即可测试已有集群\n[quote]\nesrally race --pipeline=benchmark-only --target-hosts=127.0.0.1:9200 --cluster-health=yellow --track=nyc_taxis --challenge=append-no-conflicts\n[/quote]\n[quote]\nTips:\n--cluster-health=yellow 默认 esrally 会检查集群状态，非 green 状态会直接退出。添加该参数可以避免该情况\n[/quote]\n希望这三个问答可以帮助到大家快速掌握 esrally 的用法。\n \n \n[b][size=18]进阶[/size]\n[size=16]自定义 car[/size][/b]\n\n前面讲解 car 的时候，我们提到 esrally 已经自带了一些可用的 es 配置，但是如果这些还不能满足你的时候，可以通过下面两个方案解决。\n\n1.定制自己的car\ncar 的配置文件位于 esrally 目录 benchmarks/teams/default/cars，在这里新增一个自己的 car 配置文件就可以了。这里就不赘述了，感兴趣的可以查阅 car 的文档。\n\n2.自己搭建集群\n最简单的方式是脱离 esrally 的管理，自行搭建集群，这样想怎么配置就怎么配置了。\n \n[size=16][b]自定义 track[/b][/size]\n\n虽然 esrally 自带了很多 track，而且这些数据本身也不小，简单列在下面：[code]Track\t压缩数据大小\t解压数据大小\t文档数\ngeonames\t252 MB\t3.3 GB\t11396505\ngeopoint\t482 MB\t2.3 GB\t60844404\nlogging\t1.2 GB\t31 GB\t247249096\nnested\t663 MB\t3.3 GB\t11203029\nnoaa\t947 MB\t9 GB\t33659481\nnyc_taxis\t4.5 GB\t74 GB\t165346692\npercolator\t103KB\t105 MB\t2000000\npmc\t5.5 GB\t22 GB\t574199[/code]这些数据文件位于 esrally 目录 benchmarks/data 下面。不同的 Track 有不同的测试目的，详情可以去该 github repo 下面去查看。\n\n当我们做定向测试的时候，还是希望针对自己的数据进行压测，此时可以自定义 track。操作也很简单，详情可以参考官方文档。这里简单列一下操作步骤。\n[list=1]\n[*]在 上文提到的 data 目录中创建自己的数据目录。[/*]\n[*]准备压测数据文件。 esrally 使用的是一个json文件，其实是一个一个 json object。[/*]\n[*]将准备好的数据文件压缩成 bz2 格式，然后复制到步骤 1 创建的目录中去。[/*]\n[*]新增自定义的track。可以直接复制 geoname 目录，然后修改相关的配置文件，将测试数据与 track 绑定。[/*]\n[*]添加完后，通过 esrally list rack 就可以看到自定义的 track。[/*]\n[/list]\n \n[b]分布式压测[/b]\n\nesrally 还支持分布式压测，即如果一个节点的 esrally 无法达到要求的并发数、请求数，那么可以将 esrally 分布到多台机器上去同时执行。分布式压测文档在这里，此处用到了 esrally dameon，对应命令是 esrallyd 。简单讲就是 esrally 通过 esrallyd 将多台机器组合成一个集群，然后 esrally 在执行测试任务的时候通过制定 --load-driver-hosts 便可以将测试任务分发到对应的机器上执行。这里便不赘述了，感兴趣的去看前面提到的文档。\n \n[b][size=18]最后一个问题[/size][/b]\n\n让我们回到开头提到的容量规划的问题吧！\n\n提问：一个 index 的 shard 数该如何确认？\n\n回答：\n\n其实针对这个提问，还可以再问下面两个问题。\n[list=1]\n[*]shard 设置过少是否有问题？比如一直都采用默认的 5个分片[/*]\n[*]shard 设置过多是否有问题？比如直接设置为100个分片[/*]\n[/list]\n \n要回到这两个问题，我们得先知道 shard 的作用。shard 是 es 实现分布式特性的基石，文档在索引进 es 时，es 会根据一个路由算法，将每一个文档分配到对应的 shard 上。每个 shard 实际对应一个 lucene index。那么每个 shard 能存储的文档数是否有上限呢？答案是有！每个shard最多存储 2^31 个文档，即 20亿。这是 lucene 设计决定的。那是不是只要我的文档数没有超过20亿，就可以只用一个或者很少的shard 呢？不尽然。因为随着 shard 体积的增大，其查询效率会下降，而且数据迁移和恢复的成本也会增高。官方建议单个 shard 大小不要超过 50GB，可以参见讨论一和讨论二。\n\n现在回答上面的两个问题。\nshard数过小不一定好，如果数据量很大，导致每个 shard 体积过大，会影响查询性能。\nshard数过大也不一定好，因为 es 的每次查询是要分发给所有的 shard 来查询，然后再对结果做聚合处理，如果 shard 数过多也会影响查询性能。因此 shard 的数量需要根据自己的情况测出来。\n \n官方文档有一节关于容量规划的章节，建议大家去看一下，链接在这里，其给出的步骤如下：\n[list=1]\n[*]使用生产环境的硬件配置创建单节点集群[/*]\n[*]创建一个只有一个主分片无副本的索引，设置相关的mapping信息[/*]\n[*]将真实的文档导入到步骤 2 的索引中[/*]\n[*]测试实际会用到的查询语句[/*]\n[/list]\n\n测试的过程中，关注相关指标数据，比如索引性能、查询性能，如果在某一个点相关性能数据超出了你的预期值，那么此时的 shard size大小便是符合你预期的单个 shard size的大小。接下来通过下面这个简单的计算公式便大致能确定一个 index 需要设定的 shard 数了。\n[quote]\nshard数 = index 的数据总大小/单个shard size的极限值\n[/quote]\n比如你测出单个 shard size 最大为 20 GB，而你预测该索引数据最大量在1年或者2年内不会超过 200GB，那么你的 shard 数就可以设置为10。\n\n接下来要做的事情也很明确，我们要用 esrally 完成上面的压测步骤：\n \n1.自行维护 es 节点的创建和运行，esrally 运行的时候采用 benchmark-only 模式.\n\n2.自定义 track，这里有以下两个重点：\n[list]\n[*]生成真实数据。如果你的数据无法生成很多，那么可以在 track 的 schedule 中设置 iterations 参数，即循环进行同一个操作，这样也可以测试大数据量的写性能。[/*]\n[*]定义自己的查询任务。在 track 的 operations 中是可以定义自己的查询语句的，比如下面这个[/*]\n[*][code]{\n  \u0026quot;name\u0026quot;: \u0026quot;hourly_agg\u0026quot;,\n  \u0026quot;operation-type\u0026quot;: \u0026quot;search\u0026quot;,\n  \u0026quot;index\u0026quot;: \u0026quot;logs-*\u0026quot;,\n  \u0026quot;type\u0026quot;: \u0026quot;type\u0026quot;,\n  \u0026quot;body\u0026quot;: {\n    \u0026quot;size\u0026quot;: 0,\n    \u0026quot;aggs\u0026quot;: {\n      \u0026quot;by_hour\u0026quot;: {\n        \u0026quot;date_histogram\u0026quot;: {\n          \u0026quot;field\u0026quot;: \u0026quot;@timestamp\u0026quot;,\n          \u0026quot;interval\u0026quot;: \u0026quot;hour\u0026quot;\n        }\n      }\n    }\n  }\n}[/code]其中的 body 便是自定义的查询语句，所以你可以通过自己的需求来设定查询语句，以贴近实际使用的情况。[/*]\n[/list]\n3.还要记得设置索引的 mapping 与线上一致，比如是否启用 _all 等设置。\n4.基于自定义的track来进行压测即可。要注意的是运行 esrally 的机器要和 es 机器分开，防止对 es 性能产生干扰。\n[quote]\nTips:\nesrally 默认在每次压测是会删除已有的索引后再重新创建索引，如果你不想这样，可以在每个 index 的配置中设置 auto-managed 为 false，具体文档在这里。\n通过这个参数，你就可以单独压测查询性能了，而不用每次都要先经过漫长的导入数据的过程。\n[/quote]\n \n \n[b][size=18]总结[/size][/b]\n\nesrally 针对 es 的压测设计了一套完备的基于配置文件的测试流程，极大地简化了操作难度，并且提供了可重复验证的方式。对国内用户来讲，我认为最大的难处还是在于 esrally 自带的 track 文件太大，从 国外 aws 下载很慢。好在可以自定义 track，不必完全依赖自带的 track。\n\n其他没啥好说的，esrally 棒棒哒，大家赶紧去试试吧，如果有问题欢迎来讨论！\n \n\n[url=https://segmentfault.com/a/1190000011174694?_ea=2549617]点击查看更好的排版[/url]\n \n ","title":"Elasticsearch 压测方案之 esrally 简介","uid":"86","views":"2675","votes":"7"},"_type":"doc"}
{"_id":"279","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505523843","category_id":"18","comments":"0","has_attach":"0","id":"279","message":"1.关于索引的停用词，你知多少？\nhttp://t.cn/RpYDk2c\n2. 手把手教你在Azure搭建ELK\nhttp://t.cn/RpYsAG8\n3.  你知道es可以执行包含多个词的同义词的词组查询吗？\n[url]http://t.cn/RpTvc5Z[/url] \n\n编辑：bsll\n归档：https://www.elasticsearch.cn/article/279\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第49期 (2017-09-16)","uid":"1874","views":"460","votes":"0"},"_type":"doc"}
{"_id":"284","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505867421","category_id":"18","comments":"1","has_attach":"0","id":"284","message":"1. 并不算最佳实践 只是使用Elasticsearch做时序数据库的一些小思路\n[url]http://t.cn/R0vpOVu[/url] \n2. 基于Kibana的时序实践\n[url]http://t.cn/RCVj5Wm[/url] \n3. 基于Vue的Elasticsearch可视化工具 比head更好用（github）\n[url]http://t.cn/Ro5WST3[/url]\n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/284[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第53期 (2017-09-20)","uid":"3828","views":"545","votes":"0"},"_type":"doc"}
{"_id":"290","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506033875","category_id":"18","comments":"0","has_attach":"0","id":"290","message":"1、Elasticsearch 常用数据结构及算法深入解读PPT\n[url]http://t.cn/R0297wW[/url] \n2、这一招，解决了mysql与elasticsearch删除同步的难题！\n[url]http://t.cn/R029ld9[/url] \n3、ElasticPress | 基于Elasticsearch构建你的wordpress博客检索助手！\n[url]http://t.cn/R07kUUQ[/url] \n \n编辑：laoyang360\n归档：[url]https://www.elasticsearch.cn/article/290[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n\n ","title":" Elastic日报 第55期 (2017-09-22)","uid":"1341","views":"592","votes":"2"},"_type":"doc"}
{"_id":"289","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505991152","category_id":"12","comments":"1","has_attach":"0","id":"289","message":"【摩拜-北京】 ES高级工程师\n工作职责：\n开发、维护ES，支持各种场景需求\n开发、维护fluentd/flume/kafka等大数据产品\n业务推动，解决大数据、高并发下的产品需求\n跟进研究业界前沿技术，推动产品技术升级\n\n职位要求：\n1. 编程能力扎实，熟悉Java/C++/go中的一种，具有良好的数据结构、算法、操作系统等计算机基本知识；\n2. 熟悉ElasticSearch/Lucene开源系统，有实际开发经验者优先；\n3. 具有敏捷开发、完整产品生命周期开发者优先；\n4. 学习能力强，善于独立思考，思维活跃，对技术有强烈激情；\n\n欢迎投递简历：zhengchangshuai@mobike.com\n薪资20K～50K\n公司属于高速成长的独角兽，非常国际化的一家公司，具体感兴趣的请发简历到邮箱","title":"【摩拜招聘】ES高级工程师","uid":"5402","views":"978","votes":"4"},"_type":"doc"}
{"_id":"298","_index":"forum-mysql","_score":1,"_source":{"addtime":"1506473614","category_id":"18","comments":"0","has_attach":"0","id":"298","message":"1. Elasticsearch大文件检索性能优化\n[url]http://t.cn/R0SZfFx[/url] \n2. 利用Elasticsearch、Beats、Logstash、Grafana完成API实时监控（需要翻墙）\n[url]http://t.cn/R0SZo52[/url] \n3. 小众SKD Elasticsearch的Lua客户端（Github）\n[url]http://t.cn/RLZkGbS[/url] \n \n滴滴招聘：\n[url]https://elasticsearch.cn/article/296[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/298[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第60期 (2017-09-27)","uid":"3828","views":"991","votes":"0"},"_type":"doc"}
{"_id":"307","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507597374","category_id":"18","comments":"0","has_attach":"0","id":"307","message":"1.一步一步教你如何保证elastic-stack数据的安全。\n[url]http://t.cn/ROqjpND[/url] \n2.数据分析师的探险之旅，X-Pack还是R？\n[url]http://t.cn/ROqjYzk[/url] \n3.深入分析如何使用ES中的父子文档。\n[url]http://t.cn/ROqjmzP[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/307[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n ","title":"Elastic日报 第65期 (2017-10-10)","uid":"3788","views":"464","votes":"0"},"_type":"doc"}
{"_id":"308","_index":"forum-mysql","_score":1,"_source":{"addtime":"1507687102","category_id":"18","comments":"0","has_attach":"0","id":"308","message":"1.Elasticsearch Log日志文件的那些事儿(请自备梯子)\nhttp://t.cn/ROJXBR1\n2.还在为 Elasticsearch 集群规划发愁吗？来看看完美方案吧！\nhttp://t.cn/ROJaPRo\n3.来看看 Kibana 6 新增的 dashboard only 模式吧！ \nhttp://t.cn/ROJaiqT\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/308\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第66期 (2017-10-11)","uid":"86","views":"550","votes":"0"},"_type":"doc"}
{"_id":"151","_index":"forum-mysql","_score":1,"_source":{"addtime":"1492136243","category_id":"11","comments":"0","has_attach":"0","id":"151","message":"刚开始学习使用ELK，整理一个学习资料列表，当做备忘录。\n \n[b]1.第一个当然是官方文档[/b]\n[list]\n[*][url=https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html]ElasticSearch参考手册[/url]，学习 DSL查询语法，包括查找（query）、过滤（filter）和聚合（aggs）等。[/*]\n[*][url=https://www.elastic.co/guide/en/logstash/current/index.html]Logstash参考手册[/url]，学习数据导入，包括输入（input）、过滤（filter）和输出（ output）等，主要是filter中如何对复杂文本 进行拆分和类型 转化。[/*]\n[*][url=https://www.elastic.co/guide/en/kibana/current/index.html]Kibana参考手册[/url]，使用Kibana提供的前端界面对数据进行快速展示，主要是对Visulize 模块的使[/*]\n[/list]\n[b]2.中文文档[/b]\n[list]\n[*][b][url=http://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/index.html]ElasticSearch[/url][/b][/*]\n[*]Logstash：[url=http://udn.yyuap.com/doc/logstash-best-practice-cn/index.html]Logstash 最佳实践[/url]，[url=https://kibana.logstash.es/content/]ELKStack中文指南[/url][/*]\n[*]Kibana：[url=https://kibana.logstash.es/content/]ELKStack中文指南[/url][/*]\n[/list]\n \n欢迎补充……","title":"ELK学习资料整理","uid":"2668","views":"4501","votes":"2"},"_type":"doc"}
{"_id":"153","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493016730","category_id":"5","comments":"5","has_attach":"1","id":"153","message":"[attach]553[/attach]\n 感谢 [url=http://ConvertLab.com]ConvertLab[/url] 为本站提供服务器，目前服务器已经迁移完毕，大家可以感受一下速度！\n\n \n[attach]554[/attach]\n同时感谢在此之前为本站提供网站空间的：[url=http://www.plusx.cn]谱时[/url] \n \n \n社区账号也支持 Github 绑定了。\n\n感谢大家一路支持，社区有你更精彩。","title":"社区网站服务器迁移完毕","uid":"1","views":"1719","votes":"0"},"_type":"doc"}
{"_id":"154","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493194466","category_id":"3","comments":"5","has_attach":"0","id":"154","message":"问题发生背景：\n\n1.本来我是使用logstash的默认配置向ES导入日志的。然后很嗨皮，发现一切OK，后来我开始对日志进行聚合统计，发现terms聚合时的key很奇怪，后来查询这奇怪的key,发现这些关键字都是源字符串的一段,而且全部复现场景都是出现\u0026quot;xxxx-xxxxxx\u0026quot;时就会截断，感觉像是分词器搞的鬼。所以想自己定制mapping。下面是原来的logstash配置[code]output{\nelasticsearch{\naction =\u0026gt; \u0026quot;index\u0026quot;\nhosts =\u0026gt; [\u0026quot;xxxxxx:9200\u0026quot;]\nindex =\u0026gt; \u0026quot;xxxxx\u0026quot;\ndocument_type =\u0026gt; \u0026quot;haha\u0026quot;\n}\n}[/code]\n\n\n说干就干：\n\n开始四处查阅文档，发现可以定制mapping，很开心。[code]output{\nelasticsearch{\naction =\u0026gt; \u0026quot;index\u0026quot;\nhosts =\u0026gt; [\u0026quot;xxx\u0026quot;]\nindex =\u0026gt; \u0026quot;logstashlog\u0026quot;\ntemplate =\u0026gt; \u0026quot;xx/http-logstash.json\u0026quot;\ntemplate_name =\u0026gt; \u0026quot;http-log-logstash\u0026quot;\ntemplate_overwrite =\u0026gt; true\n}\nstdout{\ncodec =\u0026gt; rubydebug\n}[/code]\n}没有什么一帆风顺：\n问题1：\n但是我发现我已经上传了自定义的template，但是就是不能生效。\n这时知道了，这个要设置order才能覆盖，默认的order是0，必须更大才行，参考\nhttp://elasticsearch.cn/article/21\n问题2：\n我看到自己上传的template的order已经是1了，怎么还是不生效呢？\n原来自己的索引名称不匹配自己的template的名称，所以不能使用，就又用了默认的template。\n改成下面后OK，终于生效了。（注意index名称变化）output{[code]elasticsearch{\naction =\u0026gt; \u0026quot;index\u0026quot;\nhosts =\u0026gt; [\u0026quot;xxx\u0026quot;]\nindex =\u0026gt; \u0026quot;http-log-logstash\u0026quot;\ndocument_type =\u0026gt; \u0026quot;haha\u0026quot;\ntemplate =\u0026gt; \u0026quot;xxx/http-logstash.json\u0026quot;\ntemplate_name =\u0026gt; \u0026quot;http-log-logstash\u0026quot;\ntemplate_overwrite =\u0026gt; true\n}\nstdout{\ncodec =\u0026gt; rubydebug\n}[/code]\n}问题3：\n发现导入失败，原来自己的时间字符串不能用默认的date的format匹配，\n如2017-04-11 00:07:25   不能用 { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot;} 的默认format匹配，\n改成：\u0026quot;format\u0026quot;: \u0026quot;yyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\u0026quot;}, \n这样就能解析了。\n一切OK，谢谢社区，谢谢Google(你是我见过的除了书籍和老师之后最提升生产力的工具)\n\n附上我的模板[code]{ \n    \u0026quot;template\u0026quot; : \u0026quot;qmpsearchlog\u0026quot;, \n    \u0026quot;order\u0026quot;:1,\n    \u0026quot;settings\u0026quot; : { \u0026quot;index.refresh_interval\u0026quot; : \u0026quot;60s\u0026quot; }, \n    \u0026quot;mappings\u0026quot; : { \n        \u0026quot;_default_\u0026quot; : { \n            \u0026quot;_all\u0026quot; : { \u0026quot;enabled\u0026quot; : false }, \n            \u0026quot;dynamic_templates\u0026quot; : [{ \n              \u0026quot;message_field\u0026quot; : { \n                \u0026quot;match\u0026quot; : \u0026quot;message\u0026quot;, \n                \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot;, \n                \u0026quot;mapping\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; } \n              } \n            }, { \n              \u0026quot;string_fields\u0026quot; : { \n                \u0026quot;match\u0026quot; : \u0026quot;*\u0026quot;, \n                \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot;, \n                \u0026quot;mapping\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; } \n              } \n            }], \n            \u0026quot;properties\u0026quot; : { \n                \u0026quot;@timestamp\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;date\u0026quot;}, \n                \u0026quot;@version\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;integer\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; }, \n                \u0026quot;path\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; }, \n\t\t\t\t\u0026quot;host\u0026quot; : { \u0026quot;type\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot; },\n                \u0026quot;record_time\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;date\u0026quot;,\u0026quot;format\u0026quot;: \u0026quot;yyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\u0026quot;}, \n                \u0026quot;method\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;unionid\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;user_name\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;query\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;ip\u0026quot;:{ \u0026quot;type\u0026quot; : \u0026quot;ip\u0026quot;}, \n                \u0026quot;webbrower\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;os\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;device\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;ptype\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;serarch_time\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;date\u0026quot;,\u0026quot;format\u0026quot;: \u0026quot;yyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\u0026quot;},\n                \u0026quot;have_ok\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;},\n                \u0026quot;legal\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\u0026quot;index\u0026quot; : \u0026quot;not_analyzed\u0026quot;}\n            } \n        } \n    } \n}[/code]\n\n\n ","title":"用logstash导入ES且自定义mapping时踩的坑","uid":"2015","views":"4518","votes":"4"},"_type":"doc"}
{"_id":"156","_index":"forum-mysql","_score":1,"_source":{"addtime":"1493393426","category_id":"5","comments":"6","has_attach":"1","id":"156","message":"这里专门用来放社区网站更新的日志。\n \n[list]\n[*]2017.4.28 支持 SSL[/*]\n[/list]\n[attach]558[/attach]\n ","title":"社区网站更新日志","uid":"1","views":"1370","votes":"2"},"_type":"doc"}
{"_id":"167","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494255503","category_id":"16","comments":"12","has_attach":"1","id":"167","message":"主办：Elastic 中文社区\n\n[attach]589[/attach]\n\n协办：HULU 北京研发中心\n\n[attach]590[/attach]\n\n\n时间：2017-05-21 13:30PM-18:00PM\n地点：北京市朝阳区望京大科技园浦项中心b座21楼  hulu\n \n[b]分享主题：[/b]\n\n[attach]591[/attach]\n个人介绍：倪顺，Hulu软件工程师，ELK粉。主要负责用户播放日志数据的收集，处理和可视化，以及服务监控。\n主题：[b]Elasticsearch 和 Kibana 在 Hulu视频的应用实践[/b]\n内容介绍：Elasticsearch作为优秀的开源工具，很早就在Hulu内部使用。Hulu是一家视频公司，我们在用Elastic stack优化视频播放体验。本次分享中，主要包括：1）Kibana可视化视频播放日志数据；2）Elastic Stack使用的经验tips。\n \n\n[attach]592[/attach]\n \n个人介绍：黄鑫，运维开发工程师，Pythonista，在监控和部署领域耕耘多年，一年前接触了 ELK。\n主题：[b]ELK CI/CD 部署实践[/b]\n内容介绍：\n使用 SaltStack 对 ELK 维护。配置管理，持续集成和持续部署的设计和实施。日常运维管理。\n- 背景介绍\n- 可用性设计\n- 配置管理和持续集成\n- 持续部署\n- 发现的问题和未来展望\n \n\n[attach]593[/attach]\n \n个人介绍：罗喆，最早加入快手的视频技术工程师，负责移动直播系统的构建和调优，并且搭建了基于大数据的质量监测系统，之前曾在腾讯从事实时视音频传输优化工作。\n主题：[b]Elastic Stack驱动的直播体验优化[/b]\n内容介绍：\n移动端视频直播业务经过2016年的井喷期，已经进入下半场，大家的关注点已经从如何构建完善的直播平台的粗放增长阶段，转入精细化运营阶段。如何在巨大的流量、复杂的应用场景、复杂的网络条件下，持续优化用户体验，是我们亟待回答的问题。构建大数据驱动的直播优化体系是快手为应对这一难题所提出的解决方案。\n为此，我们基于完善的Elastic Stack建立了流媒体大数据分析和可视化平台。一切优化均围绕着数据进行：找到用户痛点，指导优化方向，评估优化效果，走出了一条行之有效的数据驱动之路。\n演讲提纲：\n1.     快手直播的业务背景，移动直播体验优化的方法论\n2.     Elastic Stack系统构建历程和真实优化案例","title":"【线下活动】2017-05-21 Elastic Meetup 北京站日程安排","uid":"1","views":"3173","votes":"7"},"_type":"doc"}
{"_id":"171","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494501827","category_id":"2","comments":"8","has_attach":"1","id":"171","message":"[携程旅行网： 吴晓刚]\n 许多有RDBMS/SQL背景的开发者，在初次踏入ElasticSearch世界的时候，很容易就想到使用(Wildcard Query)来实现模糊查询（比如用户输入补全)，因为这是和SQL里like操作最相似的查询方式，用起来感觉非常舒适。然而近期我们线上一个搜索集群的故障揭示了，滥用wildcard query可能带来灾难性的后果。\n\n[b]故障经过[/b]\n线上有一个10来台机器组成的集群，用于某个产品线的产品搜索。数据量并不大，实时更新量也不高，并发搜索量在几百次/s。通常业务高峰期cpu利用率不超过10%，系统负载看起来很低。 但最近这个集群不定期（1天或者隔几天)会出现CPU冲高到100%的问题，持续时间从1分钟到几分钟不等。最严重的一次持续了20来分钟，导致大量的用户搜索请无求响应，从而造成生产事故。\n\n[b]问题排查[/b]\n细节太多，此处略过，直接给出CPU无故飙高的原因: 研发在搜索实现上，根据用户输入的关键词，在首尾加上通配符，使用wildcard query来实现模糊搜索，例如使用\u0026quot;*迪士尼*\u0026quot;来搜索含有“迪士尼”关键字的产品。 然而用户输入的字符串长度没有做限制，导致首尾通配符中间可能是很长的一个字符串。 后果就是对应的wildcard Query执行非常慢，非常消耗CPU。\n\n[b]复现方法[/b]\n1. 创建一个只有一条文档的索引[code]POST test_index/type1/?refresh=true\n{\n  \u0026quot;foo\u0026quot;: \u0026quot;bar\u0026quot;\n}[/code]2. 使用wildcard query执行一个首尾带有通配符*的长字符串查询[code]POST /test_index/_search\n{\n  \u0026quot;query\u0026quot;: {\n    \u0026quot;wildcard\u0026quot;: {\n      \u0026quot;foo\u0026quot;: {\n        \u0026quot;value\u0026quot;: \u0026quot;*在迪士尼乐园，点亮心中奇梦。它是一个充满创造力、冒险精神与无穷精彩的快地。您可在此游览全球最大的迪士尼城堡——奇幻童话城堡，探索别具一格又令人难忘的六大主题园区——米奇大街、奇想花园、梦幻世界、探险岛、宝藏湾和明日世界，和米奇朋友在一起，感觉欢乐时光开业于2016年上海国际旅游度假区秀沿路亚朵酒店位于上海市浦东新区沪南公路（沪南公路与秀沿路交汇处），临近周浦万达广场、地铁11号线秀沿路站，距离上海南站、人民广场约20公里，距离迪线距*\u0026quot;\n      }\n    }\n  }\n}[/code]3. 查看结果[code]{\n  \u0026quot;took\u0026quot;: 3445,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 0,\n    \u0026quot;max_score\u0026quot;: null,\n    \u0026quot;hits\u0026quot;: \n  }\n}[/code]即使no hits，耗时却是惊人的3.4秒 (测试机是macbook pro, i7 CPU)，并且执行过程中，CPU有一个很高的尖峰。\n \n线上的查询比我这个范例要复杂得多，会同时查几个字段，实际测试下来，一个查询可能会执行十几秒钟。 在有比较多长字符串查询的时候，集群可能就DOS了。\n\n[b]探查深层次根源[/b]\n为什么对只有一条数据的索引做这个查询开销这么高？ 直觉上应该是瞬间返回结果才对!\n\n回答这个问题前，可以再做个测试，如果继续加大查询字符串的长度，到了一定长度后，ES直接抛异常了，服务器ES里异常给出的cause如下:\n[quote]\n \nCaused by: org.apache.lucene.util.automaton.TooComplexToDeterminizeException: Determinizing automaton with 22082 states and 34182 transitions would result in more than 10000 states. at org.apache.lucene.util.automaton.Operations.determinize(Operations.java:741) ~[lucene-core-6.4.1.jar:6.4.1\n \n[/quote]\n该异常来自org.apache.lucene.util.automaton这个包，异常原因的字面含义是说[i]“自动机过于复杂而无法确定状态： 由于状态和转换太多，确定一个自动机需要生成的状态超过10000个上限\u0026quot;[/i]\n\n网上查找了大量资料后，终于搞清楚了问题的来龙去脉。为了加速通配符和正则表达式的匹配速度，Lucene4.0开始会将输入的字符串模式构建成一个DFA (Deterministic Finite Automaton)，带有通配符的pattern构造出来的DFA可能会很复杂，开销很大。这个链接的博客[url=http://wpc.github.io/algorithm/2016/01/13/using-dfa-for-wildcard-matching-problem.html ]using-dfa-for-wildcard-matching-problem[/url]比较形象的介绍了如何为一个带有通配符的pattern构建DFA。借用博客里的范例，a*bc构造出来的DFA如下图:\n\n[attach]605[/attach]\n\n[b]Lucene构造DFA的实现[/b]\n看了一下Lucene的里相关的代码，构建过程大致如下:\n1. org.apache.lucene.search.WildcardQuery里的toAutomaton方法，遍历输入的通配符pattern，将每个字符变成一个自动机(automaton)，然后将每个字符的自动机链接起来生成一个新的自动机[code]public static Automaton toAutomaton(Term wildcardquery) {\n    List\u0026lt;Automaton\u0026gt; automata = new ArrayList\u0026lt;\u0026gt;();\n    \n    String wildcardText = wildcardquery.text();\n    \n    for (int i = 0; i \u0026lt; wildcardText.length();) {\n      final int c = wildcardText.codePointAt(i);\n      int length = Character.charCount(c);\n      switch(c) {\n        case WILDCARD_STRING: \n          automata.add(Automata.makeAnyString());\n          break;\n        case WILDCARD_CHAR:\n          automata.add(Automata.makeAnyChar());\n          break;\n        case WILDCARD_ESCAPE:\n          // add the next codepoint instead, if it exists\n          if (i + length \u0026lt; wildcardText.length()) {\n            final int nextChar = wildcardText.codePointAt(i + length);\n            length += Character.charCount(nextChar);\n            automata.add(Automata.makeChar(nextChar));\n            break;\n          } // else fallthru, lenient parsing with a trailing \\\n        default:\n          automata.add(Automata.makeChar(c));\n      }\n      i += length;\n    }\n    \n    return Operations.concatenate(automata);\n  }[/code]2. 此时生成的状态机是不确定状态机，也就是Non-deterministic Finite Automaton（NFA)。\n3. org.apache.lucene.util.automaton.Operations类里的determinize方法则会将NFA转换为DFA  [code]/**\n   * Determinizes the given automaton.\n   * \u0026lt;p\u0026gt;\n   * Worst case complexity: exponential in number of states.\n   * @param maxDeterminizedStates Maximum number of states created when\n   *   determinizing.  Higher numbers allow this operation to consume more\n   *   memory but allow more complex automatons.  Use\n   *   DEFAULT_MAX_DETERMINIZED_STATES as a decent default if you don't know\n   *   how many to allow.\n   * @throws TooComplexToDeterminizeException if determinizing a creates an\n   *   automaton with more than maxDeterminizedStates\n   */\n  public static Automaton determinize(Automaton a, int maxDeterminizedStates) {[/code] 代码注释里说这个过程的时间复杂度最差情况下是状态数量的指数级别！为防止产生的状态过多，消耗过多的内存和CPU，类里面对最大状态数量做了限制[code]  /**\n   * Default maximum number of states that {@link Operations#determinize} should create.\n   */\n  public static final int DEFAULT_MAX_DETERMINIZED_STATES = 10000;[/code]在有首尾通配符，并且字符串很长的情况下，这个determinize过程会产生大量的state，甚至会超过上限。\n \n至于NFA和DFA的区别是什么？ 如何相互转换？ 网上有很多数学层面的资料和论文，限于鄙人算法方面有限的知识，无精力去深入探究。 但是一个粗浅的理解是: NFA在输入一个条件的情况下，可以从一个状态转移到多种状态，而DFA只会有一个确定的状态可以转移，因此DFA在字符串匹配时速度更快。 DFA虽然搜索的时候快，但是构造方面的时间复杂度可能比较高，特别是带有首部通配符+长字符串的时候。\n\n回想Elasticsearch官方文档里对于wildcard query有特别说明，要避免使用通配符开头的term。\n[quote]\n\u0026quot; Note that this query can be slow, as it needs to iterate over many terms. In order to prevent extremely slow wildcard queries, a wildcard term should not start with one of the wildcards * or ?.\u0026quot;\n[/quote]\n\n结合对上面wildcard query底层实现的探究，也就不难理解这句话的含义了！\n\n总结： wildcard query应杜绝使用通配符打头，实在不得已要这么做，就一定需要限制用户输入的字符串长度。 最好换一种实现方式，通过在index time做文章，选用合适的分词器，比如nGram tokenizer预处理数据，然后使用更廉价的term query来实现同等的模糊搜索功能。 对于部分输入即提示的应用场景，可以考虑优先使用completion suggester, phrase/term suggeter一类性能更好,模糊程度略差的方式查询，待suggester没有匹配结果的时候，再fall back到更模糊但性能较差的wildcard, regex, fuzzy一类的查询。\n \n-----------\n补记： 有同学问regex, fuzzy query是否有同样的问题，答案是有，原因在于他们底层和wildcard一样，都是通过将pattern构造成DFA来加速字符串匹配速度的。 ","title":"[原创] ElasticSearch集群故障案例分析: 警惕通配符查询","uid":"81","views":"5278","votes":"12"},"_type":"doc"}
{"_id":"173","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494603748","category_id":"2","comments":"19","has_attach":"1","id":"173","message":"      大家好，我是重构人生，很开心能在这里和大家分享我的免费Elasticsearch 视频教程。 我是一个Elasticsearch 的DevOps ，使用了很久的开源软件，在开源社区也获得过很多小伙伴的帮助。我希望自己能为社区贡献自己的一份力。\n \n      我应该算是个热心肠的人吧，喜欢乐于助人，不过有些人的提问方式让我非常反感，甚至是厌恶，什么样的人呢，第一种，官方文档，或者百度，或者GOOGLE，等方式轻易的就可以找到解决方案却仍然拿出来提问的人。 第二种就是什么条件、环境都不描述，背景也不说上来就问，怎么样最好，如何性能最快，怎么做才能最稳定的人，我说话比较直，勿怪，对于这类人，你至少要让他知道一些概念，不然根本没法交流。  \n \n       为了解决这些问题，我想提供一种快速让一些没有经验或者经验不足的朋友去快速了解Elasticsearch，了解ES能做什么，了解ES怎么做才能达到你的要求，带着这些问题，我在头脑里构思了 两个系列的视频，第一个是ES-教程篇， 第二个是ES-实战篇,把实际的生产环境中的一些场景，剥离业务相关的，保密性的东西，以纯技术的方式与大家分享下，看我们是如何踩坑，填坑的。\n\n由于视频是个人行为，非商业性质，所以不可能做到定时更新，这点还请大家见谅，不过我肯定会用心去做。\n \n所有的视频会以两个方式去提供，一个是百度云盘里下载完整的压缩包，里面包含了视频、PPT、以及配置文件信息。另一种是通过优库视频直接看视频，PPT和配置文件到百度云上去下载。\n \n \n百度云： [url]https://pan.baidu.com/s/1i4ZsORF[/url]\n优酷：[url]http://i.youku.com/rickywag[/url]\n \n \n感谢你们的支持，如果觉得不错可以打赏我哟。","title":"分布式搜索引擎教程-Elasticsearch","uid":"2363","views":"5670","votes":"6"},"_type":"doc"}
{"_id":"174","_index":"forum-mysql","_score":1,"_source":{"addtime":"1494729697","category_id":"2","comments":"1","has_attach":"0","id":"174","message":"一直想找一个数据库用于存储各种的代码片段\n\nmysql会一点 mongodb也看过\n\n但是最终都没有弄成（或许是我性格的原因，想的太多，做的太少（算是过度设计的一种吧））\n\n后来发现了ElasticSearch\n\n觉得他能够实现我的想法（或许只是他简介里的一句话，大致的意思是：多看看数据，而非让他们躺在仓库里）\n\n我会将过程记录下来，希望对后来人有帮助\n\n（不过一切都是在Emacs环境下的，知道的人应该不多，所以能帮到的人也就更少了（其实他们也不用我帮））","title":"Emacs与ElasticSearch","uid":"2867","views":"2016","votes":"0"},"_type":"doc"}
{"_id":"182","_index":"forum-mysql","_score":1,"_source":{"addtime":"1496223919","category_id":"9","comments":"9","has_attach":"1","id":"182","message":"去年我们社区一起翻译了一本书《Elasticsearch权威指南》，并且已经在官方上线了，链接：\r\n[url]https://www.elastic.co/guide/cn/index.html[/url] \r\n \r\n[b]撒花~[/b] ???????????????????\r\n \r\n我想给大家分享一些这本书后面的故事：\r\n \r\n大家在浏览到[b]前言[/b]章节里面有一节“[url=https://www.elastic.co/guide/cn/elasticsearch/guide/current/_acknowledgments.html]鸣谢[/url]”，里面可以看到很多熟悉的名字：\r\n \r\n薛杰，骆朗，彭秋源，魏喆，饶琛琳， 风虎，路小磊，michealzh，nodexy，sdlyjzh，落英流离， sunyonggang，Singham，烧碱，龙翔，陈思，陈华， 追风侃侃，Geolem，卷发，kfypmqqw，袁伟强，yichao， 小彬，leo，tangmisi，Alex，baifan，Evan，fanyer， wwb，瑞星，刘碧琴，walker，songgl， 吕兵，东，杜宁，秦东亮，biyuhao，刘刚， yumo，王秀文，zcola，gitqh，blackoon，David，韩炳辰， 韩陆，echolihao，Xargin，abel-sun，卞顺强， bsll，冬狼，王琦，Medcl。\r\n \r\n是的，这些就是我们权威指南的核心的译者了，虽然只是列了一个名字，但是其实背后付出了很多，有一些同学是在此之前就已经做过部分翻译的同学，如：路小磊，有一些是早就出版了多本书的资深作家了，如：饶琛琳，还有很多是社区里面一直就非常活跃的同学，各种线上线下活动都能看到你们的身影，感谢你们。\r\n \r\n记得去年刚刚开始这个翻译的计划的时候，短短几天时间就收到了很多同学的报名，一下子累积人数多达80人，\r\n正所谓人多就是力量，不过任务的分配和管理也就成了一个问题，要知道权威指南纸质版有650多页，\r\n很厚的一本书，内容也真是非常多。我记得项目应该是3月份启动，到了5月份还没什么大的进展，大家都在摸索怎么去翻译，大家都无从下手，我也着急啊??，这个时候要感谢社区的热心成员：龙翔，?，他把他老婆Claire拉到我们翻译计划里面来了，?，这个翻译的事情总算有了转机，Claire在翻译项目的管理这块很专业?，提出了很多建设性意见，✍️，我们成立了一个翻译小组委员会，?，然后形成了5个翻译小组，?，每个小组由一个小组长来负责（大家积极踊跃）：\r\nA组：薛杰；\r\nB组：骆朗；\r\nC组：彭秋源；\r\nD组：饶琛琳；\r\nE组：魏喆；\r\n这样，几十个翻译志愿者分别分到了不同的翻译小组，然后以翻译小组为单位进行翻译计划的分配和认领，任务也比较具体，小组成员再内部进行协调，有问题大家一起讨论，小组内部内也可以讨论，然后翻译就开始顺利的进行了！?\r\n \r\n所以在这里要特别感谢龙翔两口子和几位翻译小组的小组长，当然还有各组的小组成员，如果没有你们，翻译工作估计要到进行到猴年马月啦，?，大家官网上面现在也看不到这些中文的资料啦！?\r\n \r\n顺便值得一提的是，同时期还有另外一个开源社区也在翻译权威指南（韩文），并且比我们早开始，然后我们在去年12月份的时候就完成了，赶在Elastic{ON}DevChina大会之前完成的，而现在我们的已经上线了，也不知道他们的完成了没有，?。\r\n \r\n权威指南的原作者Clinton和Zachary听说了我们的翻译的事情，都很兴奋，本来打算要来中国参加Elastic{ON}DevChina大会的，不过很遗憾，因为种种原因都没能过来，不过他们很支持我们，帮忙解决了后面上线的很多技术细节。\r\n \r\n相信很多人想了解具体是怎么做的，我再给大家具体介绍一下，任务的管理和分配，我们使用GoogleDocs来进行协助，大家都有修改权限，常见的术语和FAQ也都会放在里面。\r\n链接：[url=https://docs.google.com/spreadsheets/d/1vzPqcYJfz6ouY053E6WUdvS9WR8XqcHPyB7_U-72b_Q/edit?pref=2undefinedpli=1#gid=1600884528]https://docs.google.com/spreadsheets/d/1vzPqcYJfz6ouY053E6WUdvS9WR8XqcHPyB7_U-72b_Q/edit?pref=2\u0026amp;pli=1#gid=1600884528[/url]\r\n \r\n另外关于本书翻译的项目管理，我们直接使用的是GitHub（[url]https://github.com/elasticsearch-cn/elasticsearch-definitive-guide[/url] ），以asciidoc源文件为最小提交单元，每翻译完成一个文件，提交一个PR，每个PR单独Review，每个PR正常需要两个同学Review确认，正常的GitHub操作流程，和提交代码一样（文档其实本来也是和代码一样），翻译完成一篇之后，提交一个PR，打上标签“to be review”，表示翻译完了可以被Review了，Reviewer如果认可了就留言\u0026quot;LGTM\u0026quot;, 然后打上标签“To be merged”，如果有不同意见，可以在PR上面留言讨论，PR提交人可以结合意见探讨或者修改，有些PR可以要讨论和修改很多次，比如这个：[url=https://github.com/elasticsearch-cn/elasticsearch-definitive-guide/pull/9]https://github.com/elasticsearch-cn/elasticsearch-definitive-guide/pull/4[/url]，真的是不厌其烦，截止目前为止，总共提交了470多个翻译相关的PR。\r\n \r\n为什么要以Asciidoc源文件作为翻译的基础，而不是gitdoc、wiki、markdown等等呢，因为我们可以保证后续的样式和官网一致，翻译审核完成之后就能够直接的放到官网上面，以提供给更多的人去访问和学习，同时官方的docs工具链也很完善，也支持编译输出成各种格式，如PDF等。另外文档和英文格式保持一致且也是托管在GitHub上面，方便后续的更新和维护，现在权威指南英文版正在更新到最新，到时候我们可以很方便的检测变化然后同步更新，文档即源码，文档是开源重要的一部分，参与开源的方式其实也有很多种，贡献代码和贡献文档都是同等重要的啦。可持续性更新也很重要。\r\n \r\n是不是权威指南翻译完了之后就结束了呢，答案是：NO！\r\n文档和代码一样，也有Bug，也要不断完善，虽然我们在提交翻译和Review的过程中有反复进行过修改和进行过多轮的Review，（先是小组内部进行第一轮Review，打上标签“To be final review”，然后再由另外一个组的同学进行Review，然后在打上“To be merge”），但是由于大家水平有限，难免会出现各种翻译不准确、格式、表达等问题，所有希望大家能够继续帮忙改进，可以继续提交PR来完善修改，如果说嫌麻烦，可以发Issue说明哪里有问题或者觉得可以再讨论的地方，提供建设性意见。\r\n \r\n后续也会有新的翻译，也希望大家踊跃参加，为Elastic中文的社区贡献力量。\r\n \r\n一直想写这篇文章，今天终于完成啦！\r\n最后来一张上次来参加Elastic{ON}DevChina的译者合影！\r\n\r\n[attach]653[/attach]\r\n \r\n","title":"《Elasticsearch权威指南》中文版背后的故事","uid":"1","views":"3367","votes":"6"},"_type":"doc"}
{"_id":"192","_index":"forum-mysql","_score":1,"_source":{"addtime":"1498727817","category_id":"12","comments":"1","has_attach":"0","id":"192","message":"\n企业培训公司面向单位员工培训，长期招Cassandra兼职老师，一般三天左右的短周期培训，周末为主，有2人左右的小辅导，也有30人左右的培训大班，待遇优，北京，上海，成都，广州，深圳等，如您想挣点外块，积累资源，充实生活，请联系我。 \n\n要求：\n相关技术专业，本科及以上学历； \n三年以上实际项目经验； \n认真，热情，耐心，乐于助人，不保守，表达能力较好。具体再议。 \n\n感兴趣的可以联系：QQ 2355811930 ；QQ1489302364，微信15501239699，简历接收邮箱：admin@info-soft.cn \n \n \n ","title":"招兼职Cassandra培训讲师","uid":"3218","views":"885","votes":"0"},"_type":"doc"}
{"_id":"194","_index":"forum-mysql","_score":1,"_source":{"addtime":"1499616657","category_id":"2","comments":"1","has_attach":"0","id":"194","message":"spark1.6.x   elasticsearch5.x  \n \nnetty冲突\n \n[code](Netty4Utils:117)-NoSuchMethodError io.netty.buffer.CompositeByteBuf.addComponents(ZLjava/lang/Iterable;)Lio/netty/buffer/CompositeByteBuf;\nat org.elasticsearch.transport.netty4.Netty4Utils.toByteBuf(Netty4Utils.Java:78)\nat org.elasticsearch.transport.netty4.Netty4Transport.sendMessage(Netty4Transport.java:422)\nat org.elasticsearch.transport.netty4.Netty4Transport.sendMessage(Netty4Transport.java:93)\nat org.elasticsearch.transport.TcpTransport.internalSendMessage(TcpTransport.java:1058)\nat org.elasticsearch.transport.TcpTransport.sendRequestToChannel(TcpTransport.java:1040)\n[/code] 试过其他jar排除方案都不生效，暂时可以fix的解决方案\n \n```\n.put(\u0026quot;transport.type\u0026quot;,\u0026quot;netty3\u0026quot;)\n```","title":"spark1.6.3+elasticsearch5.4 netty jar冲突","uid":"2171","views":"2397","votes":"1"},"_type":"doc"}
{"_id":"195","_index":"forum-mysql","_score":1,"_source":{"addtime":"1500342274","category_id":"17","comments":"4","has_attach":"1","id":"195","message":"Vega：\r\n[url]https://vega.github.io/vega/examples/[/url]\r\n \r\nVega是什么？\r\n相比其他第三方可视化库，Vega的目的是让你更快将数据进行展现，vega通过声明的方式可以快速将你的数据进行各种格式化，而不用纠结于具体的调用细节，和SQL这种通用式交互语言类似，数据的输入是JSON。\r\n\r\n[attach]794[/attach]\r\n \r\nVega的Kibana插件下载地址：\r\n[url]https://github.com/nyurik/kibana-vega-vis/releases[/url]\r\n \r\n安装之后，就能在可视化类型里面选择Vega了，使用起来很简单，输入相应的描叙语言，如：\r\n[code]{\r\n  \u0026quot;$schema\u0026quot;: \u0026quot;https://vega.github.io/schema/vega-lite/v2.json\u0026quot;,\r\n  \u0026quot;description\u0026quot;: \u0026quot;A simple bar chart with embedded data.\u0026quot;,\r\n  \u0026quot;width\u0026quot;: 300, \u0026quot;height\u0026quot;: 200, \u0026quot;padding\u0026quot;: 5,\r\n  \u0026quot;data\u0026quot;: {\r\n    \u0026quot;values\u0026quot;: [\r\n      {\u0026quot;a\u0026quot;: \u0026quot;A\u0026quot;,\u0026quot;b\u0026quot;: 28}, {\u0026quot;a\u0026quot;: \u0026quot;B\u0026quot;,\u0026quot;b\u0026quot;: 55}, {\u0026quot;a\u0026quot;: \u0026quot;C\u0026quot;,\u0026quot;b\u0026quot;: 43},\r\n      {\u0026quot;a\u0026quot;: \u0026quot;D\u0026quot;,\u0026quot;b\u0026quot;: 91}, {\u0026quot;a\u0026quot;: \u0026quot;E\u0026quot;,\u0026quot;b\u0026quot;: 81}, {\u0026quot;a\u0026quot;: \u0026quot;F\u0026quot;,\u0026quot;b\u0026quot;: 53},\r\n      {\u0026quot;a\u0026quot;: \u0026quot;G\u0026quot;,\u0026quot;b\u0026quot;: 19}, {\u0026quot;a\u0026quot;: \u0026quot;H\u0026quot;,\u0026quot;b\u0026quot;: 87}, {\u0026quot;a\u0026quot;: \u0026quot;I\u0026quot;,\u0026quot;b\u0026quot;: 52}\r\n    ]\r\n  },\r\n  \u0026quot;mark\u0026quot;: \u0026quot;bar\u0026quot;,\r\n  \u0026quot;encoding\u0026quot;: {\r\n    \u0026quot;x\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;a\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;ordinal\u0026quot;},\r\n    \u0026quot;y\u0026quot;: {\u0026quot;field\u0026quot;: \u0026quot;b\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;quantitative\u0026quot;}\r\n  }\r\n}[/code]Vega支持各种可视化类型，更多详情请参照文档和例子：\r\n[url]https://vega.github.io/vega-lite/docs/mark.html#mark-def[/url]\r\n[url]https://vega.github.io/vega/examples/[/url]\r\n[url]https://github.com/nyurik/kibana-vega-vis#quick-demo[/url]","title":"Kibana 新的可视化插件：Vega","uid":"1","views":"5219","votes":"0"},"_type":"doc"}
{"_id":"196","_index":"forum-mysql","_score":1,"_source":{"addtime":"1500459112","category_id":"2","comments":"1","has_attach":"1","id":"196","message":"饿了么搜索推荐研发部现热招搜索相关人才\r\n投递方式：wei.chen04@ele.me\r\nQQ：2908368828\r\n岗位福利：定期技术分享，良好的技术氛围，超级nice的leader，五险一金＋补充商业保险等多种福利政策\r\n薪资：行业内有竞争力的薪资\r\n坐标：上海市普陀区金沙江路，13号线真北路下，地铁出来即是，大热天不怕晒\r\n \r\n\r\n一、搜索架构工程师\r\n岗位职责：\r\n\r\n1、负责在线搜索服务的稳定性，性能，时效性和扩展性；\r\n2、负责构建一套能快速满足多种业务检索需求的通用搜索平台；\r\n3、负责分布式搜索服务架构设计、开发与优化、稳定性监控和维护；\r\n4、关注行业搜索技术，引进和改善搜索架构；\r\n\r\n职位要求：\r\n1、本科以上学历 ，3年以上搜索相关工作经验\r\n2、精通Lucene、Elastic Search开发和实战，能够修改Lucene、Elastic Search源代码\r\n3、精通高可用、高并发分布式系统设计，有熟悉分布式搜索系统的架构和运维经验者有些\r\n4、熟练掌握多线程，线程池技术，对网络通信、异步通信、高并发访问、负载均衡等技术有深入了解\r\n5、具有高度的抽象设计能力，思路清晰，善于思考，能独立驱动、分析和解决问题\r\n6、责任心强，良好的沟通交流、团队合作精神、以结果为导向\r\n\r\n二、高级搜索工程师（Elasticsearch）\r\n\r\n    岗位职责：\r\n 1、参与平台化的各类搜索相关的功能；\r\n 2、参与系统的设计和核心代码的编写；\r\n 3、明确搜索业务需求，按时完成指定模块的设计与开发，并确保质量；\r\n 4、对自己的代码要求严格，并对已有模块进行优化升级；\r\n 5、搜索算法研究及实现，搜索相关扩展应用研发；\r\n 6、善于思考，能解决复杂的ES性能调优问题。\r\n\r\n任职要求：\r\n 1、211本科以上学历，计算机或者相关专业；\r\n 2、至少一年Elasticsearch开发经验，一年Java开发经验；\r\n 3、掌握搜索引擎基本原理、相关检索、排序算法和数据结构，良好的数据结构基础；\r\n 4、熟悉Java开发语言，熟悉Spring MVC、iBatis、netty等主流框架，熟练使用eclipse等开发工具；\r\n 5、熟悉MySQL数据库应用；\r\n 6、熟悉lucene，ELK生态，大数据平台优先；\r\n 7、对技术富有激情，对新技术有了解，思路清晰；\r\n 8、工作态度积极、踏实、认真，有责任感，有团队合作意识；\r\n \r\n \r\n欢迎大家推荐或者自荐～\r\n\r\n\r\n\r\n\r\n\r\n ","title":"［热招］饿了么搜索推荐研发部招聘信息","uid":"3377","views":"2286","votes":"2"},"_type":"doc"}
{"_id":"267","_index":"forum-mysql","_score":1,"_source":{"addtime":"1505094111","category_id":"18","comments":"0","has_attach":"0","id":"267","message":"1.使用elk来对spring Boot 程序可视化\n\nhttp://t.cn/RpM5eM4\n\n2.很多不做java的同学都不太了解es和logstash的自动垃圾回收，这里介绍一下java的gc体系\n\nhttp://t.cn/RpMf7Ve\n\n3.用Elasticsearch处理非范式数据。\n\nhttp://t.cn/RpMpNC5\n编辑：cyberdak\n\n归档：https://elasticsearch.cn/article/267\n\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第44期 (2017-09-11)","uid":"4063","views":"558","votes":"0"},"_type":"doc"}
{"_id":"318","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508202755","category_id":"18","comments":"0","has_attach":"0","id":"318","message":"1.饕餮盛宴，2017年官方推荐的Elastic十大精彩演讲，涵盖机器学习、X-pack、SQL等内容，值得收藏。\n[url]http://t.cn/R0cF6fm[/url] \n2.升级到kibana5.5.3时你可能需要重点关注的一些内容。\n[url]http://t.cn/ROQdl04[/url] \n3.低成本高回报，使用MapR网关功能复制数据到es并进行全文搜索、可视化显示。\n[url]http://t.cn/ROQdHCz[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/318[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第72期 (2017-10-17)","uid":"3788","views":"481","votes":"0"},"_type":"doc"}
{"_id":"320","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508314016","category_id":"16","comments":"0","has_attach":"1","id":"320","message":"[attach]1168[/attach]\n \nElastic Meetup 下半年活动首站位于长沙，是湖南省省会，古称潭州，别名星城，历经三千年城名、城址不变，有“屈贾之乡”、“楚汉名城”、“潇湘洙泗”之称。\n \n\n[b]主办：[/b]\n本次活动由 Elastic 与长沙软件园联合举办。\n \n[b]时间：[/b]\n2017.10.28​  下午2:30-5:30\n \n[b]地点：[/b]\n长沙市岳麓区岳麓大道588号芯城科技园2栋4楼会议室\n \n[b]主题：[/b]\n[list=1]\n[*]Elastic - Medcl - Elastic Stack 6.0 新功能介绍[/*]\n[*]芒果 TV - 刘波涛 - 芒果日志之旅[/*]\n[*]基于爬虫和 Elasticsearch 快速构建站内搜索引擎[/*]\n[*]闪电分享（5-10分钟，可现场报名）[/*]\n[/list]\n \n[b]参会报名：[/b]\nhttp://elasticsearch.mikecrm.com/O6o0yq3\n \n\n \n\n武汉、广州、深圳也在筹备中：https://elasticsearch.cn/article/261\n \n \n[b]关于 Elastic Meetup[/b]\nElastic Meetup 由 Elastic 中文社区定期举办的线下交流活动，主要围绕 Elastic 的开源产品（Elasticsearch、Logstash、Kibana 和 Beats）及周边技术，探讨在搜索、数据实时分析、日志分析、安全等领域的实践与应用。\n\n\n \n[b]关于 Elastic[/b]\n\n[b][attach]1157[/attach][/b]\n\nElastic 通过构建软件，让用户能够实时地、大规模地将数据用于搜索、日志和分析场景。Elastic 创立于 2012 年，相继开发了开源的 Elastic Stack（Elasticsearch、Kibana、Beats 和 Logstash）、X-Pack（商业功能）和 Elastic Cloud（托管服务）。截至目前，累计下载量超过 1.5 亿。Benchmark Capital、Index Ventures 和 NEA 为 Elastic 提供了超过 1 亿美元资金作为支持，Elastic 共有 600 多名员工，分布在 30 个国家/地区。有关更多信息，请访问 elastic.co/cn。\n \n[b]关于长沙软件园[/b]\n\n[b][attach]1156[/attach][/b]\n\n长沙软件园有限公司成立于2001年，注册资本3000万元人民币，位于长沙高新区麓谷科技新城，是国家科技部批准的国家火炬计划软件产业基地、国家数字媒体技术产业化基地、国家863软件专业孵化器，是国家发改委、信息产业部批准的中部地区唯一的国家软件产业基地。\n\n现有专职的管理和专业技术人员40多人，全部具有大学本科及以上学历，其中硕士和博士学历人员占35％左右，具有中高级职称人员占50％左右，具备丰富的软件行业管理、产业服务和专业技术服务的经历和经验。\n\n从软件园有限公司正式成立以来，先后承担科技部火炬计划项目：“中间件技术公共应用开发平台”和“长沙资源信息管理系统”、“长沙软件园优势领域关键共性技术开发应用平台”；承担了2个国家科技部863项目：“面向网络应用集成的软件支撑环境”、“支持银税类控制设备智能化升级的嵌入式软件平台”，承担了国家火炬计划课题，所有课题均顺利结题。\n \n \n再次感谢长沙软件园的大力支持!","title":"Elastic Meetup 长沙交流会","uid":"1","views":"1430","votes":"1"},"_type":"doc"}
{"_id":"325","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508452506","category_id":"2","comments":"3","has_attach":"0","id":"325","message":"http://mp.weixin.qq.com/s/fqy-UVGDDg35uSOEqDbaiA","title":"刨根问底 | Elasticsearch 5.X集群多节点角色配置深入详解","uid":"1341","views":"1317","votes":"1"},"_type":"doc"}
{"_id":"326","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508547290","category_id":"18","comments":"0","has_attach":"0","id":"326","message":"1.在macOS上利用Elastic Stack做登录日志处理的详细案例\n\nhttp://t.cn/RWhNVBa\n\n2.五种可能导致ES集群崩溃的操作，尤其针对5.0以下版本：\n\nhttp://t.cn/RWhjdXR\n\n3.适用于ES的情感分析插件\n\nhttp://t.cn/RWhTFH6\n\n活动预告：Elastic 长沙交流会\n\nhttps://elasticsearch.cn/article/320\n\n\n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/326\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第76期 (2017-10-21)","uid":"1874","views":"446","votes":"0"},"_type":"doc"}
{"_id":"329","_index":"forum-mysql","_score":1,"_source":{"addtime":"1508807857","category_id":"18","comments":"0","has_attach":"0","id":"329","message":"1.携程机票ElasticSearch集群运维实战。\n[url]http://t.cn/RWcy38O[/url] \n2.Elasticsearch监控那些事，指标详解！\n[url]http://t.cn/RWcyeLk[/url] \n3.微软Azure使用Elastic Stack之初体验。\n[url]http://t.cn/RWcUv6z[/url] \n活动预告：Elastic 长沙交流会\n[url]https://elasticsearch.cn/article/320[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/329[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第79期 (2017-10-24)","uid":"3788","views":"463","votes":"0"},"_type":"doc"}
{"_id":"334","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509016814","category_id":"2","comments":"1","has_attach":"0","id":"334","message":"[size=10][b]一，preference简述[/b][/size]\n\nelasticsearch可以使用preference参数来指定分片查询的优先级，即我们可以通过该参数来控制搜索时的索引数据分片。\n\n如不设置该参数：在所有有效的主分片以及副本间轮询。\n\n具体可看下：OperationRouting.java类\n[code]public ShardIterator activeInitializingShardsRandomIt() {\n    return activeInitializingShardsIt(shuffler.nextSeed());\n}  \n//自增，以实现shard间轮询操作\npublic int nextSeed() {\n    return seed.getAndIncrement();\n }\n \npublic ShardIterator activeInitializingShardsIt(int seed) {\n    if (allInitializingShards.isEmpty()) {\n        return new PlainShardIterator(shardId, shuffler.shuffle(activeShards, seed));\n    }\n    ArrayList\u0026lt;ShardRouting\u0026gt; ordered = new ArrayList\u0026lt;\u0026gt;(activeShards.size() + allInitializingShards.size());\n    ordered.addAll(shuffler.shuffle(activeShards, seed));\n    ordered.addAll(allInitializingShards);\n    return new PlainShardIterator(shardId, ordered);\n}[/code][code] private ShardIterator preferenceActiveShardIterator(IndexShardRoutingTable indexShard, String localNodeId, DiscoveryNodes nodes, @Nullable String preference) {\n        if (preference == null || preference.isEmpty()) {\n            if (awarenessAttributes.length == 0) {\n                return indexShard.activeInitializingShardsRandomIt();\n            } else {\n                return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes);\n            }\n        }\n        if (preference.charAt(0) == '_') {\n            Preference preferenceType = Preference.parse(preference);\n            if (preferenceType == Preference.SHARDS) {\n                // starts with _shards, so execute on specific ones\n                int index = preference.indexOf('|');\n\n                String shards;\n                if (index == -1) {\n                    shards = preference.substring(Preference.SHARDS.type().length() + 1);\n                } else {\n                    shards = preference.substring(Preference.SHARDS.type().length() + 1, index);\n                }\n                String[] ids = Strings.splitStringByCommaToArray(shards);\n                boolean found = false;\n                for (String id : ids) {\n                    if (Integer.parseInt(id) == indexShard.shardId().id()) {\n                        found = true;\n                        break;\n                    }\n                }\n                if (!found) {\n                    return null;\n                }\n                // no more preference\n                if (index == -1 || index == preference.length() - 1) {\n                    if (awarenessAttributes.length == 0) {\n                        return indexShard.activeInitializingShardsRandomIt();\n                    } else {\n                        return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes);\n                    }\n                } else {\n                    // update the preference and continue\n                    preference = preference.substring(index + 1);\n                }\n            }\n            preferenceType = Preference.parse(preference);\n            switch (preferenceType) {\n                case PREFER_NODES:\n                    final Set\u0026lt;String\u0026gt; nodesIds =\n                            Arrays.stream(\n                                    preference.substring(Preference.PREFER_NODES.type().length() + 1).split(\u0026quot;,\u0026quot;)\n                            ).collect(Collectors.toSet());\n                    return indexShard.preferNodeActiveInitializingShardsIt(nodesIds);\n                case LOCAL:\n                    return indexShard.preferNodeActiveInitializingShardsIt(Collections.singleton(localNodeId));\n                case PRIMARY:\n                    return indexShard.primaryActiveInitializingShardIt();\n                case REPLICA:\n                    return indexShard.replicaActiveInitializingShardIt();\n                case PRIMARY_FIRST:\n                    return indexShard.primaryFirstActiveInitializingShardsIt();\n                case REPLICA_FIRST:\n                    return indexShard.replicaFirstActiveInitializingShardsIt();\n                case ONLY_LOCAL:\n                    return indexShard.onlyNodeActiveInitializingShardsIt(localNodeId);\n                case ONLY_NODES:\n                    String nodeAttributes = preference.substring(Preference.ONLY_NODES.type().length() + 1);\n                    return indexShard.onlyNodeSelectorActiveInitializingShardsIt(nodeAttributes.split(\u0026quot;,\u0026quot;), nodes);\n                default:\n                    throw new IllegalArgumentException(\u0026quot;unknown preference [\u0026quot; + preferenceType + \u0026quot;]\u0026quot;);\n            }\n        }\n        // if not, then use it as the index\n        if (awarenessAttributes.length == 0) {\n            return indexShard.activeInitializingShardsIt(Murmur3HashFunction.hash(preference));\n        } else {\n            return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes, Murmur3HashFunction.hash(preference));\n        }\n    }\n[/code] \n \n[b]二，结果震荡问题（Bouncing Results）[/b]\n \n搜索同一query，结果ES返回的顺序却不尽相同，这就是请求轮询到不同分片，而未设置排序条件，相同相关性评分情况下，是按照所在segment中​lucene id来排序的，相同数据的不同备份之间该id是能保证一致的，故造成结果震荡问题。\n如设置该参数，则有一下9中情况\n\n`_primary`:发送到集群的相关操作请求只会在主分片上执行。\n`_primary_first`:指查询会先在主分片中查询，如果主分片找不到（挂了），就会在副本中查询。 \n`_replica`:发送到集群的相关操作请求只会在副本上执行。\n`_replica_first`：指查询会先在副本中查询，如果副本找不到（挂了），就会在主分片中查询。\n`_local`: 指查询操作会优先在本地节点有的分片中查询，没有的话再在其它节点查询。\n`_prefer_nodes:abc,xyz`:在提供的节点上优先执行（在这种情况下为'abc'或'xyz'）\n`_shards:2,3`：限制操作到指定的分片。 （`2`和“3”）。这个偏好可以与其他偏好组合，但必须首先出现：`_shards：2,3 | _primary`\n`_only_nodes:node1,node2`:指在指定id的节点里面进行查询，如果该节点只有要查询索引的部分分片，就只在这部分分片中查找，不同节点之间用“，”分隔。\n\ncustom(自定义)：注意自定义的preference参数不能以下划线\u0026quot;_\u0026quot;开头。\n当preference为自定义时，即该参数不为空，且开头不以“下划线”开头时，特别注意：如果以用户query作为自定义preference时，一定要处理以下划线开头的情况，这种情况下如果不属于以上8种情况，则会抛出异常。\n\n\n[b]三，参考：[/b]\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-preference.html\n ","title":"【源码篇】elasticsearch 搜索模块之preference参数","uid":"6245","views":"2112","votes":"3"},"_type":"doc"}
{"_id":"341","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509159457","category_id":"18","comments":"0","has_attach":"0","id":"341","message":"1.ES选举-类Bully算法\nhttp://t.cn/RWWD6LM\n2.如何更优雅的定制开发elasicsearch插件\nhttps://elasticsearch.cn/article/339\n3.你应该了解的5个 Logstash Filter 插件\nhttps://elasticsearch.cn/article/332\n活动预告：Elastic 长沙交流会 \nhttps://elasticsearch.cn/article/320\n\n感谢jiangtao，dongne的投稿。\n编辑：金桥\n归档：https://elasticsearch.cn/article/341\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第83期 (2017-10-28)","uid":"668","views":"449","votes":"0"},"_type":"doc"}
{"_id":"345","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509413078","category_id":"18","comments":"2","has_attach":"0","id":"345","message":"1.logstash实战，深入分析思科Meraki日志消息。\n[url]http://t.cn/RWrfOI7[/url] \n2.基于 Elasticsearch实现搜索建议的一些方法。\n[url]http://t.cn/RWrfudV[/url] \n3.如何在windows上安装Logstash与Kibana。\n[url]http://t.cn/RWrfQij[/url] \n活动预告：Elastic 武汉交流会 \n[url]https://elasticsearch.cn/article/344[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/345[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第86期 (2017-10-31)","uid":"3788","views":"408","votes":"0"},"_type":"doc"}
{"_id":"347","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509495954","category_id":"18","comments":"0","has_attach":"0","id":"347","message":"1. Scroll API 详解（文章有点老）\n[url]http://t.cn/RlvDxqS[/url] \n2. 你真的了解 ES 的分页么？\n[url]http://t.cn/Rlvzfni[/url] \n3. 分页查询 From\u0026amp;Size VS scroll\n[url]http://t.cn/RGBeOOK[/url] \n活动预告：Elastic 武汉交流会\n[url]https://elasticsearch.cn/article/344[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/347[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第87期 (2017-11-01)","uid":"3828","views":"439","votes":"0"},"_type":"doc"}
{"_id":"348","_index":"forum-mysql","_score":1,"_source":{"addtime":"1509501099","category_id":"2","comments":"7","has_attach":"1","id":"348","message":"先观察了下集群系统资源的使用情况，发现网络、磁盘、内存等都没有什么迹象，唯独 CPU 负载就是居高不下，系统响应很慢，几乎不响应。几次使用 JVM 命令都无功而返。经过多次使用 Top 命令，才发现导致 CPU 负载过高（飙到200多）是 %sy 这项，表面现象是操作系统内核导致。之前无数次怀疑 Java 程序问题，GC 问题，看来方向错了，既然耗那么长时间才找到一丝线索，应该好好利用。\r\n    尝试了一些命令后，发现和使用 JVM 命令一样，搞不定，比如用 ltrace 就导致 JVM 进程僵死。由于并非稳定重现，耗时好几天，才使用 strace -T -r -c -f -F -p 得到 futex、epoll_wait 占用资源。这不行，这些信息不足以说明或支撑如何解决负载问题，但 futex 这个是系统调用是互斥的信号，难道有锁方面问题，似乎应该从这个方面下手。\r\n    Linux 中有什么好的工具能在这种敲命令都没响应的情况下来获取一些信息呢？于是再找一些工具，gdb 尝试了下，直接卡死，搞不定。gstack、gcore 都不行，难道非得要 dump kernel core？\r\n但即使得到了，我对 Linux 内核的分析还没多少经验，而且耗时，中间少不了服务器频繁重启，不到万不得已不走这一步。\r\n    找了一些工具：systemtap、stap、dtrace、perf 等，于是在非繁忙时候搞了一把，systemtap 的 On-CPU、Off-CPU 及火焰图不错，至少我能拿到内核系统调用到底是哪些，然后针对火焰图里耗时的系统调用信息再找具体的解决方案。systemtap 虽好，但那个 sample-bt 脚本总不如意，在负载高的时候被自己的资源限制，改了些参数也不如意。于是转向 perf，这玩意好，轻量级，就取个 60s 信息，多来几把，嘿嘿，还正搞出一些数据。\r\n    # perf record -F 99 -ag -o p1.data -- sleep 60\r\n    # perf script -i p1.data | ./stackcollapse-perf.pl \u0026gt; out.perf-folded\r\n    # cat out.perf-folded | ./flamegraph.pl \u0026gt; perf-kernel-1.svg\r\n    \r\n[attach]1204[/attach]\r\n\r\n    将分析的数据转换为火焰图，用火眼金睛照一照，还真能看出一些问题。\r\n    通过调用依赖关系分析，根据 _spin_lock_irq 初步推测问题由 kernel 的内存管理部分触发。\r\n    似乎 CentOS 6 相对于 CentOS 5 在 kernel 内存管理模块的一些改进点（如 transparent huge page, 基于 NUMA 的内存分配等），有没有可能是 CentOS 6 新增的 THP 特性导致 cpu sys 过高？搜索下相关函数名的关键字，确定猜测正确。通过以下内核参数优化关闭系统 THP 特性（临时生效）:\r\n    # echo never \u0026gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled\r\n    # echo never \u0026gt; /sys/kernel/mm/redhat_transparent_hugepage/defrag\r\n    从火焰图我们也可以看到，申请内存的线程在等待自旋锁，操作系统现在正回收 pagecache 到 freelist。于是 zone 里来申请内存的线程都得在这里等待着，于是 load 值就高了上来。外在的表现就是，系统反应好慢啊，ssh 都登不进去（因为 ssh 也会申请内存）；即使登录进去了，敲命令也没有反应（因为这些命令也都是需要申请内存的）。\r\n    \r\n    几个概念（来源于网络）：\r\n    page cache\r\n    导致这个情况的原因是：线程在申请内存的时候，发现该 zone 的 freelist 上已经没有足够的内存可用，所以不得不去从该 zone 的 LRU 链表里回收 inactive 的 page，这种情况就是 direct reclaim（直接回收）。direct reclaim 会比较消耗时间的原因是，它在回收的时候不会区分 dirty page 和 clean page，\r\n如果回收的是 dirty page，就会触发磁盘 IO 的操作，它会首先把 dirty page 里面的内容给刷写到磁盘，再去把该 page 给放到 freelist 里。\r\n    \r\n[attach]1207[/attach]\r\n\r\n    page reclaim\r\n    在直观上，我们有一个认知，当读了一个文件，它会被缓存到内存里面，如果接下来的一几天我们一直都不会再次访问它，而且这几天都不会关闭或者重启机器，那么在这几天之后该文件就不应该再在内存里头了。这就是内核对 page cache 的管理策略：LRU（最近最少使用）。即把最近最少使用的 page cache 给回收为 free pages。\r\n    内核的页回收机制有两种：后台回收和直接回收。\r\n    后台回收是有一个内核线程 kswapd 来做的，当内存里 free 的 pages 低于一个水位（page_low）时，就会唤醒该内核线程，然后它从 LRU 链表里回收 page cache 到内存的 free_list 里头，它会一直回收直至 free 的 pages 达到另外一个水位 page_high. 如下图所示：\r\n    \r\n[attach]1205[/attach]\r\n\r\n    直接回收则是，在发生 page fault 时，没有足够可用的内存，于是线程就自己直接去回收内存，它一次性的会回收 32 个 pages。逻辑过程如下图所示\r\n    \r\n[attach]1208[/attach]\r\n\r\n\r\n    所以要避免做 direct reclaim。\r\n    memory zone\r\n    对于多核 NUMA 系统而言，内存是分节点的，不同的 CPU 对不同的内存节点的访问速度是不一样的，所以 CPU 会优先去访问靠近自己的内存节点（即速度相对快的内存区域）。\r\n    CPU 内部是依靠 MMU 来进行内存管理的，根据内存属性的不同，MMU 将一个内存节点内部又划分了不同的 zone。\r\n    对 64-bit 系统而言，一个内存节点包含三个 zone：Normal，DMA，DMA32.\r\n    对 32-bit 系统而言，一个内存节点则是包括 zone：Normal，Highmem，DMA。\r\n    Highmem 存在的目的是为了解决线性地址空间不够用的问题，在 64-bit 上由于有足够的线性地址空间所以就没了该 zone。不同 zone 存在的目的是基于数据的局部性原则，我们在写代码的时候也知道，把相关的数据给放在一起可以提高性能，memory zone 也是这个道理。于是 MMU 在分配内存时，也会尽量给同一个进程分配同一个 zone 的内存。凡事有利就有弊，这样有好处自然也可能会带来一些坏处。    \r\n    为了避免 direct reclaim，我们得保证在进程申请内存时有足够可用的 free pages，从前面我们可以看出，提高 watermark low 可以尽早的唤醒 kswapd，然后 kswapd 来做 background reclaim。为此，内核专门提供了一个 sysctl 接口给用户来使用：vm.extra_free_kbytes。\r\n    \r\n\r\n[attach]1206[/attach]\r\n\r\n\r\n    # cat /etc/sysctl.conf | grep kbytes\r\n    vm.extra_free_kbytes = 4096000\r\n    vm.min_free_kbytes = 2097152\r\n    于是我们增大这个值（比如增大到 5G），确实也解决了问题。增大该值来提高 low 水位，这样在申请内存的时候，如果 free 的内存低于了该水位，就会唤醒 kswapd 去做页回收，同时又由于还有足够的 free 内存可用所以进程能够正常申请而不触发直接回收。\r\n    线程的回收跟 memory zone 相关。也就是说 normal zone 里面的 free pages 不够用了，于是触发了 direct reclaim。但是，假如此时 DMA zone 里还有足够的 free pages 呢？线程会不会从 DMA zone 里来申请内存呢？\r\n    free 的 pages 都在其它的 zone 里头，所以线程去回收自己 zone 的 page cache 而不去使用其它 zone 的 free pages。对于这个内核也提供了一个接口给用户使用：vm.zone_reclaim_mode. 这个值在该机器上本来是1（即宁肯回收自己 zone 的 page cache，也不去申请其它 zone 的 free pages）,我把它更改为0（即只要其它 zone 有 free pages 就去其它 zone 里申请）,就解决了该问题（一设置后系统就恢复了正常）\r\n       从这个问题也可以看出，Linux 内核提供了各种各样的机制，然后我们根据具体的使用场景来选择使用的策略。目的是为了在不影响稳定性的前提下，尽可能的提升系统性能。\r\n        Linux 机制的多种多样，也给上层的开发者带来了一些苦恼：由于对底层了解的不深入，就很难选择出一个很好的策略来使用这些内核机制。\r\n    然而对这些机制的使用，也不会有一个万能公式，还是要看具体的使用场景。由于搜索服务器存在很多批量文件操作，所以对 page cache 的使用很频繁，\r\n    所以我们才选择了尽早的能够触发 background reclaim 这个策略；而如果你的文件操作不频繁，显然就没有必要去尽早的唤醒后台回收线程。\r\n        另外一个，作为一个文件服务器，它对 page cache 的需求是很大的，越多的内存作为 page cache，系统的整体性能就会越好，所以我们就没有必要为了数据的局部性而预留 DMA 内存，\r\n    两相比较肯定是 page cache 对性能的提升大于数据的局部性对性能的提升；而如果你的文件操作不多的话，那还是打开 zone_reclaim 的。\r\n    # cat /etc/sysctl.conf | grep zone\r\n    vm.zone_reclaim_mode = 0\r\n    经过调整以上这几个参数后，再持续监控一段时间，问题得以解决。\r\n\r\n \r\n\r\n在 redhat 官网和 cloudera 官网也搜到了相关的内容，附录下来，供参考。\r\n    在 redhat 的官网上，有对THP特性的细化说明：\r\n      https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Performance_Tuning_Guide/s-memory-transhuge.html\r\n    在 cloudera 的 CDH4 部署说明中，也建议将系统的 THP 的 compaction 特性关闭：\r\n        http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.2/CDH4-Installation-Guide/cdh4ig_topic_11_6.html","title":"ES集群服务器CPU负载瞬间飚高分析","uid":"1160","views":"8063","votes":"19"},"_type":"doc"}
{"_id":"370","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510457470","category_id":"2","comments":"1","has_attach":"0","id":"370","message":"[原文链接](https://segmentfault.com/a/1190000011966008)\n\n距离上一篇 [esrally 教程](https://segmentfault.com/a/1190000011174694)过去快2个月了，这期间不停有同学来询问使用中遇到的问题，尤其由于其测试数据存储在国外 aws 上，导致下载极慢。为了让大家快速上手使用 esrally，我 build 了一个可用的 docker 镜像，然后将 `13GB` 的测试数据拉取到国内的存储上，通过百度网盘的方式分享给大家。大家只要按照下面简单的几步操作就可以顺畅地使用 esrally 来进行相关测试了。\n\n## 操作步骤\n\n废话不多说，先上菜！\n\n1. 拉取镜像\n    ````\n    docker pull rockybean/esrally\n    ```\n2. 下载数据文件 链接:http://pan.baidu.com/s/1eSrjZgA  密码:aagl\n3. 进入下载后的文件夹 rally_track,执行如下命令开始测试\n    ```\n    docker run -it -v $(PWD):/root/track rockybean/esrally esrally race --track-path=/root/track/logging --offline --pipeline=benchmark-only --target-hosts=192.168.1.105:9200\n    ```\n\n打完收工！\n\n## 几点说明\n\n### 数据文件介绍\nesrally 自带的测试数据即为 rally_track 文件夹中的内容，主要包括:\n\n* Geonames(geonames): for evaluating the performance of **structured data**.\n* Geopoint(geopoint): for evaluating the performance of **geo queries**.\n* Percolator(percolator): for evaluating the performance of **percolation queries**.\n* PMC(pmc): for evaluating the performance of **full text search**.\n* NYC taxis(nyc_taxis): for evaluating the performance for **highly structured data**.\n* Nested(nested): for evaluating the performance for **nested documents**.\n* Logging(logging): for evaluating the performance of **(Web) server logs**.\n* noaa(noaa): for evaluating the performance of **range fields**.\n\n可以根据自己的需要下载对应的测试数据，不必下载全部，保证对应文件夹下载完全即可。\n\n\n### 命令解释\n\n#### docker 相关\n`docker run -it rockybean/esrally esrally` 为执行的 esrally 命令，`-v $(PWD):/root/track`是将 rally_docker 文件夹映射到 docker 容器中，`$(PWD)`是获取当前目录的意思，所以在此前要 cd 到 rally_docker 目录，当然你写全路径也是没有问题的。\n\nesrally 的 docker 镜像比较简单，可以参看 [ github 项目介绍][1]。\n\n#### esrally 相关\n该镜像是通过自定义 track 的方式来加载数据，所以命令行中用到 `--track=/root/track/logging` 的命令行参数。注意这里的 `/root/track` 即上面我们绑定到容器的目录，更换 `logging` 为其他的数据集名称即可加载其他的测试数据。\n\n该容器只支持测试第三方 es 集群，即 `--pipeline=benchmark-only` 模式。这应该也是最常见的压测需求了。\n\n\n愉快地去玩耍吧！\n\n\n\n\n  [1]: https://github.com/rockybean/esrally-docker","title":"三步上手 esrally 完成 elasticsearch 压测任务","uid":"86","views":"925","votes":"4"},"_type":"doc"}
{"_id":"371","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510473973","category_id":"18","comments":"0","has_attach":"0","id":"371","message":"1. (自备梯子)推荐三个数据库相关(MySQL,MongoDB,Elasticsearch)的课程。\nhttp://t.cn/RjPvlq1\n2. 将 ELASTICSEARCH 写入速度优化到极限\nhttp://t.cn/RWs8yvS\n3. 零点之战！探访阿里巴巴8大技术专家，提前揭秘2017双11关键技术。\nhttp://t.cn/RjPPzGc\n4. 只等你来 | Elastic Meetup 广州交流会\nhttps://elasticsearch.cn/article/364\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/371\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第98期 (2017-11-12)","uid":"4460","views":"463","votes":"1"},"_type":"doc"}
{"_id":"380","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510797164","category_id":"2","comments":"0","has_attach":"1","id":"380","message":"## Elasticsearch Java API 客户端连接\r\n\r\n一个是`TransportClient`，一个是`NodeClient`，还有一个`XPackTransportClient`\r\n\r\n- TransportClient：\r\n\r\n作为一个外部访问者，请求ES的集群，对于集群而言，它是一个外部因素。\r\n\r\n\r\n- NodeClient\r\n\r\n作为ES集群的一个节点，它是ES中的一环，其他的节点对它是感知的。\r\n\r\n- XPackTransportClient：\r\n\r\n服务安装了 `x-pack` 插件\r\n\r\n\u0026gt; 重要：客户端版本应该和服务端版本保持一致\r\n\r\n\u0026gt; TransportClient旨在被Java高级REST客户端取代，该客户端执行HTTP请求而不是序列化的Java请求。 在即将到来的Elasticsearch版本中将不赞成使用TransportClient，建议使用Java高级REST客户端。\r\n\r\n\r\n\u0026gt; 上面的警告比较尴尬，但是在 5xx版本中使用还是没有问题的，可能使用rest 客户端兼容性更好做一些。\r\n\r\n[Elasticsearch Java Rest API 手册](https://www.gitbook.com/book/quanke/elasticsearch-java-rest)\r\n\r\n### Maven Repository\r\n\r\nElasticsearch Java API包已经上传到 [Maven Central](http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22elasticsearch%22)\r\n\r\n在`pom.xml`文件中增加：\r\n\r\n\u0026gt; transport 版本号最好就是与Elasticsearch版本号一致。\r\n\r\n```\r\n\u0026lt;dependency\u0026gt;\r\n    \u0026lt;groupId\u0026gt;org.elasticsearch.client\u0026lt;/groupId\u0026gt;\r\n    \u0026lt;artifactId\u0026gt;transport\u0026lt;/artifactId\u0026gt;\r\n    \u0026lt;version\u0026gt;5.6.3\u0026lt;/version\u0026gt;\r\n\u0026lt;/dependency\u0026gt;\r\n```\r\n\r\n\r\n### Transport Client\r\n\r\n#### 不设置集群名称\r\n\r\n```\r\n// on startup\r\n\r\n//此步骤添加IP，至少一个，如果设置了\u0026quot;client.transport.sniff\u0026quot;= true 一个就够了，因为添加了自动嗅探配置\r\nTransportClient client = new PreBuiltTransportClient(Settings.EMPTY)\r\n        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;host1\u0026quot;), 9300))\r\n        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;host2\u0026quot;), 9300));\r\n\r\n// on shutdown  关闭client\r\n\r\nclient.close();\r\n```\r\n\r\n#### 设置集群名称\r\n\r\n```\r\nSettings settings = Settings.builder()\r\n        .put(\u0026quot;cluster.name\u0026quot;, \u0026quot;myClusterName\u0026quot;).build();  //设置ES实例的名称\r\nTransportClient client = new PreBuiltTransportClient(settings);  //自动嗅探整个集群的状态，把集群中其他ES节点的ip添加到本地的客户端列表中\r\n//Add transport addresses and do something with the client...\r\n```\r\n\r\n#### 增加自动嗅探配置\r\n```\r\nSettings settings = Settings.builder()\r\n        .put(\u0026quot;client.transport.sniff\u0026quot;, true).build();\r\nTransportClient client = new PreBuiltTransportClient(settings);\r\n```\r\n\r\n#### 其他配置\r\n\r\n```\r\nclient.transport.ignore_cluster_name  //设置 true ，忽略连接节点集群名验证\r\nclient.transport.ping_timeout       //ping一个节点的响应时间 默认5秒\r\nclient.transport.nodes_sampler_interval //sample/ping 节点的时间间隔，默认是5s\r\n```\r\n\u0026gt; 对于ES Client，有两种形式，一个是TransportClient，一个是NodeClient。两个的区别为：\r\nTransportClient作为一个外部访问者，通过HTTP去请求ES的集群，对于集群而言，它是一个外部因素。\r\nNodeClient顾名思义，是作为ES集群的一个节点，它是ES中的一环，其他的节点对它是感知的，不像TransportClient那样，ES集群对它一无所知。NodeClient通信的性能会更好，但是因为是ES的一环，所以它出问题，也会给ES集群带来问题。NodeClient可以设置不作为数据节点，在elasticsearch.yml中设置，这样就不会在此节点上分配数据。\r\n\r\n如果用ES的节点，仁者见仁智者见智。\r\n\r\n#### 实例\r\n\r\n```\r\npackage name.quanke.es.study;\r\n\r\nimport name.quanke.es.study.util.Utils;\r\nimport org.elasticsearch.action.search.SearchResponse;\r\nimport org.elasticsearch.client.transport.TransportClient;\r\nimport org.elasticsearch.common.settings.Settings;\r\nimport org.elasticsearch.common.transport.InetSocketTransportAddress;\r\nimport org.elasticsearch.transport.client.PreBuiltTransportClient;\r\nimport org.junit.After;\r\nimport org.junit.Before;\r\n\r\nimport java.net.InetAddress;\r\n\r\n/**\r\n * Elasticsearch 5.5.1 的client 和 ElasticsearchTemplate的初始化\r\n * 作为一个外部访问者，请求ES的集群，对于集群而言，它是一个外部因素。\r\n * Created by http://quanke.name on 2017/11/10.\r\n */\r\npublic class ElasticsearchClient {\r\n\r\n    protected TransportClient client;\r\n\r\n    @Before\r\n    public void setUp() throws Exception {\r\n\r\n        Settings esSettings = Settings.builder()\r\n                .put(\u0026quot;cluster.name\u0026quot;, \u0026quot;utan-es\u0026quot;) //设置ES实例的名称\r\n                .put(\u0026quot;client.transport.sniff\u0026quot;, true) //自动嗅探整个集群的状态，把集群中其他ES节点的ip添加到本地的客户端列表中\r\n                .build();\r\n\r\n        /**\r\n         * 这里的连接方式指的是没有安装x-pack插件,如果安装了x-pack则参考{@link ElasticsearchXPackClient}\r\n         * 1. java客户端的方式是以tcp协议在9300端口上进行通信\r\n         * 2. http客户端的方式是以http协议在9200端口上进行通信\r\n         */\r\n        client = new PreBuiltTransportClient(esSettings)\r\n                .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;192.168.1.10\u0026quot;), 9300));\r\n\r\n        System.out.println(\u0026quot;ElasticsearchClient 连接成功\u0026quot;);\r\n    }\r\n\r\n    @After\r\n    public void tearDown() throws Exception {\r\n        if (client != null) {\r\n            client.close();\r\n        }\r\n\r\n    }\r\n\r\n    protected void println(SearchResponse searchResponse) {\r\n        Utils.println(searchResponse);\r\n    }\r\n\r\n}\r\n\r\n\r\n```\r\n\u0026gt; 本实例代码已经上传到 Git [ElasticsearchClient.java](https://gitee.com/quanke/elasticsearch-java-study/blob/master/src/test/java/name/quanke/es/study/ElasticsearchClient.java）)\r\n\r\n[所有实例](https://gitee.com/quanke/elasticsearch-java-study) 已经上传到Git\r\n\r\n\r\n### XPackTransportClient\r\n如果 `ElasticSearch ` 服务安装了 `x-pack` 插件，需要`PreBuiltXPackTransportClient`实例才能访问\r\n\r\n\r\n使用Maven管理项目，把下面代码增加到`pom.xml`;\r\n\r\n\u0026gt; 一定要修改默认仓库地址为https://artifacts.elastic.co/maven ，因为这个库没有上传到Maven中央仓库,如果有自己的 maven ，请配置代理\r\n\r\n```\r\n\u0026lt;project ...\u0026gt;\r\n\r\n   \u0026lt;repositories\u0026gt;\r\n      \u0026lt;!-- add the elasticsearch repo --\u0026gt;\r\n      \u0026lt;repository\u0026gt;\r\n         \u0026lt;id\u0026gt;elasticsearch-releases\u0026lt;/id\u0026gt;\r\n         \u0026lt;url\u0026gt;https://artifacts.elastic.co/maven\u0026lt;/url\u0026gt;\r\n         \u0026lt;releases\u0026gt;\r\n            \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt;\r\n         \u0026lt;/releases\u0026gt;\r\n         \u0026lt;snapshots\u0026gt;\r\n            \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt;\r\n         \u0026lt;/snapshots\u0026gt;\r\n      \u0026lt;/repository\u0026gt;\r\n      ...\r\n   \u0026lt;/repositories\u0026gt;\r\n   ...\r\n\r\n   \u0026lt;dependencies\u0026gt;\r\n      \u0026lt;!-- add the x-pack jar as a dependency --\u0026gt;\r\n      \u0026lt;dependency\u0026gt;\r\n         \u0026lt;groupId\u0026gt;org.elasticsearch.client\u0026lt;/groupId\u0026gt;\r\n         \u0026lt;artifactId\u0026gt;x-pack-transport\u0026lt;/artifactId\u0026gt;\r\n         \u0026lt;version\u0026gt;5.6.3\u0026lt;/version\u0026gt;\r\n      \u0026lt;/dependency\u0026gt;\r\n      ...\r\n   \u0026lt;/dependencies\u0026gt;\r\n   ...\r\n\r\n \u0026lt;/project\u0026gt;\r\n```\r\n\r\n#### 实例\r\n\r\n\r\n```\r\n\r\n/**\r\n * Elasticsearch XPack Client\r\n * Created by http://quanke.name on 2017/11/10.\r\n */\r\npublic class ElasticsearchXPackClient {\r\n\r\n    protected TransportClient client;\r\n    \r\n    @Before\r\n    public void setUp() throws Exception {\r\n        /**\r\n         * 如果es集群安装了x-pack插件则以此种方式连接集群\r\n         * 1. java客户端的方式是以tcp协议在9300端口上进行通信\r\n         * 2. http客户端的方式是以http协议在9200端口上进行通信\r\n         */\r\n        Settings settings = Settings.builder()\r\n                .put(\u0026quot;xpack.security.user\u0026quot;, \u0026quot;elastic:utan100\u0026quot;)\r\n                .put(\u0026quot;cluster.name\u0026quot;, \u0026quot;utan-es\u0026quot;)\r\n                .build();\r\n        client = new PreBuiltXPackTransportClient(settings)\r\n                .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(\u0026quot;192.168.1.10\u0026quot;), 9300));\r\n//        final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();\r\n//        credentialsProvider.setCredentials(AuthScope.ANY,\r\n//                new UsernamePasswordCredentials(\u0026quot;elastic\u0026quot;, \u0026quot;utan100\u0026quot;));\r\n\r\n        System.out.println(\u0026quot;ElasticsearchXPackClient 启动成功\u0026quot;);\r\n    }\r\n\r\n    @Test\r\n    public void testClientConnection() throws Exception {\r\n\r\n        System.out.println(\u0026quot;--------------------------\u0026quot;);\r\n    }\r\n\r\n    @After\r\n    public void tearDown() throws Exception {\r\n        if (client != null) {\r\n            client.close();\r\n        }\r\n\r\n    }\r\n\r\n    protected void println(SearchResponse searchResponse) {\r\n        Utils.println(searchResponse);\r\n    }\r\n}\r\n\r\n```\r\n\r\n\u0026gt; 本实例代码已经上传到 Git [ ElasticsearchXPackClient.java](https://gitee.com/quanke/elasticsearch-java-study/blob/master/src/test/java/name/quanke/es/study/ElasticsearchXPackClient.java）)\r\n\r\n[所有实例](https://gitee.com/quanke/elasticsearch-java-study) 已经上传到Git\r\n\r\n\r\n更多请浏览 [spring-boot-starter-es](https://github.com/quanke/spring-boot-starter-es) 开源项目\r\n\r\n\r\n\u0026gt; 如何有任何问题请关注微信公众号给我留言\r\n\r\n\r\n[attach]1281[/attach]\r\n","title":"Elasticsearch Java API - 客户端连接(TransportClient，PreBuiltXPackTransportClient)（一）","uid":"6646","views":"13637","votes":"0"},"_type":"doc"}
{"_id":"382","_index":"forum-mysql","_score":1,"_source":{"addtime":"1510797340","category_id":"18","comments":"0","has_attach":"0","id":"382","message":"1.BM25 ES现在使用的Lucene相关性算法\nhttp://t.cn/RjSSp1T\n2.通过Search Guard 为Elasticsearch 进行安全加固。\nhttps://elasticsearch.cn/article/350\n3.一个将ES查询结果以PDF，HTML或CSV形式导出的ES插件\nhttp://t.cn/RjJsItO\n4、Elastic Meetup 广州交流会 \nhttps://elasticsearch.cn/article/364 \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/382\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第102期 (2017-11-16)","uid":"668","views":"391","votes":"0"},"_type":"doc"}
{"_id":"388","_index":"forum-mysql","_score":1,"_source":{"addtime":"1511147137","category_id":"2","comments":"8","has_attach":"1","id":"388","message":"如题：\r\n在日常使用中 \r\n即使没有负载的情况下\r\nes集群的各个机器的Heap总是相差比较大\r\n请问这是不是有问题","title":"请问一下 集群的 heap总是不平均 这是不是有问题呢","uid":"6425","views":"549","votes":"0"},"_type":"doc"}
{"_id":"401","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512006644","category_id":"18","comments":"0","has_attach":"0","id":"401","message":"1.手把手教你ELK+Beats实现Windows服务器系统日志监控\nhttp://t.cn/RYiJRDA\n2.使用filebeat处理kubernetes日志\nhttp://t.cn/RYiJuu2\n3.用profile api定位es慢查询\nhttp://t.cn/RYiJriB\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/401\n订阅：https://tinyletter.com/elastic-daily  ","title":"Elastic日报 第116期 (2017-11-30)","uid":"668","views":"381","votes":"0"},"_type":"doc"}
{"_id":"403","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512175912","category_id":"18","comments":"0","has_attach":"0","id":"403","message":"1、es视频教程推荐\nhttp://t.cn/RYCpaOr\n2、使用syslog-ng往ES导入日志的教程\nhttp://t.cn/RYCp1Qs\n3、使用ES时的推荐Nginx配置\nhttp://t.cn/RYCWy0t\n4、Elastic Advent Calendar, Day 1: ES6.0升级建议\n[url]http://t.cn/RYCTpXF[/url] \n \n\n编辑：bsll\n归档：https://elasticsearch.cn/article/403\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第118期 (2017-12-2)","uid":"1874","views":"403","votes":"1"},"_type":"doc"}
{"_id":"411","_index":"forum-mysql","_score":1,"_source":{"addtime":"1512687370","category_id":"18","comments":"0","has_attach":"0","id":"411","message":"1、Elasticsearch中国布道者告诉你，ELK为什么这么流行？\nhttp://t.cn/RYePUEf\n2、 基于canal的mysql和elasticsearch实时同步方案 \nhttp://t.cn/RYePfPV\n3、kafka对接Elasticsearch实战\nhttp://t.cn/RYeZm7P\n4、看过来 | 集群保障注意事项\nhttp://uee.me/y47P\n5、Elastic Meetup 深圳交流会\n[url]https://elasticsearch.cn/article/406[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/411\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第124期 (2017-12-08)","uid":"1341","views":"472","votes":"0"},"_type":"doc"}
{"_id":"426","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513737823","category_id":"18","comments":"0","has_attach":"0","id":"426","message":"1. druid vs elasticsearch(旧闻)\n[url]http://t.cn/RTmtXBL[/url] \n2. elasticsearch 5.x 字段折叠的使用\n[url]http://t.cn/RTn0hJO[/url]\n3. (英文)Elastic Advent Calendar, Day 19: 用 Elastic Stack 监控 Kubernetes\n[url]http://t.cn/RTmcU1S[/url]\n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/426[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n\n ","title":"Elastic日报 第136期 (2017-12-20)","uid":"3828","views":"387","votes":"0"},"_type":"doc"}
{"_id":"428","_index":"forum-mysql","_score":1,"_source":{"addtime":"1513824195","category_id":"13","comments":"5","has_attach":"0","id":"428","message":"1、日志文件是json格式（对应ES的索引的字段），如果输出到ES，那么对应ES的格式数据（mapping）应该怎么定义，放到哪个目录，怎么引用。\n \n2、为了方便我每条日志生成一个文件，这样文件多了会不会影响Filebeat的性能。\n \n3、接第2问怎么配置可以“读取并输出成功”就删除该日志文件。","title":"Filebeat使用的若干问题","uid":"2489","views":"1633","votes":"1"},"_type":"doc"}
{"_id":"434","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514172680","category_id":"5","comments":"29","has_attach":"1","id":"434","message":"访问地址：\r\n[url]https://index.elasticsearch.cn[/url]\r\n\r\n[attach]1573[/attach]\r\n \r\n姑且叫做：Elastic 情报局！\r\n这个东西有什么用？\r\n聚合 Elastic 社区的各种资源，\r\n[list]\r\n[*]Elastic 官网资料、文档、博客、视频[/*]\r\n[*]Elastic 中文社区[/*]\r\n[*]Elastic 英文社区[/*]\r\n[*]Github 仓库的最新事件[/*]\r\n[*]其他社区的相关主题，如 StackOverflow、Reddit等[/*]\r\n[*]等[/*]\r\n[/list]\r\n用来提供一站式的垂直搜索，\r\n方便提供您更好的学习和寻找参考资料。\r\n\r\n[attach]1493[/attach]\r\n \r\n基于开源爬虫 [url=https://github.com/infinitbyte/gopa]GOPA[/url] 和 [url=https://github.com/elastic/elasticsearch]Elasticsearch[/url] 搭建，目前试运行，功能和数据正在完善中，欢迎反馈。","title":"社区搜索试运行","uid":"1","views":"2103","votes":"21"},"_type":"doc"}
{"_id":"437","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514424841","category_id":"18","comments":"0","has_attach":"0","id":"437","message":"1.Elastic Advent Calendar总结\nhttp://t.cn/RHcsoi6\n2.elasticsearch源码分析-Setting和Environment\nhttp://t.cn/RHfjJ47\n3.一个hangout的output ClickHouse插件\nhttp://t.cn/RHcsXHq\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/437\n订阅： https://tinyletter.com/elastic-daily","title":"Elastic日报 第144期 (2017-12-28)","uid":"668","views":"449","votes":"0"},"_type":"doc"}
{"_id":"439","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514854952","category_id":"18","comments":"0","has_attach":"0","id":"439","message":"1.Elasticsearch使用场景深入详解。\n[url]http://t.cn/RHWhZ6U[/url] \n2.还在为bulk rejections犯愁，看看官网详解。\n[url]http://t.cn/RY5BJy7[/url] \n3.使用ELK分析Jenkins日志。\n[url]http://t.cn/RHOWw1X[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/439[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第146期 (2018-1-2)","uid":"3788","views":"442","votes":"1"},"_type":"doc"}
{"_id":"440","_index":"forum-mysql","_score":1,"_source":{"addtime":"1514949597","category_id":"18","comments":"0","has_attach":"0","id":"440","message":"1. Kibana 使用的 Lucene 查询语法\n[url]http://t.cn/RaFHnD8[/url] \n6.x 新增 Kuery\n[url]http://t.cn/RHYhKdv[/url] \n2. ELK6.0 部署\n[url]http://t.cn/RHYhW7l[/url] \n3. Elasticsearch 元数据(meta-fields)介绍\n[url]http://t.cn/RHYhB13[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/440[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第147期 (2018-1-3)","uid":"3828","views":"370","votes":"0"},"_type":"doc"}
{"_id":"442","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515107062","category_id":"18","comments":"0","has_attach":"0","id":"442","message":"1、mongo同步到elasticsearch解读\nhttp://t.cn/RHzUzl5\n2、Elasticsearch.缓存分类体系\nhttp://t.cn/RH47mO1\n3、你知道elasticsearch 集群启动流程吗？\n[url]http://t.cn/RHESLQK[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/442\n订阅： https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第149期 (2018-01-05)","uid":"1341","views":"401","votes":"0"},"_type":"doc"}
{"_id":"446","_index":"forum-mysql","_score":1,"_source":{"addtime":"1515429972","category_id":"2","comments":"16","has_attach":"0","id":"446","message":"【携程旅行网 吴晓刚】\n\n上周，在某多多搬砖的一位朋友在微信上找我咨询，说他们公司一个ES集群从2.4升级到5.5以后，一个很简单的Query查询耗时突然从几十毫秒，变成800-1000毫秒，几十倍的性能下降！原始问题链接:[# [Why my search slow?](https://discuss.elastic.co/t/why-my-search-slow/113736)\n](https://discuss.elastic.co/t/why-my-search-slow/113736/2)\n\n这个查询非常简单，就是3个过滤条件求交集而已:\n```\n{\n      \u0026quot;from\u0026quot;: 0,\n      \u0026quot;size\u0026quot;: 10,\n      \u0026quot;query\u0026quot;: {\n      \u0026quot;bool\u0026quot;: {\n      \u0026quot;filter\u0026quot;: [\n        {\n          \u0026quot;terms\u0026quot;: {\n            \u0026quot;goods_id\u0026quot;: [\n              \u0026quot;262628158\u0026quot;\n            ],\n            \u0026quot;boost\u0026quot;: 1.0\n          }\n        },\n        {\n          \u0026quot;terms\u0026quot;: {\n            \u0026quot;status\u0026quot;: [\n              \u0026quot;2\u0026quot;,\n              \u0026quot;4\u0026quot;\n            ],\n            \u0026quot;boost\u0026quot;: 1.0\n          }\n        },\n        {\n          \u0026quot;range\u0026quot;: {\n            \u0026quot;create_time\u0026quot;: {\n              \u0026quot;from\u0026quot;: \u0026quot;1514027649\u0026quot;,\n              \u0026quot;to\u0026quot;: \u0026quot;1514632449\u0026quot;,\n              \u0026quot;include_lower\u0026quot;: true,\n              \u0026quot;include_upper\u0026quot;: true,\n              \u0026quot;boost\u0026quot;: 1.0\n            }\n          }\n        }\n      ],\n      \u0026quot;disable_coord\u0026quot;: false,\n      \u0026quot;adjust_pure_negative\u0026quot;: true,\n      \u0026quot;boost\u0026quot;: 1.0\n    }\n  },\n  \u0026quot;sort\u0026quot;: [\n    {\n      \u0026quot;create_time\u0026quot;: {\n        \u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\n      }\n    }\n  ]\n}\n```\n通过profile查看，发现耗时主要在status字段的`build_scorer`这个阶段。\n\n对方同时提到，只要去掉`\u0026quot;status\u0026quot;:[\u0026quot;2\u0026quot;, \u0026quot;4\u0026quot;]`这个查询条件，速度就会恢复正常。进一步询问后得知，查询的索引文档总量相当巨大，达到16亿条，而status字段只有几个不同的数字，在mapping里被定义为数值型`short`。\n\n我的第一反应，status只有几个值，意味着该字段的filter得到的结果集是海量的。可能是处理这个大结果集的代价很高造成的缓慢，但是具体什么原因我一时也说不上来。 \n\n脑子里开始翻查ES 2.x -\u0026gt; 5.x升级对于数值类型和Term Query有何重大变化？想起来两点:\n1. Lucene6.0引入了重新设计的数值类型的索引结构，不再采用倒排索，而是使用了更适合范围查找的Block K-d Tree。 ES从5.0开始引入这种新结构。(参考: [searching-numb3rs-in-5.0](https://www.elastic.co/blog/searching-numb3rs-in-5.0)）\n2. Term Query由于通常非常快，从5.1.1开始不再被缓存到Query Cache\n\n显然这个status字段不用于范围查找，字段类型设置上keyword比number更合理。 但我也没想明白为何number在这场景下查询会慢这么多，所以我也稍稍有些怀疑2.x缓存了Term Query是造成性能差异的原因。 当时让朋友做了个测试，将TermQuery换成RangeQuery，被告知速度飞快，只要几十个毫秒，并且多执行几次后更是快到只有几个毫秒了。(因为RangeQuery反复执行会被Cache起来)。\n\n隔天，朋友根据建议将status先改为keyword，重新索引数据后，查询性能奇迹般的恢复到正常，所以基本可以确定和缓存无关了。\n\n恰巧社区也有人在经历同样的问题: [Elastic对类似枚举数据的搜索性能优化](https://elasticsearch.cn/question/3253) ，看起来是个普遍现象，值得研究找出问题根源。 \n\n花了几天的时间参阅技术文档，也粗略读了一下ES/Lucene相关代码后，总算搞清楚了问题的来龙去脉。 本文将对相关技术细节做分析，然后回答下面3个问题:\n\u0026gt;1. 为什么ES5.x里对数值型字段做TermQuery可能会很慢?\n\u0026gt;2. 为何Profile里显示的耗时几乎全部在`build_scorer`?\n\u0026gt;3. 为什么对同样的数值型字段做RangeQuery却又很快了？ \n\n\n为更好的理解这个问题，先谈一下几点预备知识:\n\u0026gt;* ES2.x和5.x的数值类型分别是如何索引的\n\u0026gt;* Block k-d tree的基本概念和Lucene实现\n\u0026gt;* Queries/filters执行的先后顺序及结果合并是怎样做的\n\n---\n##ES2.x和5.x的数值类型分别是如何索引的\nES5.x之前用到的Lucene版本，实际上只能够索引文本类型的数据，表面上被定义为数值类型的字段，在暗地里都被转换成了字符串，编排成了倒排索引。例如:\n\n| Term        | Postings List |\n| ------------- |:-------------:|\n| 2     | [doc3, doc5, doc10 ...]|\n| 5     | [doc1, doc3, doc9 ... ]|\n| ...  | ... |\n| 90     | [doc2, doc3, doc8 ...]|\n| 99    | [doc3, doc5, doc20 ...]|\n| ...   | ...|\n这种结构对于精确的数值查询速度还是比较快的，直接从倒排索引根据查找的term拿到postings list就好了。 但类似`range: [50, 100]`这样的范围查找就比较麻烦了，Lucene在找到对应的term后，只能将其转换成类似`50 OR 51 OR 52  ... OR 100`这样的Bool查询。可想而知，这个多条件OR查询开销很高，执行很慢。所以Lucene在创建索引的时候，会自动产生一些类似`50x75` 这样的特殊Term，指向包含在该范围的文档列表，从而可以将查询优化成类似`50x75 OR 76x99 OR 100` 这种形式。但是这种优化在字段的不同值很多，查询范围很大的时候，依然很无力。 因此早期版本的Lucene和ES的范围查询性能一直被诟病。\n\nLucene从6.0开始引入了Block k-d tree来重新设计数值类型的索引结构，其目标是让数值型数据索引的结构更紧凑，搜索速度更快。这种数据结构是为多维数值字段设计的，可以高效的用于诸如地理位置这类数据的快速过滤，但同样适用于单维度的数值型。\n\n----\n# Block k-d tree的基本概念和Lucene实现\n基本思想就是将一个N维的数值空间，不断选定包含值最多的维度做2分切割，反复迭代，直到切分出来的空间单元(`cell`)包含的值数量小于某个数值。 对于单维度的数据，实际上就是简单的对所有值做一个排序，然后反复从中间做切分，生成一个类似于B-tree这样的结构。和传统的B-tree不同的是，他的叶子结点存储的不是单值，而是一组值的集合，也就是是所谓的一个Block。每个Block内部包含的值数量控制在512- 1024个，保证值的数量在block之间尽量均匀分布。 其数据结构大致看起来是这样的:\n\n![block b-tree.jpg](http://upload-images.jianshu.io/upload_images/7952780-8274dabd9f82c157.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\nLucene将这颗B-tree的非叶子结点部分放在内存里，而叶子结点紧紧相邻存放在磁盘上。当作range查询的时候，内存里的B-tree可以帮助快速定位到满足查询条件的叶子结点块在磁盘上的位置，之后对叶子结点块的读取几乎都是顺序的。 \n\u0026gt;要注意一点，不是简单的将拿到的所有块合并就可以得到想要的docID结果集，因为查询的上下边界不一定刚好落在两端block的上下边界上。 所以如果需要拿到range filter的结果集，就要对于两端的block内的docid做扫描，将他们的值和range的上下边界做比较，挑选出match的docid集合。\n\n----------\n#Queries/filters执行的先后顺序及结果合并是怎样做的\nES的Queries/filters执行顺序比较复杂，并非按照Query里条件的排列顺序来挨个执行；也不是某些人想象的那样，每个filter/Query都独立执行，拿到各自的结果集以后，再做结果集的合并。 在[elasticsearch-query-execution-order](https://www.elastic.co/blog/elasticsearch-query-execution-order) 这篇博客里对这个主题做了比较详细的介绍。 \n\n简单来说，ES会先通过调用每个查询的`cost()`函数估算一下该查询的代价，然后选择代价最小的查询作为起点，在其圈定的docid集合上生成一个迭代器。然后反复迭代，根据和其他条件之间是AND还是OR的关系，再去决定结果集合并的方式。  \n\n\u0026gt;这个结果集的迭代，以及合并，就是上面链接里提到的`nextdoc()`和`advance()`等操作。 比较复杂的地方是这些操作根据数据类型的不同和查询类型的不同，ES都有针对性的进行操作优化，同样的操作有些可能是在内存中进行，有些则可能直接在磁盘上进行。 \n\n以最常见的keyword字段做TermQuery为例，其cost就是Term Frequency，这个值可以直接从倒排索引读取。 Frequency越高的Term，其postings list就越长，迭代起来的代价就越高。 所以如果对多个TermQuery做AND合并，就会选择Frequency最低的Term，以其postings list为起点做迭代(`nextdoc`)。 Postings list是按照docid顺序存放的，并且在数据结构上还增加了跳表来加快`advance()`操作。因此多个postings list的合并可以直接操作磁盘上的数据而不会引起过多的随机IO，加上ES5.0以后对于索引数据采取了mmap file的方式访问，热数据读取引发的磁盘IO愈发的少。  这也是为什么5.1.1之后取消了TermQuery的cache，因为在跳表和OS page cache的加持下，直接合并磁盘上的postings list已经非常快了。 取消对其cache后，可以减少构造cache的开销，并且将宝贵的cache空间留给代价更高的filter，一定程度上可以提升ES整体性能。\n\n------------\n有了这些预备知识，再来解答文首抛出的3个问题。\n###1. 为什么ES5.x里对数值型字段做TermQuery可能会很慢?\n首先，用户范例查询里还有其他更加结果集更小的TermQuery，cost更低，因此迭代器从选择从这个低代价的Query作为起点开始执行; 其次，因为数值型字段在5.x里没有采用倒排表索引， 而是以value为序，将docid切分到不同的block里面。对应的，数值型字段的TermQuery被转换为了PointRangeQuery。这个Query利用Block k-d tree进行范围查找速度非常快，但是满足查询条件的docid集合在磁盘上并非向Postlings list那样按照docid顺序存放，也就无法实现postings list上借助跳表做蛙跳的操作。  要实现对docid集合的快速advance操作，只能将docid集合拿出来，做一些再处理。 这个处理过程在`org.apache.lucene.search.PointRangeQuery#createWeight`这个方法里可以读取到。 这里就不贴冗长的代码了，主要逻辑就是在创建scorer对象的时候，顺带先将满足查询条件的docid都选出来，然后构造成一个代表docid集合的bitset，这个过程和构造Query cache的过程非常类似。 之后advance操作，就是在这个bitset上完成的。\n\n###2. 为何Profile里显示的耗时几乎全部在`build_scorer`?\n回答第一个问题的时候提到了，如果查看PointRangeQuery的源码，构造scorer对象的构造过程包含了bitset的生成过程，所以耗时的实际上是构造一个巨大的bitset并在上面生成一个迭代器。\n\n## 3. 为什么对同样的数值型字段做RangeQuery却又很快了?\n从上面数值型字段的Block k-d tree的特性可以看出，rangeQuery的结果集比较小的时候，其构造bitset的代价很低，不管是从他开始迭代做`nextdoc()`，或者从其他结果集开始迭代，对其做`advance`，都会比较快。 但是如果rangeQuery的结果集非常巨大，则构造bitset的过程会大大延缓scorer对象的构造过程，造成结果合并过程缓慢。  \n这个问题官方其实早已经意识到了，所以从ES5.4开始，引入了`indexOrDocValuesQuery`作为对RangeQuery的优化。（参考: [better-query-planning-for-range-queries-in-elasticsearch](https://www.elastic.co/blog/better-query-planning-for-range-queries-in-elasticsearch)）。 这个Query包装了上面的`PointRangeQuery`和`SortedSetDocValuesRangeQuery`，并且会根据Rang查询的数据集大小，以及要做的合并操作类型，决定用哪种Query。  如果Range的代价小，可以用来引领合并过程，就走`PointRangeQuery`，直接构造bitset来进行迭代。 而如果range的代价高，构造bitset太慢，就使用`SortedSetDocValuesRangeQuery`。 这个Query利用了DocValues这种全局docID序，并包含每个docid对应value的数据结构来做文档的匹配。 当给定一个docid的时候，一次随机磁盘访问就可以定位到该id对应的value，从而可以判断该doc是否match。 因此它非常适合从其他查询条件得到的一个小结果集作为迭代起点，对于每个docid依次调用其内部的`matches()`函数判断匹配与否。也就是说， 5.4新增的`indexOrDocValuesQuery`将Range查询过程中的顺序访问任务扔给Block k-d Tree索引，将随机访任务交给doc values。\n值得注意的是目前这个优化只针对RangeQuery！对于TermQuery，因为实际的复杂性，还未做类似的优化，也就导致对于数值型字段，Term和Range Query的性能差异极大。\n\n-----\n#小结:\n1. 在ES5.x里，一定要注意数值类型是否需要做范围查询，看似数值，但其实只用于Term或者Terms这类精确匹配的，应该定义为keyword类型。典型的例子就是索引web日志时常见的HTTP Status code。\n2. 如果RangeQuery的结果集很大，并且还需要和其他结果集更小的查询条件做AND的，应该升级到ES5.4+，该版本在底层引入的`indexOrDocValuesQuery`，可以极大提升该场景下RangeQuery的查询速度。\n\n","title":"number?keyword?傻傻分不清楚","uid":"81","views":"5147","votes":"40"},"_type":"doc"}
{"_id":"3","_index":"forum-mysql","_score":1,"_source":{"addtime":"1446373111","category_id":"5","comments":"5","has_attach":"0","id":"3","message":"相信前面大家都知道在北京和上海已经举办了2场线下活动了,下一站是哪里呢??\n [b]第四届Elasticsearch国内开发者大会站 成都站[/b]  是的 ,下一站是在成都,并且马上就要开始了,\n报名的速度了,\n紧急征集讲师和志愿者中!!!!\n \n报名地址;\nhttp://form.mikecrm.com/f.php?t=mOUa1M \n ","title":"第四届Elasticsearch国内开发者大会站 成都站 马上开始了","uid":"1","views":"3240","votes":"1"},"_type":"doc"}
{"_id":"11","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449287772","category_id":"14","comments":"0","has_attach":"0","id":"11","message":"Advent Calendar 是各大技术社区每年 12 月大多会举办的一个系列活动。原意是圣诞节前夕的小礼品，延伸为每天一篇技术小分享的意思。最常见的包括 Perl Advent、sysadmin advent、web advent、performance advent 等。个人从 2009 年开始每年都看，从2013 年开始偶尔会参加其他社区的 advent 写作。今年考虑自己在 ELK Stack 上专注较多，在历次技术大会和最终出版的《ELK Stack权威指南》之外，又有一些新的发现和收获，干脆尝试一把自己一个人的 advent，也算是对 ELK 小知识的一种查漏补缺。\n\n今天是 12 月 1 日，第一天，开天辟地，让我们也从最简单而又容易被忽略的一个小技巧开始吧！\n\n每个上手 ELK 的新用户，肯定都需要测试一下读取文件输出到终端这步。在 Logstash 中，也就是配置这样一段：[code]input {\n    file {\n        path =\u0026gt; [\u0026quot;/data/test.log\u0026quot;]\n    }\n}\noutput {\n    stdout {\n        codec =\u0026gt; rubydebug\n    }\n}[/code]不过很多新人的测试随后就卡在第二步了：当你修改一下配置，准备添加一段 filter 配置再重复运行 logstash 命令时，发现[b]终端一直停滞没有输出[/b]。\n\n这是因为：Logstash 会记录自己读取文件内容的偏移量到一个隐藏文件里，默认情况下，下次启动，他会从这个偏移量继续往后读，避免重复读取数据。\n\n这个隐藏文件，叫做 $HOME/.sincedb_****。过去很多文档，在解释了这个原理后，都会告诉大家解决办法：每次重新运行 logstash 命令之前，删除掉家目录下的 sincedb 隐藏文件。\n\n但是这种办法很笨，不是么？\n\n今天告诉大家一个更方便的办法，改用下面这段 Logstash 配置：\n[code]input {\n    file {\n        path =\u0026gt; [\u0026quot;/data/test.log\u0026quot;]\n        start_position =\u0026gt; \u0026quot;beginning\u0026quot;\n        sincedb_path =\u0026gt; \u0026quot;/dev/null\u0026quot;\n    }\n}\noutput {\n    stdout {\n        codec =\u0026gt; rubydebug\n    }\n}[/code]要点就在这行 sincedb_path =\u0026gt; \u0026quot;/dev/null\u0026quot; 了！该参数用来指定 sincedb 文件名，但是如果我们设置为 /dev/null这个 Linux 系统上特殊的空洞文件，那么 logstash 每次重启进程的时候，尝试读取 sincedb 内容，都只会读到空白内容，也就会理解成之前没有过运行记录，自然就从初始位置开始读取了！\n\n好了，第一天就是这样。更多内容，敬请期待。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day1: 怎样让Logstash每次都从头读文件？","uid":"7","views":"5978","votes":"6"},"_type":"doc"}
{"_id":"17","_index":"forum-mysql","_score":1,"_source":{"addtime":"1449507256","category_id":"14","comments":"2","has_attach":"0","id":"17","message":"用 Logstash 接收 Kafka 里的业务日志再写入 Elasticsearch 已经成为一个常见的选择。但是大多数人随后就会碰到一个问题：logstash-input-kafka 的性能上不去！\n\n这个问题，主要是由于 Logstash 用 JRuby 实现，所以数据从 Kafka 下来到最后流转进 Logstash 里，要经过四五次 Ruby 和 Java 之间的数据结构转换，大大浪费和消耗了 CPU 资源。作为优化，我们可以通过修改默认的 logstash-input-kafka 的 codec 配置为 line，把 Jrjackson 处理流程挪到 logstash-filter-json 里多线程处理，但是也只能提高一倍性能而已。\n\nLogstash 开发组目前也在实现纯 Java 版的 logstash-core-event，但是最终能提高多少，也是未知数。\n\n那么在 Logstash 性能提上去之前，围绕 Kafka 还有什么办法能高效又不失灵活的做到数据处理并写入 Elasticsearch 呢？今天给大家推荐一下携程网开源的 [url=https://github.com/childe/hangout]hangout[/url]。\n\nhangout 采用 YAML 格式配置语法，跟 Elasticsearch 一样，省去了 Logstash 解析 DSL 的复杂度。下面一段配置是 repo 中自带的 example 示例：\n[code]inputs:\n  - Kafka:\n    codec: plain\n    encoding: UTF8 # defaut UTF8\n    topic: \n      app: 2\n    consumer_settings:\n      group.id: hangout\n      zookeeper.connect: 192.168.1.200:2181\n      auto.commit.interval.ms: \u0026quot;1000\u0026quot;\n      socket.receive.buffer.bytes: \u0026quot;1048576\u0026quot;\n      fetch.message.max.bytes: \u0026quot;1048576\u0026quot;\n      num.consumer.fetchers: \u0026quot;4\u0026quot;\n  - Kafka:\n    codec: json\n    topic: \n      web: 1\n    consumer_settings:\n      group.id: hangout\n      zookeeper.connect: 192.168.1.201:2181\n      auto.commit.interval.ms: \u0026quot;5000\u0026quot;\n\nfilters:\n  - Grok:\n    match:\n      - '^(?\u0026lt;logtime\u0026gt;\\S+) (?\u0026lt;user\u0026gt;.+) (-|(?\u0026lt;level\u0026gt;\\w+)) %{DATA:msg}$'\n    remove_fields: ['message']\n  - Add:\n    fields:\n      test: 'abcd'\n    if:\n      - '\u0026lt;#if message??\u0026gt;true\u0026lt;/#if\u0026gt;'\n      - '\u0026lt;#if message?contains(\u0026quot;liu\u0026quot;)\u0026gt;true\u0026lt;#elseif message?contains(\u0026quot;warn\u0026quot;)\u0026gt;true\u0026lt;/#if\u0026gt;'\n  - Date:\n    src: logtime\n    formats:\n      - 'ISO8601'\n    remove_fields: ['logtime']\n  - Lowercase:\n    fields: ['user']\n  - Add:\n    fields:\n      me: 'I am ${user}'\n  - Remove:\n    fields:\n      - logtime\n  - Trim:\n    fields:\n      - user\n  - Rename:\n    fields:\n      me: he\n      user: she\n  - Gsub:\n    fields:\n      she: ['c','CCC']\n      he: ['(^\\w+)|(\\w+$)','XXX']\n  - Translate:\n    source: user\n    target: nick\n    dictionary_path: /tmp/app.dic\n  - KV:\n    source: msg\n    target: kv\n    field_split: ' '\n    value_split: '='\n    trim: '\\t\\\u0026quot;'\n    trimkey: '\\\u0026quot;'\n    include_keys: [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;xyz\u0026quot;,\u0026quot;12\u0026quot;]\n    exclude_keys: [\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;] # b in excluded\n    tag_on_failure: \u0026quot;KVfail\u0026quot;\n    remove_fields: ['msg']\n  - Convert:\n    fields:\n      cs_bytes: integer\n      time_taken: float\n  - URLDecode:\n    fields: [\u0026quot;query1\u0026quot;,\u0026quot;query2\u0026quot;]\n\noutputs:\n  - Stdout:\n    if:\n      - '\u0026lt;#if user==\u0026quot;childe\u0026quot;\u0026gt;true\u0026lt;/#if\u0026gt;'\n  - Elasticsearch:\n    cluster: hangoutcluster\n    hosts:\n      - 192.168.1.200\n    index: 'hangout-%{user}-%{+YYYY.MM.dd}'\n    index_type: logs # default logs\n    bulk_actions: 20000 #default 20000\n    bulk_size: 15 # default 15 MB\n    flush_interval: 10 # default 10 seconds\n    concurrent_requests: 0 # default 0, concurrent_requests设置成大于0的数, 意思着多线程处理, 以我应用的经验,还有是一定OOM风险的,强烈建议设置为0\n  - Kafka:\n    broker_list: 192.168.1.200:9092\n    topic: test2[/code]其 pipeline 设计和 Logstash 不同的是：整个 filter 和 output 流程，都在 Kafka 的 consumer 线程中完成。所以，并发线程数完全是有 Kafka 的 partitions 设置来控制的。\n\n实际运行下来，hangout 比 Logstash 确实在处理能力，尤其是 CPU 资源消耗方面，性价比要高出很多。\n\n想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day7: hangout 替代 logstash-input-kafka","uid":"7","views":"7162","votes":"2"},"_type":"doc"}
{"_id":"23","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450277875","category_id":"14","comments":"1","has_attach":"0","id":"23","message":"ELK 收集业务日志的来源，除了应用服务器以外，还有很大一部分来自客户端。考虑到客户端网络流量的因素，一般实现上都不会要求实时上报数据，而是攒一批，等到手机连上 WIFI 网络了，再统一发送出来。所以，这类客户端日志一般都有几个特点：\n[list=1]\n[*]预先已经记录成 JSON 了；[/*]\n[*]日志主体内容是一个巨大无比的数组，数据元素才是实际的单次日志记录；[/*]\n[*]一次 POST 会有几 MB 到几十 MB 大小。[/*]\n[/list]\n\n在处理这类数据的时候，第一关是别让数据超长直接给丢弃了（说的就是你啊，Rsyslog）；第二关就是拆分 JSON 数组，把几十 MB 数据扔 ES 字段里，显然是不利于搜索和统计需求的。今天我们就来说说怎么拆分 JSON 数组。\n\n假设收到的是这么一段日志：\n[code]{\u0026quot;uid\u0026quot;:123456,\u0026quot;upload_datetime\u0026quot;:\u0026quot;2015-12-10 11:38:11\u0026quot;,\u0026quot;logs\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;crash\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:55:00\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;****\u0026quot;},{\u0026quot;type\u0026quot;:\u0026quot;network_error\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:56:12\u0026quot;,\u0026quot;tracert\u0026quot;:\u0026quot;****\u0026quot;}]}[/code]首先我们知道可以在读取的时候把 JSON 数据解析成 LogStash::Event 对象：\n[code]input {\n    tcp {\n        codec =\u0026gt; json\n    }\n}[/code]但是怎么把解析出来的 logs 字段拆分成多个 event 呢？这里我们可以用一个已有插件：logstash-filter-split。\n[code]filter {\n    split {\n        field =\u0026gt; \u0026quot;logs\u0026quot;\n    }\n    date {\n        match =\u0026gt; [\u0026quot;timestamp\u0026quot;, \u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;]\n        remove_fields =\u0026gt; [\u0026quot;logs\u0026quot;, \u0026quot;timestamp\u0026quot;]\n    }\n}[/code]这样，就可以得到两个 event 了：\n[code]{\u0026quot;uid\u0026quot;:123456,\u0026quot;upload_datetime\u0026quot;:\u0026quot;2015-12-10 11:38:11\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;crash\u0026quot;,\u0026quot;@timestamp\u0026quot;:\u0026quot;2015-12-10T09:55:00Z\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;****\u0026quot;}\n{\u0026quot;uid\u0026quot;:123456,\u0026quot;upload_datetime\u0026quot;:\u0026quot;2015-12-10 11:38:11\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;network_error\u0026quot;,\u0026quot;@timestamp\u0026quot;:\u0026quot;2015-12-10T09:56:12Z\u0026quot;,\u0026quot;tracert\u0026quot;:\u0026quot;****\u0026quot;}[/code]看起来可能跟这个插件的文档描述不太一样。文档上写的是通过 terminator 字符，切割 field 字符串成多个 event。但实际上，field 设置是会自动判断的，如果 field 内容是字符串，就切割字符串成为数组再循环；如果内容已经是数组了，直接循环：\n[code]    original_value = event[@field]\n\n    if original_value.is_a?(Array)\n        splits = original_value\n    elsif original_value.is_a?(String)\n        splits = original_value.split(@terminator, -1)\n    else\n        raise LogStash::ConfigurationError, \u0026quot;Only String and Array types are splittable. field:#{@field} is of type = #{original_value.class}\u0026quot;\n    end\n\n    return if splits.length == 1\n\n    splits.each do |value|\n        next if value.empty?\n\n        event_split = event.clone\n        @logger.debug(\u0026quot;Split event\u0026quot;, :value =\u0026gt; value, :field =\u0026gt; @field)\n        event_split[(@target || @field)] = value\n        filter_matched(event_split)\n\n        yield event_split\n    end\n    event.cancel[/code]顺带提一句：这里 yield 在 Logstash 1.5.0 之前，实现有问题，生成的新事件，不会继续执行后续 filter，直接进入到 output 阶段。也就是说，如果你用 Logstash 1.4.2 来执行上面那段配置，生成的两个事件会是这样的：[code]{\u0026quot;@timestamp\u0026quot;:\u0026quot;2015-12-10T09:38:13Z\u0026quot;,\u0026quot;uid\u0026quot;:123456,\u0026quot;upload_datetime\u0026quot;:\u0026quot;2015-12-10 11:38:11\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;crash\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:55:00\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;****\u0026quot;,\u0026quot;logs\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;crash\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:55:00\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;****\u0026quot;},{\u0026quot;type\u0026quot;:\u0026quot;network_error\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:56:12\u0026quot;,\u0026quot;tracert\u0026quot;:\u0026quot;****\u0026quot;}]}\n{\u0026quot;@timestamp\u0026quot;:\u0026quot;2015-12-10T09:38:13Z\u0026quot;,\u0026quot;uid\u0026quot;:123456,\u0026quot;upload_datetime\u0026quot;:\u0026quot;2015-12-10 11:38:11\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;network_error\u0026quot;,\u0026quot;@timestamp\u0026quot;:\u0026quot;2015-12-10 17:56:12\u0026quot;,\u0026quot;tracert\u0026quot;:\u0026quot;****\u0026quot;,\u0026quot;logs\u0026quot;:[{\u0026quot;type\u0026quot;:\u0026quot;crash\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:55:00\u0026quot;,\u0026quot;reason\u0026quot;:\u0026quot;****\u0026quot;},{\u0026quot;type\u0026quot;:\u0026quot;network_error\u0026quot;,\u0026quot;timestamp\u0026quot;:\u0026quot;2015-12-10 17:56:12\u0026quot;,\u0026quot;tracert\u0026quot;:\u0026quot;****\u0026quot;}]}[/code]想了解更全面的 ELK Stack 知识和细节，欢迎购买我的《ELK Stack权威指南》，也欢迎加 QQ 群：315428175 哟。","title":"Day10: 如何处理数组形式的JSON日志","uid":"7","views":"5735","votes":"4"},"_type":"doc"}
{"_id":"31","_index":"forum-mysql","_score":1,"_source":{"addtime":"1450623110","category_id":"14","comments":"1","has_attach":"0","id":"31","message":"在logstash内部, input到filter, 以及filter到output, 消息都是通过一个队列来中转.\n\n在我写hangout的第一个版本,也是这么做的,用ArrayBlockingQueue来中转消息, 上游几个线程把消息放在queue中, 下游再几个线程把queue中的消息消费走.\n\n但是, 用下来之后, 发现在queue上面消耗的资源是相当的大,strace查看,非常大量的lock相关的系统调用, 现在的版本已经把queue去掉了. 想必Logstash也会有大量资源用在这一块.\n\nzeromq中的Parallel Pipeline正好适合这个场景,而且文档中说是lock free的, 拿来和queue对比一下看.\n\n在我自己的电脑上测试,2.6 GHz Intel Core i5.  一个主线程生成10,000,000个随机数, 分发给四个线程消费.\n\n用Queue来实现, 需要约37秒, CPU使用率在150%. 用zeromq的ipc来传递消息, 只需要22秒, 期间CPU使用率在250%. 总的CPU使用时间都60秒左右.\n\n不知道java中还有没有更合适的Queue可以用在这个场景中.至少zeromq和ArrayBlockingQueue相比, zeromq可以更快的处理消息, 但代价就是更高的CPU使用率.","title":"Day18: 程序内的消息流:ArrayBlockingQueue和zeromq对比","uid":"666","views":"2340","votes":"2"},"_type":"doc"}
{"_id":"37","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451032377","category_id":"2","comments":"4","has_attach":"1","id":"37","message":"地址：[url]https://github.com/medcl/elasticsearch-rtf[/url]\r\n \r\n[b]使用git快速签出最新版：[/b]\r\ngit clone git://github.com/medcl/elasticsearch-rtf.git -b master --depth 1\r\n \r\n[b]包含插件：[/b]\r\nelasticsearch-analysis-ik-1.6.2        elasticsearch-analysis-pinyin-1.5.2\r\nelasticsearch-analysis-mmseg-1.6.2     elasticsearch-analysis-stconvert-1.6.1\r\n\r\n[b]使用：[/b]\r\ncd elasticsearch/bin \r\n./elasticsearch\r\n \r\n ","title":"elasticsearch-rtf更新至2.1.1","uid":"1","views":"5354","votes":"0"},"_type":"doc"}
{"_id":"47","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451377588","category_id":"2","comments":"0","has_attach":"0","id":"47","message":"今天头一次出现的，其实也不算什么问题。\n通过数据库获取到了1126个条件数据，然后叠加进bool进行查询，直接抛出个异常：\nTooManyClauses[maxClauseCount is set to 1024]\n问了Medcl大神，得知是超过默认搜索条件大小的问题，可以通过参数修改\n[code]index.query.bool.max_clause_count: 4096[/code]M大也说，太BT了。。。 这么多条件查询。。。\n我也觉得挺BT的，自己想想都有点小激动，太佩服自己了。。。","title":"关于提示TooManyClauses[maxClauseCount is set to 1024]的问题。","uid":"568","views":"5912","votes":"1"},"_type":"doc"}
{"_id":"45","_index":"forum-mysql","_score":1,"_source":{"addtime":"1451268093","category_id":"1","comments":"2","has_attach":"1","id":"45","message":"圣诞节收到了elastic圣诞老人medcl送来的圣诞礼物，在此特别感谢！\n发个赞吧！\n晒图@！\n\n[attach]74[/attach]\n\n[attach]71[/attach]\n\n[attach]69[/attach]\n\n[attach]73[/attach]\n\n[attach]70[/attach]\n\n[attach]72[/attach]\n\n[attach]75[/attach]\n居然有个瓶起子，看来不喝一台是不行了。。。\nsugru据说是什么都能粘的‘硅胶’。。。\nelastic的周边越来越强大了。\n特别感谢medcl大神对中国地区elastic用户的关照！","title":"感谢elastic送来的圣诞礼物！","uid":"568","views":"2489","votes":"4"},"_type":"doc"}
{"_id":"50","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452655229","category_id":"5","comments":"3","has_attach":"0","id":"50","message":"elasticsearch-analysis-ik：\n[url]https://github.com/medcl/elasticsearch-analysis-ik[/url]\n \nelasticsearch-analysis-mmseg： \n[url]https://github.com/medcl/elasticsearch-analysis-mseg[/url]\n \n主要更新配置文件存放路径，之前版本的配置文件存放在elasticsearch的config目录，现在都修改为插件的相对目录了，主要是简化部署，现在可在Found（https://found.elastic.co）部署了。","title":"elasticsearch-analysis-ik和elasticsearch-analysis-mmseg更新至1.7.0","uid":"1","views":"2946","votes":"0"},"_type":"doc"}
{"_id":"53","_index":"forum-mysql","_score":1,"_source":{"addtime":"1452853400","category_id":"13","comments":"1","has_attach":"0","id":"53","message":"书接上回:[url]http://elasticsearch.cn/article/48[/url]\n\n我们打开Packetbeat项目，看看里面长什么样：\n\n[img]http://log.medcl.net/wp-content/uploads/2016/01/Snip20160113_7.png[/img]\n[img]http://log.medcl.net/wp-content/uploads/2016/01/Snip20160113_8.png[/img]\n现在beats项目都合并在一起了，第一级可以看到各个子项目：\n/libbeat: 公共依赖；\n/filebeat: 替代Logstash-forwarder，处理日志类型数据；\n/packetbeat: 本文扩展重点，网络抓包；\n/topbeat: 监控系统性能；\n/winlogbeat: 监控windows下面的日志信息；\n/vender: 依赖的第三方库；\n/tests: 用于测试的pcamp抓包文件，非常有用；\n/scripts: 一些用于开发和测试的Docker脚本文件；\n\n现在重点看看/packetbeat下面目录都有些什么：\n/packetbeat/main.go： 启动入口，里面没有什么逻辑；\n/packetbeat/beat/： 里面就一个packetbeat.go文件，packetbeat主程序，处理配置和命令行参数，协议需要在这里进行注册；\n/packetbeat/config/: 里面就一个config.go文件，定义了所有的配置相关的struct结构体，新协议需要在这里定义其配置的结构体；\n/packetbeat/debian/: debian打包相关；\n/packetbeat/decoder/: 解码类，网络传输层包的解码；\n/packetbeat/docs/: 项目的相关文档；\n/packetbeat/etc/: 示例配置文件；\n/packetbeat/procs/: 获取系统内核运作状态与进程信息的工具类；\n/packetbeat/protos/：自定义协议类，每个目录对应一个应用协议，我们需要在此新增我们的协议，如SMTP；\n/packetbeat/sniffer/: 三种不同抓包方式的实现：pcap、af_packet、pf_ring，关于这三者的区别，请参照文档：Traffic Capturing Options；\n/packetbeat/tests/： 测试相关的文件，里面有每一个协议的pcab抓包样板，还有一堆Python测试脚本；\n\n知道项目的大概架构就知道从哪下手了，下节分解。","title":"Packetbeat协议扩展开发教程（2）","uid":"1","views":"5033","votes":"0"},"_type":"doc"}
{"_id":"205","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501635188","category_id":"18","comments":"0","has_attach":"0","id":"205","message":"1. ELK 与 Raspberry Pi 的另类极客玩法  [url]http://t.cn/R9MLk7E[/url]\n只要你有一个树莓派， 就可以轻松打造一个跑在“云”上的便携式 ELK 集群。\n\n2. Elasticsearch 安全 Search Guard 落地实践  [url]http://t.cn/R9ZeqNp[/url]\nSearch Guard 是一款 Elasticsearch 比较通用且方便的认证插件，这篇文章主要讲解了如何快速接入 Search Guard 插件。\n\n3. Docker Logging with the ELK Stack\nPart 1  [url]http://t.cn/R9MUnJS[/url] \nPart 2  [url]http://t.cn/R9M4UNz[/url]\n关于 Docker 日志的采集应该是 ELK 应用最广泛的一面，具体的一些细节可以参考上述文档。该文档共有两部分。\n\n编辑：江水\n\n归档：[url]https://elasticsearch.cn/article/205[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第4期 (2017-08-02)","uid":"3828","views":"1017","votes":"3"},"_type":"doc"}
{"_id":"212","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501834371","category_id":"12","comments":"0","has_attach":"0","id":"212","message":"[b]岗位职责（工作内容）[/b]\n[list]\n[*]负责数据分析产品全栈式开发；[/*]\n[*]指导开发人员工作，提升团队整体的技术能力；[/*]\n[*]学习研究业界前沿技术，并迅速转化为项目生产力。[/*]\n[/list]\n\n[b]任职资格、技能和经验[/b]\n[list]\n[*]全栈开发能力，熟悉JS/CSS/Html，Node.js等；[/*]\n[*]前端开发能力优秀者优先；[/*]\n[*]具有数据分析类产品设计或研发经验技术优先；[/*]\n[*]注重代码质量，能高效编写优雅的代码；[/*]\n[*]思路清晰，善于思考，能独立分析和解决问题，责任心强，具备良好的团队合作精神和承受压力的能力；[/*]\n[*]具备广泛的技术视野和很强的技术前瞻性。[/*]\n[/list]\n \n工作地点北京、杭州，薪资待遇优厚，欢迎各位大神！\n联系方式：wending.ywd@alibaba-inc.com","title":"【阿里巴巴】【急聘】数据分析产品开发专家","uid":"3935","views":"876","votes":"0"},"_type":"doc"}
{"_id":"215","_index":"forum-mysql","_score":1,"_source":{"addtime":"1501980629","category_id":"18","comments":"0","has_attach":"0","id":"215","message":"1. 基于Elasticsearch构建千亿流量日志搜索平台实战 http://t.cn/R9hVYoW\n\n来自七牛云的大数据高级工程师使用ES的经验分享\n\n\n\n\n2. Autocomplete Using Elasticsearch http://t.cn/R9Sjr07\n\n怎么实现谷歌、百度搜索的自动补全，这里利用es提供了一种可能的方法\n\n\n\n\n3. 谈谈ES的Recovery http://t.cn/R9SsrK2\n\n关于ES集群的快速恢复，社区里的这篇文章值得一看。\n\n\n\n\n编辑：bsll\n\n归档：https://elasticsearch.cn/article/215\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第8期 (2017-08-06)","uid":"1874","views":"823","votes":"0"},"_type":"doc"}
{"_id":"217","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502153953","category_id":"18","comments":"0","has_attach":"0","id":"217","message":"1.了解 Kibana 最新的针对时序型数据的 Time Series Visual Builder，看这两篇博客就够了：\n\nhttp://t.cn/R9lbflp 和 http://t.cn/R9lbq3W\n\n2.基于 Kibana 的开源的分析方案，实时掌握加密货币(如：比特币)的最新行情：\n\nhttp://t.cn/R9lGuZi\n\n3.Github 工程师团队分享的如何实现项目标签的智能推荐：\n\nhttp://t.cn/R9lqS2A\n\n \n\n编辑：Medcl\n\n归档：https://elasticsearch.cn/article/217\n\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第10期 (2017-08-08)","uid":"1","views":"810","votes":"1"},"_type":"doc"}
{"_id":"218","_index":"forum-mysql","_score":1,"_source":{"addtime":"1502239648","category_id":"18","comments":"0","has_attach":"0","id":"218","message":"1.采集生产环境的数据并进行分析，log or metrics 是一个问题 http://t.cn/R9TSJNl\n\n2.应对不同数据量/场景的Elastic Stack架构 http://t.cn/R9ToO9C\n\nElastic 官方推荐\n\n3.Elastic 官方于昨晚发布了6.0.0 beta 版，Elastic Stack 已进入一个全新的时代 http://t.cn/R9HhiNs\n\n同时发布的还有 Kibana 和 Beats 6.0.0 beta 版\n\n \n\n编辑：江水\n\n归档：https://elasticsearch.cn/article/218\n\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第11期 (2017-08-09)","uid":"3828","views":"659","votes":"3"},"_type":"doc"}
{"_id":"459","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516240504","category_id":"18","comments":"0","has_attach":"0","id":"459","message":"1.ElasticSearch 5.6源码解析HTTP/TCP请求\nhttp://t.cn/RQSwjeQ\n2.elasticsearch的慢日志\nhttp://t.cn/RQSwH4X\n3.Zabbix3.4.5:历史数据支持Elasticsearch\nhttp://t.cn/RQSw86k\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/459\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第162期 (2018-01-18)","uid":"668","views":"304","votes":"0"},"_type":"doc"}
{"_id":"467","_index":"forum-mysql","_score":1,"_source":{"addtime":"1516689092","category_id":"2","comments":"1","has_attach":"1","id":"467","message":"线上es服务目性能忽然出现问题，JVM Heap占比很高 所有的查询性能变慢了很多 昨天忽然发现的问题,目前只是关闭了一些index 但是没什么效果，有大佬知道可以从哪些方便着手分析一下问题吗？\r\n[attach]1576[/attach]\r\n\r\n[attach]1575[/attach]\r\n ","title":"线上es服务目性能忽然出现问题，JVM Heap占比很高 所有的查询性能变慢了很多","uid":"7593","views":"740","votes":"0"},"_type":"doc"}
{"_id":"479","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517491103","category_id":"11","comments":"0","has_attach":"1","id":"479","message":"接上一篇：[Elastic 中文社区运维监控实战 (1) - 序](https://elasticsearch.cn/article/470)\r\n\r\n本文为系列文章第二篇，主要介绍如何把 Elastic 中文社区的网站服务器监控起来，对有同样想了解如何使用 Elastic Stack 来做运维监控的同学，可以作为一个很好的参考和入门资料，学习门槛定义为入门级。\r\n\r\n## 本节内容\r\n\r\n在深入到具体的监控指标收集的细节之前，今天先主要介绍一下 Elastic 中文社区的总体方案。这样我们在动手之前会有一个总体的思路和对所用工具有一个大致的了解。\r\n\r\n\u0026lt;!--more--\u0026gt;\r\n\r\n## 技术选型\r\n\r\n\u0026gt; 工欲善其事必先利其器\r\n\r\n前面已经提到我们要对服务器进行各项性能指标的监控以及日志的监控。\r\n\r\n看起来很复杂，因为有很多信息需要收集。\r\n好在我们有 Elastic Stack，使用它们来作为我们的监控工具，整个工作就变得简单了，我们结合我们社区监控的这个场景，具体来看的话，需要的工具主要是如下几个：\r\n\r\n* 监控数据存储：[Elasticsearch](https://www.elastic.co/cn/products/elasticsearch)\r\n\r\nElasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎。简单易用，用户众多，性能优良，久经考验，支持单节点部署到虚拟机，并可随着业务增长无缝伸缩扩容至上千个节点规模的集群，PB 级别数据也不在话下。\r\n\r\n日志数据和指标监控数据都能放，通过集中式存储所有的这些时序型数据，可以快速方便的对这些数据进行分析和关联，实在是排障运维和性能调优的不二选择，你如果还不知道 Elasticsearch，那我只能说你真的是 out 了。\r\n\r\n* 日志数据收集：[Filebeat](https://www.elastic.co/cn/products/beats/filebeat)\r\n\r\nElastic Beats 家族的一员，Go 语言编写，轻量级，无依赖，这样就可以很方便的完成收集端的部署，所以如果你的场景和我一样， 可以优先使用 Filebeat 代替 Logstash 来收集日志，当然如果有日志的进一步加工，可以让 Filebeat 把数据发送给 Logstash，然后 Logstash 处理完之后再发送给 Elasticsearch。\r\n\r\nFilebeat 使用很灵活，可以指定你的日志路径来进行收集，还可以对数据进行预过滤，对于一些常见的监控需求，Filebeat 以模块的方式替你打包好了一切，如：日志路径配置、解析规则、机器学习的任务，甚至还自带 Dashboard，简单几个操作，就可以完成从数据收集到最终可视化分析的所有工作。\r\n\r\n* 指标数据收集：[Metricbeat](https://www.elastic.co/cn/products/beats/metricbeat)\r\n\r\n我们这次需要监控的服务器都是一些常规的指标，而 Metricbeat 刚好都支持这些指标的收集，你说这不巧了不是。\r\n\r\nMetricbeat 同样也是 Elastic Beats 家族的一员，同样也是开源的。定位是一个轻量级的监控指标采集器，采用 Go 语言编写，同样提供的是一个很小的无依赖的二进制文件包，能够收集服务器（Linux、Windows、Mac）本身的运行指标，如： CPU 使用率、内存、文件系统、磁盘 IO 和网络 IO 统计数据等，还能获取服务器上面的各项服务的运行指标，常见的如： Apache、NGINX、MongoDB、MySQL、PostgreSQL、Prometheus、Redis 等都有直接支持，并且内置了 Elasticsearch 索引和 mapping 设置，以及 Ingest pipeline 设置，还提前预置了不少 Kibana 的 Dashboard，开箱即用、即分析。\r\n\r\n* 数据分析展现：[Kibana](https://www.elastic.co/cn/products/kibana)\r\n\r\n和 Elasticsearch 工作的最佳拍档，结合 Elasticsearch 的实时分析能力，可以非常方便的对各种数据进行搜索和分析，你可以灵活的自定义的各种图形展现和 Dashboard，不用编写一行代码，即可进行数据分析，除了分析，还整合了 Elastic Stack 的各个产品的管理功能，作为 Elastic Stack 的图形交互终端。\r\n\r\n除了上面这些工具，后续我们还可以考虑使用 [Auditbeat](https://www.elastic.co/cn/products/beats/auditbeat) 来收集服务器的安全行为日志，使用 [Heartbeat](https://www.elastic.co/cn/products/beats/heartbeat) 来监控各个服务的端口是否正常，我们先完成基本的监控之后，再慢慢将这些加上。\r\n\r\n可以看到，我们没有用到 [Logstash](https://www.elastic.co/cn/products/logstash)，是的，这个规模的监控，可以不考虑 Logstash，这样我们可以做到架构简单和足够的轻量级。\r\n\r\n上面列的这些软件都是 [Elastic](https://www.elastic.co) 家族的产品，并且都是开源的，所有的源码都在：https://github.com/elastic/ 。\r\n\r\n## 部署方案\r\n\r\n在收集数据之前，我们需要明确我们数据放在哪里，毫无疑问，所有的数据都将放在 Elasticsearch 里面，不过 Elasticsearch 不能部署在 Elastic 中文社区的这台服务器上面，一个是资源的限制，另外一个是基于安全的考虑，如果 Elastic 社区的服务器挂了，数据不光收不到，连什么时候挂的都不知道。所以我们需要把 Elasticsearch 服务搭建在别的地方，有多种选择：\r\n\r\n* 使用 [Elastic Cloud](https://www.elastic.co/cn/cloud)，很方便就能开通，缺点国内访问速度慢，暂时还没开放机器学习的功能。\r\n* 使用[阿里云的 Elasticsearch](https://data.aliyun.com/product/elasticsearch)，Elastic  官方合作伙伴，国内唯一包含 X-Pack 的完整功能的 Elasticsearch 云服务，国内访问速度快。\r\n* 自己搭建的 Elasticsearch 集群。\r\n\r\n使用[阿里云的 Elasticsearch](https://data.aliyun.com/product/elasticsearch) 无疑很方便，不过我家里刚好有一台服务器，型号 HP Gen8，16GB 内存，上面运行了 SmartOS，跑几个 zone 很轻松，每天用来备份社区的数据库，再来起一个 Elasticsearch 服务也很方便，通过路由器将内网 IP 映射出去，让社区服务器将监控数据发送到这台服务器上面来，安全上面，需要保证这台服务器不被黑客攻击，需要做一些必要的访问控制，可以使用 X-Pack 的身份验证，结合 IP 白名单功能，只允许内网和 Elastic 中文社区服务器的 IP 访问。\r\n\r\n我们将之命名为：Ops Center，方便后面招呼。\r\n\r\n可以看到，Elastic 社区服务器除了启动 Filebeat 和 Metricbeat 之外，不需要额外做什么服务器本身的设置。\r\n\r\n这里画一个简单的部署拓扑图，方便理解：\r\n\r\n[attach]1617[/attach]\r\n\r\n今天主要写到这里，后面将具体介绍它们的安装部署过程。\r\n","title":"Elastic 中文社区运维监控实战 (2) - 总体方案","uid":"1","views":"1369","votes":"5"},"_type":"doc"}
{"_id":"488","_index":"forum-mysql","_score":1,"_source":{"addtime":"1517969657","category_id":"9","comments":"0","has_attach":"0","id":"488","message":"Master为最新版本的文档，其余版本的文档后续再补全。\n\nGithub地址：[https://github.com/Mosongxing/elasticsearch-php](https://github.com/Mosongxing/elasticsearch-php)\n\n文档地址（个人测试版）：[http://doc.songsong.net.cn/elasticsearch-php/](http://doc.songsong.net.cn/elasticsearch-php/)","title":"elasticsearch-php中文文档","uid":"7747","views":"1317","votes":"1"},"_type":"doc"}
{"_id":"502","_index":"forum-mysql","_score":1,"_source":{"addtime":"1518486934","category_id":"18","comments":"0","has_attach":"0","id":"502","message":"1.Elastic Stack 6.2 发布。 \nhttp://t.cn/R8rHoet\n \n2.Elasticsearch : java 9 相关改进。 \nhttp://t.cn/RRIs0RY\n \n3.别名的特殊应用 \nhttp://t.cn/RRMPLaA\n \n编辑：cyberdak\n归档：https://elasticsearch.cn/article/502\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第188期 (2018-02-13)","uid":"4063","views":"369","votes":"0"},"_type":"doc"}
{"_id":"504","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519263909","category_id":"18","comments":"0","has_attach":"0","id":"504","message":"1. Elasticsearch6.2新增自定义vega可视化。\n[http://t.cn/REh8K0O](http://t.cn/REh8K0O) \n\n2. 调整Elasticsearch碎片的思考和收益。\n[http://t.cn/REh8C0l](http://t.cn/REh8C0l) \n\n3. ES-Spark连接ES后，ES Client节点流量打满分析。\n[http://t.cn/REh8pXb](http://t.cn/REh8pXb) \n\n\n\n* 编辑：金桥\n\n* 归档：https://elasticsearch.cn/article/504 \n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第190期 (2018-02-22)","uid":"668","views":"379","votes":"0"},"_type":"doc"}
{"_id":"506","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519433757","category_id":"18","comments":"0","has_attach":"0","id":"506","message":"1. ES6.2支持对非英文日志进行分类\n[http://t.cn/REwaWPN](http://t.cn/REwaWPN) \n\n2. 运行400+节点的ES集群的经验分享\n[http://t.cn/RR5zYwk](http://t.cn/RR5zYwk) \n\n3. 新人课堂：ES中动态映射和自定义映射的介绍\n[http://t.cn/REAxpSS](http://t.cn/REAxpSS) \n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/506\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第192期 (2018-02-24)","uid":"1874","views":"339","votes":"0"},"_type":"doc"}
{"_id":"510","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519785890","category_id":"18","comments":"0","has_attach":"0","id":"510","message":"1. MySQL 千万级别数据量迁移 Elasticsearch 5.6.1实战\n[url]http://t.cn/R8rQJph[/url] \n2. Elastic Stack 监控实战\n[url]http://t.cn/R8xmOWI[/url] \n[url]http://t.cn/R8xnT1B[/url] \n3. Elasticsearch 6.1.2 cluster on Kubernetes\n[url]http://dwz.cn/7voTtA[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/510[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第196期 (2018-02-28)","uid":"3828","views":"331","votes":"0"},"_type":"doc"}
{"_id":"513","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519793251","category_id":"5","comments":"21","has_attach":"1","id":"513","message":"by Elastic CEO Shay Banon [原文](https://www.elastic.co/blog/doubling-down-on-open)\n\n[attach]1822[/attach]\n\n我很高兴的宣布，我们将公开我们 X-Pack 特性的所有代码 - Security、Monitoring、Alerting、Graph、Reporting、专门的 APM UI、Canvas、Elasticsearch SQL、Search Profiler、Grok Debugger、Elastic Maps Service zoom levels 以及 Machine Learning  - 为了促进我们与客户及社区的更大的协作，正如我们今天为我们的开源代码所做的一样。                         \n\n我为我们公司围绕我们的开源产品而自豪，一直以来我们都没有破坏创新或放弃对开放的承诺。当我们展望未来的时候，我们看到了一个机会，让我们更加坚信开放，甚至更加彻底，同时引入一个新的、更加高效的模式来构建一个成功的、可持续的围绕开源的商业模式。\n\n这篇博客概述了我们做出这些改变的想法和细节，不过，让我澄清一件事 - 我们是一家开源软件公司。我们将继续保持为一家开源软件公司。我们比以往任何时候都要更加开放，我个人，我的团队，整体而言，都致力于此。\n\n## 为什么开源?\n\n当我第一次开始写 Elasticsearch 的时候，我知道它必须是开源的。开源作为一种开发模式和分发方式，提供了接触更多人的机会。所有这些人都能做出贡献。当然，通过代码可以做出贡献，但也可以通过使用免费的软件，持续不断的推进可能的边界。\n\n与社区的合作可以确保，当你的项目成功时，会有一群热情的、专门的开发者指导你的特性开发，并将产品推向新的有趣的方向。例如，将聚合功能引入 Elasticsearch 让其可被当做一个可扩展的用于数据分析的产品。而像 Kibana 和 Logstash 这样的项目，以及后来的 Beats 的加入，无不令人鼓舞。随着我们用户的需求变得更加深入和专业，我们总能找到新的方法来支持他们，有些是通过新的功能、有些是产品，比如机器学习、APM 和站内搜索。\n\n我们对开源的承诺深入了。这是我们花费大部分工程力量投入的地方，我们的社区贡献者和用户对我们创新进程也同样至关重要。但是，像我们这样快速推进产品的发展，需要大量的投资，这也是我们围绕这些技术成立一家公司的原因。\n\n## 为什么商业软件?\n\n那么，如果我们对开源软件已有如此深的见解，那为什么还是编写了商业软件呢？\n\n我们是一家企业。作为企业的一部分，我们相信那些能够付款给我们的企业，应该付款给我们。而那些不能的，他们也不必付款给我们。作为回报，我们有义务确保我们继续添加功能和价值给我们所有的用户，并确保与我们的商业关系对客户有益。这是一家健康的公司所需要的平衡。\n\n销售支持订阅服务是一个常见的开源软件的商业模式。可悲的是，只有支持的商业模式会朝向关于什么对用户最好以及什么对公司最好这样的冲突之中。在这种情况下，公司将没有动力让他们的产品更加简单好用，更加稳固和可扩展，因为那意味着这将吞噬其技术支持的利益。我们从来没有，也永远不会忍受为了确保公司继续经营而不让我们的软件变的更好。我们想要继续改进，我们支持服务的目标是让你的项目成功，然后你能成为你自有 Elastic Stack 部署的专家。\n\n另外一种办法  -- 如果你们听过我的演讲，你们可能听我讨论过这个问题 -- 即构建一个‘企业版’的软件。这种，从本质上来讲，导致了社区的分裂，并在客户和用户之间产生了分歧。它的结果就是创建一种版本 -- 要么企业版，要么社区版 --  被认为是权威的，往往滞后 master 很多。一个缺少特性的版本。一个在不同周期测试和发布的版本。一个有效的关闭了源代码的版本，因为您无法知道为了支持商业特性而更改了哪些内容。在 Elastic，所有我们的客户同时也是我们开源软件用户，使用相同版本的软件产品。我们不会创建一个社区版与企业版的版本。\n\n那还有什么？识别高价值特性并将其作为核心软件的商业扩展。这种商业模式，我们有时候叫它“open core”，这是我们创造 X-Pack 的最终产物。为了构建和集成由我们维护知识产权（IP）的特性和功能，并提供订阅服务或免费的基础授权。保持我们对知识产权的控制，使我们能够有能力投资我们大部分的工程资源和时间，可以继续改进我们的核心，我们的开源产品。\n\n这种方法使我们能够在世界各地建立一个分布式的公司，让我们感到惊讶的是，Elastic Stack 是如何被用来解决各种实际的、具体的问题的。添加适用于我们用户的特性和功能，并开发一些使我们能够持续到未来的功能。\n\n但是这种方法也存在挑战…\n\n## 更加开放\n\n你是否知道 X-Pack 提供了一层免费的功能？这些能力诸如 Monitoring、Search Profiler、Grok Debugger 以及额外的 Elastic Maps 缩放级别。你是否知道我们还将在这一层继续添加更多功能，如 Canvas 和 Elasticsearch SQL？\n\n当我们往X-Pack 里添加免费功能的时候，我们这么做是因为我们知道这些功能可以帮助用户更好的使用 Elastic Stack。不幸的是，太多功能你都不知道 -- 也许知道 -- 或得益于这些功能。所以这意味着有很大一部分用户在使用我们软件的时候往往不是最佳实践。\n\n我们也知道，获得这个免费软件的过程是一个糟糕的用户体验，涉及到一个完整的集群重启。并且如果你想查看代码，抱歉，不可以。尤其是这些免费功能和很大一部分用户相关，你会问我们一些很好但是很难的问题，比如：“我如何就这些免费功能与你们交互？”，“我如何开启一个 issue 或是贡献代码？”\n\n而我们没有很好的答案。\n\n通过公开 X-Pack 的代码，我们解决了这些我们部分产品开源以及部分产品不是的问题。很快，所有的免费的和商业的特性你都可以开启一个 issue、查看特性讨论、检查源代码、与我们协助和提交一个 pull request。\n\n## 具体细节\n\n这意味着什么，技术上来说？\n\n自 6.3 版本起，所有 $PRODUCT（项目）仓库(Elasticsearch, Logstash, Kibana, Beats) ：\n\n* 所有现存的 Apache 2.0 协议的代码都将保持相同的协议，什么都不用动。\n* 我们会创建一个新的 X-Pack 目录，将 x-pack-$PRODUCT 的代码放入到该目录，基于 Elastic EULA 协议，允许相应的衍生和贡献。\n* 我们将修改最顶层的协议为一个简单的 Elastic License，包含这个仓库里面那些文件是Apache 2.0，那些是 Elastic EULA 的详细细节。\n\n同时，X-Pack 功能将打包到默认的发行版里面。所有免费的功能都包含在里面且默认开启且永远不会出现‘过期’，而商业特性则可以通过试用证书可选的启用。因为免费的证书永远不会过期，所以你再也不用通过注册来就直接获取它了。除此以外，一个只包含 Apache 2.0 协议代码的包也会同样会创建并提供下载。\n\n更多信息以及常见问题，可以在 [Opening X-Pack](http://elastic.co/products/x-pack/open) 页找到。\n\n##  总结\n\n我们相信开源。作为一种分布模式。作为一种建立企业的方法。作为我们公司的未来。\n我们承诺并保持我们将保持开放，并对我们将在 6.3 比以往任何时候都更加开放而感到兴奋。\n\n\n感谢你们对我们的信任。","title":"开放公开，火力全开：Elastic 宣布公开其商业产品 X-Pack 的源代码","uid":"1","views":"8134","votes":"19"},"_type":"doc"}
{"_id":"515","_index":"forum-mysql","_score":1,"_source":{"addtime":"1519944193","category_id":"18","comments":"0","has_attach":"0","id":"515","message":"1. NLP领域使用Elasticsearch详解\nhttp://t.cn/RE6gJXA\n2.使用Elasticsearch计算文章相似性\nhttp://t.cn/RE6gCSL\n3.Elasticsearch实现高质量的推荐系统\n[url]http://t.cn/RE6gWZF[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/515\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第198期 (2018-03-02)","uid":"1341","views":"336","votes":"0"},"_type":"doc"}
{"_id":"518","_index":"forum-mysql","_score":1,"_source":{"addtime":"1520214179","category_id":"18","comments":"0","has_attach":"0","id":"518","message":"1. App搜索一站式解决方案 , swiftype-app-search开始公测\nhttp://t.cn/REOPVZy\n2. Conveyor : 图形化数据导入工具\nhttp://t.cn/REOhwGT\n3. Kibana 文档参看强化插件，以markdown格式展示文档\nhttp://t.cn/REOhKgB\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/518\n订阅：https://tinyletter.com/elastic-daily","title":"​Elastic日报 第201期 (2018-03-05)","uid":"4063","views":"303","votes":"0"},"_type":"doc"}
{"_id":"537","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521150672","category_id":"18","comments":"0","has_attach":"0","id":"537","message":"1.HELK：一款具有高级分析功能的漏洞挖掘平台\nhttp://t.cn/REnLO2j\n2.Grafana不同数据源处理实战\nhttp://t.cn/RnZizQP\n3.Elasticsearch提升性能建议\n[url]http://t.cn/RnZiA9g[/url] \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/537\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第212期 (2018-03-16)","uid":"1341","views":"631","votes":"0"},"_type":"doc"}
{"_id":"541","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521508523","category_id":"18","comments":"0","has_attach":"0","id":"541","message":"1.使用Logz.io和ELK记录AWS Route 53日志实战。\n[url]http://t.cn/Rnce1bM[/url] \n2.每个BI分析师都需要知道的五个ELK工具。\n[url]http://t.cn/Rnc3HCu[/url] \n3.Elasticsearch MinHash 插件。\n[url]http://t.cn/RntiJhO[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/541[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n \n ","title":"Elastic日报 第216期 (2018-03-20)","uid":"3788","views":"543","votes":"0"},"_type":"doc"}
{"_id":"542","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521601148","category_id":"18","comments":"0","has_attach":"0","id":"542","message":"1.  基于Elasticsearch的搜索广告召回方案\n[url]http://t.cn/RnIkzJc[/url] \n2. eBay的Elasticsearch性能调优实践（上）\n[url]http://t.cn/RnbcLUW[/url] \n3. 基于日志的交换机故障预测\n[url]http://t.cn/RQxBhux[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/542[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第217期 (2018-03-21)","uid":"3828","views":"541","votes":"0"},"_type":"doc"}
{"_id":"547","_index":"forum-mysql","_score":1,"_source":{"addtime":"1521939952","category_id":"18","comments":"0","has_attach":"0","id":"547","message":"1.将用于Geo Enrichment的lucene-geo-gazetteer与Apache NiFi集成。\nhttp://t.cn/RnKwHpP\n2.为什么NoSQL数据库是创业的最佳解决方案。\nhttp://t.cn/RnKyjmi\n3.(自备梯子)大数据和位置智能如何改变世界。\nhttp://t.cn/RnKZjVW\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/547\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第221期 (2018-03-25)","uid":"4460","views":"825","votes":"0"},"_type":"doc"}
{"_id":"560","_index":"forum-mysql","_score":1,"_source":{"addtime":"1522834908","category_id":"2","comments":"3","has_attach":"0","id":"560","message":"        这两天在看ES数据备份方面的事情，因为我们ES集群的存储空间有限，需要定时对ES的数据进行备份和清理，把备份的数据存储到其他地方去，然后在ES集群中释放掉。\n        看大家好多是主要考虑数据的安全性才做的数据的备份，我们就比较low了，我们就是因硬盘不够，要删数据。上个项目是因为日志数据重要程度一般般，就保留了一个月的量，然后也没有做数据的备份转储。这次上线的项目要求就高点了，需要删除的数据存储到其他地方，但是硬盘的容量更低了。所以就需要做ES数据备份和转储，转储完了就清掉。\n        这里是用ES官方推荐的数据快照方案，这个方案可以完全通过ES API进行操作，比价方便、快捷，在数据恢复方面也是方便的。\n先上ES官方的链接，大家看看：[url]https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html[/url]\n        然后就是步骤了：\n执行过程分为两部分：\n一、准备过程\n1、添加ES备份存储目录\n在集群的每台机器上进行目录创建\nmkdir /home/esdata\n2、挂载共享文件存储目录\n在集群的每台机器上目录挂载\nmount -t nfs 10.70.61.80:/home/apmtest /home/esdata\n3、修改ES集群配置\n在ES集群的每台机器上都添加path.repo属性\npath.repo: [\u0026quot;/home/esdata\u0026quot;]\n4、重启ES集群\nES集群重启必须是关闭所有机器后，再启动。\n5、建立备份仓库\nPUT /_snapshot/my_backup   \n{ \n    \u0026quot;type\u0026quot;: \u0026quot;fs\u0026quot;,   \n    \u0026quot;settings\u0026quot;: { \n        \u0026quot;location\u0026quot;: \u0026quot;/home/esdata\u0026quot;   \n    } \n}\n\n二、备份数据快照\n1、通过API执行备份\nPUT /_snapshot/my_backup/snapshot_2018.03.01?wait_for_completion=true \n{ \n    \u0026quot;indices\u0026quot;: \u0026quot;filebeat-2018.03.01\u0026quot; \n}\n \n        快照仓库需要注意的地方就是需要在整个集群的每一台机器上挂载相同的共享文件存储目录，保证在集群里做的操作是输出到相同的地方的。\n \n下面来一份shell脚本，可以定时执行，是做ES数据的定时转储和清理的，大家可以借鉴一下[code]#!/bin/bash\nESIP=127.0.0.1\nDATE=`date -d '-2 days' +'%Y.%m.%d'`\nINDEX='{ \u0026quot;indices\u0026quot;: \u0026quot;'$DATE'\u0026quot; }'\necho \u0026quot;begin to backup ES LOG...\u0026quot;\n \ncurl -XPUT \u0026quot;http://$ESIP:9200/_snapshot/my_backup/snapshot_$DATE?wait_for_completion=true\u0026quot; -d $INDEX\n \necho \u0026quot;----------------------------------------------------------------------------\u0026quot;\n \necho \u0026quot;begin to clean ES LOG...\u0026quot;\n \nURL1=\u0026quot;http://$ESIP:9200/filebeat-$DATE\u0026quot;\n \ncurl -XDELETE $URL1\n\n \necho \u0026quot;TRANSFER AND CLEAN ES LOG END!\u0026quot;[/code]","title":"ES数据备份和清理-快照","uid":"3221","views":"928","votes":"0"},"_type":"doc"}
{"_id":"573","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523591545","category_id":"2","comments":"14","has_attach":"1","id":"573","message":"⚠️ 截止目前最新的ES6版本6.2.3，存在一个复制片恢复过程中可能引起flush死循环的BUG。 我们近期一个ES6.2.2的集群触发了这个bug，导致了一些麻烦。对于写入量很高的集群，这个BUG可能会导致系统的文件描述符被耗尽，结点挂掉，并且重启后依然挂掉的情况。  \n \n这个问题发生的时候，必须找到数据目录下，存在大量translog文件的索引目录(可能会有上万的translog文件)，找到对应目录的索引名称，然后关闭复制片，待translog清理完毕以后，再打开复制片重新复制。 \n \n该问题有人已经在GITHUB上汇报如下:\n[url=https://github.com/elastic/elasticsearch/issues/29097]issues/29097[/url]\n \nBUG已经被确认，修复代码已经进入6.2.4 [url=https://github.com/elastic/elasticsearch/pull/29125]pull/29125[/url] ，但该版本还未正式release。\n \n准备上6版本的同学先请稍待新版本发布以后再行动，已经在6版本的同学，注意监控结点的FD数量，持续升高的情况需要进行关注。\n[attach]2011[/attach]\n \n ","title":"6.x 复制片恢复引起flush操作死循环的BUG","uid":"81","views":"990","votes":"10"},"_type":"doc"}
{"_id":"578","_index":"forum-mysql","_score":1,"_source":{"addtime":"1523926407","category_id":"18","comments":"0","has_attach":"0","id":"578","message":"1.一文告诉你为什么ELK如此流行与重要。\n[url]http://t.cn/RmQhDoR[/url] \n2.Elasticsearch全文搜索快速入门。\n[url]http://t.cn/RmQhFmc[/url] \n3.使用kafka与ElK收集并分析Log4j日志实战。\n[url]http://t.cn/RmQ7P4y[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/578[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第244期 (2018-04-17)","uid":"3788","views":"350","votes":"0"},"_type":"doc"}
{"_id":"585","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524360508","category_id":"18","comments":"0","has_attach":"0","id":"585","message":"1.elasticsearch命令行工具。\nhttp://t.cn/Ruhm7CF\n2.(自备梯子)并行扫描和滚动Elasticsearch索引。\nhttp://t.cn/RuhppeE\n3.(自备梯子)更好的数据表UI设计是这样的。\nhttp://t.cn/RuhukIh\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/585\n订阅：https://tinyletter.com/elastic-daily ","title":"Elastic日报 第249期 (2018-04-22)","uid":"4460","views":"336","votes":"0"},"_type":"doc"}
{"_id":"586","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524421175","category_id":"3","comments":"2","has_attach":"0","id":"586","message":"使用filebeat采集数据，使用document_type 区分不同的类型的日志\nlogstash 输入日志到文件，这样方面查看，也方便将怎么相同的服务运行在不同的服务器里面日志汇总\n\nlogstash 配置如下\n```\ninput{\n  beats{\n    port =\u0026gt; 5044\n    codec =\u0026gt; \u0026quot;json\u0026quot;\n  }\n}\n\noutput{\n   if [type]  == \u0026quot;123_server\u0026quot; {\n    file {\n      path =\u0026gt; \u0026quot;/home/logs/123-server.log\u0026quot;\n      codec =\u0026gt; plain{ charset =\u0026gt; \u0026quot;GBK\u0026quot; }\n      gzip =\u0026gt; true\n        }\n  }\n}\n\n```\n其实需要2个条件，输入的日志尽量保持和原来的日志一样\n我这个代码输出全部是乱码，无论怎么修改编码格式\n求大神指点下","title":"logstash输出到文件","uid":"3611","views":"1211","votes":"0"},"_type":"doc"}
{"_id":"587","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524445247","category_id":"18","comments":"0","has_attach":"0","id":"587","message":"1.深入了解es从TF/IDF切换到BM25算法带来的改变。\nhttp://t.cn/Ruw2krx\nhttp://t.cn/RuwLvk4\nhttp://t.cn/RuwL7GF\n\n2.从5.x升级到6.x可能导致的查询问题。\nhttp://t.cn/Ruw6WVq\n\n3.用elasticsearch为你的项目提供垂直搜索服务。\n[url]http://t.cn/RuwQdN8[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/587\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第250期 (2018-04-23)","uid":"4063","views":"402","votes":"0"},"_type":"doc"}
{"_id":"593","_index":"forum-mysql","_score":1,"_source":{"addtime":"1524702848","category_id":"18","comments":"0","has_attach":"0","id":"593","message":"1. X-Pack 公开代码的官方文章介绍，快来编译体验吧，新版的 Index Management UI 很赞呦！\nhttp://t.cn/RufNgMg\n\n2. 关于 elastic 公司公开 x-pack 代码的原因，不妨来听下这个 podcast\nhttp://t.cn/RufpGgm\n\n3. 360° Monitoring of Your Microservices(自备梯子)\nhttps://www.youtube.com/watch?v=kDzvQp8ggwk\n\n\n编辑：rockybean\n归档：https://elasticsearch.cn/article/593\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第253期 (2018-04-26)","uid":"86","views":"413","votes":"0"},"_type":"doc"}
{"_id":"599","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525224273","category_id":"18","comments":"0","has_attach":"0","id":"599","message":"1.IBM基于Spark与Elasticsearch的推荐系统案例。\n[url]http://t.cn/RYfMJa2[/url] \n2.elasticsearch源码深入分析——文档(document)的落地。\n[url]http://t.cn/RuYKtDS[/url] \n3.Elasticsearch+Dubbo+Spring实践。\n[url]http://t.cn/RuYK0tc[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/599[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url] \n ","title":"Elastic日报 第259期 (2018-05-02)","uid":"3788","views":"414","votes":"0"},"_type":"doc"}
{"_id":"604","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525478552","category_id":"18","comments":"0","has_attach":"0","id":"604","message":" \n1、利用ARS(自适应副本选择）提升es响应速度\n     http://t.cn/Ruuehn0\n2、ES6.3 SQL功能预览（需翻墙）\n    http://t.cn/RuuehnO\n3、一周热点：复联3要上映了，先看看这篇非剧透科普文章。\n    http://t.cn/RuuehnN\n编辑:  bsll\n归档：https://elasticsearch.cn/article/604\n订阅：https://tinyletter.com/elastic-daily \n ","title":"Elastic日报 第262期 (2018-05-05)","uid":"1874","views":"424","votes":"0"},"_type":"doc"}
{"_id":"606","_index":"forum-mysql","_score":1,"_source":{"addtime":"1525662915","category_id":"18","comments":"0","has_attach":"0","id":"606","message":"1.Elastic Stack运维数据分析从0到1。\nhttp://t.cn/RuDatRv\n\n2.Elasticsearch中的geo功能。\nhttp://t.cn/RuDifvS\n\n3.利用ELK搭建Docker容器化应用日志中心。\n[url]http://t.cn/Rm4RQRS[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/606\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第264期 (2018-05-07)","uid":"4063","views":"423","votes":"0"},"_type":"doc"}
{"_id":"680","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529719068","category_id":"18","comments":"0","has_attach":"0","id":"680","message":"1. 基于hanlp的ES分词插件(可以作为IK的补充）。\n[http://t.cn/RrAUlTZ](http://t.cn/RrAUlTZ) \n\n2. Berlin Buzzword 2018中ES开发人员的演讲(需翻墙）。\n[http://t.cn/RrAcrKY](http://t.cn/RrAcrKY) \n\n3. 一周热点：一个正则表达式引发的惨案。\n[http://t.cn/RrAVq9K](http://t.cn/RrAVq9K) \n\n活动预告\n1. 6月30日南京meetup参会报名中\n[https://elasticsearch.cn/m/article/647](https://elasticsearch.cn/m/article/647)\n\n2. 7月21日上海meetup演讲申请中\n[https://elasticsearch.cn/m/article/655](https://elasticsearch.cn/m/article/655)\n\n* 编辑：bsll\n\n* 归档：https://elasticsearch.cn/article/680\n\n* 订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第311期 (2018-06-23)","uid":"1874","views":"363","votes":"0"},"_type":"doc"}
{"_id":"679","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529620610","category_id":"18","comments":"0","has_attach":"0","id":"679","message":"1、Elastic 社区电台 第三期，嘉宾：徐胜、张延明@饿了么\nhttp://t.cn/Rrz2mog\n2、spring boot elasticsearch 5.x/6.x版本整合详解\nhttp://t.cn/Rrz57ZR\n3、elasticsearchr: R语言轻量级的Elasticsearch客户端\nhttp://t.cn/Rrzqk9o\n\n活动预告：\n1.6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647 \n2.7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655 \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/679\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第310期 (2018-06-22)","uid":"1341","views":"338","votes":"0"},"_type":"doc"}
{"_id":"673","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529199049","category_id":"18","comments":"0","has_attach":"0","id":"673","message":"1.为nginx日志配置ELK。\nhttp://t.cn/RBTxsci\n2.(自备梯子)高可用性日志记录中的冒险 -  Kubernetes上的Elasticsearch，Logstash和Kibana（ELK）。\nhttp://t.cn/RBY9GYn\n3.(自备梯子)是什么能让一个国家善于踢足球？\n[url]http://t.cn/RBYKRRC[/url] \n \n活动预告\n \n1. 6月30日南京meetup参会报名中\nhttps://elasticsearch.cn/m/article/647\n2. 7月21日上海meetup演讲申请中\nhttps://elasticsearch.cn/m/article/655\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/673\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第305期 (2018-06-17)","uid":"4460","views":"312","votes":"0"},"_type":"doc"}
{"_id":"676","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529396817","category_id":"2","comments":"15","has_attach":"0","id":"676","message":"我单机装了个6.3.0\n执行的时候老出现如下错误,有老铁遇到过吗?\n \n我是这么来启动的\n./elasticsearch-sql-cli http://127.0.0.1:9200[code]sql\u0026gt; show tables;\n      name      |     type\n----------------+---------------\nhello           |BASE TABLE\n\nsql\u0026gt; select * from hello;\nServer error [Server encountered an error [Cannot extract value [deliveraddress.address] from source]. [SqlIllegalArgumentException[Cannot extract value [deliveraddress.address] from source]\n\tat org.elasticsearch.xpack.sql.execution.search.extractor.FieldHitExtractor.extractFromSource(FieldHitExtractor.java:139)\n\tat org.elasticsearch.xpack.sql.execution.search.extractor.FieldHitExtractor.extract(FieldHitExtractor.java:95)\n\tat org.elasticsearch.xpack.sql.execution.search.SearchHitRowSet.getColumn(SearchHitRowSet.java:114)\n\tat org.elasticsearch.xpack.sql.session.AbstractRowSet.column(AbstractRowSet.java:18)[/code] \n \n \n这是测试数据的mapping[code]{\n  \u0026quot;test2\u0026quot;: {\n    \u0026quot;properties\u0026quot;: {\n      \u0026quot;deliveraddress\u0026quot;: {\n        \u0026quot;properties\u0026quot;: {\n          \u0026quot;phone_no\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;default\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;boolean\u0026quot;\n          },\n          \u0026quot;address\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;province\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;city\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;mapping_id\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;name\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;full_address\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;zip_code\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          }\n        }\n      },\n      \u0026quot;alipaywealth\u0026quot;: {\n        \u0026quot;properties\u0026quot;: {\n          \u0026quot;balance\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          },\n          \u0026quot;total_quotient\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          },\n          \u0026quot;huabei_creditamount\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          },\n          \u0026quot;mapping_id\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n            \u0026quot;fields\u0026quot;: {\n              \u0026quot;keyword\u0026quot;: {\n                \u0026quot;ignore_above\u0026quot;: 256,\n                \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n              }\n            }\n          },\n          \u0026quot;huabei_totalcreditamount\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          },\n          \u0026quot;total_profit\u0026quot;: {\n            \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot;\n          }\n        }\n      },\n      \u0026quot;id\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\n        \u0026quot;fields\u0026quot;: {\n          \u0026quot;keyword\u0026quot;: {\n            \u0026quot;ignore_above\u0026quot;: 256,\n            \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\n          }\n        }\n      }\n    }\n  }\n}[/code]\n这是测试数据[code]{\n  \u0026quot;_id\u0026quot;: \u0026quot;5b1cbc7935eb6e0007a154bb\u0026quot;,\n  \u0026quot;deliveraddress\u0026quot;: [\n    {\n      \u0026quot;phone_no\u0026quot;: \u0026quot;13*******98\u0026quot;,\n      \u0026quot;default\u0026quot;: true,\n      \u0026quot;address\u0026quot;: \u0026quot;江苏省无asdads市徐***镇\u0026quot;,\n      \u0026quot;province\u0026quot;: \u0026quot;江苏\u0026quot;,\n      \u0026quot;city\u0026quot;: \u0026quot;无锡\u0026quot;,\n      \u0026quot;mapping_id\u0026quot;: \u0026quot;3561511087asdasd341\u0026quot;,\n      \u0026quot;name\u0026quot;: \u0026quot;b***\u0026quot;,\n      \u0026quot;full_address\u0026quot;: \u0026quot;湖asd***上7号\u0026quot;,\n      \u0026quot;zip_code\u0026quot;: \u0026quot;214400\u0026quot;\n    },\n    {\n      \u0026quot;phone_no\u0026quot;: \u0026quot;15*******70\u0026quot;,\n      \u0026quot;default\u0026quot;: false,\n      \u0026quot;address\u0026quot;: \u0026quot;江苏省苏州asdasdasd张家港经济技术开发区\u0026quot;,\n      \u0026quot;province\u0026quot;: \u0026quot;江苏\u0026quot;,\n      \u0026quot;city\u0026quot;: \u0026quot;苏州\u0026quot;,\n      \u0026quot;mapping_id\u0026quot;: \u0026quot;3561511asdasd505341\u0026quot;,\n      \u0026quot;name\u0026quot;: \u0026quot;a**\u0026quot;,\n      \u0026quot;full_address\u0026quot;: \u0026quot;新asd路***德***\u0026quot;,\n      \u0026quot;zip_code\u0026quot;: \u0026quot;215600\u0026quot;\n    }\n  ],\n  \u0026quot;alipaywealth\u0026quot;: {\n    \u0026quot;balance\u0026quot;: 0,\n    \u0026quot;total_quotient\u0026quot;: 0,\n    \u0026quot;huabei_creditamount\u0026quot;: 500,\n    \u0026quot;mapping_id\u0026quot;: \u0026quot;3561511asdsa63505341\u0026quot;,\n    \u0026quot;huabei_totalcreditamount\u0026quot;: 500,\n    \u0026quot;total_profit\u0026quot;: 0\n  }\n}[/code] \n \n---\n \n初步怀疑是不是不支持嵌套,数组啥的呀\n \n然后我就翻了翻源码,发现了这个\n \n我的错误就是在最后一个else里出现的\n \n仔细一看,发现这个地方循环只要走了两次,或者前面的条件不成立就肯定会抛这个异常,这怎么看上去像是有点问题呢\n \n[code]    @SuppressWarnings(\u0026quot;unchecked\u0026quot;)\n    Object extractFromSource(Map\u0026lt;String, Object\u0026gt; map) {\n        Object value = map;\n        boolean first = true;\n        // each node is a key inside the map\n        for (String node : path) {\n            if (value == null) {\n                return null;\n            } else if (first || value instanceof Map) {\n                first = false;\n                value = ((Map\u0026lt;String, Object\u0026gt;) value).get(node);\n            } else {\n                throw new SqlIllegalArgumentException(\u0026quot;Cannot extract value [{}] from source\u0026quot;, fieldName);\n            }\n        }\n        return unwrapMultiValue(value);\n    }[/code]","title":"有老铁测试了es6.3.0的sql功能吗?","uid":"1075","views":"1401","votes":"0"},"_type":"doc"}
{"_id":"621","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526436924","category_id":"3","comments":"2","has_attach":"0","id":"621","message":"官网的在线调试地址：[url]http://grokdebug.herokuapp.com/[/url]\n \nGrok Debugger中文站：[url]http://grok.qiexun.net/[/url]\n \n自己本地搭建：[url]http://blog.51cto.com/fengwan/1758845[/url]","title":"Grok Debugger","uid":"2371","views":"496","votes":"2"},"_type":"doc"}
{"_id":"622","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526437048","category_id":"18","comments":"0","has_attach":"0","id":"622","message":"1.Elasticsearch词频统计与原理解读\n[url]http://t.cn/R3xR5qv[/url] \n2.自定义Spark Partitioner提升es-hadoop Bulk效率\n[url]http://t.cn/R3oHaKq[/url] \n3.Filebeat to Elasticsearch 针对于Filebeat端性能优化--性能提升230%\n[url]http://t.cn/R3oQvF2[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/622[/url] \n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第273期 (2018-05-16)","uid":"3828","views":"391","votes":"1"},"_type":"doc"}
{"_id":"628","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526773338","category_id":"18","comments":"0","has_attach":"0","id":"628","message":"1.Open Data + Node.JS + Elasticsearch - 1300万个街道地址和计数。\nhttp://t.cn/R3HTu7T\n2.设计完美的Elasticsearch集群。\nhttp://t.cn/R3HlIbV\n3.框架还是语言？\nhttp://t.cn/R3HWnGL\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/628\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第277期 (2018-05-20)","uid":"4460","views":"352","votes":"1"},"_type":"doc"}
{"_id":"629","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526859946","category_id":"2","comments":"2","has_attach":"0","id":"629","message":"有 SQL 背景的同学在学习 Elasticsearch 时，面对一个查询需求，不由自主地会先思考如何用 SQL 来实现，然后再去想 Elasticsearch 的 Query DSL 如何实现。那么本篇就给大家讲一条常见的 SQL 语句如何用 Elasticsearch 的查询语言实现。\n\n\n\n# 1. SQL语句\n\n假设我们有一个汽车的数据集，每个汽车都有车型、颜色等字段，我希望获取颜色种类大于1个的前2车型。假设汽车的数据模型如下：\n\n```json\n{\n    \u0026quot;model\u0026quot;:\u0026quot;modelA\u0026quot;,\n    \u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;\n}\n```\n\n假设我们有一个 *cars* 表，通过如下语句创建测试数据。\n\n```sql\nINSERT INTO cars (model,color) VALUES ('A','red'); \nINSERT INTO cars (model,color) VALUES ('A','white'); \nINSERT INTO cars (model,color) VALUES ('A','black'); \nINSERT INTO cars (model,color) VALUES ('A','yellow'); \nINSERT INTO cars (model,color) VALUES ('B','red'); \nINSERT INTO cars (model,color) VALUES ('B','white'); \nINSERT INTO cars (model,color) VALUES ('C','black'); \nINSERT INTO cars (model,color) VALUES ('C','red'); \nINSERT INTO cars (model,color) VALUES ('C','white'); \nINSERT INTO cars (model,color) VALUES ('C','yellow'); \nINSERT INTO cars (model,color) VALUES ('C','blue'); \nINSERT INTO cars (model,color) VALUES ('D','red');\nINSERT INTO cars (model,color) VALUES ('A','red'); \n```\n\n那么实现我们需求的 SQL 语句也比较简单，实现如下：\n\n```sql\nSELECT model,COUNT(DISTINCT color) color_count FROM cars GROUP BY model HAVING color_count \u0026gt; 1 ORDER BY color_count desc LIMIT 2;\n```\n\n这条查询语句中 **Group By** 是按照 model 做分组， **Having color_count\u0026gt;1** 限定了车型颜色种类大于1，**ORDER BY color_count desc ** 限定结果按照颜色种类倒序排列，而 **LIMIT 2** 限定只返回前3条数据。\n\n那么在 Elasticsearch 中如何实现这个需求呢？\n\n# 2. 在 Elasticsearch 模拟测试数据\n\n首先我们需要先在 elasticsearch 中插入测试的数据，这里我们使用 *bulk 接口* ，如下所示：\n\n```\nPOST _bulk\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;1\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;A\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;2\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;A\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;white\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;3\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;A\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;black\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;4\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;A\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;yellow\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;5\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;B\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;6\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;B\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;white\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;7\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;C\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;black\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;8\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;C\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;9\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;C\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;white\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;10\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;C\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;yellow\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;11\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;C\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;blue\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;12\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;D\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;}\n{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;cars\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;13\u0026quot;}}\n{\u0026quot;model\u0026quot;:\u0026quot;A\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;red\u0026quot;}\n```\n\n 其中 *index* 为 cars，*type* 为 doc，所有数据与mysql 数据保持一致。大家可以在 Kibana 的 Dev Tools 中执行上面的命令，然后执行下面的查询语句验证数据是否已经成功存入。\n\n```\nGET cars/_search\n```\n\n# 3. Group By VS Terms/Metric Aggregation\n\nSQL 中 *Group By* 语句在 Elasticsearch 中对应的是 *Terms Aggregation*，即分桶聚合，对应 *Group By color* 的语句如下所示：\n\n```json\nGET cars/_search\n{\n  \u0026quot;size\u0026quot;:0,\n  \u0026quot;aggs\u0026quot;:{\n    \u0026quot;models\u0026quot;:{\n      \u0026quot;terms\u0026quot;:{\n        \u0026quot;field\u0026quot;:\u0026quot;model.keyword\u0026quot;\n      }\n    }\n  }\n}\n```\n\n结果如下：\n\n```json\n{\n  \u0026quot;took\u0026quot;: 161,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;skipped\u0026quot;: 0,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 13,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;: []\n  },\n  \u0026quot;aggregations\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;doc_count_error_upper_bound\u0026quot;: 0,\n      \u0026quot;sum_other_doc_count\u0026quot;: 0,\n      \u0026quot;buckets\u0026quot;: [\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;A\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;C\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;B\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 2\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;D\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 1\n        }\n      ]\n    }\n  }\n}\n```\n\n我们看 **aggregations** 这个 key 下面的即为返回结果。\n\nSQL 语句中还有一项是 `COUNT(DISTINCT color) color_count` 用于计算每个 model 的颜色数，在 Elasticsearch 中我们需要使用一个指标类聚合 **Cardinality** ，进行不同值计数。语句如下：\n\n```sql\nGET cars/_search\n{\n  \u0026quot;size\u0026quot;: 0,\n  \u0026quot;aggs\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;terms\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;model.keyword\u0026quot;\n      },\n      \u0026quot;aggs\u0026quot;: {\n        \u0026quot;color_count\u0026quot;: {\n          \u0026quot;cardinality\u0026quot;: {\n            \u0026quot;field\u0026quot;: \u0026quot;color.keyword\u0026quot;\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n其返回结果如下：\n\n```json\n{\n  \u0026quot;took\u0026quot;: 74,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;skipped\u0026quot;: 0,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 13,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;: []\n  },\n  \u0026quot;aggregations\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;doc_count_error_upper_bound\u0026quot;: 0,\n      \u0026quot;sum_other_doc_count\u0026quot;: 0,\n      \u0026quot;buckets\u0026quot;: [\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;A\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 4\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;C\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 5\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;B\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 2,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 2\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;D\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 1,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 1\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n结果中 *color_count* 即为每个 model 的颜色数，但这里所有的模型都返回了，我们只想要颜色数大于1的模型，因此这里还要加一个过滤条件。\n\n\n\n\n\n# 4. Having Condition VS Bucket Filter Aggregation\n\n**Having color_count \u0026gt; 1** 在 Elasticsearch 中对应的是 *Bucket Filter* 聚合，语句如下所示：\n\n```json\nGET cars/_search\n{\n  \u0026quot;size\u0026quot;: 0,\n  \u0026quot;aggs\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;terms\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;model.keyword\u0026quot;\n      },\n      \u0026quot;aggs\u0026quot;: {\n        \u0026quot;color_count\u0026quot;: {\n          \u0026quot;cardinality\u0026quot;: {\n            \u0026quot;field\u0026quot;: \u0026quot;color.keyword\u0026quot;\n          }\n        },\n        \u0026quot;color_count_filter\u0026quot;: {\n          \u0026quot;bucket_selector\u0026quot;: {\n            \u0026quot;buckets_path\u0026quot;: {\n              \u0026quot;colorCount\u0026quot;: \u0026quot;color_count\u0026quot;\n            },\n            \u0026quot;script\u0026quot;: \u0026quot;params.colorCount\u0026gt;1\u0026quot;\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n返回结果如下：\n\n```json\n{\n  \u0026quot;took\u0026quot;: 39,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;skipped\u0026quot;: 0,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 13,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;: []\n  },\n  \u0026quot;aggregations\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;doc_count_error_upper_bound\u0026quot;: 0,\n      \u0026quot;sum_other_doc_count\u0026quot;: 0,\n      \u0026quot;buckets\u0026quot;: [\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;A\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 4\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;C\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 5\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;B\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 2,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 2\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n此时返回结果只包含颜色数大于1的模型，但大家会发现颜色数多的 C 不是在第一个位置，我们还需要做排序处理。\n\n# 5. Order By Limit VS Bucket Sort Aggregation\n\n**ORDER BY color_count desc LIMIT  3** 在 Elasticsearch 中可以使用 Bucket Sort 聚合实现，语句如下所示：\n\n```sql\nGET cars/_search\n{\n  \u0026quot;size\u0026quot;: 0,\n  \u0026quot;aggs\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;terms\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;model.keyword\u0026quot;\n      },\n      \u0026quot;aggs\u0026quot;: {\n        \u0026quot;color_count\u0026quot;: {\n          \u0026quot;cardinality\u0026quot;: {\n            \u0026quot;field\u0026quot;: \u0026quot;color.keyword\u0026quot;\n          }\n        },\n        \u0026quot;color_count_filter\u0026quot;: {\n          \u0026quot;bucket_selector\u0026quot;: {\n            \u0026quot;buckets_path\u0026quot;: {\n              \u0026quot;colorCount\u0026quot;: \u0026quot;color_count\u0026quot;\n            },\n            \u0026quot;script\u0026quot;: \u0026quot;params.colorCount\u0026gt;1\u0026quot;\n          }\n        },\n        \u0026quot;color_count_sort\u0026quot;: {\n          \u0026quot;bucket_sort\u0026quot;: {\n            \u0026quot;sort\u0026quot;: {\n              \u0026quot;color_count\u0026quot;: \u0026quot;desc\u0026quot;\n            },\n            \u0026quot;size\u0026quot;: 2\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n返回结果如下：\n\n```json\n{\n  \u0026quot;took\u0026quot;: 32,\n  \u0026quot;timed_out\u0026quot;: false,\n  \u0026quot;_shards\u0026quot;: {\n    \u0026quot;total\u0026quot;: 5,\n    \u0026quot;successful\u0026quot;: 5,\n    \u0026quot;skipped\u0026quot;: 0,\n    \u0026quot;failed\u0026quot;: 0\n  },\n  \u0026quot;hits\u0026quot;: {\n    \u0026quot;total\u0026quot;: 13,\n    \u0026quot;max_score\u0026quot;: 0,\n    \u0026quot;hits\u0026quot;: []\n  },\n  \u0026quot;aggregations\u0026quot;: {\n    \u0026quot;models\u0026quot;: {\n      \u0026quot;doc_count_error_upper_bound\u0026quot;: 0,\n      \u0026quot;sum_other_doc_count\u0026quot;: 0,\n      \u0026quot;buckets\u0026quot;: [\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;C\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 5\n          }\n        },\n        {\n          \u0026quot;key\u0026quot;: \u0026quot;A\u0026quot;,\n          \u0026quot;doc_count\u0026quot;: 5,\n          \u0026quot;color_count\u0026quot;: {\n            \u0026quot;value\u0026quot;: 4\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n至此我们便将 SQL 语句实现的功能用 Elasticsearch 查询语句实现了。对比 SQL 语句与 Elasticsearch 的查询语句，大家会发现后者复杂了很多，但并非无章可循，随着大家对常见语法越来越熟悉，相信一定会越写越得心应手！","title":"Elasticsearch如何实现 SQL语句中 Group By 和 Limit 的功能","uid":"86","views":"824","votes":"7"},"_type":"doc"}
{"_id":"632","_index":"forum-mysql","_score":1,"_source":{"addtime":"1526877016","category_id":"44","comments":"14","has_attach":"1","id":"632","message":"\r\n[attach]2240[/attach]\r\n Elastic Podcast 第二期来啦, 这一次我们来到了位于上海的携程旅行网，携程内部大量运用了 Elasticsearch 来进行集中式的运维日志管理和为业务部门提供统一的搜索服务平台，目前线上总共部署了多达 94 个 Elasticsearch 集群和超过 700 多个 Elasticsearch 节点，每天新增日志 1600 亿条，峰值达到 300 万每秒，存放在 Elasticsearch 里面的索引文档达到 2.5 万亿，磁盘存储达到 PB 级。想知道携程是如何应对这些海量数据下的挑战，以及最佳实践，让我们一起来收听这一期的 Podcast，跟随携程的两位技术负责人吴晓刚和胡航来一探究竟。\r\n\r\n\r\n[b]主持人：[/b]\r\n\r\nElastic 技术布道师，曾勇（Medcl）。\r\n\r\n\r\n[b]嘉宾：[/b]\r\n\r\n吴晓刚，携程技术保障部系统研发总监， Elasticsearch 国内早期实践者，中文社区活跃用户。 曾在 eBay, Morgan Stanley, PPTV 等国内外公司从事系统软件研发、系统集成与技术支持工作。对于大规模 IT 系统的运维自动化、可视化、性能优化具有浓厚的兴趣。在技术方面一直抱有知其然知其所以然的态度。\r\n\r\n\r\n胡航，携程旅行网高级技术经理，负责相关搜索实现、SOA服务的开发。曾供职于腾讯、盛大等公司，对新技术持有强烈的好奇心，目前关注于 Elasticsearch 的业务实现、JVM 性能优化等。\r\n\r\n\r\n可以点击下面的任意链接来收听（时长约 50 分钟）：\r\n[list]\r\n[*]SoundCloud：https://soundcloud.com/elastic-cn/elastic-podcast2-wuxiaogang_huhangctrip[/*]\r\n[*]喜马拉雅：[url]http://m.ximalaya.com/111156131/sound/89571047[/url] [/*]\r\n[*]蜻蜓 FM：http://m.qingting.fm/vchannels/244978/programs/9145776[/*]\r\n[/list]\r\n\r\n往期：[url=https://www.elastic.co/cn/blog/elastic-podcast-episode-one-xiehengyue-from-derbysoft]Elastic 在德比软件的使用[/url]\r\n\r\n\r\n[b]关于 Elastic Podcast[/b]\r\n\r\n《Elastic Podcast》是由 Elastic 中文社区发起的一档谈话类的播客节目，节目会定期邀请 Elastic 开源软件的用户，一起来聊一聊围绕他们在使用 Elastic 开源软件过程中的各种话题，包括行业应用、架构案例、经验分享等等。\r\n \r\n\r\n[attach]2239[/attach]\r\n[胡航/吴晓刚/曾勇]","title":"Elastic Podcast 第二期，嘉宾：吴晓刚/胡航@Ctrip","uid":"1","views":"1074","votes":"6"},"_type":"doc"}
{"_id":"634","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527006488","category_id":"2","comments":"8","has_attach":"0","id":"634","message":"\u0026gt; Elastic Podcast 第二期来啦, 这一次我们来到了位于上海的携程旅行网，携程内部大量运用了 Elasticsearch来进行集中式的运维日志管理和为业务部门提供统一的搜索服务平台，\n\u0026gt; 目前线上总共部署了多达 94 个 Elasticsearch 集群和超过\n\u0026gt; 700 多个 Elasticsearch 节点，每天新增日志 1600 亿条，峰值达到 300 万每秒，存放在 Elasticsearch里面的索引文档达到 2.5 万亿，磁盘存储达到 PB 级。\n\u0026gt; 想知道携程是如何应对这些海量数据下的挑战，以及最佳实践，让我们一起来收听这一期的 Podcast，跟随携程的两位技术负责人吴晓刚和胡航来一探究竟。\n\n音频地址：http://m.ximalaya.com/111156131/sound/89571047\n\n主持人：Elastic 技术布道师，曾勇（Medcl）。\n嘉宾：\n1、吴晓刚（Wood大叔），携程技术保障部系统研发总监， Elasticsearch 国内早期实践者，中文社区活跃用户。 曾在 eBay, Morgan Stanley, PPTV 等国内外公司从事系统软件研发、系统集成与技术支持工作。对于大规模 IT 系统的运维自动化、可视化、性能优化具有浓厚的兴趣。在技术方面一直抱有知其然知其所以然的态度。\n\n2、胡航，携程旅行网高级技术经理，负责相关搜索实现、SOA服务的开发。曾供职于腾讯、盛大等公司，对新技术持有强烈的好奇心，目前关注于 Elasticsearch 的业务实现、JVM 性能优化等。\n\n# 1、携程Elasticsearch使用历史\n## 1.1 运维组Wood大叔：\n2014年，ES0.9版本。\n选型对比：MongoDB——数据量级大了以后，出现性能瓶颈。\n调研后，选型：ELK（Elasticsearch、Logstash、Kibana）。\n实现效果：实时看效果、查询、聚合。\n\n## 1.2 胡航业务组：\n业务场景：酒店价格。\n选型依据：ES分布式、可调试性能好。\n版本：ES2.3。\n时间：2017年中，逐步转向ES，5.3版本。\n效果：显著。专注于后端开发，业务交由业务团队自己去做。\n\n# 2、携程Elasticsearch规模\n\n## 2.1 运维组Wood大叔：\n集群：94个。最小三个节点，最大：360+节点。\n节点：700+。\n每日增量：1600亿条。\n峰值：300W/s。\n总数据量：2.5万亿，PB数量级。\n面对挑战：\n1）实时写入。\n2）业务流程相关，几个月-2年的历史数据。\n\n## 2.2 胡航业务组：\n业务场景：3集群，每集群6个节点。\n单个索引：最大1000W-2000W。\n\n关注：ES基础框架，帮业务部分实现写入、查询、DSL调优。\n查询：3000-4000/s。\n\n携程ES规模量全国数一数二，有很大挑战。\n\n# 3、携程Elasticsearch淌过的坑\n\n## 3.1 运维组Wood大叔：\n###  3.1.1 痛点1：内存溢出。\n\n原因：早期版本，对查询限制做的不充分；数据量上了规模，查询、聚合会非常耗内存。\n\n升级版本后，ES做了很多处理，集群层面做了限制。越来越稳定。\n\n### 3.1.2 痛点2：集群故障无法恢复。\n### 3.1.3 痛点3：translog做不完。\n### 3.1.4 痛点4：集群的平台化管理。\n需要：研究底层工作机制，找到规避方法。\n经验丰富后，运维效率提升。\n\n## 3.2胡航业务组：\n### 3.2.1  痛点1：ES基础不熟悉带来的问题；\n### 3.2.2 痛点2：性能问题——最终排查是ES5.X keyword类型的原因。\n\n# 4、架构\n## 4.1运维组Wood大叔：\n1、早期：ELK+redis（中间缓存）\n\n挑战：\n1）redis承受能力差。\n\n2）redis单线程。\n\n改善：\n1）redis改为kafka（磁盘级别），数据畅通了。\n\n2）Logstash内存消耗大。——改为：logstash forward，推荐官方Beats。\n\n3）数据规模后，需要很多服务器，Logstash非常耗内存。\n\n优化：用golang开发了一个gohangout (https://github.com/childe/gohangout ) ，\n\n内存比java 版的hangout(https://github.com/childe/hangout) 内存大幅降低。\n\n## 4.2 胡航搜索业务组：\n\n1）单点集群压力瓶颈。\n\n改为：业务数据导入ES，提供定制客户端。\n\n2）搜索平台，接入更多业务需求。\n\n不方便在kibana做定制开发，自己做了简单网站查询数据、监控，满足业务的贴切需求。\n\n# 5、ES6.3最新特性（抢先看）\n\n## 5.1 ES6.3 支持Sql接口\n\nWood大叔：\nkibana看DSL，拷贝后修改。新用户不熟悉，会不方便。\n\nBI部分也需要，类似sql的查询。\n\n优点：更简单，发挥更大的作用。\n\n携程BI部门——应用场景：搜索的关键词、 统计热词，目的地等信息。\n\nKibana满足不了需求，就要写代码。如果有了sql，会非常快的开发。\n\n胡航搜索业务组：\n写DSL，还是稍微复杂。借助 NLPChina ElasticsearchSql插件实现。\n\n实际应用发现插件还是有问题，期待ES官方推出Sql查询。\n\n## 5.2 增加kibana丰富表现力\n## 5.3 更快的索引速度\nrefresh优化：提升吞吐。\n\n# 6、ELK Stack最喜欢的特性\nWood大叔：\n丰富的扩展能力，用户不必关心底层的实现。通过服务器增加节点，方便大数据量查询。\n\n胡航：\nES可视化、可调试特性。\n举例：\n1）出现问题排查DSL是不是合适？Mapping是不是合适？\n\n2）相信ES的社区，不必关心底层，更多的时间做业务（解放双手）。\n\n3）ES中做好数据模型，实现业务需求。\n\n# 7、ELK Stack最需要完善的\n\nWood大叔：\n1）集群的保护待更进一步完善\n数据丢失后的处理？\n\n节点损毁后的处理？\n\n目的：减轻运维的负担；\n\n2）甄别坏查询，Slow log存在缺陷。\n很难判定真正故障是哪个慢查询。\n\n集群发下故障的时候，有API实时分析会更好（比单纯查slow log）。\n\n胡航：\n1）ES坑还很多，比较耗费时间。\n\n2）期待社区对常见问题整理。\n\n3）期待官方总结完善的向导，类似：Cookbook。\n\n初级上手的话可以参考借鉴（大家缺乏经验）\n\n# 8、初学者的建议\n1）初学者必读——《Elasticsearch: 权威指南》（英文、中文）\nWOOD大叔至少看了3遍。\n\n2）不断的实践。\n\n3）带着问题，再去找文档，构建知识体系。\n\n4）多参与社区，尝试理解和解决社区问题，不断学习，以提升自己。\n互帮互助，共同成长！\n\n5）中文社区的小建议：问题精华版收集——新手通读，学习前人经验。\n\n# 9、如何看待Elasticsearch在国内的发展？\n1）参与和贡献，国内做的不足；\n\n2）中文分词插件等，如：分词质量要求高，专业语义搜索支持（提高搜索相关性等）、情感标注、NLP等。\n\n3）在中文应用场景应用更加丰富。\n\n4）社区问题比较分散，社区需要意见领袖，加强某领域讨论、深入交流等。\n\n5）medcl：ElasticTips成立，大家都去参与，以图片形式分享。\n\n6) 社区还会做更多的事情，大家多分享、互相交流。\n\n#10、小结\n非常震惊，wood大叔看了3遍《Elasticsearch: 权威指南》，我们没有理由不努力。\n\n共勉，加油！\n\n","title":"干货 | Elasticsearch 布道者Medcl对话携程Wood大叔核心笔记","uid":"1341","views":"1101","votes":"7"},"_type":"doc"}
{"_id":"637","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527150915","category_id":"2","comments":"0","has_attach":"1","id":"637","message":"2018年的数据引擎排名已经出啦，不知道各位小伙伴留意没~~~\r\n[attach]2255[/attach]\r\nElasticsearch强势进入前十，是一颗冉冉升起的新星。\r\n \r\n一些小伙伴经常会碰到选取何种数据引擎的情况。在此，我们将把几个热门的开源数据引擎进行对比，供大家参考。\r\n[attach]2254[/attach]\r\n\r\n从上表看出：\r\nMySQL：将数据保存在不同的表中，使用SQL语言进行交互，是目前非常流行的关系型数据库管理系统。如果您需要一个传统的数据库，那么MySQL是不错的选择。\r\nMongoDB：基于分布式文件存储的NoSQL数据库，数据结构由键值对组成，具有可扩展性。如果您需要存储和查询非结构化信息，不太需要分析或全文检索，那么MongoDB是不错的选择。\r\nRedis：高性能的键值对数据库，支持一定程度的事务性。主要应用为缓存，对读写有非常高性能要求的场景中，是不错的选择。但因为是靠全内存加速，所以数据量大的情况下，配置要求也很高。\r\nElasticsearch：基于Lucene的分布式搜索引擎，具有全文检索，同义词处理，相关度排名，复杂数据分析的能力。如果您想做文本类检索，及相关性排序，以及指标类分析，Elasticsearch会非常适合。它在文档全文检索（网站搜索，APP搜索）和日志分析（运营，运维）领域拥有得天独厚的优势。\r\n \r\n此文抛砖引玉，欢迎小伙伴留言讨论不同数据引擎的适用场景~~\r\n\r\n另有想快速体验Elasticsearch欢迎戳下面链接~~~\r\n[u][b][size=16][url=https://www.huaweicloud.com/product/es.html]华为云搜索服务[/url][/size][/b][/u]是云上的Elasticsearch，具有简单易用、无忧运维、弹性灵活、数据可靠等特点，欢迎使用~~~~\r\n ","title":"[技术交流] Elasticsearch冉冉升起，几款开源数据引擎对比","uid":"8616","views":"478","votes":"0"},"_type":"doc"}
{"_id":"642","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527503671","category_id":"2","comments":"2","has_attach":"0","id":"642","message":"[url=https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster]How many shards should I have in my Elasticsearch cluster?[/url]\n \nElasticsearch is a very versatile platform, that supports a variety of use cases, and provides great flexibility around data organisation and replication strategies. This flexibility can however sometimes make it hard to determine up-front how to best organize your data into indices and shards, especially if you are new to the Elastic Stack. While suboptimal choices  will not necessarily cause problems when first starting out, they have the potential to cause performance problems as data volumes grow over time. The more data the cluster holds, the more difficult it also becomes to correct the problem, as reindexing of large amounts of data can sometimes be required.\n\nWhen we come across users that are experiencing performance problems, it is not uncommon that this can be traced back to issues around how data is indexed and number of shards in the cluster. This is especially true for use-cases involving multi-tenancy and/or use of time-based indices. When discussing this with users, either in person at events or meetings or via our forum, some of the most common questions are “How many shards should I have?” and “How large should my shards be?”.\n\nThis blog post aims to help you answer these questions and provide practical guidelines for use cases that involve the use of time-based indices, e.g. logging or security analytics, in a single place.\n\nWhat is a shard?\n\nBefore we start, we need to establish some facts and terminology that we will need in later sections.\n\nData in Elasticsearch is organized into indices. Each index is made up of one or more shards. Each shard is an instance of a Lucene index, which you can think of as a self-contained search engine that indexes and handles queries for a subset of the data in an Elasticsearch cluster.\n\nAs data is written to a shard, it is periodically published into new immutable Lucene segments on disk, and it is at this time it becomes available for querying. This is referred to as a refresh. How this works is described in greater detail in Elasticsearch: the Definitive Guide.\n\nAs the number of segments grow, these are periodically consolidated into larger segments. This process is referred to as merging. As all segments are immutable, this means that the disk space used will typically fluctuate during indexing, as new, merged segments need to be created before the ones they replace can be deleted. Merging can be quite resource intensive, especially with respect to disk I/O.\n\nThe shard is the unit at which Elasticsearch distributes data around the cluster. The speed at which Elasticsearch can move shards around when rebalancing data, e.g. following a failure, will depend on the size and number of shards as well as network and disk performance.\n\nTIP: Avoid having very large shards as this can negatively affect the cluster's ability to recover from failure. There is no fixed limit on how large shards can be, but a shard size of 50GB is often quoted as a limit that has been seen to work for a variety of use-cases.\n\nIndex by retention period\n\nAs segments are immutable, updating a document requires Elasticsearch to first find the existing document, then mark it as deleted and add the updated version. Deleting a document also requires the document to be found and marked as deleted. For this reason, deleted documents will continue to tie up disk space and some system resources until they are merged out, which can consume a lot of system resources.\n\nElasticsearch allows complete indices to be deleted very efficiently directly from the file system, without explicitly having to delete all records individually. This is by far the most efficient way to delete data from Elasticsearch.\n\nTIP: Try to use time-based indices for managing data retention whenever possible. Group data into indices based on the retention period. Time-based indices also make it easy to vary the number of primary shards and replicas over time, as this can be changed for the next index to be generated. This simplifies adapting to changing data volumes and requirements.\n\nAre indices and shards not free?\n\nFor each Elasticsearch index, information about mappings and state is stored in the cluster state. This is kept in memory for fast access. Having a large number of indices in a cluster can therefore result in a large cluster state, especially if mappings are large. This can become slow to update as all updates need to be done through a single thread in order to guarantee consistency before the changes are distributed across the cluster.\n\nTIP: In order to reduce the number of indices and avoid large and sprawling mappings, consider storing data with similar structure in the same index rather than splitting into separate indices based on where the data comes from. It is important to find a good balance between the number of indices and the mapping size for each individual index.\n\nEach shard has data that need to be kept in memory and use heap space. This includes data structures holding information at the shard level, but also at the segment level in order to define where data reside on disk. The size of these data structures is not fixed and will vary depending on the use-case.\n\nOne important characteristic of the segment related overhead is however that it is not strictly proportional to the size of the segment. This means that larger segments have less overhead per data volume compared to smaller segments. The difference can be substantial.\n\nIn order to be able to store as much data as possible per node, it becomes important to manage heap usage and reduce the amount of overhead as much as possible. The more heap space a node has, the more data and shards it can handle.\n\nIndices and shards are therefore not free from a cluster perspective, as there is some level of resource overhead for each index and shard.\n\nTIP: Small shards result in small segments, which increases overhead. Aim to keep the average shard size between a few GB and a few tens of GB. For use-cases with time-based data, it is common to see shards between 20GB and 40GB in size.\n\nTIP: As the overhead per shard depends on the segment count and size, forcing smaller segments to merge into larger ones through a forcemerge operation can reduce overhead and improve query performance. This should ideally be done once no more data is written to the index. Be aware that this is an expensive operation that should ideally be performed during off-peak hours.\n\nTIP: The number of shards you can hold on a node will be proportional to the amount of heap you have available, but there is no fixed limit enforced by Elasticsearch. A good rule-of-thumb is to ensure you keep the number of shards per node below 20 to 25 per GB heap it has configured. A node with a 30GB heap should therefore have a maximum of 600-750 shards, but the further below this limit you can keep it the better. This will generally help the cluster stay in good health.\n\nHow does shard size affect performance?\n\nIn Elasticsearch, each query is executed in a single thread per shard. Multiple shards can however be processed in parallel, as can multiple queries and aggregations against the same shard.\n\nThis means that the minimum query latency, when no caching is involved, will depend on the data, the type of query, as well as the size of the shard. Querying lots of small shards will make the processing per shard faster, but as many more tasks need to be queued up and processed in sequence, it is not necessarily going to be faster than querying a smaller number of larger shards. Having lots of small shards can also reduce the query throughput if there are multiple concurrent queries.\n\nTIP: The best way to determine the maximum shard size from a query performance perspective is to benchmark using realistic data and queries. Always benchmark with a query and indexing load representative of what the node would need to handle in production, as optimizing for a single query might give misleading results.\n\nHow do I manage shard size?\n\nWhen using time-based indices, each index has traditionally been associated with a fixed time period. Daily indices are very common, and often used for holding data with short retention period or large daily volumes. These allow retention period to be managed with good granularity and makes it easy to adjust for changing volumes on a daily basis. Data with a longer retention period, especially if the daily volumes do not warrant the use of daily indices, often use weekly or monthly induces in order to keep the shard size up. This reduces the number of indices and shards that need to be stored in the cluster over time.\n\nTIP: If using time-based indices covering a fixed period, adjust the period each index covers based on the retention period and expected data volumes in order to reach the target shard size.\n\nTime-based indices with a fixed time interval works well when data volumes are reasonably predictable and change slowly. If the indexing rate can vary quickly, it is very difficult to maintain a uniform target shard size.\n\nIn order to be able to better handle this type of scenarios, the Rollover and Shrink APIs were introduced. These add a lot of flexibility to how indices and shards are managed, specifically for time-based indices.\n\nThe rollover index API makes it possible to specify the number of documents and index should contain and/or the maximum period documents should be written to it. Once one of these criteria has been exceeded, Elasticsearch can trigger a new index to be created for writing without downtime. Instead of having each index cover a specific time-period, it is now possible to switch to a new index at a specific size, which makes it possible to more easily achieve an even shard size for all indices.\n\nIn cases where data might be updated, there is no longer a distinct link between the timestamp of the event and the index it resides in when using this API, which may make updates significantly less efficient as each update my need to be preceded by a search.\n\nTIP: If you have time-based, immutable data where volumes can vary significantly over time, consider using the rollover index API to achieve an optimal target shard size by dynamically varying the time-period each index covers. This gives great flexibility and can help avoid having too large or too small shards when volumes are unpredictable.\n\n\nThe shrink index API allows you to shrink an existing index into a new index with fewer primary shards. If an even spread of shards across nodes is desired during indexing, but this will result in too small shards, this API can be used to reduce the number of primary shards once the index is no longer indexed into. This will result in larger shards, better suited for longer term storage of data.\n\n\nTIP: If you need to have each index cover a specific time period but still want to be able to spread indexing out across a large number of nodes, consider using the shrink API to reduce the number of primary shards once the index is no longer indexed into. This API can also be used to reduce the number of shards in case you have initially configured too many shards.\n\n\nConclusions\n\nThis blog post has provided tips and practical guidelines around how to best manage data in Elasticsearch. If you are interested in learning more, \u0026quot;Elasticsearch: the definitive guide\u0026quot; contains a section about designing for scale, which is well worth reading even though it is a bit old.\n\nA lot of the decisions around how to best distribute your data across indices and shards will however depend on the use-case specifics, and it can sometimes be hard to determine how to best apply the advice available. For more in-depth and personal advice you can engage with us commercially through a subscription and let our Support and Consulting teams help accelerate your project. If you are happy to discuss your use-case in the open, you can also get help from our community and through our public forum.","title":"转载一篇关于shard数量设计的文章，很赞","uid":"2710","views":"534","votes":"0"},"_type":"doc"}
{"_id":"652","_index":"forum-mysql","_score":1,"_source":{"addtime":"1527986788","category_id":"18","comments":"0","has_attach":"0","id":"652","message":"1.Fluent Bit教程：发送到Elasticsearch。\nhttp://t.cn/R1Wg7R8\n2.通过Elasticsearch-Hadoop连接器将Apache Pig和Hadoop与ElasticSearch配合使用。\nhttp://t.cn/R1WkDmY\n3.(自备梯子如何在不到一个小时内加密你的整个生活？\nhttp://t.cn/R1WDg9U\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/652\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第291期 (2018-06-03)","uid":"4460","views":"328","votes":"0"},"_type":"doc"}
{"_id":"664","_index":"forum-mysql","_score":1,"_source":{"addtime":"1528771343","category_id":"18","comments":"0","has_attach":"0","id":"664","message":"1.一文了解 Elasticsearch 所有设置项及其默认值。\n[url]http://t.cn/RB5c2w3[/url] \n2.Elasticsearch 默认分词器与中文分词器比较。\n[url]http://t.cn/RB4lLPT[/url] \n3.Nginx+Naxsi+Nxapi+Elasticsearch+Kibana安装教程。\n[url]http://t.cn/RB4lGaI[/url] \n\n编辑：叮咚光军\n归档：[url]https://elasticsearch.cn/article/664[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第300期 (2018-06-12)","uid":"3788","views":"294","votes":"0"},"_type":"doc"}
{"_id":"669","_index":"forum-mysql","_score":1,"_source":{"addtime":"1529015008","category_id":"18","comments":"0","has_attach":"0","id":"669","message":"1、Elasticsearch基于地址的自动补全解决方案\nhttp://t.cn/R1Upw7t\n2、Elasticsearch高效管理时序数据\nhttp://t.cn/RBodlTg\n3、Elasticsearch机器学习插件\n[url]http://t.cn/RJu5cw5[/url] \n \n[b]活动预告[/b]\n6月30日南京meetup参会报名中 \nhttps://elasticsearch.cn/m/article/647\n7月21日上海meetup演讲申请中 \nhttps://elasticsearch.cn/m/article/655\n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/669\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第303期 (2018-06-15)","uid":"1341","views":"402","votes":"1"},"_type":"doc"}
{"_id":"686","_index":"forum-mysql","_score":1,"_source":{"addtime":"1530070333","category_id":"18","comments":"0","has_attach":"0","id":"686","message":"1. 浅谈ES技术与实践\n[url]http://t.cn/RBaaEP1[/url] \n2.日志采集中的关键技术分析\n[url]http://t.cn/RroGKAZ[/url] \n3.基于微服务的日志中心设计、实现与关键配置\n[url]http://t.cn/RBSE3Mx[/url] \n \n活动预告\n1. 6月30日南京meetup参会报名中\n[url]https://elasticsearch.cn/m/article/647[/url] \n2. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n \n编辑：江水\n归档：[url]https://elasticsearch.cn/article/686[/url]\n订阅：[url]https://tinyletter.com/elastic-daily[/url]\n ","title":"Elastic日报 第315期 (2018-06-27)","uid":"3828","views":"470","votes":"1"},"_type":"doc"}
{"_id":"706","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531100290","category_id":"18","comments":"1","has_attach":"0","id":"706","message":"1. Kibana 索引查看插件，可以方便统计系统有多少种类型的index，更加方便管理\nhttp://t.cn/REhrlVK\n\n2.es 配置多个 data path 时的分配策略\nhttp://t.cn/RdC7kw5\n\n3.关于reindex性能的讨论\n[url]http://t.cn/RdCy0nL[/url] \n\n活动预告\n1. 7月21日上海meetup演讲申请中\n[url]https://elasticsearch.cn/m/article/655[/url] \n\n编辑：cyberdak\n归档：[url=https://elasticsearch.cn/article/{}]https://elasticsearch.cn/article/[/url]706\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第327期 (2018-07-09)","uid":"4063","views":"387","votes":"1"},"_type":"doc"}
{"_id":"716","_index":"forum-mysql","_score":1,"_source":{"addtime":"1531716352","category_id":"18","comments":"0","has_attach":"0","id":"716","message":"1. 基于Kubernetes的ESaaS架构及实现细节\nhttp://t.cn/RgbgnUI\n\n2. 去哪儿的es as a service 实践\nhttp://t.cn/RgbeGwf\n\n3.PB级ES集群的管理经验\n[url]http://t.cn/RtNmXMk[/url] \n\n1. 7月21日上海meetup倒计时\nhttps://elasticsearch.cn/m/article/655\n\n2. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/716\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第334期 (2018-07-16)","uid":"4063","views":"289","votes":"0"},"_type":"doc"}
{"_id":"732","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532575072","category_id":"18","comments":"0","has_attach":"0","id":"732","message":"1.elastic收购Insight.io，未来将提供代码搜索功能\nhttp://t.cn/RewNoj6\n2.ElasticSearch搜索建议实现\nhttp://t.cn/Rey4YWA\n3.从一份定义文件详解Logstash插件结构\nhttp://t.cn/Rey48dJ\n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n \n编辑：金桥\n归档：https://elasticsearch.cn/article/732\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第344期 (2018-07-26)","uid":"668","views":"322","votes":"0"},"_type":"doc"}
{"_id":"736","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532829190","category_id":"18","comments":"0","has_attach":"0","id":"736","message":"1.使用DOCKER和ELASTICSEARCH构建全文搜索应用程序。\nhttp://t.cn/R8JpA7F\n2.(自备梯子)在Kubernetes上部署Elasticsearch集群指南。\nhttp://t.cn/RexZNXY\n3.(自备梯子)如何学会不再担心和享受压力。\nhttp://t.cn/Rex2x83\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/736\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第347 (2018-07-29)","uid":"4460","views":"284","votes":"0"},"_type":"doc"}
{"_id":"737","_index":"forum-mysql","_score":1,"_source":{"addtime":"1532922216","category_id":"18","comments":"0","has_attach":"0","id":"737","message":"1.Lucene解析 - 基本概念。\n[url]http://t.cn/ReST6cG[/url] \n\n2.相关度评分背后的理论。\n[url]http://t.cn/ReKFICn[/url] \n\n3. 搜索服务 Sphinx 介绍 以及和 ES 的对比。\nhttp://t.cn/R5U5MOj\nhttp://t.cn/RVchT59\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/737\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第348期 (2018-07-30)","uid":"4063","views":"293","votes":"0"},"_type":"doc"}
{"_id":"745","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533521525","category_id":"18","comments":"0","has_attach":"0","id":"745","message":"1、跟随 car2go 学习使用 ELK Stack 来做商业分析\nhttp://t.cn/RDw9baD\n2、es相关的分布式一致性算法介绍:bully,gossip,raft\nhttp://t.cn/Rt3MpnJ\n3、磁盘RAID的各种IOPS计算方式以及测试\nhttp://t.cn/RDwLG6x\n\n活动预告：\nElastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑：cybedak\n归档：https://elasticsearch.cn/article/745\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第355期 (2018-08-06)","uid":"4063","views":"272","votes":"0"},"_type":"doc"}
{"_id":"746","_index":"forum-mysql","_score":1,"_source":{"addtime":"1533607897","category_id":"18","comments":"0","has_attach":"0","id":"746","message":"1.容易造成Elasticsearch崩溃的一些操作。\nhttp://t.cn/RDbSVIO\n2.使用datadog监控Elasticsearch集群。\nhttp://t.cn/RDbSibW\n3.Elasticsearch远程日志。\n[url]http://t.cn/RDbOX9U[/url] \n\n活动预告\n1. Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/746\n订阅：https://tinyletter.com/elastic-daily\n ","title":" Elastic日报 第356期 (2018-08-07)","uid":"3788","views":"281","votes":"0"},"_type":"doc"}
{"_id":"758","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534348319","category_id":"18","comments":"0","has_attach":"0","id":"758","message":"1.从Tableau到Elastic: 看Samtec如何进行流式BI\nhttp://t.cn/RDo2OXR\n2.搜索引擎 ElasticSearch\nhttp://t.cn/Rrifuz5\n3.Grafana与Kibana的主要差异\nhttp://t.cn/RDFwTe0\n\n活动预告：\n1. Elastic 中国开发者大会预热票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：wt\n归档：https://elasticsearch.cn/article/758\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第365期 (2018-08-16)","uid":"3851","views":"295","votes":"0"},"_type":"doc"}
{"_id":"760","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534459024","category_id":"18","comments":"0","has_attach":"0","id":"760","message":"1、SSM 架构结合ElasticSearch 的电影搜索开源项目\nhttp://t.cn/RDdxGyR\n2、用PROFILE API 定位 ES 慢查询\nhttp://t.cn/Rk7PYNZ\n3、同步Mysql数据到Elasticsearch的工具\nhttps://elasticsearch.cn/article/756\n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\nhttps://elasticsearch.cn/article/759\n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\nhttps://conf.elasticsearch.cn/2018/shenzhen.html \n\n编辑：铭毅天下\n归档：https://elasticsearch.cn/article/760\n订阅：https://tinyletter.com/elastic-daily","title":" Elastic日报 第366期 (2018-08-17)","uid":"1341","views":"252","votes":"0"},"_type":"doc"}
{"_id":"766","_index":"forum-mysql","_score":1,"_source":{"addtime":"1534906402","category_id":"18","comments":"0","has_attach":"0","id":"766","message":"1. Elasticsearch 运维\n[url]http://t.cn/RkKcGWm[/url] \n2. Elasticsearch之基本查询\n[url]http://t.cn/RGtNQV2[/url] \n3. Elasticsearch之查询过滤\n[url]http://t.cn/RGcFE2K[/url] \n\n活动预告：\n1、Elastic Meetup 北京线下沙龙征稿中\n[url]https://elasticsearch.cn/article/759[/url] \n2、Elastic 中国开发者大会 2018 ，开始接受演讲申请和赞助合作\n[url]https://conf.elasticsearch.cn/2018/shenzhen.html[/url] \n\n编辑：江水\n归档：[url]https://elasticsearch.cn/article/766[/url] \n订阅：[url]https://tinyletter.com/elastic-daily[/url]","title":"Elastic日报 第371期 (2018-08-22)","uid":"3828","views":"289","votes":"0"},"_type":"doc"}
{"_id":"772","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535242976","category_id":"18","comments":"0","has_attach":"0","id":"772","message":"1.Kibana高级搜索入门。\nhttp://t.cn/Rk1SYUC\n2.(自备梯子)四大NoSQL数据库。\nhttp://t.cn/Rk1anR2\n3.(自备梯子)您必须在“按时交付的软件”和“良好软件”之间进行选择。\nhttp://t.cn/Rk1abPX\n\n活动预告：\n1、Elastic 中国开发者大会最后一波早鸟票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/772\n订阅：https://tinyletter.com/elastic-daily","title":"​Elastic日报 第375期 (2018-08-26)","uid":"4460","views":"270","votes":"0"},"_type":"doc"}
{"_id":"774","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535420843","category_id":"18","comments":"0","has_attach":"0","id":"774","message":"1.在Elasticsearch Service上部署hot-warm-logging 集群。\nhttp://t.cn/RksKnp8\n2.Elasticsearch6.4尝新和骚动的Redis。\nhttp://t.cn/RksKey6\n3.LEAISTIC:管理Elasticsearch的微服务库。\nhttp://t.cn/Rks9Pw7\n​\n1、活动预告：Elastic 中国开发者大会最后一波早鸟票发售进行中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下沙龙正在报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/774\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第377期 (2018-08-28)","uid":"3788","views":"222","votes":"0"},"_type":"doc"}
{"_id":"783","_index":"forum-mysql","_score":1,"_source":{"addtime":"1535940126","category_id":"18","comments":"0","has_attach":"0","id":"783","message":"1.kibana Prometheus 监控插件\nhttp://t.cn/RFT1agw\n\n2.logstash 6.4 新特性简介\nhttp://t.cn/RFYDKng\n\n3.elasticsearch rest read only 插件\n[url]http://t.cn/RZpF03g[/url] \n\n​活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n2、Elastic Meetup 9月8日 北京线下交流活动免费报名中\nhttps://elasticsearch.cn/article/759\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/783\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第383期 (2018-09-03)","uid":"4063","views":"279","votes":"0"},"_type":"doc"}
{"_id":"797","_index":"forum-mysql","_score":1,"_source":{"addtime":"1536831384","category_id":"2","comments":"1","has_attach":"0","id":"797","message":"集群中有两个索引，我想监控每个索引的qps，indices.total.search.query_total这个参数是统计的 该索引 所有分片的查询总次数吗，需要除以分片数吗","title":"统计监控es 集群中某个索引qps， indices.total.search.query_total ","uid":"9045","views":"267","votes":"0"},"_type":"doc"}
{"_id":"802","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537159946","category_id":"18","comments":"0","has_attach":"0","id":"802","message":"1、了解 Elastic app search 中的多语言引擎\nhttp://t.cn/EvXxgIG\n2、拉波银行：使用 Elasticsearch 来增强在线银行业务体验\nhttp://t.cn/EvXJ6y9\n3、从应用层深入到内核的elasticsearch调优指南\nhttp://t.cn/RmOXAb3\n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n\n编辑: cyberdak\n归档：https://elasticsearch.cn/article/802\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第397期 (2018-09-17）","uid":"4063","views":"222","votes":"0"},"_type":"doc"}
{"_id":"807","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537343205","category_id":"18","comments":"0","has_attach":"0","id":"807","message":"1. Elasticsearch 检索聚合和LBS\nhttp://t.cn/RCnZYiX\n2. Elasticsearch检索实战\nhttp://t.cn/R91coqv\n3. 用 Go 开发 Elasticsearch Prometheus Exporter\nhttp://t.cn/RkG3XPO\n 活动预告\n1. Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑: 江水\n归档：https://elasticsearch.cn/article/807\n订阅：https://tinyletter.com/elastic-daily\n ","title":"Elastic日报 第399期 (2018-09-19）","uid":"3828","views":"240","votes":"0"},"_type":"doc"}
{"_id":"812","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537630169","category_id":"2","comments":"0","has_attach":"0","id":"812","message":"\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922231732.png)\n\n如果你关注过 elasticsearch 的日志，可能会看到如下类似的内容：\n\n```\n[2018-06-30T17:57:23,848][WARN ][o.e.m.j.JvmGcMonitorService] [qoo--eS] [gc][228384] overhead, spent [2.2s] collecting in the last [2.3s]\n\n[2018-06-30T17:57:29,020][INFO ][o.e.m.j.JvmGcMonitorService] [qoo--eS] [gc][old][228385][160772] duration [5s], collections [1]/[5.1s], total [5s]/[4.4d], memory [945.4mb]-\u0026gt;[958.5mb]/[1007.3mb], all_pools {[young] [87.8mb]-\u0026gt;[100.9mb]/[133.1mb]}{[survivor] [0b]-\u0026gt;[0b]/[16.6mb]}{[old] [857.6mb]-\u0026gt;[857.6mb]/[857.6mb]}\n```\n\n看到其中的`[gc]`关键词你也猜到了这是与 GC 相关的日志，那么你了解每一部分的含义吗？如果不了解，你可以继续往下看了。\n\n我们先从最简单的看起：\n\n1. 第一部分是`日志发生的时间`\n2. 第二部分是`日志级别`，这里分别是`WARN`和`INFO`\n3. 第三部分是`输出日志的类`，我们后面也会讲到这个类\n4. 第四部分是`当前 ES 节点名称`\n5. 第五部分是 `gc` 关键词，我们就从这个关键词聊起。\n\n`友情提示：`对 GC 已经了如指掌的同学，可以直接翻到最后看答案。\n\n# 1. 什么是 GC？\n\nGC，全称是 `Garbage Collection` （垃圾收集）或者 `Garbage Collector`(垃圾收集器)。\n\n在使用 C语言编程的时候，我们要手动的通过 `malloc` 和 `free`来申请和释放数据需要的内存，如果忘记释放内存，就会发生内存泄露的情况，即无用的数据占用了宝贵的内存资源。而Java 语言编程不需要显示的申请和释放内存，因为 JVM 可以自动管理内存，这其中最重要的一部分就是 `GC`，即 JVM 可以自主地去释放无用数据（垃圾）占用的内存。\n\n我们研究 GC 的主要原因是 GC 的过程会有 `Stop The World`(STW)的情况发生，即此时用户线程会停止工作，如果 STW 的时间过长，则应用的可用性、实时性等就下降的很厉害。\n\n`GC`主要解决如下3个问题：\n\n1. 如何找到垃圾？\n2. 如何回收垃圾？\n3. 何时回收垃圾？\n\n我们一个个来看下。\n\n## 1.1 如何找到垃圾？\n\n所谓垃圾，指的是不再被使用（引用）的对象。Java 的对象都是在堆(Heap)上创建的，我们这里默认也只讨论堆。那么现在问题就变为如何判定一个对象是否还有被引用，思路主要有如下两种：\n\n1. **引用计数法**，即在对象被引用时加1，去除引用时减1，如果引用值为0，即表明该对象可回收了。\n2. **可达性分析法**，即通过遍历已知的存活对象(**GC Roots**)的引用链来标记出所有存活对象\n\n方法1简单粗暴效率高，但准确度不行，尤其是面对互相引用的垃圾对象时无能为力。\n\n方法2是目前常用的方法，这里有一个关键是 `GC Roots`，它是判定的源头，感兴趣的同学可以自己去研究下，这里就不展开讲了。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180910231556.png)\n\n\n\n## 1.2 如何回收垃圾？\n\n垃圾找到了，该怎么回收呢？看起来似乎是个很傻的问题。直接收起来扔掉不就好了？！对应到程序的操作，就是直接将这些对象占用的空间标记为**空闲**不就好了吗？那我们就来看一下这个基础的回收算法：标记-清除(Mark-Sweep)算法。\n\n### 1.2.1 标记-清除 算法(Mark Sweep)\n\n该算法很简单，使用通过**可达性分析**分析方法标记出垃圾，然后直接回收掉垃圾区域。它的一个显著问题是一段时间后，内存会出现**大量碎片**，导致虽然碎片总和很大，但无法满足一个大对象的内存申请，从而导致 OOM，而过多的内存碎片（需要类似链表的数据结构维护），也会导致标记和清除的操作成本高，效率低下，如下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922172533.png)\n\n### 1.2.2 复制算法(Copying)\n\n为了解决上面算法的效率问题，有人提出了复制算法。它将可用**内存一分为二**，每次只用一块，当这一块内存不够用时，便触发 GC，将当前存活对象复制(Copy)到另一块上，以此往复。这种算法高效的原因在于分配内存时只需要将指针后移，不需要维护链表等。但它**最大的问题是对内存的浪费**，使用率只有 50%。\n\n但这种算法在一种情况下会很高效：Java 对象的存活时间极短。据 IBM 研究，Java 对象高达 98% 是**朝生夕死**的，这也意味着每次 GC 可以回收大部分的内存，需要复制的数据量也很小，这样它的执行效率就会很高。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922172806.png)\n\n### 1.2.3 标记-整理算法(Mark Compact)\n\n该算法解决了第1中算法的内存碎片问题，它会在回收阶段将所有内存做整理，如下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922173022.png)\n\n但它的问题也在于增加了整理阶段，也就增加了 GC 的时间。\n\n### 1.2.4  分代收集算法(Generation Collection)\n\n既然大部分 Java 对象是**朝生夕死**的，那么我们将内存按照 Java 生存时间分为 `新生代(Young)` 和 `老年代(Old)`，前者存放短命僧，后者存放长寿佛，当然长寿佛也是由短命僧升级上来的。然后针对两者可以采用不同的回收算法，比如对于`新生代`采用复制算法会比较高效，而对`老年代`可以采用标记-清除或者标记-整理算法。这种算法也是最常用的。JVM Heap 分代后的划分一般如下所示，新生代一般会分为 Eden、Survivor0、Survivor1区，便于使用复制算法。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922162421.png)\n\n将内存分代后的 GC 过程一般类似下图所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922175612.png)\n\n1. 对象一般都是先在 `Eden`区创建\n2. 当`Eden`区满，触发 Young GC，此时将 `Eden`中还存活的对象复制到 `S0`中，并清空 `Eden`区后继续为新的对象分配内存\n3. 当`Eden`区再次满后，触发又一次的 Young GC，此时会将 `Eden`和`S0`中存活的对象复制到 `S1`中，然后清空`Eden`和`S0`后继续为新的对象分配内存\n4. 每经过一次 Young GC，存活下来的对象都会将自己存活次数加1，当达到一定次数后，会随着一次 Young GC 晋升到 `Old`区\n5. `Old`区也会在合适的时机进行自己的 GC\n\n\n\n## 1.2.5 常见的垃圾收集器\n\n前面我们讲了众多的垃圾收集算法，那么其具体的实现就是垃圾收集器，也是我们实际使用中会具体用到的。现代的垃圾收集机制基本都是分代收集算法，而 `Young`与 `Old`区分别有不同的垃圾收集器，简单总结如下图：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922180954.png)\n\n\n\n从上图我们可以看到 `Young`与 `Old`区有不同的垃圾收集器，实际使用时会搭配使用，也就是上图中两两连线的收集器是可以搭配使用的。这些垃圾收集器按照运行原理大概可以分为如下几类：\n\n- **Serial GC**，**串行**，单线程的收集器，运行 GC 时需要停止所有的用户线程，且只有一个 GC 线程\n- **Parallel GC**，**并行**，多线程的收集器，是 Serial 的多线程版，运行时也需要停止所有用户线程，但同时运行多个 GC 线程，所以效率高一些\n- **Concurrent  GC**，**并发**，多线程收集器，GC 分多阶段执行，部分阶段允许用户线程与 GC 线程同时运行，这也就是并发的意思，大家要和并行做一个区分。\n- 其他\n\n我们下面简单看一下他们的运行机制。\n\n### 1.2.5.1 Serial GC\n\n该类 `Young区`的为 `Serial GC`，`Old区`的为`Serial Old GC`。执行大致如下所示：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922182714.png)\n\n### 1.2.5.2 Parallel GC\n\n该类`Young 区`的有 `ParNew`和 `Parallel Scavenge`，`Old 区`的有`Parallel Old`。其运行机制如下，相比 Serial GC ，其最大特点在于 GC 线程是并行的，效率高很多：\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922183500.png)\n\n### 1.2.5.3 Concurrent Mark-Sweep GC\n\n该类目前只是针对 `Old 区`，最常见就是`CMS GC`，它的执行分为多个阶段，只有部分阶段需要停止用户进程，这里不详细介绍了，感兴趣可以去找相关文章来看，大体执行如下：\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922184139.png)\n\n### 1.2.5.4 其他\n\n目前最新的 GC 有`G1GC`和`ZGC`，其运行机制与上述均不相同，虽然他们也是分代收集算法，但会把 Heap 分成多个 region 来做处理，这里不展开讲，感兴趣的可以参看最后参考资料的内容。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180918075324.png)\n\n## 1.2.6 Elasticsearch 的 GC 组合\n\nElasticsearch 默认的 GC 配置是`CMS GC` ，其 `Young 区`用 `ParNew`，`Old 区`用`CMS`，大家可以在 `config/jvm.options`中看到如下的配置：\n\n```\n## GC configuration\n-XX:+UseConcMarkSweepGC\n-XX:CMSInitiatingOccupancyFraction=75\n-XX:+UseCMSInitiatingOccupancyOnly\n```\n\n## 1.3 何时进行回收？\n\n现在我们已经知道如何找到和回收垃圾了，那么什么时候回收呢？简单总结如下：\n\n1. `Young 区`的GC 都是在 `Eden 区`满时触发\n2. Serial Old 和 Parallel Old  在 `Old 区`是在 Young GC 时预测Old 区是否可以为 young 区 promote 到 old 区 的 object 分配空间，如果不可用则触发 Old GC。这个也可以理解为是 `Old区`满时。\n3. CMS GC 是在 `Old 区`大小超过一定比例后触发，而不是 Old 区满。这个原因在于 CMS GC 是并发的算法，也就是说在 GC 线程收集垃圾的时候，用户线程也在运行，因此需要预留一些 Heap 空间给用户线程使用，防止由于无法分配空间而导致 Full GC 发生。\n\n\n\n## 2. GC Log 如何阅读？\n\n前面讲了这么多，终于可以回到开篇的问题了，我们直接来看答案\n\n```\n[2018-06-30T17:57:23,848][WARN ][o.e.m.j.JvmGcMonitorService] [qoo--eS] [gc][228384] overhead, spent [2.2s] collecting in the last [2.3s]\n```\n\n\\[gc\\]\\[这是第**228384**次GC 检查\\] 在最近 **2.3 s** 内花了 **2.2s** 用来做垃圾收集，这占比似乎有些过了，请抓紧来关注下。\n\n```\n[2018-06-30T17:57:29,020][INFO ][o.e.m.j.JvmGcMonitorService] [qoo--eS] [gc][old][228385][160772] duration [5s], collections [1]/[5.1s], total [5s]/[4.4d], memory [945.4mb]-\u0026gt;[958.5mb]/[1007.3mb], all_pools {[young] [87.8mb]-\u0026gt;[100.9mb]/[133.1mb]}{[survivor] [0b]-\u0026gt;[0b]/[16.6mb]}{[old] [857.6mb]-\u0026gt;[857.6mb]/[857.6mb]}\n```\n\n我们直接来看具体的含义好了，相信有了前面的 GC 基础知识，大家在看这里解释的时候就非常清楚了。\n\n- \\[gc\\]\\[本次是 **old** GC]\\[这是第**228385**次 GC 检查][从 JVM 启动至今发生的第 **160772**次 GC] \n\n- **duration** \\[本次检查到的 GC 总耗时 **5** 秒，可能是多次的加和], \n\n- **collections** [从上次检查至今总共发生**1**次 GC]/[从上次检查至今已过去  **5.1** 秒], \n\n- **total** [本次检查到的 GC 总耗时为 **5** 秒]/[从 JVM 启动至今发生的 GC 总耗时为 **4.4** 天]，\n\n- **memory** [ GC 前 Heap memory 空间]-\u0026gt;[GC 后 Heap memory 空间]/[Heap memory 总空间], \n\n- **all_pools**(分代部分的详情) {[**young** 区]\\[GC 前 Memory ]-\u0026gt;[GC后 Memory]/[young区 Memory 总大小] } {[**survivor** 区]\\[GC 前 Memory ]-\u0026gt;[GC后 Memory]/[survivor区 Memory 总大小] }{[**old** 区]\\[GC 前 Memory ]-\u0026gt;[GC后 Memory]/[old区 Memory 总大小] }\n\n\n\n# 3. 看看源码\n\n从日志中我们可以看到输出这些日志的类名叫做`JvmGcMonitorService`，我们去源码中搜索很快会找到它`/Users/rockybean/code/elasticsearch/core/src/main/java/org/elasticsearch/monitor/jvm/JvmGcMonitorService.java`，这里就不详细展开讲解源码了，它执行的内容大概如下图所示:\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922161322.png)\n\n关于打印日志的格式在源码也有，如下所示：\n\n```java\nprivate static final String SLOW_GC_LOG_MESSAGE =\n\u0026quot;[gc][{}][{}][{}] duration [{}], collections [{}]/[{}], total [{}]/[{}], memory [{}]-\u0026gt;[{}]/[{}], all_pools {}\u0026quot;;\nprivate static final String OVERHEAD_LOG_MESSAGE = \u0026quot;[gc][{}] overhead, spent [{}] collecting in the last [{}]\u0026quot;;\n```\n\n\n\n另外细心的同学会发现输出的日志中 gc 只分了 young 和 old ，原因在于 ES 对 GC Name 做了封装，封装的类为：`org.elasticsearch.monitor.jvm.GCNames`，相关代码如下：\n\n```java\n    public static String getByMemoryPoolName(String poolName, String defaultName) {\n        if (\u0026quot;Eden Space\u0026quot;.equals(poolName) || \u0026quot;PS Eden Space\u0026quot;.equals(poolName) || \u0026quot;Par Eden Space\u0026quot;.equals(poolName) || \u0026quot;G1 Eden Space\u0026quot;.equals(poolName)) {\n            return YOUNG;\n        }\n        if (\u0026quot;Survivor Space\u0026quot;.equals(poolName) || \u0026quot;PS Survivor Space\u0026quot;.equals(poolName) || \u0026quot;Par Survivor Space\u0026quot;.equals(poolName) || \u0026quot;G1 Survivor Space\u0026quot;.equals(poolName)) {\n            return SURVIVOR;\n        }\n        if (\u0026quot;Tenured Gen\u0026quot;.equals(poolName) || \u0026quot;PS Old Gen\u0026quot;.equals(poolName) || \u0026quot;CMS Old Gen\u0026quot;.equals(poolName) || \u0026quot;G1 Old Gen\u0026quot;.equals(poolName)) {\n            return OLD;\n        }\n        return defaultName;\n    }\n\n    public static String getByGcName(String gcName, String defaultName) {\n        if (\u0026quot;Copy\u0026quot;.equals(gcName) || \u0026quot;PS Scavenge\u0026quot;.equals(gcName) || \u0026quot;ParNew\u0026quot;.equals(gcName) || \u0026quot;G1 Young Generation\u0026quot;.equals(gcName)) {\n            return YOUNG;\n        }\n        if (\u0026quot;MarkSweepCompact\u0026quot;.equals(gcName) || \u0026quot;PS MarkSweep\u0026quot;.equals(gcName) || \u0026quot;ConcurrentMarkSweep\u0026quot;.equals(gcName) || \u0026quot;G1 Old Generation\u0026quot;.equals(gcName)) {\n            return OLD;\n        }\n        return defaultName;\n    }\n```\n\n在上面的代码中，你会看到很多我们在上一节中提到的 GC 算法的名称。\n\n至此，源码相关部分也讲解完毕，感兴趣的大家可以自行去查阅。\n\n# 4. 总结\n\n讲解 GC 的文章已经很多，本文又唠唠叨叨地讲一遍基础知识，是希望对于第一次了解 GC 的同学有所帮助。因为只有了解了这些基础知识，你才不至于被这些 GC 的输出吓懵。希望本文对你理解 ES 的 GC 日志 有所帮助。\n\n# 5. 参考资料\n\n1. Java Hotspot G1 GC的一些关键技术（[https://mp.weixin.qq.com/s/4ufdCXCwO56WAJnzng_-ow](https://mp.weixin.qq.com/s/4ufdCXCwO56WAJnzng_-ow)）\n2. Understanding Java Garbage Collection（[https://www.cubrid.org/blog/understanding-java-garbage-collection](https://www.cubrid.org/blog/understanding-java-garbage-collection)）\n3. 《深入理解Java虚拟机：JVM高级特性与最佳实践》\n\n# 6. 相关推荐\n\n如果你想深入的了解 JAVA GC 的知识，可以关注 `ElasticTalk` 公众号，回复 `GC`关键词后即可获取作者推荐的电子书等资料。\n\n![](http://p8z8qq24s.bkt.clouddn.com/img20180922191503.png)\n\n![elasticTalk,qrcode](http://p8z8qq24s.bkt.clouddn.com/img20180721120024.png)\n\n","title":"你看懂 Elasticsearch Log 中的 GC 日志了吗？ ","uid":"86","views":"766","votes":"5"},"_type":"doc"}
{"_id":"816","_index":"forum-mysql","_score":1,"_source":{"addtime":"1537841338","category_id":"18","comments":"0","has_attach":"0","id":"816","message":"1.(自备翻墙)使用React和Elastic Search构建自动补全组件。\nhttp://t.cn/Evkj2mY\n2.数据中心位置对Elasticsearch有影响吗？\nhttp://t.cn/EPViN14\n3.你看懂 Elasticsearch Log 中的 GC 日志了吗？\nhttp://t.cn/EPViabV\n\n活动预告\n1、Elastic 中国开发者大会门票发售中\nhttps://conf.elasticsearch.cn/2018/shenzhen.html\n \n编辑：叮咚光军\n归档：https://elasticsearch.cn/article/816\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第405期 (2018-09-25)","uid":"3788","views":"240","votes":"0"},"_type":"doc"}
{"_id":"993","_index":"forum-mysql","_score":1,"_source":{"addtime":"1539860148","category_id":"18","comments":"0","has_attach":"0","id":"993","message":"1.Elasticsearch聚合优化\nhttp://t.cn/R8WIKta\n2.searchguard-6的安装和配置\nhttp://t.cn/EzV6KoO\n3.Lucene就是这么简单\nhttp://t.cn/EvcvMy1\n\n编辑：金桥\n归档：https://elasticsearch.cn/article/993\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第421期 (2018-10-18)","uid":"668","views":"159","votes":"0"},"_type":"doc"}
{"_id":"6346","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548389336","category_id":"44","comments":"0","has_attach":"1","id":"6346","message":"欢迎来到Elastic社区电台的第十期节目，本期我们节目的嘉宾是来自于360企业安全集团的资深研发工程师张超和段军义，张超也是 Elasticsearch 相关新书《Elasticsearch 源码解析与优化实战》的作者，让我们一起走进360企业安全的大数据团队，了解他们是如何使用 Elasticsearch 来解决公司内部和外部客户的各类需求，以及在实践过程中的经验分享。\n\n### 收听地址\n\n- [喜马拉雅: https://www.ximalaya.com/keji/14965410/155209795](https://www.ximalaya.com/keji/14965410/155209795)\n- [Apple iTunes: https://itunes.apple.com/cn/podcast/elastic-社区电台](https://itunes.apple.com/cn/podcast/elastic-社区电台/)\n\n[attach]3461[/attach]\n\n### 时间线\n\n- 00:20 - 嘉宾介绍\n- 02:10 - 张超的新书《Elasticsearch 源码解析与优化实战》\n- 04:21 - 360 与 Elasticsearch 的故事\n- 05:25 - Elasticsearch 在 360 的应用场景介绍\n- 07:30 - 产品选型与比较\n- 08:20 - 有关版本升级的经验分享\n- 12:00 - 典型场景的数据规模及配置情况\n- 15:00 - 360 基于 Elasticsearch 的源码优化\n- 21:00 - Frozen Index 与按需加载的需求\n- 22:00 - Rollup 数据上卷的功能介绍\n- 26:00 - 关于如何学习 Elasticsearch 的经验分享\n- 29:00 - Elasticsearch 踩坑故事分享\n- 37:00 - 关于入库与副本同步的改进问题讨论\n- 30:30 - 关于异地多活与 CCR 的介绍\n- 41:00 - 关于 Elasticsearch 相关职位的要求\n- 42:00 - 360 团队对于 Elastic 未来的期望\n- 43:50 - 有关目前 Elasticsearch 的痛点\n- 46:00 - 有关 Rollover 的功能介绍\n- 48:00 - 尾声\n\n\n\n### 嘉宾\n\n- 张超，大数据平台内核资深研发工程师，《Elasticsearch源码解析与优化实战》作者，就职于360企业安全集团，在基础大数据平台部门负责 Elasticsearch 内核研发工作，喜欢研究底层原理与系统优化，尤其喜欢解决深层次的问题。\n\n- 段军义，大数据平台资深开发工程师，就职于360企业安全集团，主要负责Elasticsearch研发，喜欢研究Java、Linux、搜索相关技术。\n\n\n\n### 主持人\n\nElastic 技术布道师，曾勇（Medcl）。\n\n\n### 关于360企业安全\n\n360企业安全创建于2012年，是360公司继个人安全市场后致力服务于政府企业机构网络安全与信息安全管理的安全产品业务线。作为中国互联网安全的领导者，360凭借在PC终端安全、移动终端安全、桌面安全管理、大数据分析、云安全等方面的深厚积累，成功推出各行业用户所急需的终端安全与管理一体化、未知高级威胁检测、移动终端安全管理、大数据安全分析等多项创新型企业安全产品。\n\n\n### 关于Elastic社区电台\n\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\n\n\n### 相关链接\n\n- [360企业安全团队招聘链接](https://m.zhipin.com/weijd/v2/job/767a79572d9307d31X183dq_FFA~)\n\n- [Rollups](https://www.elastic.co/guide/en/elasticsearch/reference/6.5/rollup-apis.html)\n\n- [Rollover](https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indices-rollover-index.html)\n\n-  [CCR](https://www.elastic.co/guide/en/elastic-stack-overview/master/xpack-ccr.html)","title":"访谈：Elasticsearch在360企业安全集团的应用实践","uid":"1","views":"505","votes":"4"},"_type":"doc"}
{"_id":"6339","_index":"forum-mysql","_score":1,"_source":{"addtime":"1548036993","category_id":"18","comments":"0","has_attach":"0","id":"6339","message":"1.针对Logstash吞吐量一次优化\nhttp://t.cn/E5X40JT\n\n2.Opbeat已死，请用Elastic APM\nhttp://t.cn/EyhRQRJ\n\n3.亿级PV的ELK集群实践之路\nhttp://t.cn/RnvPElX\n\n编辑：cyberdak\n归档：https://elasticsearch.cn/article/6339\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第516期 (2019-01-21) ","uid":"4063","views":"136","votes":"0"},"_type":"doc"}
{"_id":"6337","_index":"forum-mysql","_score":1,"_source":{"addtime":"1547944012","category_id":"18","comments":"0","has_attach":"0","id":"6337","message":"1.Java应用日志导入ELK。\nhttp://t.cn/E5GiA1T\n2.使用Tokens分发Cassandra数据。\nhttp://t.cn/E5GIOd5\n3.(自备梯子)为什么如此难以让计算机像人一样说话？\nhttp://t.cn/EqFOf04\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6337\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第515期 (2019-01-20)","uid":"4460","views":"143","votes":"0"},"_type":"doc"}
{"_id":"6319","_index":"forum-mysql","_score":1,"_source":{"addtime":"1546735872","category_id":"18","comments":"0","has_attach":"0","id":"6319","message":"1.Elasticsearch查询与Spring Data。\nhttp://t.cn/EGM5RCs\n2.Spring Data Elasticsearch介绍。\nhttp://t.cn/EAE698A\n3.(自备梯子)区块链是互联网失败的提示。\nhttp://t.cn/EbmQ42J\n\n编辑：至尊宝\n归档：https://elasticsearch.cn/article/6319\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第501期 (2019-01-06)","uid":"4460","views":"209","votes":"0"},"_type":"doc"}
{"_id":"6308","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545889797","category_id":"18","comments":"0","has_attach":"0","id":"6308","message":"1.ELK基础篇；\nhttp://t.cn/EApHfmI\n2.es存储详解。\nhttp://t.cn/Eb8LFXD\n3.es集群部署的一些配置项。\nhttp://t.cn/Eb8yNc1\n\n编辑：wt\n归档：https://elasticsearch.cn/article/6308\n订阅：https://tinyletter.com/elastic-daily","title":"Elastic日报 第494期 (2018-12-31)","uid":"3851","views":"132","votes":"0"},"_type":"doc"}
{"_id":"6222","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545649777","category_id":"44","comments":"0","has_attach":"1","id":"6222","message":"欢迎来到 Elastic 社区电台的第九期节目，我们本期节目的嘉宾是来自于 vivo 互联网负责搜索业务研发的杨振涛，vivo 从 Elasticsearch 2.1.1 版本开始，如今使用 100 多个 Elasticsearch 集群来支撑全球 2 亿多台手机每天的各种搜索请求，如 vivo 的应用商店、游戏、音乐、主题、壁纸、铃声等各种手机服务背后的搜索服务，也包括产品配件、售后、FAQ 等企业门户官网的搜索请求。今天让我们一起走进 vivo，看看 vivo 具体是如何使用 Elasticsearch 来解决这些搜索问题的。\n\n可以点击下面的任意链接来收听（时长约 50 分钟）：\n\n- Apple iTunes: [https://itunes.apple.com/cn/podcast/elastic-社区电台/](https://itunes.apple.com/cn/podcast/elastic-%E7%A4%BE%E5%8C%BA%E7%94%B5%E5%8F%B0/)\n- 喜马拉雅：[https://www.ximalaya.com/keji/14965410/146649768](https://www.ximalaya.com/keji/14965410/146649768)\n- 蜻蜓 FM：[https://www.qingting.fm/channels/244978/programs/10396421](https://www.qingting.fm/channels/244978/programs/10396421)\n\n## 嘉宾\n\n[attach]3368[/attach]\n\n杨振涛，vivo 互联网搜索引擎架构师，专注于数据的存储、检索与可视化，以及 DevOps 与软件过程改进。Elastic 中文社区深圳地区负责人，发起并组织 Elasticsearch、Redis、Jenkins 等主题的技术沙龙，并参与多个开源项目的文档翻译和中文化工作。 技术翻译爱好者，InfoQ 中文社区编辑，TED Translator。\n\n## 主持人\nElastic 技术布道师，曾勇（Medcl）。\n\n## 关于 vivo\nvivo为一个专注于智能手机领域的手机品牌，vivo和追求乐趣、充满活力、年轻时尚的群体一起打造拥有卓越外观、专业级音质、极致影像、愉悦体验的智能产品，并将敢于追求极致、持续创造惊喜作为vivo的坚定追求。\n\n## 关于 Elastic 社区电台\nElastic 开源社区举办的一款播客类节目， 邀请来自开源社区的用户，一起聊聊 Elastic 开源产品的使用案例、经验分享、架构变迁等等。\n\n## 相关链接\n\n- [社区活动计划](https://meetup.elasticsearch.cn/event/plan/2019.html)\n\n- [vivo 招聘页面](https://hr.vivo.com)\n","title":"访谈：2亿+ vivo 手机背后搜索服务平台的故事","uid":"1","views":"319","votes":"6"},"_type":"doc"}
{"_id":"6221","_index":"forum-mysql","_score":1,"_source":{"addtime":"1545646726","category_id":"14","comments":"0","has_attach":"1","id":"6221","message":"​首先还是祝大家圣诞快乐，既然是节日，我们就讨论一个比较轻松的话题。如何使用6.5引入[数据管道处理器](https://www.elastic.co/guide/en/elasticsearch/reference/current/pipeline-processor.html)来更好的治理预定义好的数据管道。\n\n# 背景\n\n2018这一年来拜访了很多用户，其中有相当一部分在数据摄取时遇到包括性能在内的各种各样的问题，那么大多数在我们做了ingest节点的调整后得到了很好的解决。Ingest节点不是万能的，但是使用起来简单，而且抛开后面数据节点来看性能提升趋于线性。所以我一直本着能用ingest节点解决的问题，绝不麻烦其他组件的大体原则 ：-）\n\n下面快速回顾一下ingest节点的角色定位。\n\n[attach]3367[/attach]\n\n# 使用场景\n\n通过上面的图纸我们很容易看到ingest节点可以在数据被索引之前，通过预定义好的处理管道对其进行治理。但这里一直存在一个局限性，就是只能通过一条管道。那么一直以来应对这个不便的方案就是把所有的处理器和细节全部配置到当前管道下。那么带来的问题也是比较明显的：\n\n* 复制、粘贴很多相同的管道配置在不同数据管道里\n* 非常难管理、维护冗长的管道\n* 如果要更新一个处理细节的话要找到定位所有使用过这个逻辑的管道\n\n其实这块对于开发的同学们很好理解，当你经常复制、粘贴代码的时候，就是时候好好思考一下了。我想说到这里大家其实已经明白了，这个管道处理器实际就是提供了一个允许你在一个管道内调用其他管道的方案。\n\n他的使用非常简单，就像函数调用一样只有一个必要参数`name`：\n\n```\n{\n  \u0026quot;pipeline\u0026quot;: {\n    \u0026quot;name\u0026quot;: \u0026quot;\u0026lt;其他管道的名称 - 英文字符\u0026gt;\u0026quot;\n  }\n}\n```\n\n当然，也像其他处理器一样提供了`on_failure`参数来处理错误，并且还有一个非常实用的`if`参数来判断是否执行这个管道，这里就不做详细介绍了。\n\n# 举例\n\n这里我们用一个非常简单的案例来看看如何使用管道处理器。\n\n假设在Elastic公司，我们使用员工卡来作为进入公司和各个部门以及房间的钥匙，并且这些刷卡事件也会被记录下来。那么由于上班卡机和门禁供应商不同，数据格式也不一样。但是最后都有一个通用的逻辑，就是除了事件发生的时间，我们还会记录下数据录入到Elasticsearch的时间。\n\n首先我们看一下原始数据：\n\n```\n# 公司正门卡机数据\n2018-12-25T08:59:59.312Z,front_door,binw,entered\n\n# 架构部门禁数据\n@timestamp=2018-12-25T09:15:34.414Z device_id=recreation_hall user=binw event=entered\n```\n\n那如果在6.5之前，我们定义2条管道是这个样子\n\n1. 正门卡机管道\n* grok 解析数据\n* 打上数据录入的时间戳\n* 明确录入时间戳的处理器\n\n2. 门禁数据管道\n* KV 解析数据\n* 打上数据录入的时间戳\n* 明确录入时间戳的处理器\n\n很明显又66.67%的配置都是重复的，所以这里我们可以更优雅的解决这个问题\n\n1. 统一的数据录入时间戳处理器\n* 打上数据录入的时间戳\n* 明确录入时间戳的处理器\n\n```\nPUT _ingest/pipeline/pl_cmn\n{\n  \u0026quot;description\u0026quot;: \u0026quot;刷卡数据通用管道\u0026quot;,\n  \u0026quot;processors\u0026quot;: [\n    {\n      \u0026quot;set\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;ingest_timestamp\u0026quot;,\n        \u0026quot;value\u0026quot;: \u0026quot;{{_ingest.timestamp}}\u0026quot;\n      }\n    },\n    {\n      \u0026quot;set\u0026quot;: {\n        \u0026quot;field\u0026quot;: \u0026quot;cmn_processed\u0026quot;,\n        \u0026quot;value\u0026quot;: \u0026quot;yes\u0026quot;\n      }\n    }\n  ]\n}\n```\n\n2. 正门卡机管道\n* grok 解析数据\n* \u0026lt;调用管道 pl_cmn\u0026gt;\n\n```\nPOST _ingest/pipeline/_simulate\n{\n  \u0026quot;pipeline\u0026quot;: {\n    \u0026quot;description\u0026quot;: \u0026quot;正门打卡机数据处理管道\u0026quot;,\n    \u0026quot;processors\u0026quot;: [\n      {\n        \u0026quot;grok\u0026quot;: {\n          \u0026quot;field\u0026quot;: \u0026quot;message\u0026quot;,\n          \u0026quot;patterns\u0026quot;: [\n            \u0026quot;%{TIMESTAMP_ISO8601:@timestamp},%{WORD:device_id},%{USER:user},%{WORD:event}\u0026quot;\n          ]\n        }\n      },\n      {\n        \u0026quot;pipeline\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;pl_cmn\u0026quot;\n        }\n      }\n    ]\n  },\n  \u0026quot;docs\u0026quot;: [\n    {\n      \u0026quot;_source\u0026quot;: {\n        \u0026quot;message\u0026quot;: \u0026quot;2018-12-25T08:59:59.312Z,front_door,binw,entered\u0026quot;\n      }\n    }\n  ]\n}\n```\n\n3. 门禁数据管道\n* KV 解析数据\n* \u0026lt;调用管道 pl_cmn\u0026gt;\n\n```\nPOST _ingest/pipeline/_simulate\n{\n  \u0026quot;pipeline\u0026quot;: {\n    \u0026quot;description\u0026quot;: \u0026quot;架构部门禁数据处理管道\u0026quot;,\n    \u0026quot;processors\u0026quot;: [\n      {\n        \u0026quot;kv\u0026quot;: {\n          \u0026quot;field\u0026quot;: \u0026quot;message\u0026quot;,\n          \u0026quot;field_split\u0026quot;: \u0026quot; \u0026quot;,\n          \u0026quot;value_split\u0026quot;: \u0026quot;=\u0026quot;\n        }\n      },\n      {\n        \u0026quot;pipeline\u0026quot;: {\n          \u0026quot;name\u0026quot;: \u0026quot;pl_cmn\u0026quot;\n        }\n      }\n    ]\n  },\n  \u0026quot;docs\u0026quot;: [\n    {\n      \u0026quot;_source\u0026quot;: {\n        \u0026quot;message\u0026quot;: \u0026quot;@timestamp=2018-12-25T09:15:34.414Z device_id=recreation_hall user=binw event=entered\u0026quot;\n      }\n    }\n  ]\n}\n```\n\n好啦，这个例子非常简单。但当面对复杂业务场景的时候，会让你整个数据管道的管理比以前整齐很多。再结合合理的架构和数据治理，ingest节点也可以让你的整个数据处理能力有所提升。\n\n# 写在最后\n\n在文章的例子里，我们往索引里灌注的是一个个的事件数据。那要如何对数据中的实体进行有效的分析呢？那不得不说到面向实体的数据模型设计。Elasticsearch本身也提供了工具能让我们快速实现，让我们明年有机会的时候再与大家分享吧。最后还是祝愿大家度过一个愉快的圣诞节和元旦！","title":"Day 25 - Elasticsearch Ingest节点数据管道处理器","uid":"8169","views":"305","votes":"3"},"_type":"doc"}